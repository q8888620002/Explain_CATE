{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a564a210-0143-46d2-b58a-9d635659dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import umap\n",
    "import umap.plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../CATENets/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import catenets.models.torch.pseudo_outcome_nets as pseudo_outcome_nets\n",
    "\n",
    "\n",
    "def normalize_data(x_train):\n",
    "    \n",
    "    x_normalized_train = (x_train - np.min(x_train, axis=0)) / (np.max(x_train, axis=0) - np.min(x_train, axis=0))\n",
    "\n",
    "    return x_normalized_train\n",
    "\n",
    "\n",
    "def subgroup_ate(\n",
    "    method: str,\n",
    "    features: List[int],\n",
    "    y_true_train: np.ndarray,\n",
    "    y_true_test: np.ndarray,\n",
    "    estimated_ate_test: np.ndarray,\n",
    "    iss_test: np.ndarray\n",
    ") -> None:\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(  \n",
    "        max_depth=5\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(x_train[:, features], y_true_train)\n",
    "\n",
    "    y_pred = xgb_model.predict(x_test[:, features])\n",
    "    \n",
    "    ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "    auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "    \n",
    "    print(\"%s - auroc %s\"%(method, auroc))\n",
    "    print(\"%s - ATE %s\"%(method, ate))\n",
    "    \n",
    "    # if iss_test.any():  \n",
    "    print(\"%s - iss %s; %s \"%(method , np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1))\n",
    "    print(\"===================================\")\n",
    "\n",
    "def feature_idx(\n",
    "    method: str,\n",
    "    cohort: str\n",
    ")-> List[int]:\n",
    "    \n",
    "    if method == \"shap\":\n",
    "        file_path = f\"../results/{cohort}/naive_shap_top_5_features_xlearner.csv\"\n",
    "    elif method == \"ig\":\n",
    "        file_path = f\"../results/{cohort}/integrated_gradients_top_5_features_xlearner.csv\"\n",
    "    elif method == \"shap - 0 \":\n",
    "        file_path = f\"../results/{cohort}/shapley_value_sampling_top_5_features_xlearner.csv\"\n",
    "        \n",
    "    df = pd.read_csv(file_path,keep_default_na=False)\n",
    "    df_sorted = df.sort_values(\n",
    "        by='count (%)', \n",
    "        ascending=False\n",
    "    )\n",
    "    print(df_sorted[\"feature\"].head(5).tolist() )\n",
    "    return [ x.columns.get_loc(col) for col in df_sorted[\"feature\"].head(5) ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b303b39-fc42-4284-a5ca-355dcaa24bca",
   "metadata": {},
   "source": [
    "## Responder cohort analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c8c731f6-d7c0-47d9-84a8-59370707eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40033/2438182252.py:4: DtypeWarning: Columns (9,16,45,57,58,59,60,61,62,63,64,71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_year = pd.read_csv(\"../data/all_year.csv\", index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6434566378593445, train_loss: 0.6783382296562195\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5833740234375, train_loss: 0.35875338315963745\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5279456377029419, train_loss: 0.2741718888282776\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.49107691645622253, train_loss: 0.1359776109457016\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4555080533027649, train_loss: 0.09119388461112976\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.4188792407512665, train_loss: 0.06903786957263947\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.39292556047439575, train_loss: 0.054843444377183914\n",
      "[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.3756180703639984, train_loss: 0.04403012990951538\n",
      "[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.35730335116386414, train_loss: 0.03987251967191696\n",
      "[po_estimator_0_impute_pos] Epoch: 450, current validation loss: 0.3448267877101898, train_loss: 0.05806581303477287\n",
      "[po_estimator_0_impute_pos] Epoch: 500, current validation loss: 0.33096975088119507, train_loss: 0.027261197566986084\n",
      "[po_estimator_0_impute_pos] Epoch: 550, current validation loss: 0.31829699873924255, train_loss: 0.025651197880506516\n",
      "[po_estimator_0_impute_pos] Epoch: 600, current validation loss: 0.30898186564445496, train_loss: 0.021802186965942383\n",
      "[po_estimator_0_impute_pos] Epoch: 650, current validation loss: 0.29861971735954285, train_loss: 0.021610239520668983\n",
      "[po_estimator_0_impute_pos] Epoch: 700, current validation loss: 0.2891969382762909, train_loss: 0.01878548413515091\n",
      "[po_estimator_0_impute_pos] Epoch: 750, current validation loss: 0.28058692812919617, train_loss: 0.017699746415019035\n",
      "[po_estimator_0_impute_pos] Epoch: 800, current validation loss: 0.2744825780391693, train_loss: 0.025801969692111015\n",
      "[po_estimator_0_impute_pos] Epoch: 850, current validation loss: 0.26895904541015625, train_loss: 0.013540920801460743\n",
      "[po_estimator_0_impute_pos] Epoch: 900, current validation loss: 0.26419588923454285, train_loss: 0.022056888788938522\n",
      "[po_estimator_0_impute_pos] Epoch: 950, current validation loss: 0.25798261165618896, train_loss: 0.011879093945026398\n",
      "[po_estimator_0_impute_pos] Epoch: 1000, current validation loss: 0.25195595622062683, train_loss: 0.01064609456807375\n",
      "[po_estimator_0_impute_pos] Epoch: 1050, current validation loss: 0.24671082198619843, train_loss: 0.017709609121084213\n",
      "[po_estimator_0_impute_pos] Epoch: 1100, current validation loss: 0.24227598309516907, train_loss: 0.01665685325860977\n",
      "[po_estimator_0_impute_pos] Epoch: 1150, current validation loss: 0.2369259148836136, train_loss: 0.00915349368005991\n",
      "[po_estimator_0_impute_pos] Epoch: 1200, current validation loss: 0.23228393495082855, train_loss: 0.0083010233938694\n",
      "[po_estimator_0_impute_pos] Epoch: 1250, current validation loss: 0.22709493339061737, train_loss: 0.007772260345518589\n",
      "[po_estimator_0_impute_pos] Epoch: 1300, current validation loss: 0.22323527932167053, train_loss: 0.0069844103418290615\n",
      "[po_estimator_0_impute_pos] Epoch: 1350, current validation loss: 0.21881714463233948, train_loss: 0.006524865981191397\n",
      "[po_estimator_0_impute_pos] Epoch: 1400, current validation loss: 0.21561630070209503, train_loss: 0.01142410933971405\n",
      "[po_estimator_0_impute_pos] Epoch: 1450, current validation loss: 0.21088957786560059, train_loss: 0.006044263020157814\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7259592413902283, train_loss: 0.7486211061477661\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.639112651348114, train_loss: 0.5687299966812134\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5791444778442383, train_loss: 0.44604164361953735\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5393972992897034, train_loss: 0.34666311740875244\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5136058926582336, train_loss: 0.2747481167316437\n",
      "[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5043538212776184, train_loss: 0.22532734274864197\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6046914458274841, train_loss: 0.6880481839179993\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5755266547203064, train_loss: 0.4593443274497986\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5582583546638489, train_loss: 0.35163798928260803\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5520173907279968, train_loss: 0.24175003170967102\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5525545477867126, train_loss: 0.23019777238368988\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7873637080192566, train_loss: 0.8283712863922119\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6716596484184265, train_loss: 0.6477293968200684\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5729485154151917, train_loss: 0.5084207653999329\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.494081050157547, train_loss: 0.4007377028465271\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.42904236912727356, train_loss: 0.3164006173610687\n",
      "[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.3813157081604004, train_loss: 0.2465653121471405\n",
      "[po_estimator_1_impute_pos] Epoch: 300, current validation loss: 0.34739062190055847, train_loss: 0.20581687986850739\n",
      "[po_estimator_1_impute_pos] Epoch: 350, current validation loss: 0.32476451992988586, train_loss: 0.16675032675266266\n",
      "[po_estimator_1_impute_pos] Epoch: 400, current validation loss: 0.3080519139766693, train_loss: 0.14003002643585205\n",
      "[po_estimator_1_impute_pos] Epoch: 450, current validation loss: 0.2944038212299347, train_loss: 0.11842317879199982\n",
      "[po_estimator_1_impute_pos] Epoch: 500, current validation loss: 0.2844216227531433, train_loss: 0.10316074639558792\n",
      "[po_estimator_1_impute_pos] Epoch: 550, current validation loss: 0.2784999907016754, train_loss: 0.09238485991954803\n",
      "[po_estimator_1_impute_pos] Epoch: 600, current validation loss: 0.2729705572128296, train_loss: 0.07905007898807526\n",
      "[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4504067003726959, train_loss: 0.6130020022392273\n",
      "[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2622547447681427, train_loss: 0.004152362700551748\n",
      "[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2556847631931305, train_loss: 0.005987516604363918\n",
      "[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.25605112314224243, train_loss: 0.0022585547994822264\n",
      "[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2570628523826599, train_loss: 0.0010745803592726588\n",
      "[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.452951580286026, train_loss: 0.4719866216182709\n",
      "[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.15992999076843262, train_loss: 0.07511425018310547\n",
      "[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.15184658765792847, train_loss: 0.049305498600006104\n",
      "[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1511303335428238, train_loss: 0.05529756844043732\n",
      "[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1510397344827652, train_loss: 0.04730589687824249\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8304519653320312, train_loss: 0.8504958748817444\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.7115874886512756, train_loss: 0.4185239374637604\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6076083779335022, train_loss: 0.242380753159523\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5266143083572388, train_loss: 0.20923040807247162\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4775068759918213, train_loss: 0.11356569826602936\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.4372846782207489, train_loss: 0.07830004394054413\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.4079875648021698, train_loss: 0.06063408404588699\n",
      "[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.3808847665786743, train_loss: 0.050733596086502075\n",
      "[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.364067941904068, train_loss: 0.039919205009937286\n",
      "[po_estimator_0_impute_pos] Epoch: 450, current validation loss: 0.35045942664146423, train_loss: 0.06619497388601303\n",
      "[po_estimator_0_impute_pos] Epoch: 500, current validation loss: 0.33773157000541687, train_loss: 0.05197431147098541\n",
      "[po_estimator_0_impute_pos] Epoch: 550, current validation loss: 0.3276820182800293, train_loss: 0.051081348210573196\n",
      "[po_estimator_0_impute_pos] Epoch: 600, current validation loss: 0.3205869793891907, train_loss: 0.022882111370563507\n",
      "[po_estimator_0_impute_pos] Epoch: 650, current validation loss: 0.31340646743774414, train_loss: 0.02271127700805664\n",
      "[po_estimator_0_impute_pos] Epoch: 700, current validation loss: 0.307075560092926, train_loss: 0.02060658670961857\n",
      "[po_estimator_0_impute_pos] Epoch: 750, current validation loss: 0.3005017340183258, train_loss: 0.017781885340809822\n",
      "[po_estimator_0_impute_pos] Epoch: 800, current validation loss: 0.2955262362957001, train_loss: 0.016500867903232574\n",
      "[po_estimator_0_impute_pos] Epoch: 850, current validation loss: 0.2891523540019989, train_loss: 0.014992144890129566\n",
      "[po_estimator_0_impute_pos] Epoch: 900, current validation loss: 0.28294169902801514, train_loss: 0.013792027719318867\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7369253039360046, train_loss: 0.732524037361145\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6279731392860413, train_loss: 0.5449521541595459\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5712260603904724, train_loss: 0.422280490398407\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5383039712905884, train_loss: 0.3366754949092865\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5217417478561401, train_loss: 0.2707127630710602\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7400726675987244, train_loss: 0.8757904767990112\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6319743990898132, train_loss: 0.6213749051094055\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5578886866569519, train_loss: 0.4286644160747528\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4995996654033661, train_loss: 0.3315677046775818\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4609173834323883, train_loss: 0.23546786606311798\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.4363630414009094, train_loss: 0.18518848717212677\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.4290792644023895, train_loss: 0.1451777070760727\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8827372193336487, train_loss: 0.941035270690918\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.7473524212837219, train_loss: 0.7134614586830139\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6412044167518616, train_loss: 0.5810139775276184\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5514300465583801, train_loss: 0.44756051898002625\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.47817927598953247, train_loss: 0.342815101146698\n",
      "[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.4208349287509918, train_loss: 0.2783444821834564\n",
      "[po_estimator_1_impute_pos] Epoch: 300, current validation loss: 0.38138142228126526, train_loss: 0.21545447409152985\n",
      "[po_estimator_1_impute_pos] Epoch: 350, current validation loss: 0.35301607847213745, train_loss: 0.17596454918384552\n",
      "[po_estimator_1_impute_pos] Epoch: 400, current validation loss: 0.3345372974872589, train_loss: 0.15569093823432922\n",
      "[po_estimator_1_impute_pos] Epoch: 450, current validation loss: 0.32175517082214355, train_loss: 0.12461842596530914\n",
      "[po_estimator_1_impute_pos] Epoch: 500, current validation loss: 0.31432342529296875, train_loss: 0.1082107350230217\n",
      "[po_estimator_1_impute_pos] Epoch: 550, current validation loss: 0.30485329031944275, train_loss: 0.09384322911500931\n",
      "[po_estimator_1_impute_pos] Epoch: 600, current validation loss: 0.30148813128471375, train_loss: 0.08222359418869019\n",
      "[po_estimator_1_impute_pos] Epoch: 650, current validation loss: 0.29793089628219604, train_loss: 0.07122708857059479\n",
      "[te_estimator] Epoch: 0, current validation loss: 11.033541679382324, train_loss: 237.87979125976562\n",
      "[te_estimator] Epoch: 50, current validation loss: 10.826937675476074, train_loss: 242.00936889648438\n",
      "[te_estimator] Epoch: 100, current validation loss: 10.81682014465332, train_loss: 234.63272094726562\n",
      "[te_estimator] Epoch: 150, current validation loss: 10.813804626464844, train_loss: 234.7137451171875\n",
      "[te_estimator] Epoch: 200, current validation loss: 10.814697265625, train_loss: 330.3130187988281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DRLearner(\n",
       "  (_te_estimator): BasicNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=46, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_po_estimator): BasicNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=46, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (_propensity_estimator): PropensityNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=46, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "      (4): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluid_cohort = pd.read_pickle(\"../data/trauma_responder.pkl\")\n",
    "\n",
    "\n",
    "all_year = pd.read_csv(\"../data/all_year.csv\", index_col=0)\n",
    "\n",
    "fluid_cohort = pd.merge(fluid_cohort,all_year[['registryid','iss']],on='registryid', how='left')\n",
    "fluid_cohort[\"iss\"] = pd.to_numeric(fluid_cohort[\"iss\"], errors='coerce')\n",
    "\n",
    "#\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='proc')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='ethnicity')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='residencestate')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='toxicologyresults')))]\n",
    "\n",
    "\n",
    "x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "                                                            \"COV\",\n",
    "                                                            \"TT\",\n",
    "                                                            \"scenegcsmotor\",\n",
    "                                                            \"scenegcseye\",\n",
    "                                                            \"scenegcsverbal\",\n",
    "                                                            \"edgcsmotor\",\n",
    "                                                            \"edgcseye\",\n",
    "                                                            \"edgcsverbal\",\n",
    "                                                            \"outcome\",\n",
    "                                                            \"sex_F\",\n",
    "                                                            \"traumatype_P\",\n",
    "                                                            \"traumatype_other\"\n",
    "                                                            ])]\n",
    "\n",
    "n, feature_size = x.shape\n",
    "names = x.drop([\"treated\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"treated\")\n",
    "iss_index = x.columns.get_loc(\"iss\")\n",
    "sex_index = x.columns.get_loc(\"sex_M\")\n",
    "\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index and i != iss_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "## impute missing value\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             fluid_cohort[\"outcome\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=fluid_cohort[\"treated\"]\n",
    "                                    )\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "                                             x_train,  \n",
    "                                             y_train, \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=x_train[:, treatment_index]\n",
    "                                    )\n",
    "\n",
    "w_train = x_train[:, treatment_index]\n",
    "w_val = x_val[:, treatment_index]\n",
    "w_test =  x_test[:, treatment_index]\n",
    "\n",
    "\n",
    "iss_train = x_train[:, iss_index]\n",
    "iss_test =  x_test[:, iss_index]\n",
    "\n",
    "x_train = x_train[:,var_index]\n",
    "x_val = x_val[:, var_index]\n",
    "x_test = x_test[:, var_index]\n",
    "\n",
    "x_learner = pseudo_outcome_nets.XLearner( \n",
    "    \n",
    "    x_train.shape[1],\n",
    "    binary_y=(len(np.unique(y_train)) == 2),\n",
    "    n_layers_out=2,\n",
    "    n_units_out=100,\n",
    "    batch_size=128,\n",
    "    n_iter=1500,\n",
    "    nonlin=\"relu\",\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "dr_learner = pseudo_outcome_nets.DRLearner( \n",
    "    \n",
    "    x_train.shape[1],\n",
    "    binary_y=(len(np.unique(y_train)) == 2),\n",
    "    n_layers_out=2,\n",
    "    n_units_out=100,\n",
    "    batch_size=128,\n",
    "    n_iter=1500,\n",
    "    nonlin=\"relu\",\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "\n",
    "\n",
    "x_learner.fit(x_train, y_train, w_train)\n",
    "dr_learner.fit(x_train, y_train, w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "4c9871b8-6526-4242-ae7e-1e558f89c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debug DR\n",
    "\n",
    "def train_nuisance_models(\n",
    "    x_val: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    w_val: np.ndarray\n",
    ")-> tuple:\n",
    "\n",
    "    mu0 = xgb.XGBClassifier()\n",
    "    mu1 = xgb.XGBClassifier()\n",
    "    m = xgb.XGBClassifier()\n",
    "    rf = xgb.XGBClassifier(\n",
    "        reg_lambda=2,\n",
    "        max_depth=3,\n",
    "        colsample_bytree=0.2,\n",
    "        min_split_loss=10\n",
    "    )\n",
    "\n",
    "    x0, x1 = x_val[w_val == 0], x_val[w_val == 1]\n",
    "    y0, y1 = y_val[w_val == 0], y_val[w_val == 1]\n",
    "\n",
    "    mu0.fit(x0, y0)\n",
    "    mu1.fit(x1, y1)\n",
    "    m.fit(x_val, y_val)\n",
    "    rf.fit(x_val, w_val)\n",
    "\n",
    "    return mu0, mu1, rf, m\n",
    "\n",
    "def calculate_if_pehe(\n",
    "    w_test: np.ndarray,\n",
    "    p: np.ndarray,\n",
    "    prediction: np.ndarray,\n",
    "    t_plugin: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    ident: np.ndarray\n",
    ")-> np.ndarray:\n",
    "\n",
    "    EPS = 1e-7\n",
    "    a = w_test - p\n",
    "    c = p * (ident - p)\n",
    "    b = 2 * np.ones(len(w_test)) * w_test * (w_test - p) / (c + EPS)\n",
    "\n",
    "    plug_in = (t_plugin - prediction) ** 2\n",
    "    l_de = (ident - b) * t_plugin ** 2 + b * y_test * (t_plugin - prediction) + (- a * (t_plugin - prediction) ** 2 + prediction ** 2)\n",
    "\n",
    "    return np.sum(plug_in) + np.sum(l_de)\n",
    "\n",
    "\n",
    "def calculate_pseudo_outcome_pehe_dr(\n",
    "    w_test: np.ndarray,\n",
    "    p: np.ndarray,\n",
    "    prediction: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    mu_1: np.ndarray,\n",
    "    mu_0: np.ndarray\n",
    ")-> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    calculating pseudo outcome for DR\n",
    "    \"\"\"\n",
    "    # p = 0.5*np.ones(len(w_test))\n",
    "    \n",
    "    EPS = 1e-7\n",
    "    w_1 = w_test / (p + EPS)\n",
    "    w_0 = (1 - w_test) / (EPS + 1 - p)\n",
    "    \n",
    "    pseudo_outcome = (w_1 - w_0) * y_test + ((1 - w_1) * mu_1 - (1 - w_0) * mu_0)\n",
    "        \n",
    "    # pseudo_outcome = np.clip(pseudo_outcome, -1, 1)\n",
    "    return np.sqrt(np.mean((prediction - pseudo_outcome) ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c9abfb6b-ea8f-4535-ba0e-21a72eceb0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for propensity model 0.5\n",
      "0.019449778 0.29920733\n",
      "pehe_dr: xlearner 1.7713610607056494\n",
      "pehe_dr: drlearner 1.7435651065139144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_plugin0, xgb_plugin1, rf, m = train_nuisance_models(x_train, y_train, w_train)\n",
    "\n",
    "mu_0 = xgb_plugin0.predict_proba(x_test)[:, 1]\n",
    "mu_1 = xgb_plugin1.predict_proba(x_test)[:, 1]\n",
    "\n",
    "mu = m.predict_proba(x_test)[:, 1]\n",
    "p = rf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print(\"AUROC for propensity model\", roc_auc_score(w_test, p))\n",
    "\n",
    "t_plugin = mu_1 - mu_0\n",
    "ident = np.ones(len(p))\n",
    "\n",
    "x_prediction = x_learner.predict(X=x_test).detach().cpu().numpy().flatten()\n",
    "dr_prediction = dr_learner.predict(X=x_test).detach().cpu().numpy().flatten()\n",
    "\n",
    "print(np.mean(x_prediction), np.mean(dr_prediction))\n",
    "\n",
    "print(\"pehe_dr: xlearner\", calculate_pseudo_outcome_pehe_dr(w_test, p, x_prediction, y_test, mu_1, mu_0))\n",
    "print(\"pehe_dr: drlearner\", calculate_pseudo_outcome_pehe_dr(w_test, p, dr_prediction, y_test, mu_1, mu_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ffa0d321-dfba-410d-82e4-2fa97fe0b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21012758868640846 0.022916098208791365\n",
      "0.2053813276515269 0.04399229782697588\n",
      "['traumatype_B', 'causecode_CUT', 'sex_M', 'edgcs', 'causecode_GUN']\n",
      "['PH', 'HCT', 'temps2', 'scenegcs', 'traumatype_B']\n",
      "['temps2', 'HCT', 'PH', 'traumatype_B', 'NA']\n",
      "mean ISS:  29.70394736842105\n",
      "original 0.03809869510749887\n",
      "original - iss 29.774647887323944 28.699999999999996\n",
      "===================================\n",
      "shap - auroc 0.4797402597402597\n",
      "shap - ATE 0.01854604204211075\n",
      "shap - iss 27.14285714285715; 31.890243902439025 \n",
      "===================================\n",
      "shap - 0  - auroc 0.5272727272727273\n",
      "shap - 0  - ATE 0.024508233179862216\n",
      "shap - 0  - iss 29.89655172413794; 29.446153846153845 \n",
      "===================================\n",
      "ig - auroc 0.5787012987012987\n",
      "ig - ATE 0.022168964689857615\n",
      "ig - iss 29.835616438356162; 29.582278481012654 \n",
      "===================================\n",
      "clinical - auroc 0.5522077922077921\n",
      "clinical - ATE 0.022064024341085304\n",
      "clinical - iss 29.422535211267608; 29.950617283950614 \n",
      "===================================\n",
      "full features - auroc 0.5067532467532467\n",
      "full features - ATE 0.02080623888317373\n",
      "full features - iss 29.961538461538467; 29.432432432432435 \n",
      "===================================\n",
      "random features - auroc 0.5404329004329005\n",
      "random features - ATE 0.025402061902391516\n",
      "random features - iss 32.19540229885058; 26.36923076923077 \n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "results_train = pickle.load(open(\"../results/responder/train_xlearner.pkl\", \"rb\"))\n",
    "results_test = pickle.load(open(\"../results/responder/test_xlearner.pkl\", \"rb\"))\n",
    "\n",
    "print(np.mean(results_train), np.std(results_train)/np.sqrt(results_train.shape[1]))\n",
    "print(np.mean(results_test), np.std(results_test)/np.sqrt(results_test.shape[1]))\n",
    "\n",
    "estimated_ate_train = np.mean(results_train, axis=0)\n",
    "estimated_ate_test = np.mean(results_test, axis=0)\n",
    "threshold = np.mean(estimated_ate_train)\n",
    "\n",
    "y_true_train = (estimated_ate_train > threshold)\n",
    "y_true_test = (estimated_ate_test > threshold)\n",
    "\n",
    "scenefirstbloodpressure = x.columns.get_loc(\"scenefirstbloodpressure\")\n",
    "lac  = x.columns.get_loc(\"LAC\")\n",
    "inr  = x.columns.get_loc(\"INR\")\n",
    "hgb  = x.columns.get_loc(\"HGB\")\n",
    "\n",
    "explainers = {\n",
    "    \"shap\": feature_idx(\"shap\",\"responder\"),\n",
    "    \"shap - 0 \": feature_idx(\"shap - 0 \",\"responder\" ), #[temp, ph, bd, hgb, pulse ]\n",
    "    \"ig\": feature_idx(\"ig\",\"responder\" ), #[ph, na, temp, gender, fio2 ],\n",
    "    \n",
    "    \"clinical\": [lac, inr, hgb,scenefirstbloodpressure ],\n",
    "    \"full features\": [ i for i in range(x_train.shape[1])],\n",
    "    \"random features\": np.random.randint(x_train.shape[1], size=(5)),\n",
    "}\n",
    "\n",
    "\n",
    "print(\"mean ISS: \", np.mean(iss_test)*74+1)\n",
    "print(\"original\", np.sum(estimated_ate_test[w_test==1])/n)\n",
    "print(\"original - iss\", np.mean(iss_test[w_test==1])*74+1, np.mean(iss_test[w_test==0])*74+1)\n",
    "print(\"===================================\")\n",
    "\n",
    "for explainer, features in explainers.items():\n",
    "    subgroup_ate(\n",
    "        explainer,\n",
    "        features,\n",
    "        y_true_train,\n",
    "        y_true_test,\n",
    "        estimated_ate_test,\n",
    "        iss_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d310673-83d3-4ec2-a5c7-682ee9462cc9",
   "metadata": {},
   "source": [
    "## Transfusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0c9b4841-7234-4ce3-957f-82991b765a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40033/4013390563.py:3: DtypeWarning: Columns (9,16,45,57,58,59,60,61,62,63,64,71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_year = pd.read_csv(\"../data/all_year.csv\", index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6739606857299805, train_loss: 0.6328368186950684\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.56540447473526, train_loss: 0.4371078312397003\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5294803977012634, train_loss: 0.3286193907260895\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5187534689903259, train_loss: 0.2616085410118103\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5173234343528748, train_loss: 0.21626016497612\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7102606296539307, train_loss: 0.7698997855186462\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6301138401031494, train_loss: 0.5559946894645691\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.588813841342926, train_loss: 0.43144458532333374\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5775468945503235, train_loss: 0.35479027032852173\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5773111581802368, train_loss: 0.34524253010749817\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5250498652458191, train_loss: 0.6484407186508179\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4142739176750183, train_loss: 0.4264881908893585\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36961740255355835, train_loss: 0.32659751176834106\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3397482931613922, train_loss: 0.2526484727859497\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31733036041259766, train_loss: 0.2032012790441513\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3001965880393982, train_loss: 0.1643403023481369\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.28703954815864563, train_loss: 0.1306864470243454\n",
      "[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.28106263279914856, train_loss: 0.1081545278429985\n",
      "[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.2767820358276367, train_loss: 0.08821838349103928\n",
      "[po_estimator_0_impute_pos] Epoch: 450, current validation loss: 0.2738279402256012, train_loss: 0.07197018712759018\n",
      "[po_estimator_0_impute_pos] Epoch: 500, current validation loss: 0.2723516523838043, train_loss: 0.06485212594270706\n",
      "[po_estimator_0_impute_pos] Epoch: 550, current validation loss: 0.2721189856529236, train_loss: 0.06273364275693893\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6913928985595703, train_loss: 0.7436426281929016\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5921018719673157, train_loss: 0.5218468308448792\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5423858761787415, train_loss: 0.3994162082672119\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.515751302242279, train_loss: 0.31394702196121216\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.49708303809165955, train_loss: 0.2487134486436844\n",
      "[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.48476240038871765, train_loss: 0.1982221007347107\n",
      "[po_estimator_1_impute_pos] Epoch: 300, current validation loss: 0.47891560196876526, train_loss: 0.15956774353981018\n",
      "[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39279627799987793, train_loss: 0.3554351329803467\n",
      "[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20231814682483673, train_loss: 0.08519378304481506\n",
      "[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1983179897069931, train_loss: 0.05723673105239868\n",
      "[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1983589380979538, train_loss: 0.05489892512559891\n",
      "[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19750821590423584, train_loss: 0.06170463562011719\n",
      "[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41543903946876526, train_loss: 0.417458176612854\n",
      "[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22362631559371948, train_loss: 0.11416696012020111\n",
      "[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2246779501438141, train_loss: 0.10114090144634247\n",
      "[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22595611214637756, train_loss: 0.09514261782169342\n",
      "[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22726334631443024, train_loss: 0.09091208130121231\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9563050270080566, train_loss: 0.9369258284568787\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.7964532375335693, train_loss: 0.6505061984062195\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.691957414150238, train_loss: 0.467741459608078\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6308855414390564, train_loss: 0.351865291595459\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6014087200164795, train_loss: 0.2696707546710968\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.5893762707710266, train_loss: 0.20877541601657867\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.5870882868766785, train_loss: 0.1678064614534378\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7950848340988159, train_loss: 0.7844098806381226\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6500327587127686, train_loss: 0.5382185578346252\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6022112369537354, train_loss: 0.4061935842037201\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5907808542251587, train_loss: 0.3245294988155365\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5889699459075928, train_loss: 0.270850270986557\n",
      "[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.2661954164505005, train_loss: 1.1330928802490234\n",
      "[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 1.0256966352462769, train_loss: 0.8073593378067017\n",
      "[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.8543949723243713, train_loss: 0.5858443379402161\n",
      "[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.7194273471832275, train_loss: 0.4308679699897766\n",
      "[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6203435659408569, train_loss: 0.3134228587150574\n",
      "[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.5582304000854492, train_loss: 0.24500082433223724\n",
      "[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.5171194672584534, train_loss: 0.20160864293575287\n",
      "[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.48464450240135193, train_loss: 0.16445766389369965\n",
      "[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.4594680368900299, train_loss: 0.13804160058498383\n",
      "[po_estimator_0_impute_pos] Epoch: 450, current validation loss: 0.44198906421661377, train_loss: 0.1180185079574585\n",
      "[po_estimator_0_impute_pos] Epoch: 500, current validation loss: 0.4281296730041504, train_loss: 0.10733766108751297\n",
      "[po_estimator_0_impute_pos] Epoch: 550, current validation loss: 0.41694432497024536, train_loss: 0.09105119854211807\n",
      "[po_estimator_0_impute_pos] Epoch: 600, current validation loss: 0.4078591763973236, train_loss: 0.07907157391309738\n",
      "[po_estimator_0_impute_pos] Epoch: 650, current validation loss: 0.40035757422447205, train_loss: 0.07132089138031006\n",
      "[po_estimator_0_impute_pos] Epoch: 700, current validation loss: 0.39423060417175293, train_loss: 0.06121780723333359\n",
      "[po_estimator_0_impute_pos] Epoch: 750, current validation loss: 0.3900577127933502, train_loss: 0.054761990904808044\n",
      "[po_estimator_0_impute_pos] Epoch: 800, current validation loss: 0.38675883412361145, train_loss: 0.04916924983263016\n",
      "[po_estimator_0_impute_pos] Epoch: 850, current validation loss: 0.3836463987827301, train_loss: 0.04441261291503906\n",
      "[po_estimator_0_impute_pos] Epoch: 900, current validation loss: 0.38118523359298706, train_loss: 0.04015609622001648\n",
      "[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8059265613555908, train_loss: 0.8038969039916992\n",
      "[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6968860030174255, train_loss: 0.5652480721473694\n",
      "[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6395695805549622, train_loss: 0.4236433207988739\n",
      "[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6112441420555115, train_loss: 0.335610032081604\n",
      "[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5971914529800415, train_loss: 0.26751089096069336\n",
      "[te_estimator] Epoch: 0, current validation loss: 7.08620023727417, train_loss: 1.3985004425048828\n",
      "[te_estimator] Epoch: 50, current validation loss: 6.627137184143066, train_loss: 0.6479944586753845\n",
      "[te_estimator] Epoch: 100, current validation loss: 6.627769947052002, train_loss: 0.5485662817955017\n",
      "[te_estimator] Epoch: 150, current validation loss: 6.627701282501221, train_loss: 0.5156482458114624\n",
      "[te_estimator] Epoch: 200, current validation loss: 6.625478744506836, train_loss: 0.5400710105895996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DRLearner(\n",
       "  (_te_estimator): BasicNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=51, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_po_estimator): BasicNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=51, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=100, out_features=1, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (_propensity_estimator): PropensityNet(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=51, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=100, out_features=2, bias=True)\n",
       "      (4): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluid_cohort = pd.read_pickle(\"../data/low_bp_survival.pkl\")\n",
    "\n",
    "all_year = pd.read_csv(\"../data/all_year.csv\", index_col=0)\n",
    "\n",
    "fluid_cohort = pd.merge(fluid_cohort,all_year[['registryid','iss']],on='registryid', how='left')\n",
    "fluid_cohort[\"iss\"] = pd.to_numeric(fluid_cohort[\"iss\"], errors='coerce')\n",
    "\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='proc')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='ethnicity')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='residencestate')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='toxicologyresults')))]\n",
    "\n",
    "\n",
    "x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "                                                    \"COV\",\n",
    "                                                    \"TT\",\n",
    "                                                    \"scenegcsmotor\",\n",
    "                                                    \"scenegcseye\",\n",
    "                                                    \"scenegcsverbal\",\n",
    "                                                    \"edgcsmotor\",\n",
    "                                                    \"edgcseye\",\n",
    "                                                    \"edgcsverbal\",\n",
    "                                                    \"outcome\",\n",
    "                                                    \"sex_F\",\n",
    "                                                    \"traumatype_P\",\n",
    "                                                    \"traumatype_other\",\n",
    "                                                ])\n",
    "                    ]\n",
    "\n",
    "n, feature_size = x.shape\n",
    "names = x.drop([\"treated\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"treated\")\n",
    "iss_index = x.columns.get_loc(\"iss\")\n",
    "sex_index = x.columns.get_loc(\"sex_M\")\n",
    "\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index and i != iss_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "## impute missing value\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             fluid_cohort[\"outcome\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=fluid_cohort[\"treated\"]\n",
    "                                    )\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "                                             x_train,  \n",
    "                                             y_train, \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=x_train[:, treatment_index]\n",
    "                                    )\n",
    "\n",
    "\n",
    "w_train = x_train[:, treatment_index]\n",
    "w_val = x_val[:, treatment_index]\n",
    "w_test =  x_test[:, treatment_index]\n",
    "\n",
    "iss_train = x_train[:, iss_index]\n",
    "iss_test =  x_test[:, iss_index]\n",
    "\n",
    "x_train = x_train[:,var_index]\n",
    "x_val = x_val[:, var_index]\n",
    "x_test = x_test[:, var_index]\n",
    "\n",
    "x_learner = pseudo_outcome_nets.XLearner( \n",
    "    \n",
    "    x_train.shape[1],\n",
    "    binary_y=(len(np.unique(y_train)) == 2),\n",
    "    n_layers_out=2,\n",
    "    n_units_out=100,\n",
    "    batch_size=128,\n",
    "    n_iter=1500,\n",
    "    nonlin=\"relu\",\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "dr_learner = pseudo_outcome_nets.DRLearner( \n",
    "    \n",
    "    x_train.shape[1],\n",
    "    binary_y=(len(np.unique(y_train)) == 2),\n",
    "    n_layers_out=2,\n",
    "    n_units_out=100,\n",
    "    batch_size=128,\n",
    "    n_iter=1500,\n",
    "    nonlin=\"relu\",\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "\n",
    "\n",
    "x_learner.fit(x_train, y_train, w_train)\n",
    "dr_learner.fit(x_train, y_train, w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "905b53c7-82e6-4f5a-99db-f571eaed7699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC for propensity model 0.8305577849117175\n",
      "0.8321216786995042\n",
      "0.9044934055773273\n"
     ]
    }
   ],
   "source": [
    "xgb_plugin0, xgb_plugin1, rf, m = train_nuisance_models(x_train, y_train, w_train)\n",
    "\n",
    "mu_0 = xgb_plugin0.predict_proba(x_test)[:, 1]\n",
    "mu_1 = xgb_plugin1.predict_proba(x_test)[:, 1]\n",
    "\n",
    "mu = m.predict_proba(x_test)[:, 1]\n",
    "p = rf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "print(\"AUROC for propensity model\", roc_auc_score(w_test, p))\n",
    "\n",
    "t_plugin = mu_1 - mu_0\n",
    "ident = np.ones(len(p))\n",
    "\n",
    "x_prediction = x_learner.predict(X=x_test).detach().cpu().numpy().flatten()\n",
    "dr_prediction = dr_learner.predict(X=x_test).detach().cpu().numpy().flatten()\n",
    "\n",
    "print(calculate_pseudo_outcome_pehe_dr(w_test, p, x_prediction, y_test, mu_1, mu_0))\n",
    "print(calculate_pseudo_outcome_pehe_dr(w_test, p, dr_prediction, y_test, mu_1, mu_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c35378c9-cefd-4d65-8b8e-83b465a69dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.055822201781090916 0.01128492608250522\n",
      "-0.047783710723696506 0.021390057599922293\n",
      "['traumatype_B', 'causecode_CUT', 'sex_M', 'edgcs', 'causecode_GUN']\n",
      "['PH', 'HCT', 'temps2', 'scenegcs', 'traumatype_B']\n",
      "['temps2', 'HCT', 'PH', 'traumatype_B', 'NA']\n",
      "mean ISS:  29.641791044776117\n",
      "original -0.007331925282529388\n",
      "original - iss 33.169642857142854 25.202247191011242\n",
      "===================================\n",
      "shap - auroc 0.5117559523809524\n",
      "shap - ATE -0.0019779173414263707\n",
      "shap - iss 30.457627118644066; 29.30281690140845 \n",
      "===================================\n",
      "shap - 0  - auroc 0.5209821428571428\n",
      "shap - 0  - ATE -0.0034720158256382576\n",
      "shap - 0  - iss 30.16822429906542; 29.04255319148936 \n",
      "===================================\n",
      "ig - auroc 0.5019345238095239\n",
      "ig - ATE -0.0044988380711659245\n",
      "ig - iss 32.14563106796117; 27.010204081632654 \n",
      "===================================\n",
      "clinical - auroc 0.4758928571428571\n",
      "clinical - ATE -0.0047931352598718805\n",
      "clinical - iss 30.703703703703702; 28.40860215053764 \n",
      "===================================\n",
      "full features - auroc 0.4903273809523809\n",
      "full features - ATE -0.0037122418315509755\n",
      "full features - iss 29.284090909090907; 29.920353982300888 \n",
      "===================================\n",
      "random features - auroc 0.48288690476190477\n",
      "random features - ATE -0.005529476734865233\n",
      "random features - iss 28.414141414141422; 30.833333333333336 \n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "results_train = pickle.load(open(\"../results/massive_trans/train_xlearner.pkl\", \"rb\"))\n",
    "results_test = pickle.load(open(\"../results/massive_trans/test_xlearner.pkl\", \"rb\"))\n",
    "\n",
    "print(np.mean(results_train), np.std(results_train)/np.sqrt(results_train.shape[1]))\n",
    "print(np.mean(results_test), np.std(results_test)/np.sqrt(results_test.shape[1]))\n",
    "\n",
    "estimated_ate_train = np.mean(results_train, axis=0)\n",
    "estimated_ate_test = np.mean(results_test, axis=0)\n",
    "threshold = np.mean(estimated_ate_train)\n",
    "\n",
    "y_true_train = (estimated_ate_train > threshold)\n",
    "y_true_test = (estimated_ate_test > threshold)\n",
    "\n",
    "scenefirstbloodpressure = x.columns.get_loc(\"scenefirstbloodpressure\")\n",
    "lac  = x.columns.get_loc(\"LAC\")\n",
    "inr  = x.columns.get_loc(\"INR\")\n",
    "hgb  = x.columns.get_loc(\"HGB\")\n",
    "\n",
    "explainers = {\n",
    "    \"shap\": feature_idx(\"shap\",\"responder\"), #[gender,trauma ,cause_cut, edgcs, cause_mv ]\n",
    "    \"shap - 0 \": feature_idx(\"shap - 0 \",\"responder\" ), #[temp, ph, bd, hgb, trauma ]\n",
    "    \"ig\": feature_idx(\"ig\",\"responder\" ), #[ph, na, temp, gender, trauma ],\n",
    "    \n",
    "    \"clinical\": [lac, inr, hgb,scenefirstbloodpressure ],\n",
    "    \"full features\": [ i for i in range(x_train.shape[1])],\n",
    "    \"random features\": np.random.randint(x_train.shape[1], size=(5)),\n",
    "}\n",
    "\n",
    "print(\"mean ISS: \", np.mean(iss_test)*74+1)\n",
    "print(\"original\", np.sum(estimated_ate_test[w_test==1])/n)\n",
    "print(\"original - iss\", np.mean(iss_test[w_test==1])*74+1, np.mean(iss_test[w_test==0])*74+1)\n",
    "print(\"===================================\")\n",
    "\n",
    "for explainer, features in explainers.items():\n",
    "    subgroup_ate(\n",
    "        explainer,\n",
    "        features,\n",
    "        y_true_train,\n",
    "        y_true_test,\n",
    "        estimated_ate_test,\n",
    "        iss_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "adf36707-bff1-459b-a85f-4f4f8e991b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ist3 = pd.read_sas(\"../data/datashare_aug2015.sas7bdat\")\n",
    "\n",
    "continuous_vars = [\n",
    "                    \"gender\",\n",
    "                    \"age\",\n",
    "                    \"weight\",\n",
    "                    \"glucose\",\n",
    "                    \"gcs_eye_rand\",\n",
    "                    \"gcs_motor_rand\",\n",
    "                    \"gcs_verbal_rand\",\n",
    "                    # \"gcs_score_rand\",   \n",
    "                     \"nihss\" ,\n",
    "                     \"sbprand\",\n",
    "                     \"dbprand\",\n",
    "                  ]\n",
    "\n",
    "cate_variables = [\n",
    "                     # \"livealone_rand\",\n",
    "                     # \"indepinadl_rand\",\n",
    "                     \"infarct\",\n",
    "                     \"antiplat_rand\",\n",
    "                     # \"atrialfib_rand\",\n",
    "                    #  \"liftarms_rand\",\n",
    "                    # \"ablewalk_rand\",\n",
    "                    # \"weakface_rand\",\n",
    "                    # \"weakarm_rand\",\n",
    "                    # \"weakleg_rand\",\n",
    "                    # \"dysphasia_rand\",\n",
    "                    # \"hemianopia_rand\",\n",
    "                    # \"visuospat_rand\",\n",
    "                    # \"brainstemsigns_rand\",\n",
    "                    # \"otherdeficit_rand\",\n",
    "                    \"stroketype\"\n",
    "                 ]\n",
    "\n",
    "outcomes = [\"dead7\",\"dead6mo\",\"aliveind6\"]\n",
    "treatment = [\"itt_treat\"]\n",
    "\n",
    "x = ist3[continuous_vars + cate_variables + treatment]\n",
    "\n",
    "x = pd.get_dummies(x, columns=cate_variables)\n",
    "\n",
    "n, feature_size = x.shape\n",
    "\n",
    "\n",
    "names = x.drop([\"itt_treat\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"itt_treat\")\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "## impute missing value\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             ist3[\"aliveind6\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=20,\n",
    "                                    )\n",
    "\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "                                            x_train,\n",
    "                                            y_train,\n",
    "                                            test_size=0.2,\n",
    "                                            random_state=50,\n",
    "                                    )\n",
    "\n",
    "\n",
    "w_train = x_train[:, treatment_index] == 0\n",
    "w_test =  x_test[:, treatment_index] == 0\n",
    "\n",
    "x_train = x_train[:,var_index]\n",
    "x_test = x_test[:, var_index]\n",
    "\n",
    "y_train = y_train ==0\n",
    "y_test = y_test ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fba6dfda-3782-4257-bf5b-6bb749dc839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014999985861160743 0.0019497298885327702\n",
      "0.0012145126779307496 0.003587692772870593\n",
      "['antiplat_rand_2.0', 'infarct_0.0', 'stroketype_2.0', 'stroketype_1.0', 'infarct_2.0']\n",
      "['gcs_eye_rand', 'nihss', 'gcs_motor_rand', 'glucose', 'stroketype_2.0']\n",
      "['gcs_eye_rand', 'gcs_motor_rand', 'age', 'stroketype_1.0', 'gcs_verbal_rand']\n",
      "shap - auroc 0.5198528292863198\n",
      "shap - ATE 4.7815562819653894e-05\n",
      "shap - 0  - auroc 0.46081606921588664\n",
      "shap - 0  - ATE -2.1063881854126236e-05\n",
      "ig - auroc 0.4662724723375579\n",
      "ig - ATE -0.0001588486487205452\n",
      "full features - auroc 0.4940273037542662\n",
      "full features - ATE 0.0001482719506322724\n",
      "random features - auroc 0.4747994608812852\n",
      "random features - ATE -3.9418327892153094e-05\n"
     ]
    }
   ],
   "source": [
    "results_train = pickle.load(open(\"../results/ist3/train_xlearner.pkl\", \"rb\"))\n",
    "results_test = pickle.load(open(\"../results/ist3/test_xlearner.pkl\", \"rb\"))\n",
    "\n",
    "print(np.mean(results_train), np.std(results_train)/np.sqrt(results_train.shape[1]))\n",
    "print(np.mean(results_test), np.std(results_test)/np.sqrt(results_test.shape[1]))\n",
    "\n",
    "estimated_ate_train = np.mean(results_train, axis=0)\n",
    "estimated_ate_test = np.mean(results_test, axis=0)\n",
    "threshold = np.mean(estimated_ate_train)\n",
    "\n",
    "y_true_train = (estimated_ate_train > threshold)\n",
    "y_true_test = (estimated_ate_test > threshold)\n",
    "\n",
    "# scenefirstbloodpressure = x.columns.get_loc(\"scenefirstbloodpressure\")\n",
    "# lac  = x.columns.get_loc(\"LAC\")\n",
    "# inr  = x.columns.get_loc(\"INR\")\n",
    "# hgb  = x.columns.get_loc(\"HGB\")\n",
    "\n",
    "explainers = {\n",
    "    \"shap\": feature_idx(\"shap\",\"ist3\"), #[gender,trauma ,cause_cut, edgcs, cause_mv ]\n",
    "    \"shap - 0 \": feature_idx(\"shap - 0\",\"ist3\" ), #[temp, ph, bd, hgb, trauma ]\n",
    "    \"ig\": feature_idx(\"ig\",\"ist3\" ), #[ph, na, temp, gender, trauma ],\n",
    "    \n",
    "    # \"clinical\": [lac, inr, hgb,scenefirstbloodpressure ],\n",
    "    \"full features\": [ i for i in range(x_train.shape[1])],\n",
    "    \"random features\": np.random.randint(x_train.shape[1], size=(5)),\n",
    "}\n",
    "\n",
    "for explainer, features in explainers.items():\n",
    "    subgroup_ate(\n",
    "        explainer,\n",
    "        features,\n",
    "        y_true_train,\n",
    "        y_true_test,\n",
    "        estimated_ate_test,\n",
    "        None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d06d9b-14e5-43ba-a3c4-634511aba502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6., 15., 13., 17.,  8., 15.,  8.,  3.,  1.,  2.]),\n",
       " array([ 1. ,  8.4, 15.8, 23.2, 30.6, 38. , 45.4, 52.8, 60.2, 67.6, 75. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.hist(iss_test[y_pred==1]*74+1)\n",
    "plt.hist(iss_test[y_pred==0]*74+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a7fc6-96c2-4bf9-8d86-e548f10f965b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
