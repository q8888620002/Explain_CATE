python run_clinical_experiments.py -d ist3 -t 5 -n 10 -l XLearner -device cuda
True
shuffle dataset:  True
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7780734896659851, train_loss: 0.7676296234130859
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5486411452293396, train_loss: 0.45393964648246765
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5104818344116211, train_loss: 0.3656633794307709
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5064610242843628, train_loss: 0.3261212110519409
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5069811344146729, train_loss: 0.31542590260505676
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7312963604927063, train_loss: 0.7680651545524597
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6271669268608093, train_loss: 0.4927912652492523
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6289749145507812, train_loss: 0.4682285189628601
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6307195425033569, train_loss: 0.4640676975250244
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6327138543128967, train_loss: 0.4566959738731384
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6899268627166748, train_loss: 0.6999187469482422
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47777995467185974, train_loss: 0.4558912217617035
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4576132893562317, train_loss: 0.3844258785247803
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4566619098186493, train_loss: 0.35947155952453613
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.456663578748703, train_loss: 0.3545458912849426
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7189043760299683, train_loss: 0.7924480438232422
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5272366404533386, train_loss: 0.5253197550773621
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5038208365440369, train_loss: 0.4670671820640564
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5026599168777466, train_loss: 0.4456135034561157
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5023716688156128, train_loss: 0.43986210227012634
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5019010901451111, train_loss: 0.43951985239982605
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7634612917900085, train_loss: 0.7995447516441345
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1850120723247528, train_loss: 0.1473122239112854
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18076637387275696, train_loss: 0.11613409966230392
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1806831806898117, train_loss: 0.11249534040689468
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1809481382369995, train_loss: 0.11112692207098007
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6800407767295837, train_loss: 0.7065731883049011
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24681025743484497, train_loss: 0.16045652329921722
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.24412815272808075, train_loss: 0.11837293952703476
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.24406947195529938, train_loss: 0.11510173231363297
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.24428021907806396, train_loss: 0.11083290725946426
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   1%|▏         | 190/15001 [00:00<00:39, 378.81it/s]Shapley Value Sampling attribution:   3%|▎         | 380/15001 [00:01<00:38, 378.78it/s]Shapley Value Sampling attribution:   4%|▍         | 570/15001 [00:01<00:38, 379.30it/s]Shapley Value Sampling attribution:   5%|▌         | 761/15001 [00:02<00:37, 379.67it/s]Shapley Value Sampling attribution:   6%|▋         | 951/15001 [00:02<00:37, 379.54it/s]Shapley Value Sampling attribution:   8%|▊         | 1141/15001 [00:03<00:36, 378.99it/s]Shapley Value Sampling attribution:   9%|▉         | 1331/15001 [00:03<00:36, 379.18it/s]Shapley Value Sampling attribution:  10%|█         | 1551/15001 [00:04<00:33, 398.34it/s]Shapley Value Sampling attribution:  12%|█▏        | 1795/15001 [00:04<00:30, 426.04it/s]Shapley Value Sampling attribution:  14%|█▎        | 2059/15001 [00:05<00:28, 457.06it/s]Shapley Value Sampling attribution:  15%|█▌        | 2323/15001 [00:05<00:26, 478.70it/s]Shapley Value Sampling attribution:  17%|█▋        | 2588/15001 [00:06<00:25, 494.05it/s]Shapley Value Sampling attribution:  20%|█▉        | 2928/15001 [00:06<00:21, 549.85it/s]Shapley Value Sampling attribution:  22%|██▏       | 3336/15001 [00:07<00:18, 629.93it/s]Shapley Value Sampling attribution:  25%|██▌       | 3782/15001 [00:07<00:15, 708.83it/s]Shapley Value Sampling attribution:  28%|██▊       | 4249/15001 [00:08<00:13, 776.52it/s]Shapley Value Sampling attribution:  32%|███▏      | 4734/15001 [00:08<00:12, 834.26it/s]Shapley Value Sampling attribution:  35%|███▍      | 5219/15001 [00:09<00:11, 874.86it/s]Shapley Value Sampling attribution:  38%|███▊      | 5703/15001 [00:09<00:10, 902.45it/s]Shapley Value Sampling attribution:  41%|████      | 6187/15001 [00:10<00:09, 922.07it/s]Shapley Value Sampling attribution:  44%|████▍     | 6672/15001 [00:10<00:08, 936.07it/s]Shapley Value Sampling attribution:  48%|████▊     | 7157/15001 [00:11<00:08, 946.15it/s]Shapley Value Sampling attribution:  51%|█████     | 7631/15001 [00:11<00:07, 943.13it/s]Shapley Value Sampling attribution:  54%|█████▍    | 8115/15001 [00:12<00:07, 950.41it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8602/15001 [00:12<00:06, 956.91it/s]Shapley Value Sampling attribution:  61%|██████    | 9081/15001 [00:13<00:06, 889.08it/s]Shapley Value Sampling attribution:  64%|██████▎   | 9531/15001 [00:14<00:07, 730.50it/s]Shapley Value Sampling attribution:  67%|██████▋   | 10002/15001 [00:14<00:06, 783.14it/s]Shapley Value Sampling attribution:  70%|██████▉   | 10484/15001 [00:15<00:05, 830.56it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10968/15001 [00:15<00:04, 867.81it/s]Shapley Value Sampling attribution:  76%|███████▋  | 11451/15001 [00:16<00:03, 895.31it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11934/15001 [00:16<00:03, 915.36it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12419/15001 [00:17<00:02, 930.76it/s]Shapley Value Sampling attribution:  86%|████████▌ | 12902/15001 [00:17<00:02, 940.94it/s]Shapley Value Sampling attribution:  89%|████████▉ | 13386/15001 [00:18<00:01, 948.61it/s]Shapley Value Sampling attribution:  92%|█████████▏| 13870/15001 [00:18<00:01, 954.14it/s]Shapley Value Sampling attribution:  96%|█████████▌| 14354/15001 [00:19<00:00, 958.03it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14838/15001 [00:19<00:00, 960.64it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:19<00:00, 760.82it/s]
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 486/15001 [00:00<00:14, 970.19it/s]Shapley Value Sampling attribution:   6%|▋         | 972/15001 [00:01<00:14, 970.71it/s]Shapley Value Sampling attribution:  10%|▉         | 1459/15001 [00:01<00:13, 971.25it/s]Shapley Value Sampling attribution:  13%|█▎        | 1945/15001 [00:02<00:16, 790.91it/s]Shapley Value Sampling attribution:  16%|█▌        | 2361/15001 [00:03<00:20, 612.83it/s]Shapley Value Sampling attribution:  18%|█▊        | 2702/15001 [00:04<00:23, 522.09it/s]Shapley Value Sampling attribution:  20%|█▉        | 2991/15001 [00:05<00:26, 461.69it/s]Shapley Value Sampling attribution:  22%|██▏       | 3242/15001 [00:05<00:27, 420.78it/s]Shapley Value Sampling attribution:  23%|██▎       | 3465/15001 [00:06<00:29, 395.22it/s]Shapley Value Sampling attribution:  24%|██▍       | 3670/15001 [00:07<00:30, 376.98it/s]Shapley Value Sampling attribution:  26%|██▌       | 3862/15001 [00:07<00:30, 363.68it/s]Shapley Value Sampling attribution:  27%|██▋       | 4046/15001 [00:08<00:30, 353.62it/s]Shapley Value Sampling attribution:  28%|██▊       | 4224/15001 [00:08<00:31, 346.59it/s]Shapley Value Sampling attribution:  29%|██▉       | 4398/15001 [00:09<00:31, 341.19it/s]Shapley Value Sampling attribution:  30%|███       | 4569/15001 [00:09<00:30, 337.25it/s]Shapley Value Sampling attribution:  32%|███▏      | 4738/15001 [00:10<00:30, 334.13it/s]Shapley Value Sampling attribution:  33%|███▎      | 4905/15001 [00:10<00:30, 331.80it/s]Shapley Value Sampling attribution:  34%|███▍      | 5071/15001 [00:11<00:30, 330.97it/s]Shapley Value Sampling attribution:  35%|███▍      | 5237/15001 [00:11<00:29, 329.89it/s]Shapley Value Sampling attribution:  36%|███▌      | 5409/15001 [00:12<00:28, 333.49it/s]Shapley Value Sampling attribution:  37%|███▋      | 5589/15001 [00:12<00:27, 341.09it/s]Shapley Value Sampling attribution:  39%|███▊      | 5780/15001 [00:13<00:26, 352.66it/s]Shapley Value Sampling attribution:  40%|███▉      | 5971/15001 [00:13<00:25, 361.08it/s]Shapley Value Sampling attribution:  41%|████      | 6161/15001 [00:14<00:24, 366.35it/s]Shapley Value Sampling attribution:  42%|████▏     | 6369/15001 [00:14<00:22, 380.60it/s]Shapley Value Sampling attribution:  44%|████▍     | 6596/15001 [00:15<00:20, 402.44it/s]Shapley Value Sampling attribution:  46%|████▌     | 6924/15001 [00:15<00:16, 477.98it/s]Shapley Value Sampling attribution:  49%|████▉     | 7351/15001 [00:16<00:12, 590.23it/s]Shapley Value Sampling attribution:  52%|█████▏    | 7831/15001 [00:16<00:10, 700.55it/s]Shapley Value Sampling attribution:  55%|█████▌    | 8302/15001 [00:17<00:08, 772.65it/s]Shapley Value Sampling attribution:  58%|█████▊    | 8689/15001 [00:18<00:09, 635.30it/s]Shapley Value Sampling attribution:  60%|██████    | 9064/15001 [00:18<00:08, 664.92it/s]Shapley Value Sampling attribution:  64%|██████▎   | 9548/15001 [00:19<00:07, 746.80it/s]Shapley Value Sampling attribution:  67%|██████▋   | 10033/15001 [00:19<00:06, 808.62it/s]Shapley Value Sampling attribution:  70%|███████   | 10518/15001 [00:20<00:05, 854.37it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10999/15001 [00:20<00:04, 885.42it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11484/15001 [00:21<00:03, 909.65it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11959/15001 [00:21<00:03, 921.27it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12441/15001 [00:22<00:02, 933.45it/s]Shapley Value Sampling attribution:  86%|████████▌ | 12926/15001 [00:22<00:02, 943.80it/s]Shapley Value Sampling attribution:  89%|████████▉ | 13411/15001 [00:23<00:01, 951.14it/s]Shapley Value Sampling attribution:  93%|█████████▎| 13896/15001 [00:23<00:01, 956.41it/s]Shapley Value Sampling attribution:  96%|█████████▌| 14381/15001 [00:24<00:00, 960.39it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14866/15001 [00:24<00:00, 962.98it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:24<00:00, 601.83it/s]
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:08<02:05,  8.99s/it]importance j:  13%|█▎        | 2/15 [00:22<02:33, 11.83s/it]importance j:  20%|██        | 3/15 [00:32<02:09, 10.77s/it]importance j:  27%|██▋       | 4/15 [00:44<02:06, 11.48s/it]importance j:  33%|███▎      | 5/15 [00:55<01:52, 11.23s/it]importance j:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]importance j:  47%|████▋     | 7/15 [01:18<01:31, 11.44s/it]importance j:  53%|█████▎    | 8/15 [01:27<01:14, 10.64s/it]importance j:  60%|██████    | 9/15 [01:39<01:07, 11.27s/it]importance j:  67%|██████▋   | 10/15 [01:48<00:52, 10.50s/it]importance j:  73%|███████▎  | 11/15 [02:00<00:43, 10.91s/it]importance j:  80%|████████  | 12/15 [02:09<00:31, 10.39s/it]importance j:  87%|████████▋ | 13/15 [02:19<00:20, 10.20s/it]importance j:  93%|█████████▎| 14/15 [02:31<00:10, 10.63s/it]importance j: 100%|██████████| 15/15 [02:40<00:00, 10.20s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7308334708213806, train_loss: 0.7245633602142334
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5190397500991821, train_loss: 0.43250346183776855
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5178033709526062, train_loss: 0.3993041515350342
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5184597373008728, train_loss: 0.39683184027671814
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5195564031600952, train_loss: 0.3935292661190033
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8945289254188538, train_loss: 0.8871109485626221
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6557307839393616, train_loss: 0.5686104893684387
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6020792126655579, train_loss: 0.4709793031215668
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5966292023658752, train_loss: 0.4174914062023163
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5979230403900146, train_loss: 0.4128293991088867
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6964313983917236, train_loss: 0.699048638343811
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5342222452163696, train_loss: 0.4747965335845947
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5090139508247375, train_loss: 0.403947114944458
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5013313293457031, train_loss: 0.36145853996276855
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5009393692016602, train_loss: 0.3271580934524536
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7913022041320801, train_loss: 0.7986542582511902
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5700781345367432, train_loss: 0.5266361832618713
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5481700301170349, train_loss: 0.4491123855113983
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5501794815063477, train_loss: 0.4496243894100189
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5515456199645996, train_loss: 0.43085798621177673
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5628219842910767, train_loss: 0.5269662737846375
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22314955294132233, train_loss: 0.14489960670471191
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21143440902233124, train_loss: 0.11874601989984512
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2104692906141281, train_loss: 0.09894087165594101
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20977148413658142, train_loss: 0.10367310047149658
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.2377914190292358, train_loss: 1.3318954706192017
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21575206518173218, train_loss: 0.15089093148708344
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21586813032627106, train_loss: 0.131394162774086
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21547377109527588, train_loss: 0.12628553807735443
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21521438658237457, train_loss: 0.12462460249662399
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7152461409568787, train_loss: 0.7210791110992432
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5466318130493164, train_loss: 0.42234599590301514
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5491747856140137, train_loss: 0.40580305457115173
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5511955618858337, train_loss: 0.3952450454235077
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5535561442375183, train_loss: 0.3937721252441406
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9631196856498718, train_loss: 0.9586925506591797
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6661079525947571, train_loss: 0.5341562628746033
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6107913255691528, train_loss: 0.4490242004394531
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5997953414916992, train_loss: 0.39870986342430115
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5991119146347046, train_loss: 0.3871217668056488
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5987966060638428, train_loss: 0.3946343660354614
[po_estimator_1_impute_pos] Epoch: 300, current validation loss: 0.5984663367271423, train_loss: 0.3768877685070038
[po_estimator_1_impute_pos] Epoch: 350, current validation loss: 0.598415732383728, train_loss: 0.3859001398086548
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7651433944702148, train_loss: 0.7031821012496948
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5858713388442993, train_loss: 0.4602951407432556
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5590837001800537, train_loss: 0.3956519067287445
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.554681658744812, train_loss: 0.3617454767227173
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5551796555519104, train_loss: 0.3489060401916504
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6106581091880798, train_loss: 0.6810749769210815
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5362560749053955, train_loss: 0.5049865245819092
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5271399617195129, train_loss: 0.4513084888458252
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5269054174423218, train_loss: 0.4414302706718445
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5275224447250366, train_loss: 0.4353707730770111
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5346530675888062, train_loss: 0.5335163474082947
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19885945320129395, train_loss: 0.13331158459186554
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19510266184806824, train_loss: 0.11197211593389511
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19506579637527466, train_loss: 0.11278147995471954
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19482484459877014, train_loss: 0.11061539500951767
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6139041185379028, train_loss: 0.7130782008171082
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19556477665901184, train_loss: 0.16014797985553741
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19129668176174164, train_loss: 0.1414615660905838
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19152094423770905, train_loss: 0.13616739213466644
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19137786328792572, train_loss: 0.13082526624202728
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6915028095245361, train_loss: 0.6863691210746765
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5204334855079651, train_loss: 0.424039363861084
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5182363390922546, train_loss: 0.38049405813217163
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5187780261039734, train_loss: 0.3854547142982483
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5196818709373474, train_loss: 0.3728894591331482
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7647200226783752, train_loss: 0.7380284070968628
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6147632002830505, train_loss: 0.4871382713317871
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6039671897888184, train_loss: 0.4363332986831665
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6044118404388428, train_loss: 0.44471073150634766
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6049193143844604, train_loss: 0.4213959574699402
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.611983597278595, train_loss: 0.6490786075592041
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5081430673599243, train_loss: 0.4354272782802582
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5040499567985535, train_loss: 0.3850821852684021
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5044418573379517, train_loss: 0.37534642219543457
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.504986584186554, train_loss: 0.38132715225219727
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6589988470077515, train_loss: 0.6834119558334351
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5373386740684509, train_loss: 0.5016753077507019
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5277435183525085, train_loss: 0.4365806579589844
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5274049043655396, train_loss: 0.420965313911438
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5274096727371216, train_loss: 0.40849873423576355
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2120882272720337, train_loss: 1.2389940023422241
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17776860296726227, train_loss: 0.13398006558418274
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1783006489276886, train_loss: 0.11302163451910019
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.17814069986343384, train_loss: 0.1155330166220665
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.17861974239349365, train_loss: 0.11265327781438828
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9563705921173096, train_loss: 0.9722825884819031
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2069099396467209, train_loss: 0.15462981164455414
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2025848925113678, train_loss: 0.12474896013736725
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20182180404663086, train_loss: 0.1263507455587387
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20121192932128906, train_loss: 0.12329114973545074
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6906012892723083, train_loss: 0.6600338220596313
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5153315663337708, train_loss: 0.4080430269241333
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5154702067375183, train_loss: 0.3806261420249939
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5165448188781738, train_loss: 0.37341946363449097
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5179365873336792, train_loss: 0.3575431704521179
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7190518379211426, train_loss: 0.7044439315795898
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6028932332992554, train_loss: 0.47430896759033203
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5863166451454163, train_loss: 0.42376574873924255
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5840441584587097, train_loss: 0.4007551074028015
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5834432244300842, train_loss: 0.3952283263206482
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8153723478317261, train_loss: 0.8366701006889343
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5758935809135437, train_loss: 0.4749223589897156
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5368014574050903, train_loss: 0.39150315523147583
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5314710140228271, train_loss: 0.34457311034202576
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5313809514045715, train_loss: 0.34707963466644287
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6688106656074524, train_loss: 0.7282840609550476
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5390901565551758, train_loss: 0.4873363971710205
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5362856984138489, train_loss: 0.45252928137779236
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5359684228897095, train_loss: 0.4425722360610962
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5358108878135681, train_loss: 0.44658908247947693
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9350989460945129, train_loss: 0.9549105763435364
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21627593040466309, train_loss: 0.12248299270868301
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21574728190898895, train_loss: 0.10708051174879074
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21537084877490997, train_loss: 0.10354965180158615
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21481961011886597, train_loss: 0.10374684631824493
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4486147463321686, train_loss: 0.4913075864315033
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1983576864004135, train_loss: 0.14924493432044983
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19646091759204865, train_loss: 0.12883609533309937
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19616056978702545, train_loss: 0.12765708565711975
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19614121317863464, train_loss: 0.12468469142913818
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.782938539981842, train_loss: 0.782484769821167
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5873802900314331, train_loss: 0.4805006682872772
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5845599174499512, train_loss: 0.4388807713985443
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5854333639144897, train_loss: 0.43820247054100037
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.586512565612793, train_loss: 0.43175262212753296
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7021897435188293, train_loss: 0.6894530057907104
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6005798578262329, train_loss: 0.5090417265892029
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5882928967475891, train_loss: 0.44576096534729004
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.587042510509491, train_loss: 0.43493127822875977
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5863773822784424, train_loss: 0.42846354842185974
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5858893394470215, train_loss: 0.42085573077201843
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7652779817581177, train_loss: 0.7592425346374512
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6336298584938049, train_loss: 0.4874424636363983
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6289744973182678, train_loss: 0.4414249360561371
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6293338537216187, train_loss: 0.4320261478424072
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6299928426742554, train_loss: 0.4253184199333191
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8201596736907959, train_loss: 0.7798277139663696
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6252057552337646, train_loss: 0.5363467335700989
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6070986390113831, train_loss: 0.4636973738670349
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.607382595539093, train_loss: 0.4509894847869873
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.607675313949585, train_loss: 0.44766920804977417
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4929591119289398, train_loss: 0.4897006154060364
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21186694502830505, train_loss: 0.15434502065181732
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21044456958770752, train_loss: 0.12998954951763153
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21060428023338318, train_loss: 0.12604427337646484
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21080945432186127, train_loss: 0.12367480993270874
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8603048920631409, train_loss: 0.9380165338516235
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23648999631404877, train_loss: 0.1500040590763092
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.23610074818134308, train_loss: 0.13925646245479584
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.23624274134635925, train_loss: 0.1340760886669159
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.23680166900157928, train_loss: 0.13297238945960999
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.888121485710144, train_loss: 0.9234468340873718
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5832821726799011, train_loss: 0.4809562861919403
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5625925660133362, train_loss: 0.38997411727905273
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5630521178245544, train_loss: 0.37388861179351807
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5633845329284668, train_loss: 0.3891807198524475
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6977725028991699, train_loss: 0.7264239192008972
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5947062373161316, train_loss: 0.47081172466278076
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5961688160896301, train_loss: 0.4543536305427551
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5978102087974548, train_loss: 0.45418787002563477
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5995836853981018, train_loss: 0.45990413427352905
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0076814889907837, train_loss: 0.9891855716705322
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6533098816871643, train_loss: 0.5129662752151489
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5731686949729919, train_loss: 0.39663204550743103
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5505822896957397, train_loss: 0.3323118984699249
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.550011396408081, train_loss: 0.32314473390579224
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6977090835571289, train_loss: 0.6944977045059204
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.562947690486908, train_loss: 0.4762418270111084
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5607925653457642, train_loss: 0.4508802592754364
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.56086665391922, train_loss: 0.44410666823387146
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5611141920089722, train_loss: 0.4403845965862274
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4804878830909729, train_loss: 0.5523848533630371
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2049584686756134, train_loss: 0.12825869023799896
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20511846244335175, train_loss: 0.11960496753454208
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20557992160320282, train_loss: 0.11526896804571152
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2059333771467209, train_loss: 0.11340519040822983
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6291205286979675, train_loss: 0.7135135531425476
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19843506813049316, train_loss: 0.15444880723953247
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1978864222764969, train_loss: 0.14613167941570282
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1983322948217392, train_loss: 0.14075399935245514
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1981169432401657, train_loss: 0.13971126079559326
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8246654272079468, train_loss: 0.8734860420227051
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5437718033790588, train_loss: 0.45798739790916443
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.53497713804245, train_loss: 0.3962108790874481
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5354520678520203, train_loss: 0.37908899784088135
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5361095666885376, train_loss: 0.3763675093650818
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.706815242767334, train_loss: 0.7247728705406189
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5966929793357849, train_loss: 0.4792219400405884
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5921190977096558, train_loss: 0.43175503611564636
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.592660129070282, train_loss: 0.42323970794677734
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5929322838783264, train_loss: 0.43160396814346313
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.780943751335144, train_loss: 0.7994811534881592
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5457519292831421, train_loss: 0.4676567018032074
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5170298218727112, train_loss: 0.38147103786468506
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5153939127922058, train_loss: 0.35468143224716187
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5161279439926147, train_loss: 0.3485327959060669
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7510157227516174, train_loss: 0.8108919858932495
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5409736037254333, train_loss: 0.4965118169784546
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.526490330696106, train_loss: 0.4470199942588806
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5263336300849915, train_loss: 0.4458634853363037
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.526477575302124, train_loss: 0.4272480905056
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.4153164625167847, train_loss: 1.4299489259719849
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2027461975812912, train_loss: 0.13401073217391968
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20037326216697693, train_loss: 0.10904403775930405
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2001342922449112, train_loss: 0.09938590973615646
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2003406435251236, train_loss: 0.1018025279045105
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5841618180274963, train_loss: 0.6877081990242004
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.18997003138065338, train_loss: 0.15649151802062988
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1888824701309204, train_loss: 0.13271479308605194
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.18910905718803406, train_loss: 0.12795811891555786
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.18935847282409668, train_loss: 0.13350991904735565
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6935538649559021, train_loss: 0.66263747215271
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5359715223312378, train_loss: 0.4206717908382416
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.527388870716095, train_loss: 0.3684017062187195
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5277546644210815, train_loss: 0.3524278402328491
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5284290909767151, train_loss: 0.35695719718933105
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7488793134689331, train_loss: 0.7582120895385742
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6178414821624756, train_loss: 0.5088436603546143
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6046769022941589, train_loss: 0.4379323720932007
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6044081449508667, train_loss: 0.42705482244491577
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6041531562805176, train_loss: 0.416398286819458
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7062088251113892, train_loss: 0.6806046366691589
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.543923556804657, train_loss: 0.44999465346336365
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.524665117263794, train_loss: 0.3963063955307007
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.523971438407898, train_loss: 0.3652138113975525
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5246883630752563, train_loss: 0.35909003019332886
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6917957663536072, train_loss: 0.6710513830184937
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5515367388725281, train_loss: 0.4851076006889343
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5486910939216614, train_loss: 0.45781540870666504
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5489200353622437, train_loss: 0.44909101724624634
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5489841103553772, train_loss: 0.4415934979915619
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.33955103158950806, train_loss: 0.3551163077354431
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2041609287261963, train_loss: 0.12300660461187363
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20053358376026154, train_loss: 0.10176251083612442
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20006823539733887, train_loss: 0.10016901791095734
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19961221516132355, train_loss: 0.10042380541563034
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.36994948983192444, train_loss: 0.4452977180480957
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20461153984069824, train_loss: 0.16755889356136322
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20454619824886322, train_loss: 0.1620456874370575
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20508992671966553, train_loss: 0.15819571912288666
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20509065687656403, train_loss: 0.1523158997297287
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6667038202285767, train_loss: 0.6149435043334961
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.544539749622345, train_loss: 0.4097118377685547
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5453752279281616, train_loss: 0.3885757327079773
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5464301109313965, train_loss: 0.38268065452575684
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5474770069122314, train_loss: 0.3761134147644043
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.662792980670929, train_loss: 0.6578539609909058
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5981281399726868, train_loss: 0.4716791808605194
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5980907678604126, train_loss: 0.45482370257377625
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5986577272415161, train_loss: 0.44098609685897827
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5997249484062195, train_loss: 0.43819162249565125
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6861883401870728, train_loss: 0.6919814944267273
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5436445474624634, train_loss: 0.43906423449516296
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5437816381454468, train_loss: 0.41325482726097107
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5439137816429138, train_loss: 0.4050031304359436
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5445468425750732, train_loss: 0.3999808728694916
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7439594268798828, train_loss: 0.7902177572250366
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5394461750984192, train_loss: 0.498812198638916
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5290893316268921, train_loss: 0.42958447337150574
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5300602316856384, train_loss: 0.4310069978237152
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5309649109840393, train_loss: 0.41833043098449707
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5035235285758972, train_loss: 0.4942470192909241
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19119127094745636, train_loss: 0.13115213811397552
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19114723801612854, train_loss: 0.11543946713209152
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19116589426994324, train_loss: 0.11895010620355606
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19103816151618958, train_loss: 0.11267918348312378
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8115189671516418, train_loss: 0.8154997825622559
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21271087229251862, train_loss: 0.15394264459609985
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20891131460666656, train_loss: 0.1331200748682022
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20850162208080292, train_loss: 0.12766195833683014
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20909550786018372, train_loss: 0.12577621638774872
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6889016032218933, train_loss: 0.6991298198699951
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.513467013835907, train_loss: 0.41526222229003906
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5110927224159241, train_loss: 0.3759079873561859
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5119495391845703, train_loss: 0.3714481294155121
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5132021903991699, train_loss: 0.3657170236110687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7271522283554077, train_loss: 0.7551915049552917
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6110633015632629, train_loss: 0.49186277389526367
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6035130023956299, train_loss: 0.421435683965683
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6028717160224915, train_loss: 0.41194042563438416
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6025038361549377, train_loss: 0.4072917699813843
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7936201691627502, train_loss: 0.839108407497406
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5317962765693665, train_loss: 0.46346724033355713
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5085756778717041, train_loss: 0.37996286153793335
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5087485909461975, train_loss: 0.3741747736930847
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5093101859092712, train_loss: 0.34832143783569336
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6937115788459778, train_loss: 0.6727232933044434
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.57590651512146, train_loss: 0.5016144514083862
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5641819834709167, train_loss: 0.4417010247707367
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5622991919517517, train_loss: 0.4159795045852661
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5617952942848206, train_loss: 0.4258905351161957
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44129249453544617, train_loss: 0.42526674270629883
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22919096052646637, train_loss: 0.13262875378131866
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22250373661518097, train_loss: 0.10036341100931168
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2222563624382019, train_loss: 0.09648875147104263
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22220151126384735, train_loss: 0.09967090934515
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5136302709579468, train_loss: 0.4865979254245758
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21552301943302155, train_loss: 0.16616074740886688
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20508399605751038, train_loss: 0.13181836903095245
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20502768456935883, train_loss: 0.1299929916858673
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2049361616373062, train_loss: 0.12778332829475403
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6905480027198792, train_loss: 0.7080332636833191
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5406026840209961, train_loss: 0.44368812441825867
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5320432186126709, train_loss: 0.3882470726966858
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5322391986846924, train_loss: 0.3853154182434082
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5324231386184692, train_loss: 0.3701096475124359
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7072407007217407, train_loss: 0.7342998385429382
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5830575823783875, train_loss: 0.5021988749504089
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5822601318359375, train_loss: 0.45239830017089844
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5829501152038574, train_loss: 0.4497014880180359
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5836235880851746, train_loss: 0.44754892587661743
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6312935948371887, train_loss: 0.6910220384597778
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5169507265090942, train_loss: 0.4563950002193451
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5150071978569031, train_loss: 0.4028701186180115
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.515274167060852, train_loss: 0.3925802409648895
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.515832781791687, train_loss: 0.3901078701019287
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7519725561141968, train_loss: 0.7755534052848816
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5602163076400757, train_loss: 0.5117806792259216
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5408430695533752, train_loss: 0.4323870539665222
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5354946255683899, train_loss: 0.42144355177879333
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5359663963317871, train_loss: 0.4088149070739746
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8721448183059692, train_loss: 0.9526243209838867
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19839325547218323, train_loss: 0.12362418323755264
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1974261850118637, train_loss: 0.11418356746435165
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19705328345298767, train_loss: 0.10819561779499054
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19704799354076385, train_loss: 0.10685864835977554
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6030046939849854, train_loss: 0.6400728225708008
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21052522957324982, train_loss: 0.17721325159072876
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2078767567873001, train_loss: 0.14577558636665344
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20748929679393768, train_loss: 0.14577308297157288
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20720632374286652, train_loss: 0.14128851890563965
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6954670548439026, train_loss: 0.7033981084823608
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5279030203819275, train_loss: 0.41972655057907104
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5256045460700989, train_loss: 0.37520715594291687
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5265240669250488, train_loss: 0.38551902770996094
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5276995897293091, train_loss: 0.35939741134643555
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7088497877120972, train_loss: 0.7136885523796082
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6142503023147583, train_loss: 0.47139567136764526
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6136115789413452, train_loss: 0.4389581084251404
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6140482425689697, train_loss: 0.43765005469322205
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6145257949829102, train_loss: 0.4208257794380188
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8045651912689209, train_loss: 0.7893998622894287
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.611428439617157, train_loss: 0.4925330579280853
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5714883804321289, train_loss: 0.3948655128479004
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5611936450004578, train_loss: 0.3266061246395111
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5598775744438171, train_loss: 0.31708550453186035
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7895452380180359, train_loss: 0.7683120965957642
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5797116756439209, train_loss: 0.5172315835952759
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5485667586326599, train_loss: 0.43868154287338257
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5482251048088074, train_loss: 0.42366212606430054
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5486260056495667, train_loss: 0.41776204109191895
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6862977743148804, train_loss: 0.7273228764533997
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20246592164039612, train_loss: 0.12188444286584854
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2018205225467682, train_loss: 0.11693437397480011
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20177717506885529, train_loss: 0.10825750976800919
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20204100012779236, train_loss: 0.10693182051181793
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4390442967414856, train_loss: 0.5580374002456665
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20138075947761536, train_loss: 0.15723775327205658
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20081408321857452, train_loss: 0.15020647644996643
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20007717609405518, train_loss: 0.1439874917268753
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19984158873558044, train_loss: 0.13364054262638092
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8323979377746582, train_loss: 0.8816628456115723
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5666002035140991, train_loss: 0.49014031887054443
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.543319046497345, train_loss: 0.38403409719467163
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5438919067382812, train_loss: 0.3789413571357727
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5444269776344299, train_loss: 0.37346363067626953
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7629345059394836, train_loss: 0.781061589717865
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5911989808082581, train_loss: 0.5026406645774841
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5808828473091125, train_loss: 0.4292566180229187
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.581282913684845, train_loss: 0.4161738157272339
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5819432735443115, train_loss: 0.41093215346336365
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7483831644058228, train_loss: 0.6770691871643066
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.588470995426178, train_loss: 0.45679569244384766
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.560027539730072, train_loss: 0.3821665644645691
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5556934475898743, train_loss: 0.34762606024742126
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5557146668434143, train_loss: 0.3446110188961029
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7065184116363525, train_loss: 0.7266380190849304
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5474233031272888, train_loss: 0.5070047378540039
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5421748757362366, train_loss: 0.4474674165248871
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5426698923110962, train_loss: 0.449800968170166
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5428469777107239, train_loss: 0.4441303014755249
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5395944714546204, train_loss: 0.5700711607933044
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20567046105861664, train_loss: 0.14258348941802979
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19801564514636993, train_loss: 0.10602054744958878
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19731421768665314, train_loss: 0.09699999541044235
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19738583266735077, train_loss: 0.09699888527393341
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41085371375083923, train_loss: 0.41050073504447937
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21152053773403168, train_loss: 0.15502150356769562
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20353826880455017, train_loss: 0.12866057455539703
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20334990322589874, train_loss: 0.12581521272659302
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20342043042182922, train_loss: 0.12180497497320175
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6802313923835754, train_loss: 0.6204478144645691
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5469253659248352, train_loss: 0.4230216443538666
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5443735122680664, train_loss: 0.3699047565460205
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5452578663825989, train_loss: 0.3703119158744812
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5464198589324951, train_loss: 0.36545389890670776
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6289784908294678, train_loss: 0.6562143564224243
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5582568645477295, train_loss: 0.4748629927635193
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5570512413978577, train_loss: 0.43825191259384155
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5571568608283997, train_loss: 0.42893487215042114
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5573831796646118, train_loss: 0.42767858505249023
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.65873122215271, train_loss: 0.6771515607833862
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5314850211143494, train_loss: 0.42835530638694763
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5261041522026062, train_loss: 0.3838750123977661
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.526183009147644, train_loss: 0.37266016006469727
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5267812013626099, train_loss: 0.35893648862838745
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6851367354393005, train_loss: 0.6860529184341431
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5406991839408875, train_loss: 0.48966917395591736
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5336072444915771, train_loss: 0.4348120391368866
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5341668725013733, train_loss: 0.4281247556209564
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5347471833229065, train_loss: 0.4213765859603882
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5223422050476074, train_loss: 0.522792398929596
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.221061110496521, train_loss: 0.13134221732616425
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21639947593212128, train_loss: 0.10714554786682129
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21546514332294464, train_loss: 0.10292013734579086
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2151186168193817, train_loss: 0.10224218666553497
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3296813368797302, train_loss: 0.4216122329235077
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20670387148857117, train_loss: 0.16064411401748657
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20600421726703644, train_loss: 0.13951486349105835
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20569336414337158, train_loss: 0.1384820193052292
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20602105557918549, train_loss: 0.1297532618045807
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7233960032463074, train_loss: 0.6650218963623047
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5424296259880066, train_loss: 0.416726291179657
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5408294796943665, train_loss: 0.3710886240005493
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5418155789375305, train_loss: 0.3638354241847992
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.543340802192688, train_loss: 0.3547949492931366
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8259516358375549, train_loss: 0.823349118232727
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6133464574813843, train_loss: 0.5050839185714722
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5854918360710144, train_loss: 0.4318961799144745
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5848696827888489, train_loss: 0.4073432683944702
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5843807458877563, train_loss: 0.4137681722640991
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7335923910140991, train_loss: 0.7713314890861511
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.555047333240509, train_loss: 0.46712252497673035
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5325421094894409, train_loss: 0.3795406222343445
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5326100587844849, train_loss: 0.365531861782074
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.532739520072937, train_loss: 0.3598414659500122
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.671295166015625, train_loss: 0.6696031093597412
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5491228699684143, train_loss: 0.4788386821746826
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.548404335975647, train_loss: 0.44126051664352417
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5490549206733704, train_loss: 0.42102640867233276
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5497046709060669, train_loss: 0.4303576350212097
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5403307676315308, train_loss: 0.5414038896560669
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.23972764611244202, train_loss: 0.1427314281463623
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2291017323732376, train_loss: 0.11659915745258331
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22987443208694458, train_loss: 0.10548710823059082
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22935797274112701, train_loss: 0.10451330989599228
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.47020629048347473, train_loss: 0.514096200466156
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20984870195388794, train_loss: 0.15284278988838196
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20640037953853607, train_loss: 0.13522613048553467
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20624205470085144, train_loss: 0.13275325298309326
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20633211731910706, train_loss: 0.12745454907417297
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:13<03:04, 13.16s/it]importance j:  13%|█▎        | 2/15 [00:21<02:16, 10.52s/it]importance j:  20%|██        | 3/15 [00:33<02:10, 10.84s/it]importance j:  27%|██▋       | 4/15 [00:43<01:58, 10.79s/it]importance j:  33%|███▎      | 5/15 [00:52<01:41, 10.14s/it]importance j:  40%|████      | 6/15 [01:05<01:38, 11.00s/it]importance j:  47%|████▋     | 7/15 [01:14<01:22, 10.34s/it]importance j:  53%|█████▎    | 8/15 [01:27<01:18, 11.16s/it]importance j:  60%|██████    | 9/15 [01:36<01:03, 10.53s/it]importance j:  67%|██████▋   | 10/15 [01:47<00:53, 10.79s/it]importance j:  73%|███████▎  | 11/15 [01:58<00:42, 10.69s/it]importance j:  80%|████████  | 12/15 [02:07<00:30, 10.25s/it]importance j:  87%|████████▋ | 13/15 [02:21<00:23, 11.52s/it]importance j:  93%|█████████▎| 14/15 [02:30<00:10, 10.74s/it]importance j: 100%|██████████| 15/15 [02:44<00:00, 11.54s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9163904190063477, train_loss: 0.9762294292449951
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5578693747520447, train_loss: 0.5099766850471497
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.52601557970047, train_loss: 0.41061949729919434
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5250963568687439, train_loss: 0.38747668266296387
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5255351066589355, train_loss: 0.37293192744255066
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6848098039627075, train_loss: 0.6754988431930542
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.591410219669342, train_loss: 0.49677011370658875
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.586464524269104, train_loss: 0.45467352867126465
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5861152410507202, train_loss: 0.4557619094848633
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5863117575645447, train_loss: 0.4395958185195923
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5453100800514221, train_loss: 0.5943937301635742
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47485435009002686, train_loss: 0.4306252598762512
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.47409355640411377, train_loss: 0.38249731063842773
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.47430703043937683, train_loss: 0.3771723210811615
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.47455868124961853, train_loss: 0.37843260169029236
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.75489741563797, train_loss: 0.7289016246795654
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6056100726127625, train_loss: 0.4985494613647461
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5786013603210449, train_loss: 0.4461422860622406
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5795372724533081, train_loss: 0.4407433867454529
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5798926949501038, train_loss: 0.4267137050628662
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7594184279441833, train_loss: 0.7474513649940491
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21293629705905914, train_loss: 0.1347397118806839
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20619061589241028, train_loss: 0.10289168357849121
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20658105611801147, train_loss: 0.09779822081327438
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20632046461105347, train_loss: 0.09766348451375961
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7384938597679138, train_loss: 0.830636203289032
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19357265532016754, train_loss: 0.15536823868751526
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1888524740934372, train_loss: 0.13500569760799408
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.18875841796398163, train_loss: 0.1304813176393509
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1886259913444519, train_loss: 0.12330037355422974
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6539254188537598, train_loss: 0.6056426763534546
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5475523471832275, train_loss: 0.4128532111644745
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.549450159072876, train_loss: 0.40143370628356934
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5510210394859314, train_loss: 0.38627883791923523
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5527679324150085, train_loss: 0.3831936717033386
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7037832140922546, train_loss: 0.7066299915313721
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5942134261131287, train_loss: 0.4729120135307312
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5942414999008179, train_loss: 0.44548487663269043
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5946000814437866, train_loss: 0.4392812252044678
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5954462289810181, train_loss: 0.4375302493572235
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6652498841285706, train_loss: 0.6835956573486328
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5278059840202332, train_loss: 0.4482209086418152
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5158992409706116, train_loss: 0.37682220339775085
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5159878730773926, train_loss: 0.3697969913482666
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.516291081905365, train_loss: 0.3622607886791229
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7229877710342407, train_loss: 0.7994488477706909
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5688530802726746, train_loss: 0.52763432264328
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5537254810333252, train_loss: 0.4549858570098877
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5515434741973877, train_loss: 0.42738303542137146
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5513722896575928, train_loss: 0.43626588582992554
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5363554954528809, train_loss: 0.5702810287475586
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18298524618148804, train_loss: 0.14230109751224518
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1834849715232849, train_loss: 0.1303652822971344
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18442896008491516, train_loss: 0.12939080595970154
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18550877273082733, train_loss: 0.12484290450811386
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.42069390416145325, train_loss: 0.46868109703063965
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21012979745864868, train_loss: 0.1597195565700531
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21009591221809387, train_loss: 0.14183969795703888
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20967236161231995, train_loss: 0.13875167071819305
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21008256077766418, train_loss: 0.1340460330247879
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6905790567398071, train_loss: 0.6508485674858093
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5246178507804871, train_loss: 0.41686365008354187
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5227915048599243, train_loss: 0.3828020989894867
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.523508608341217, train_loss: 0.38291501998901367
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.524480402469635, train_loss: 0.3804147243499756
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9618203043937683, train_loss: 0.9379897117614746
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.7178296446800232, train_loss: 0.5499898791313171
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6499260663986206, train_loss: 0.442996084690094
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6306573748588562, train_loss: 0.404085636138916
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6302007436752319, train_loss: 0.39100074768066406
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8020392656326294, train_loss: 0.7717132568359375
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5815282464027405, train_loss: 0.4542155861854553
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5533721446990967, train_loss: 0.36582493782043457
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.550310492515564, train_loss: 0.326335608959198
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5510859489440918, train_loss: 0.3250712454319
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7555562257766724, train_loss: 0.7525296211242676
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5492221713066101, train_loss: 0.514877200126648
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5234556198120117, train_loss: 0.4644553065299988
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5203179717063904, train_loss: 0.4191940426826477
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5207544565200806, train_loss: 0.40196388959884644
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4250038266181946, train_loss: 0.4884067177772522
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18446141481399536, train_loss: 0.13247127830982208
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18347834050655365, train_loss: 0.11801891773939133
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18397140502929688, train_loss: 0.10604119300842285
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18417784571647644, train_loss: 0.10533968359231949
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5505125522613525, train_loss: 0.6134674549102783
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22924068570137024, train_loss: 0.1616971790790558
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2243967056274414, train_loss: 0.141793355345726
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22421327233314514, train_loss: 0.13383036851882935
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22461535036563873, train_loss: 0.13492821156978607
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7376638650894165, train_loss: 0.7540740966796875
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5185693502426147, train_loss: 0.4343101978302002
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5133441090583801, train_loss: 0.3956370949745178
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5140241980552673, train_loss: 0.38393545150756836
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5149181485176086, train_loss: 0.37849101424217224
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6713478565216064, train_loss: 0.6558462381362915
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5929275155067444, train_loss: 0.4862428605556488
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5897402763366699, train_loss: 0.43454357981681824
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5899794697761536, train_loss: 0.428558349609375
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5903512835502625, train_loss: 0.41805100440979004
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7948462963104248, train_loss: 0.797379195690155
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5736598372459412, train_loss: 0.48638224601745605
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5331886410713196, train_loss: 0.38905438780784607
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5280817151069641, train_loss: 0.360021710395813
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.528301477432251, train_loss: 0.3570816218852997
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6511757373809814, train_loss: 0.7044075727462769
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5066227912902832, train_loss: 0.47974154353141785
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5005554556846619, train_loss: 0.43475341796875
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5008145570755005, train_loss: 0.42913883924484253
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5012355446815491, train_loss: 0.41076335310935974
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5766055583953857, train_loss: 0.6143764853477478
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20017406344413757, train_loss: 0.1373692750930786
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19819346070289612, train_loss: 0.11642201244831085
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19823959469795227, train_loss: 0.11219374090433121
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19869087636470795, train_loss: 0.10927484184503555
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4435661733150482, train_loss: 0.5952072143554688
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2004370242357254, train_loss: 0.1665755957365036
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20088419318199158, train_loss: 0.16014474630355835
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20118726789951324, train_loss: 0.1561489999294281
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2011641263961792, train_loss: 0.15554840862751007
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6975493431091309, train_loss: 0.689344584941864
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5872987508773804, train_loss: 0.45361757278442383
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5878477096557617, train_loss: 0.4341074824333191
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5885990262031555, train_loss: 0.43170738220214844
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5897672176361084, train_loss: 0.42215365171432495
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8725460767745972, train_loss: 0.8720619678497314
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6217131614685059, train_loss: 0.5272519588470459
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6001845002174377, train_loss: 0.46293994784355164
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5957363247871399, train_loss: 0.41895395517349243
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5960103869438171, train_loss: 0.4170410633087158
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6738659739494324, train_loss: 0.7189253568649292
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5965451598167419, train_loss: 0.4898347854614258
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5972195267677307, train_loss: 0.4382217824459076
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5989327430725098, train_loss: 0.42836588621139526
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6006916761398315, train_loss: 0.4208153486251831
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7342111468315125, train_loss: 0.7002294063568115
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.589209794998169, train_loss: 0.5307958126068115
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.587225079536438, train_loss: 0.5010296106338501
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.587447464466095, train_loss: 0.49122413992881775
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5881853699684143, train_loss: 0.48611873388290405
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4189568758010864, train_loss: 0.46095362305641174
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22957812249660492, train_loss: 0.1540016233921051
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22964106500148773, train_loss: 0.131703183054924
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22965213656425476, train_loss: 0.1282835751771927
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2298799753189087, train_loss: 0.12944860756397247
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4227023422718048, train_loss: 0.4882518947124481
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24421212077140808, train_loss: 0.18944044411182404
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2411888688802719, train_loss: 0.15098167955875397
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.24084614217281342, train_loss: 0.147433802485466
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2411930114030838, train_loss: 0.14421722292900085
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7628228664398193, train_loss: 0.7650085687637329
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5370188355445862, train_loss: 0.4544149339199066
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5253241658210754, train_loss: 0.3798008859157562
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5260828733444214, train_loss: 0.37925708293914795
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5267895460128784, train_loss: 0.3644368648529053
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9247966408729553, train_loss: 0.9417213201522827
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6155977845191956, train_loss: 0.5073093175888062
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5977638959884644, train_loss: 0.43417614698410034
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5971614122390747, train_loss: 0.42206764221191406
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5971278548240662, train_loss: 0.43675434589385986
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7885131239891052, train_loss: 0.791187047958374
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5849899649620056, train_loss: 0.4942401051521301
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5466887354850769, train_loss: 0.3954942226409912
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5384811162948608, train_loss: 0.3369714021682739
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5380494594573975, train_loss: 0.3272685110569
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7734208703041077, train_loss: 0.812090277671814
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5446906089782715, train_loss: 0.48863857984542847
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5401089787483215, train_loss: 0.44336017966270447
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5404790639877319, train_loss: 0.4378301799297333
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5407280921936035, train_loss: 0.4401646554470062
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6069782972335815, train_loss: 0.6892010569572449
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2148737758398056, train_loss: 0.12884697318077087
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21264943480491638, train_loss: 0.1066887378692627
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21247749030590057, train_loss: 0.10628118366003036
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21227999031543732, train_loss: 0.0998271107673645
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4807869493961334, train_loss: 0.5744112133979797
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2083737701177597, train_loss: 0.16614177823066711
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20798315107822418, train_loss: 0.1490871161222458
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20822075009346008, train_loss: 0.1451195329427719
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20829235017299652, train_loss: 0.13827675580978394
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7130704522132874, train_loss: 0.7363070249557495
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5102541446685791, train_loss: 0.4359027147293091
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5017784833908081, train_loss: 0.3704427182674408
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5022642016410828, train_loss: 0.37888890504837036
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5028700828552246, train_loss: 0.3687478303909302
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6437147855758667, train_loss: 0.6858195066452026
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5851886868476868, train_loss: 0.4775281846523285
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5864319205284119, train_loss: 0.4690609872341156
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5874322056770325, train_loss: 0.4749698042869568
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.58844393491745, train_loss: 0.4530503451824188
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8382328152656555, train_loss: 0.8611429929733276
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5770502686500549, train_loss: 0.4895595908164978
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5433478355407715, train_loss: 0.3933316171169281
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5426187515258789, train_loss: 0.3743692636489868
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5428804755210876, train_loss: 0.37221992015838623
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8122815489768982, train_loss: 0.8125569224357605
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5527345538139343, train_loss: 0.504749059677124
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5207693576812744, train_loss: 0.4388771057128906
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5191728472709656, train_loss: 0.4066894054412842
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5188953876495361, train_loss: 0.3935457170009613
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3669716417789459, train_loss: 0.38292744755744934
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18774092197418213, train_loss: 0.12911294400691986
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18732133507728577, train_loss: 0.12032725661993027
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18748649954795837, train_loss: 0.1156572699546814
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18781009316444397, train_loss: 0.11243126541376114
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6130694150924683, train_loss: 0.6787958145141602
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1973058134317398, train_loss: 0.15990661084651947
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19456881284713745, train_loss: 0.13262473046779633
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19420833885669708, train_loss: 0.12825918197631836
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19325439631938934, train_loss: 0.12343468517065048
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7366281747817993, train_loss: 0.7527379989624023
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5539857745170593, train_loss: 0.45083343982696533
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5510503649711609, train_loss: 0.3854513168334961
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5518997311592102, train_loss: 0.3804311752319336
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5526133179664612, train_loss: 0.37885475158691406
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.691983699798584, train_loss: 0.722427248954773
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5796452164649963, train_loss: 0.49771445989608765
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.565674364566803, train_loss: 0.4264807105064392
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5661497116088867, train_loss: 0.4215414226055145
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5666812658309937, train_loss: 0.4204410910606384
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6406073570251465, train_loss: 0.6673489809036255
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5086556673049927, train_loss: 0.4432928264141083
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4970821142196655, train_loss: 0.37373608350753784
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4968796670436859, train_loss: 0.37023770809173584
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.49727001786231995, train_loss: 0.3649391829967499
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9396077990531921, train_loss: 0.8972933292388916
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6286777853965759, train_loss: 0.5349531173706055
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5723267793655396, train_loss: 0.44374892115592957
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5585216283798218, train_loss: 0.39700847864151
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5589162707328796, train_loss: 0.39144736528396606
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4202912747859955, train_loss: 0.46356797218322754
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20987333357334137, train_loss: 0.13101468980312347
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20805959403514862, train_loss: 0.10803010314702988
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20815663039684296, train_loss: 0.10395721346139908
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2081657201051712, train_loss: 0.10399004071950912
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.36468151211738586, train_loss: 0.44981813430786133
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19282042980194092, train_loss: 0.16599483788013458
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1871144026517868, train_loss: 0.1278967708349228
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1873045116662979, train_loss: 0.12584206461906433
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1868876814842224, train_loss: 0.12238717079162598
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.622808039188385, train_loss: 0.6129468679428101
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5255948305130005, train_loss: 0.4169124960899353
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5269087553024292, train_loss: 0.3899131715297699
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5278792381286621, train_loss: 0.4071882367134094
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5291666388511658, train_loss: 0.38676345348358154
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6409813165664673, train_loss: 0.6129852533340454
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5921026468276978, train_loss: 0.4806198477745056
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5918160676956177, train_loss: 0.44899818301200867
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5924525856971741, train_loss: 0.43783944845199585
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5930045247077942, train_loss: 0.429559588432312
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8048381209373474, train_loss: 0.8710240125656128
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5448884963989258, train_loss: 0.48169875144958496
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5301985740661621, train_loss: 0.377733439207077
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5312780141830444, train_loss: 0.37113475799560547
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5315437912940979, train_loss: 0.364205539226532
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7378345131874084, train_loss: 0.7741872668266296
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.556771993637085, train_loss: 0.5021309852600098
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5542880296707153, train_loss: 0.45640748739242554
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5547624230384827, train_loss: 0.45467185974121094
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5560014247894287, train_loss: 0.4532690942287445
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3746908903121948, train_loss: 0.43363896012306213
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2028234302997589, train_loss: 0.14262957870960236
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20273929834365845, train_loss: 0.13603316247463226
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20310024917125702, train_loss: 0.13085278868675232
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2038571983575821, train_loss: 0.1274927258491516
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6845929622650146, train_loss: 0.7528242468833923
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21521994471549988, train_loss: 0.150193452835083
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21317477524280548, train_loss: 0.12855367362499237
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21338391304016113, train_loss: 0.12151246517896652
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21282783150672913, train_loss: 0.12155327945947647
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7734184861183167, train_loss: 0.7770811319351196
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5462696552276611, train_loss: 0.46886205673217773
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.52435702085495, train_loss: 0.3815842568874359
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5247746109962463, train_loss: 0.3591550290584564
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.525268018245697, train_loss: 0.359668493270874
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7324180006980896, train_loss: 0.7050495147705078
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6247590780258179, train_loss: 0.4775490164756775
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6084603071212769, train_loss: 0.4235626459121704
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6104975938796997, train_loss: 0.40481990575790405
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6111993789672852, train_loss: 0.40009379386901855
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6863086223602295, train_loss: 0.6693322062492371
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5480185151100159, train_loss: 0.43570202589035034
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5398236513137817, train_loss: 0.3642510771751404
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5403856039047241, train_loss: 0.35762032866477966
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5406895279884338, train_loss: 0.35820531845092773
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5808632969856262, train_loss: 0.6054818630218506
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5251617431640625, train_loss: 0.4752581715583801
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5248239040374756, train_loss: 0.4526606500148773
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5248682498931885, train_loss: 0.44818028807640076
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.525130569934845, train_loss: 0.44285792112350464
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3990216553211212, train_loss: 0.41970396041870117
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19935061037540436, train_loss: 0.13023154437541962
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19847847521305084, train_loss: 0.1142033115029335
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1986427903175354, train_loss: 0.1106007844209671
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19860607385635376, train_loss: 0.10704489052295685
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.36738184094429016, train_loss: 0.40509292483329773
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20248350501060486, train_loss: 0.15491819381713867
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2007312774658203, train_loss: 0.12509319186210632
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2005072981119156, train_loss: 0.12052349001169205
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20029711723327637, train_loss: 0.11775833368301392
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.74894779920578, train_loss: 0.7056840658187866
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5742117166519165, train_loss: 0.4423215091228485
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5629324913024902, train_loss: 0.3845313489437103
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5634377598762512, train_loss: 0.3707854151725769
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.564166784286499, train_loss: 0.3858606219291687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8232865333557129, train_loss: 0.8170002698898315
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6473620533943176, train_loss: 0.5104394555091858
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6213520169258118, train_loss: 0.4259647727012634
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6189461946487427, train_loss: 0.4053342938423157
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6189385056495667, train_loss: 0.4214414954185486
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.854827344417572, train_loss: 0.8649269938468933
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6195825338363647, train_loss: 0.5023949146270752
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5617097020149231, train_loss: 0.3927456736564636
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5481489896774292, train_loss: 0.3491991460323334
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5478761196136475, train_loss: 0.32053467631340027
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6697811484336853, train_loss: 0.6840173602104187
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5458731651306152, train_loss: 0.4738461375236511
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5463750958442688, train_loss: 0.45552414655685425
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5463539958000183, train_loss: 0.4674318730831146
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5471417903900146, train_loss: 0.4431385397911072
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4698982834815979, train_loss: 0.5348997712135315
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19747890532016754, train_loss: 0.12951025366783142
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19633382558822632, train_loss: 0.11674538999795914
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19636328518390656, train_loss: 0.10976336151361465
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19649317860603333, train_loss: 0.10659883171319962
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2820644974708557, train_loss: 0.2938344180583954
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20878341794013977, train_loss: 0.1511884480714798
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20773011445999146, train_loss: 0.14554224908351898
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2074117362499237, train_loss: 0.14220379292964935
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20756910741329193, train_loss: 0.14157569408416748
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7280743718147278, train_loss: 0.7579878568649292
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.529400646686554, train_loss: 0.45969051122665405
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5128797888755798, train_loss: 0.3870980143547058
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5134755969047546, train_loss: 0.3665928840637207
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.51409512758255, train_loss: 0.3643887937068939
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7380964159965515, train_loss: 0.7460016012191772
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6032281517982483, train_loss: 0.4994332194328308
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5877522826194763, train_loss: 0.41797885298728943
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5882167220115662, train_loss: 0.40880709886550903
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5887669920921326, train_loss: 0.40657466650009155
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7444262504577637, train_loss: 0.722553014755249
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5630080699920654, train_loss: 0.4384118914604187
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5379716157913208, train_loss: 0.370614230632782
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5359575748443604, train_loss: 0.34944629669189453
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5359759330749512, train_loss: 0.3383871912956238
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8332750797271729, train_loss: 0.7126281261444092
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6074836850166321, train_loss: 0.502621054649353
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5628244876861572, train_loss: 0.43837666511535645
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5540862083435059, train_loss: 0.39280566573143005
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5543698668479919, train_loss: 0.36237025260925293
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.41551196575164795, train_loss: 0.4627239406108856
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2019919753074646, train_loss: 0.13674554228782654
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2017199695110321, train_loss: 0.12552808225154877
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20190934836864471, train_loss: 0.12329524010419846
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20223653316497803, train_loss: 0.11656253784894943
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5646040439605713, train_loss: 0.7061395049095154
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21042777597904205, train_loss: 0.1720675528049469
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20679764449596405, train_loss: 0.14571237564086914
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20651140809059143, train_loss: 0.1394590139389038
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20641778409481049, train_loss: 0.13416947424411774
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8104721307754517, train_loss: 0.7985171675682068
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5491384863853455, train_loss: 0.455977201461792
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5446687340736389, train_loss: 0.4022630453109741
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5455841422080994, train_loss: 0.3981510102748871
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5465265512466431, train_loss: 0.3974344730377197
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6490123271942139, train_loss: 0.6509608030319214
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5965431332588196, train_loss: 0.47870954871177673
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5963653922080994, train_loss: 0.4545382857322693
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5970260500907898, train_loss: 0.4441951513290405
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5977814793586731, train_loss: 0.44233593344688416
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7031274437904358, train_loss: 0.7554999589920044
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5111903548240662, train_loss: 0.45396900177001953
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5031228065490723, train_loss: 0.3875015377998352
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5033659934997559, train_loss: 0.384176105260849
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5039162039756775, train_loss: 0.3767234683036804
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6190773248672485, train_loss: 0.6663402915000916
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5318955183029175, train_loss: 0.4820079803466797
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5315179824829102, train_loss: 0.46172034740448
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5320276618003845, train_loss: 0.4423559904098511
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.532810389995575, train_loss: 0.43806159496307373
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.41123199462890625, train_loss: 0.41578373312950134
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1969316303730011, train_loss: 0.1278899759054184
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1975734829902649, train_loss: 0.11717984825372696
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19820119440555573, train_loss: 0.11058802902698517
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19877517223358154, train_loss: 0.1080109104514122
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8955422043800354, train_loss: 0.9636587500572205
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20703735947608948, train_loss: 0.14808061718940735
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2042960822582245, train_loss: 0.12261991947889328
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20416611433029175, train_loss: 0.11795148998498917
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2038550078868866, train_loss: 0.11746447533369064
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9007476568222046, train_loss: 0.8951253890991211
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5718998312950134, train_loss: 0.4704570770263672
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5450349450111389, train_loss: 0.37482285499572754
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5442814230918884, train_loss: 0.3257673382759094
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5447788238525391, train_loss: 0.3222390413284302
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6925085186958313, train_loss: 0.6682752370834351
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6002466082572937, train_loss: 0.4715132713317871
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5954931974411011, train_loss: 0.43585166335105896
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5957319736480713, train_loss: 0.43080824613571167
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5960507392883301, train_loss: 0.4259204864501953
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7815795540809631, train_loss: 0.7800859808921814
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5906020402908325, train_loss: 0.4742548167705536
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5579851269721985, train_loss: 0.3878908157348633
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5487456917762756, train_loss: 0.3410235047340393
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5481681227684021, train_loss: 0.3458596169948578
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8740096092224121, train_loss: 0.8244762420654297
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5834454298019409, train_loss: 0.519198477268219
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5454995632171631, train_loss: 0.43971681594848633
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5390015244483948, train_loss: 0.40332144498825073
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5384862422943115, train_loss: 0.399656742811203
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5516321063041687, train_loss: 0.5398556590080261
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21587979793548584, train_loss: 0.12281091511249542
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.212380051612854, train_loss: 0.10257259756326675
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21140258014202118, train_loss: 0.10346157848834991
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21167407929897308, train_loss: 0.10133381187915802
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5074977278709412, train_loss: 0.5982562303543091
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19360949099063873, train_loss: 0.15823368728160858
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19049036502838135, train_loss: 0.1391182839870453
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1905660480260849, train_loss: 0.13184694945812225
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19076459109783173, train_loss: 0.13376449048519135
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7219693064689636, train_loss: 0.7699026465415955
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5304210186004639, train_loss: 0.46296948194503784
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5201171636581421, train_loss: 0.3978920876979828
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5205233693122864, train_loss: 0.3848765790462494
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5211479663848877, train_loss: 0.3854944109916687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8089050054550171, train_loss: 0.816260039806366
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6211624145507812, train_loss: 0.49432802200317383
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5946494340896606, train_loss: 0.42235487699508667
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5935242772102356, train_loss: 0.40344953536987305
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5932695269584656, train_loss: 0.3871022164821625
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7613204121589661, train_loss: 0.7379686832427979
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5758102536201477, train_loss: 0.4560084939002991
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.551967442035675, train_loss: 0.3763901889324188
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5489389896392822, train_loss: 0.3227464258670807
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5494252443313599, train_loss: 0.32942771911621094
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7450471520423889, train_loss: 0.7408837080001831
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5434436202049255, train_loss: 0.50260329246521
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5334596037864685, train_loss: 0.4393433928489685
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5348166227340698, train_loss: 0.4272233843803406
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5355557203292847, train_loss: 0.4279208183288574
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5533249974250793, train_loss: 0.642439067363739
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20276778936386108, train_loss: 0.14666986465454102
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19863860309123993, train_loss: 0.1221594363451004
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19809307157993317, train_loss: 0.11732146888971329
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19751010835170746, train_loss: 0.11518555134534836
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4211598336696625, train_loss: 0.4510706961154938
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21622224152088165, train_loss: 0.1711755245923996
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20874778926372528, train_loss: 0.14094379544258118
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20764514803886414, train_loss: 0.13929496705532074
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20669770240783691, train_loss: 0.1315414160490036
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7050247192382812, train_loss: 0.730949878692627
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5041277408599854, train_loss: 0.4638074040412903
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4881451725959778, train_loss: 0.37838801741600037
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4880039691925049, train_loss: 0.3533528745174408
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.48869866132736206, train_loss: 0.35666489601135254
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6332118511199951, train_loss: 0.6698263883590698
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5343589186668396, train_loss: 0.5156917572021484
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5202280282974243, train_loss: 0.4539661407470703
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5149362087249756, train_loss: 0.40322765707969666
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5151371359825134, train_loss: 0.3967967927455902
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6977849006652832, train_loss: 0.7401940226554871
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.48919516801834106, train_loss: 0.44432735443115234
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.47439199686050415, train_loss: 0.388782262802124
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.47436633706092834, train_loss: 0.3644638657569885
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4744971692562103, train_loss: 0.3636958599090576
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6208575963973999, train_loss: 0.6744987368583679
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5186634659767151, train_loss: 0.49579674005508423
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5185586810112, train_loss: 0.4628298878669739
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.519014835357666, train_loss: 0.4594058692455292
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.519646406173706, train_loss: 0.45421701669692993
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7539482116699219, train_loss: 0.7375995516777039
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2097918838262558, train_loss: 0.1413053572177887
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20001019537448883, train_loss: 0.10940220206975937
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2009158432483673, train_loss: 0.10381632298231125
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20057742297649384, train_loss: 0.10329083353281021
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9099920392036438, train_loss: 1.0423825979232788
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2504418194293976, train_loss: 0.15953531861305237
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.25018107891082764, train_loss: 0.14043234288692474
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.25055620074272156, train_loss: 0.1367749124765396
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.25071972608566284, train_loss: 0.1323981136083603
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 243/15001 [00:00<00:30, 484.08it/s]Shapley Value Sampling attribution:   3%|▎         | 489/15001 [00:01<00:29, 487.58it/s]Shapley Value Sampling attribution:   5%|▍         | 738/15001 [00:01<00:28, 491.84it/s]Shapley Value Sampling attribution:   7%|▋         | 984/15001 [00:02<00:28, 487.82it/s]Shapley Value Sampling attribution:   8%|▊         | 1228/15001 [00:02<00:28, 479.90it/s]Shapley Value Sampling attribution:  10%|█         | 1552/15001 [00:03<00:25, 535.92it/s]Shapley Value Sampling attribution:  13%|█▎        | 1953/15001 [00:03<00:20, 621.81it/s]Shapley Value Sampling attribution:  16%|█▌        | 2394/15001 [00:04<00:17, 703.62it/s]Shapley Value Sampling attribution:  19%|█▉        | 2859/15001 [00:04<00:15, 773.73it/s]Shapley Value Sampling attribution:  22%|██▏       | 3337/15001 [00:05<00:14, 829.43it/s]Shapley Value Sampling attribution:  25%|██▌       | 3816/15001 [00:05<00:12, 868.58it/s]Shapley Value Sampling attribution:  29%|██▊       | 4294/15001 [00:06<00:11, 894.97it/s]Shapley Value Sampling attribution:  32%|███▏      | 4742/15001 [00:06<00:12, 831.98it/s]Shapley Value Sampling attribution:  34%|███▍      | 5163/15001 [00:07<00:12, 788.62it/s]Shapley Value Sampling attribution:  37%|███▋      | 5618/15001 [00:07<00:11, 822.21it/s]Shapley Value Sampling attribution:  41%|████      | 6092/15001 [00:08<00:10, 857.54it/s]Shapley Value Sampling attribution:  44%|████▍     | 6569/15001 [00:08<00:09, 885.34it/s]Shapley Value Sampling attribution:  47%|████▋     | 7048/15001 [00:09<00:08, 906.31it/s]Shapley Value Sampling attribution:  50%|█████     | 7526/15001 [00:09<00:08, 920.58it/s]Shapley Value Sampling attribution:  53%|█████▎    | 8006/15001 [00:10<00:07, 931.74it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8485/15001 [00:10<00:06, 939.08it/s]Shapley Value Sampling attribution:  60%|█████▉    | 8964/15001 [00:11<00:06, 944.34it/s]Shapley Value Sampling attribution:  63%|██████▎   | 9443/15001 [00:11<00:05, 948.13it/s]Shapley Value Sampling attribution:  66%|██████▌   | 9922/15001 [00:12<00:05, 950.96it/s]Shapley Value Sampling attribution:  69%|██████▉   | 10403/15001 [00:12<00:04, 953.88it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10882/15001 [00:13<00:04, 954.69it/s]Shapley Value Sampling attribution:  76%|███████▌  | 11363/15001 [00:13<00:03, 956.58it/s]Shapley Value Sampling attribution:  79%|███████▉  | 11842/15001 [00:14<00:03, 956.60it/s]Shapley Value Sampling attribution:  82%|████████▏ | 12321/15001 [00:14<00:02, 955.71it/s]Shapley Value Sampling attribution:  85%|████████▌ | 12800/15001 [00:15<00:02, 956.00it/s]Shapley Value Sampling attribution:  89%|████████▊ | 13279/15001 [00:15<00:01, 955.05it/s]Shapley Value Sampling attribution:  92%|█████████▏| 13757/15001 [00:16<00:01, 873.37it/s]Shapley Value Sampling attribution:  95%|█████████▍| 14201/15001 [00:17<00:01, 697.26it/s]Shapley Value Sampling attribution:  97%|█████████▋| 14581/15001 [00:18<00:00, 635.82it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14923/15001 [00:18<00:00, 600.25it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:18<00:00, 790.59it/s]
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 258/15001 [00:00<00:28, 515.62it/s]Shapley Value Sampling attribution:   3%|▎         | 516/15001 [00:01<00:28, 514.07it/s]Shapley Value Sampling attribution:   5%|▌         | 774/15001 [00:01<00:27, 513.79it/s]Shapley Value Sampling attribution:   7%|▋         | 1031/15001 [00:02<00:27, 507.68it/s]Shapley Value Sampling attribution:   9%|▊         | 1286/15001 [00:02<00:27, 507.85it/s]Shapley Value Sampling attribution:  10%|█         | 1543/15001 [00:03<00:26, 509.23it/s]Shapley Value Sampling attribution:  12%|█▏        | 1801/15001 [00:03<00:25, 511.36it/s]Shapley Value Sampling attribution:  14%|█▎        | 2057/15001 [00:04<00:25, 510.46it/s]Shapley Value Sampling attribution:  15%|█▌        | 2315/15001 [00:04<00:24, 511.68it/s]Shapley Value Sampling attribution:  17%|█▋        | 2571/15001 [00:05<00:24, 511.42it/s]Shapley Value Sampling attribution:  19%|█▉        | 2830/15001 [00:05<00:23, 512.85it/s]Shapley Value Sampling attribution:  21%|██        | 3087/15001 [00:06<00:23, 509.91it/s]Shapley Value Sampling attribution:  22%|██▏       | 3342/15001 [00:06<00:22, 509.71it/s]Shapley Value Sampling attribution:  24%|██▍       | 3597/15001 [00:07<00:22, 508.20it/s]Shapley Value Sampling attribution:  26%|██▌       | 3852/15001 [00:07<00:21, 508.34it/s]Shapley Value Sampling attribution:  27%|██▋       | 4107/15001 [00:08<00:21, 508.67it/s]Shapley Value Sampling attribution:  29%|██▉       | 4362/15001 [00:08<00:20, 507.76it/s]Shapley Value Sampling attribution:  31%|███       | 4616/15001 [00:09<00:20, 507.54it/s]Shapley Value Sampling attribution:  32%|███▏      | 4870/15001 [00:09<00:19, 507.32it/s]Shapley Value Sampling attribution:  34%|███▍      | 5125/15001 [00:10<00:19, 507.79it/s]Shapley Value Sampling attribution:  36%|███▌      | 5379/15001 [00:10<00:18, 506.43it/s]Shapley Value Sampling attribution:  38%|███▊      | 5633/15001 [00:11<00:18, 505.67it/s]Shapley Value Sampling attribution:  39%|███▉      | 5915/15001 [00:11<00:17, 522.59it/s]Shapley Value Sampling attribution:  42%|████▏     | 6250/15001 [00:12<00:15, 566.43it/s]Shapley Value Sampling attribution:  44%|████▍     | 6646/15001 [00:12<00:13, 633.40it/s]Shapley Value Sampling attribution:  47%|████▋     | 7081/15001 [00:13<00:11, 704.11it/s]Shapley Value Sampling attribution:  50%|████▉     | 7450/15001 [00:13<00:10, 714.03it/s]Shapley Value Sampling attribution:  52%|█████▏    | 7808/15001 [00:14<00:10, 696.32it/s]Shapley Value Sampling attribution:  55%|█████▍    | 8213/15001 [00:14<00:09, 729.60it/s]Shapley Value Sampling attribution:  58%|█████▊    | 8693/15001 [00:15<00:07, 797.31it/s]Shapley Value Sampling attribution:  61%|██████    | 9167/15001 [00:15<00:06, 841.66it/s]Shapley Value Sampling attribution:  64%|██████▍   | 9645/15001 [00:16<00:06, 875.42it/s]Shapley Value Sampling attribution:  67%|██████▋   | 10123/15001 [00:16<00:05, 898.96it/s]Shapley Value Sampling attribution:  71%|███████   | 10602/15001 [00:17<00:04, 916.12it/s]Shapley Value Sampling attribution:  74%|███████▍  | 11080/15001 [00:17<00:04, 927.81it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11561/15001 [00:18<00:03, 937.76it/s]Shapley Value Sampling attribution:  80%|████████  | 12041/15001 [00:18<00:03, 943.90it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12514/15001 [00:19<00:02, 944.36it/s]Shapley Value Sampling attribution:  87%|████████▋ | 12994/15001 [00:19<00:02, 948.81it/s]Shapley Value Sampling attribution:  90%|████████▉ | 13476/15001 [00:20<00:01, 953.02it/s]Shapley Value Sampling attribution:  93%|█████████▎| 13956/15001 [00:20<00:01, 954.96it/s]Shapley Value Sampling attribution:  96%|█████████▌| 14436/15001 [00:21<00:00, 956.20it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14915/15001 [00:21<00:00, 956.21it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:21<00:00, 690.76it/s]
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:09<02:09,  9.23s/it]importance j:  13%|█▎        | 2/15 [00:20<02:19, 10.71s/it]importance j:  20%|██        | 3/15 [00:34<02:22, 11.91s/it]importance j:  27%|██▋       | 4/15 [00:44<02:03, 11.21s/it]importance j:  33%|███▎      | 5/15 [00:58<02:03, 12.39s/it]importance j:  40%|████      | 6/15 [01:07<01:40, 11.15s/it]importance j:  47%|████▋     | 7/15 [01:23<01:41, 12.67s/it]importance j:  53%|█████▎    | 8/15 [01:31<01:19, 11.33s/it]importance j:  60%|██████    | 9/15 [01:47<01:16, 12.70s/it]importance j:  67%|██████▋   | 10/15 [01:56<00:57, 11.45s/it]importance j:  73%|███████▎  | 11/15 [02:10<00:49, 12.32s/it]importance j:  80%|████████  | 12/15 [02:21<00:35, 11.78s/it]importance j:  87%|████████▋ | 13/15 [02:32<00:23, 11.65s/it]importance j:  93%|█████████▎| 14/15 [02:45<00:11, 11.92s/it]importance j: 100%|██████████| 15/15 [02:57<00:00, 12.03s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7918753623962402, train_loss: 0.8060259819030762
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5524007678031921, train_loss: 0.477417916059494
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5293952226638794, train_loss: 0.3971051871776581
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5290325880050659, train_loss: 0.3687320649623871
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5293393135070801, train_loss: 0.38272231817245483
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7444939613342285, train_loss: 0.7756063938140869
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5988314747810364, train_loss: 0.516244113445282
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5849100351333618, train_loss: 0.45069918036460876
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5850842595100403, train_loss: 0.45070427656173706
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5848330855369568, train_loss: 0.447136253118515
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5816671848297119, train_loss: 0.6126844882965088
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.49268582463264465, train_loss: 0.4415915012359619
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4860304594039917, train_loss: 0.3925153911113739
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4850359857082367, train_loss: 0.3813713490962982
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.48507454991340637, train_loss: 0.36479514837265015
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.837336540222168, train_loss: 0.8539997935295105
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5794569849967957, train_loss: 0.5280577540397644
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5665545463562012, train_loss: 0.46040865778923035
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5680217146873474, train_loss: 0.4531393051147461
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5691772699356079, train_loss: 0.45924049615859985
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6281332969665527, train_loss: 0.5807177424430847
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.23782934248447418, train_loss: 0.1439962238073349
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22919686138629913, train_loss: 0.11079277843236923
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22855179011821747, train_loss: 0.11077799648046494
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2283879667520523, train_loss: 0.10415661334991455
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4964377284049988, train_loss: 0.5286237597465515
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22943539917469025, train_loss: 0.163427472114563
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22709092497825623, train_loss: 0.15235674381256104
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22701556980609894, train_loss: 0.14813947677612305
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22565963864326477, train_loss: 0.14775435626506805
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7442717552185059, train_loss: 0.7791010141372681
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5454612374305725, train_loss: 0.4416031241416931
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5447103381156921, train_loss: 0.40088993310928345
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5455328822135925, train_loss: 0.39807233214378357
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5467507839202881, train_loss: 0.3850720524787903
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6153391599655151, train_loss: 0.6406317353248596
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.56062251329422, train_loss: 0.4749128818511963
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.56123948097229, train_loss: 0.46381038427352905
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5620502829551697, train_loss: 0.4704422354698181
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5632644891738892, train_loss: 0.4569636285305023
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7275630235671997, train_loss: 0.7705900073051453
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5590734481811523, train_loss: 0.47390979528427124
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.525789737701416, train_loss: 0.3830298185348511
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5194039344787598, train_loss: 0.3503202795982361
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5203160047531128, train_loss: 0.3410640358924866
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7101200222969055, train_loss: 0.7532905340194702
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5633020401000977, train_loss: 0.504080593585968
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5594418048858643, train_loss: 0.4611435532569885
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5597076416015625, train_loss: 0.45663976669311523
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5598856210708618, train_loss: 0.45303601026535034
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42384636402130127, train_loss: 0.5005237460136414
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20626519620418549, train_loss: 0.12721523642539978
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20507404208183289, train_loss: 0.12106721848249435
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20492054522037506, train_loss: 0.11643820255994797
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20450837910175323, train_loss: 0.11549343913793564
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5158700942993164, train_loss: 0.5655709505081177
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19855569303035736, train_loss: 0.15445120632648468
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1962667852640152, train_loss: 0.14786243438720703
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1959110051393509, train_loss: 0.14357513189315796
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19565057754516602, train_loss: 0.13288845121860504
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7428452372550964, train_loss: 0.7516721487045288
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5450661778450012, train_loss: 0.4689667224884033
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5334502458572388, train_loss: 0.39687174558639526
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5336562991142273, train_loss: 0.38628336787223816
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5340800881385803, train_loss: 0.38159045577049255
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8710704445838928, train_loss: 0.8724708557128906
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.638783872127533, train_loss: 0.500227153301239
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6300858855247498, train_loss: 0.427816241979599
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6309677362442017, train_loss: 0.4218611717224121
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6317511796951294, train_loss: 0.4111827313899994
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6791249513626099, train_loss: 0.7068294882774353
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.560178816318512, train_loss: 0.4448781907558441
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5561915040016174, train_loss: 0.37351393699645996
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.556454598903656, train_loss: 0.37308287620544434
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5565921068191528, train_loss: 0.3711242377758026
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6389918923377991, train_loss: 0.6569247841835022
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5243225693702698, train_loss: 0.4970274865627289
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5138294696807861, train_loss: 0.43221306800842285
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5108538866043091, train_loss: 0.410073459148407
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5107987523078918, train_loss: 0.406110942363739
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4295569062232971, train_loss: 0.4706304967403412
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19689473509788513, train_loss: 0.1334650069475174
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19648048281669617, train_loss: 0.11814448982477188
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19656284153461456, train_loss: 0.11590094864368439
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1965980976819992, train_loss: 0.11296292394399643
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5568718910217285, train_loss: 0.5843527317047119
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22933949530124664, train_loss: 0.15816770493984222
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22443510591983795, train_loss: 0.1305653154850006
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22327767312526703, train_loss: 0.12568581104278564
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2229841649532318, train_loss: 0.11691248416900635
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7184644937515259, train_loss: 0.7451831698417664
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5234346985816956, train_loss: 0.43899819254875183
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5222457647323608, train_loss: 0.40317022800445557
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5231513381004333, train_loss: 0.39428791403770447
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5244556665420532, train_loss: 0.39385363459587097
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6764548420906067, train_loss: 0.6852930784225464
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5853014588356018, train_loss: 0.47390228509902954
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5863334536552429, train_loss: 0.4586957097053528
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5875414609909058, train_loss: 0.44548508524894714
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5889801383018494, train_loss: 0.4412815570831299
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6627681255340576, train_loss: 0.7019907236099243
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5305030345916748, train_loss: 0.44259223341941833
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.526189923286438, train_loss: 0.3951277732849121
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5263358950614929, train_loss: 0.3900442123413086
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5265923738479614, train_loss: 0.3878270983695984
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7234451174736023, train_loss: 0.7131401896476746
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5735947489738464, train_loss: 0.4847894608974457
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5536229014396667, train_loss: 0.42766064405441284
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5481672883033752, train_loss: 0.40063974261283875
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.548089325428009, train_loss: 0.38555580377578735
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.374121904373169, train_loss: 1.515222191810608
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19755658507347107, train_loss: 0.128327414393425
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1925451159477234, train_loss: 0.10034339874982834
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1923629343509674, train_loss: 0.10191833972930908
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1924058347940445, train_loss: 0.09937293827533722
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35566189885139465, train_loss: 0.4477294981479645
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19432343542575836, train_loss: 0.16834500432014465
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19489921629428864, train_loss: 0.16636323928833008
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19565419852733612, train_loss: 0.15978680551052094
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19647198915481567, train_loss: 0.15805315971374512
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.735227108001709, train_loss: 0.692631185054779
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.592424750328064, train_loss: 0.45917361974716187
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5945662260055542, train_loss: 0.4374515414237976
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5963464379310608, train_loss: 0.4390212893486023
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5983216762542725, train_loss: 0.43016713857650757
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7034342288970947, train_loss: 0.727617621421814
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5897923111915588, train_loss: 0.4976292550563812
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5833005309104919, train_loss: 0.45158034563064575
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5834559798240662, train_loss: 0.4386872947216034
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5839746594429016, train_loss: 0.44106847047805786
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7376322150230408, train_loss: 0.7600571513175964
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6165502071380615, train_loss: 0.505290687084198
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6111916899681091, train_loss: 0.4495707154273987
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.611500084400177, train_loss: 0.43731603026390076
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6124621033668518, train_loss: 0.43606168031692505
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9289387464523315, train_loss: 0.9216418266296387
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6139483451843262, train_loss: 0.5629210472106934
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5709903240203857, train_loss: 0.47470182180404663
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5677593946456909, train_loss: 0.4466719627380371
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5673345923423767, train_loss: 0.4442809522151947
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7140491604804993, train_loss: 0.699530303478241
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2528128921985626, train_loss: 0.14118066430091858
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2507759630680084, train_loss: 0.1201595589518547
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2507091760635376, train_loss: 0.11930253356695175
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2513062059879303, train_loss: 0.11485133320093155
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5010789632797241, train_loss: 0.6604166030883789
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21980257332324982, train_loss: 0.17636863887310028
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21899297833442688, train_loss: 0.15022149682044983
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21928681433200836, train_loss: 0.14691254496574402
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21962174773216248, train_loss: 0.14445315301418304
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.743620753288269, train_loss: 0.7013306617736816
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5490913987159729, train_loss: 0.427721232175827
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5430364608764648, train_loss: 0.38752254843711853
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5432470440864563, train_loss: 0.3837014138698578
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5435855984687805, train_loss: 0.3703577220439911
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7590083479881287, train_loss: 0.7699551582336426
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5961782336235046, train_loss: 0.4925072193145752
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5759077668190002, train_loss: 0.432223916053772
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5766969323158264, train_loss: 0.41447433829307556
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5766403079032898, train_loss: 0.41261106729507446
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7413161993026733, train_loss: 0.7370705008506775
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5573035478591919, train_loss: 0.4553947448730469
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5412829518318176, train_loss: 0.37134188413619995
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5414982438087463, train_loss: 0.3550442159175873
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5413482785224915, train_loss: 0.3575139045715332
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6615011692047119, train_loss: 0.6710643768310547
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5649839639663696, train_loss: 0.4897705018520355
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5631886124610901, train_loss: 0.4439436197280884
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.563153088092804, train_loss: 0.44221800565719604
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5638495683670044, train_loss: 0.4273819327354431
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4675353169441223, train_loss: 0.446792334318161
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1891586035490036, train_loss: 0.12675073742866516
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1891242414712906, train_loss: 0.11136084049940109
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1891416609287262, train_loss: 0.10858064144849777
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18975257873535156, train_loss: 0.10541494935750961
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.42671239376068115, train_loss: 0.46996745467185974
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21176744997501373, train_loss: 0.1600041389465332
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21153196692466736, train_loss: 0.13921169936656952
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21189925074577332, train_loss: 0.13549737632274628
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2122848927974701, train_loss: 0.12902092933654785
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7669426798820496, train_loss: 0.759351909160614
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5350496172904968, train_loss: 0.408142626285553
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5365396738052368, train_loss: 0.3747382164001465
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.53786700963974, train_loss: 0.38211140036582947
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5396975874900818, train_loss: 0.3677332103252411
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7919646501541138, train_loss: 0.7796949148178101
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6116877198219299, train_loss: 0.5032877326011658
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5932110548019409, train_loss: 0.42789822816848755
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5941783785820007, train_loss: 0.4082567095756531
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.594728946685791, train_loss: 0.40704846382141113
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7185936570167542, train_loss: 0.7327156066894531
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5301961302757263, train_loss: 0.4477824568748474
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.505691647529602, train_loss: 0.3807423710823059
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5050860047340393, train_loss: 0.36012157797813416
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5050563216209412, train_loss: 0.36079177260398865
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5709533095359802, train_loss: 0.6209737062454224
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5170891880989075, train_loss: 0.47674453258514404
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5165917873382568, train_loss: 0.44286906719207764
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5165026783943176, train_loss: 0.4448966681957245
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5165688395500183, train_loss: 0.43592607975006104
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2737252712249756, train_loss: 1.3937042951583862
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18901945650577545, train_loss: 0.12413487583398819
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18850362300872803, train_loss: 0.1028459444642067
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18868716061115265, train_loss: 0.10613216459751129
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1889118105173111, train_loss: 0.09978219121694565
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7167268395423889, train_loss: 0.7766966223716736
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21039031445980072, train_loss: 0.15907959640026093
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20603515207767487, train_loss: 0.14016678929328918
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20592133700847626, train_loss: 0.13553036749362946
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20599739253520966, train_loss: 0.13230910897254944
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.808607280254364, train_loss: 0.830585241317749
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5458474159240723, train_loss: 0.45437294244766235
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5310901999473572, train_loss: 0.3682849407196045
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5316469073295593, train_loss: 0.36804187297821045
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5322089195251465, train_loss: 0.3590030074119568
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.865109920501709, train_loss: 0.8945610523223877
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6217775940895081, train_loss: 0.5461326241493225
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5946966409683228, train_loss: 0.45421919226646423
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5946661233901978, train_loss: 0.4374253749847412
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5947006940841675, train_loss: 0.4229733645915985
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6918065547943115, train_loss: 0.7075705528259277
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5416551232337952, train_loss: 0.4493746757507324
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5350784659385681, train_loss: 0.3947989344596863
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5351288914680481, train_loss: 0.3838060796260834
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5354821681976318, train_loss: 0.3827851712703705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8818941712379456, train_loss: 0.8906513452529907
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5820468664169312, train_loss: 0.5234939455986023
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5487292408943176, train_loss: 0.4491996765136719
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.547061562538147, train_loss: 0.42246270179748535
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5468116998672485, train_loss: 0.41204899549484253
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8146684765815735, train_loss: 0.7606149911880493
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19610367715358734, train_loss: 0.12314090877771378
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19620849192142487, train_loss: 0.11249899864196777
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19622601568698883, train_loss: 0.10974416881799698
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19638490676879883, train_loss: 0.10612054169178009
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3566976487636566, train_loss: 0.378428190946579
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21725581586360931, train_loss: 0.16038189828395844
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21021413803100586, train_loss: 0.14026978611946106
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20920127630233765, train_loss: 0.13195525109767914
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2084680050611496, train_loss: 0.12880373001098633
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7661163806915283, train_loss: 0.7564570307731628
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.546728253364563, train_loss: 0.444633424282074
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5334647297859192, train_loss: 0.3741067349910736
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5341731905937195, train_loss: 0.3618650436401367
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5347999930381775, train_loss: 0.35804593563079834
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7602627873420715, train_loss: 0.7585042715072632
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5934007167816162, train_loss: 0.4701656699180603
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5863178968429565, train_loss: 0.4255465269088745
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5864756107330322, train_loss: 0.42208313941955566
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5866677761077881, train_loss: 0.41535550355911255
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7602667808532715, train_loss: 0.7622698545455933
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5770766139030457, train_loss: 0.4691305160522461
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5580003261566162, train_loss: 0.3927389979362488
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5568488240242004, train_loss: 0.37071236968040466
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.557183563709259, train_loss: 0.368027925491333
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6948711276054382, train_loss: 0.7322112917900085
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5502575635910034, train_loss: 0.4963317811489105
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5443850159645081, train_loss: 0.4605419337749481
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5442461371421814, train_loss: 0.45404213666915894
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5445030331611633, train_loss: 0.43931543827056885
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5611276030540466, train_loss: 0.5291942358016968
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22100040316581726, train_loss: 0.13129360973834991
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21732710301876068, train_loss: 0.10511674731969833
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21709102392196655, train_loss: 0.1015985980629921
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2165650576353073, train_loss: 0.10134591162204742
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.38242846727371216, train_loss: 0.39381954073905945
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22031636536121368, train_loss: 0.15435226261615753
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21125365793704987, train_loss: 0.12347947806119919
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21136474609375, train_loss: 0.12005429714918137
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2113824486732483, train_loss: 0.11763973534107208
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7740341424942017, train_loss: 0.7834665179252625
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5467207431793213, train_loss: 0.4482364058494568
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5346237421035767, train_loss: 0.3817124366760254
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5350561738014221, train_loss: 0.36566823720932007
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5358760952949524, train_loss: 0.37029632925987244
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6387726068496704, train_loss: 0.7021597623825073
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5761852860450745, train_loss: 0.4918050169944763
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5763696432113647, train_loss: 0.4637258052825928
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5769126415252686, train_loss: 0.46370041370391846
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5776559114456177, train_loss: 0.45450934767723083
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6785927414894104, train_loss: 0.7022966146469116
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5484052300453186, train_loss: 0.46853670477867126
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5336335301399231, train_loss: 0.3981393277645111
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5333901047706604, train_loss: 0.36802586913108826
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5336930751800537, train_loss: 0.3634518086910248
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6683682203292847, train_loss: 0.698299765586853
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5351356267929077, train_loss: 0.4899551570415497
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5307630896568298, train_loss: 0.45094913244247437
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5300322771072388, train_loss: 0.43137606978416443
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5300688147544861, train_loss: 0.4239575266838074
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7457764744758606, train_loss: 0.8113924264907837
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19712121784687042, train_loss: 0.12135306745767593
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19747814536094666, train_loss: 0.10865955799818039
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19729800522327423, train_loss: 0.109838105738163
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19765421748161316, train_loss: 0.10612104088068008
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45416030287742615, train_loss: 0.4839160442352295
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2147308886051178, train_loss: 0.1574309915304184
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21151801943778992, train_loss: 0.1348542422056198
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21156363189220428, train_loss: 0.13242536783218384
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.212106853723526, train_loss: 0.1318892538547516
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7780095934867859, train_loss: 0.7513071894645691
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5696108341217041, train_loss: 0.4476335048675537
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.546202540397644, train_loss: 0.3728625178337097
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5461108088493347, train_loss: 0.3450378179550171
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5467624068260193, train_loss: 0.34260162711143494
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6486107707023621, train_loss: 0.6458349227905273
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5852962136268616, train_loss: 0.4658958911895752
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5800060629844666, train_loss: 0.43271803855895996
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5794779062271118, train_loss: 0.4144975543022156
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5793709754943848, train_loss: 0.4158751368522644
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0550631284713745, train_loss: 1.0544898509979248
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6291025280952454, train_loss: 0.5417650938034058
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5475419759750366, train_loss: 0.4061543941497803
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.522754967212677, train_loss: 0.35004162788391113
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5187121629714966, train_loss: 0.3307192027568817
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7511758804321289, train_loss: 0.7341563105583191
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.58738112449646, train_loss: 0.5023877620697021
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5719236731529236, train_loss: 0.42927539348602295
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5725716352462769, train_loss: 0.425519198179245
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5728177428245544, train_loss: 0.4124607741832733
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3067867159843445, train_loss: 0.3568190932273865
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18969997763633728, train_loss: 0.13400617241859436
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18915481865406036, train_loss: 0.11535234749317169
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18963536620140076, train_loss: 0.11818426847457886
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18991771340370178, train_loss: 0.11681332439184189
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.44167882204055786, train_loss: 0.4659837782382965
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19511647522449493, train_loss: 0.16520249843597412
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1920727789402008, train_loss: 0.1359461545944214
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1923079639673233, train_loss: 0.12949199974536896
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1926211416721344, train_loss: 0.12733976542949677
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7261856198310852, train_loss: 0.7423120737075806
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.519463062286377, train_loss: 0.4201209545135498
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.515093207359314, train_loss: 0.37314364314079285
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5154297947883606, train_loss: 0.36389070749282837
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5160252451896667, train_loss: 0.3615163564682007
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7256512641906738, train_loss: 0.7311453223228455
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5905821919441223, train_loss: 0.48446041345596313
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5857610702514648, train_loss: 0.4342631697654724
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5861191153526306, train_loss: 0.42990073561668396
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5867599844932556, train_loss: 0.4165264070034027
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8046858310699463, train_loss: 0.7844456434249878
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5361905694007874, train_loss: 0.453496515750885
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5162466168403625, train_loss: 0.3907334506511688
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5167244076728821, train_loss: 0.35831722617149353
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5170261859893799, train_loss: 0.35446175932884216
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7751970291137695, train_loss: 0.7409799098968506
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5809680819511414, train_loss: 0.5145024657249451
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5568907260894775, train_loss: 0.44312167167663574
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5559604167938232, train_loss: 0.41144782304763794
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5563730597496033, train_loss: 0.42322707176208496
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6093239784240723, train_loss: 0.6867381930351257
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19007734954357147, train_loss: 0.13673341274261475
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18682333827018738, train_loss: 0.11351539939641953
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18712833523750305, train_loss: 0.11094146966934204
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18723033368587494, train_loss: 0.10639675706624985
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8354154825210571, train_loss: 0.8263125419616699
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19989293813705444, train_loss: 0.1478617936372757
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19665050506591797, train_loss: 0.12641620635986328
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19655650854110718, train_loss: 0.12440396845340729
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1967610865831375, train_loss: 0.12092764675617218
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8412785530090332, train_loss: 0.8508666753768921
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5262993574142456, train_loss: 0.44024547934532166
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5229006409645081, train_loss: 0.3926374316215515
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.523945152759552, train_loss: 0.3840101957321167
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.525360107421875, train_loss: 0.3843895196914673
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6807672381401062, train_loss: 0.7075142860412598
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5994699001312256, train_loss: 0.4888463616371155
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5973398685455322, train_loss: 0.45328372716903687
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5974452495574951, train_loss: 0.4489678144454956
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5979263186454773, train_loss: 0.4370749890804291
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6206775307655334, train_loss: 0.6095604300498962
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5175996422767639, train_loss: 0.42232173681259155
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5166295766830444, train_loss: 0.3806546628475189
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5169485211372375, train_loss: 0.38518744707107544
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5175158381462097, train_loss: 0.3792771100997925
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6594568490982056, train_loss: 0.7729520797729492
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5247067213058472, train_loss: 0.5187084674835205
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5259737968444824, train_loss: 0.49782034754753113
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5270480513572693, train_loss: 0.4901576042175293
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5282723903656006, train_loss: 0.4798138737678528
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8242715001106262, train_loss: 0.9498757719993591
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2174980789422989, train_loss: 0.13041198253631592
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21555520594120026, train_loss: 0.10601141303777695
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21594223380088806, train_loss: 0.11163051426410675
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21595439314842224, train_loss: 0.10502052307128906
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.49959078431129456, train_loss: 0.6228083968162537
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.18420758843421936, train_loss: 0.1523088961839676
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1839601695537567, train_loss: 0.13930003345012665
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.18395847082138062, train_loss: 0.13888809084892273
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1845272183418274, train_loss: 0.13284553587436676
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7913745045661926, train_loss: 0.8075480461120605
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.545076847076416, train_loss: 0.46200618147850037
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5277677774429321, train_loss: 0.3818690776824951
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5284480452537537, train_loss: 0.37105751037597656
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.52889484167099, train_loss: 0.3646162450313568
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7477071285247803, train_loss: 0.7655959129333496
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5797514915466309, train_loss: 0.4848540723323822
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5718895196914673, train_loss: 0.42852136492729187
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5716066956520081, train_loss: 0.41957855224609375
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5717339515686035, train_loss: 0.4226180911064148
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6648251414299011, train_loss: 0.6669484376907349
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.520971417427063, train_loss: 0.41360053420066833
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5192832350730896, train_loss: 0.3852556645870209
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5195507407188416, train_loss: 0.3646419644355774
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5199694037437439, train_loss: 0.36924561858177185
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6183146834373474, train_loss: 0.6101521253585815
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5741376876831055, train_loss: 0.4809918999671936
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5732731223106384, train_loss: 0.4458322525024414
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5735622048377991, train_loss: 0.4304008185863495
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5746038556098938, train_loss: 0.42413681745529175
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40262454748153687, train_loss: 0.4620412290096283
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1972724050283432, train_loss: 0.12964263558387756
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19812528789043427, train_loss: 0.12691299617290497
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1987975686788559, train_loss: 0.12196926027536392
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19972184300422668, train_loss: 0.11908606439828873
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.751625120639801, train_loss: 0.8410672545433044
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.225218266248703, train_loss: 0.16524949669837952
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22472432255744934, train_loss: 0.15872998535633087
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2240988165140152, train_loss: 0.15069948136806488
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2240726500749588, train_loss: 0.14728452265262604
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7915125489234924, train_loss: 0.7869365215301514
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5568099021911621, train_loss: 0.4568929672241211
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5381094813346863, train_loss: 0.3752921521663666
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5394395589828491, train_loss: 0.36649736762046814
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.54012131690979, train_loss: 0.3547467589378357
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7207728028297424, train_loss: 0.7101685404777527
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.598882794380188, train_loss: 0.49363136291503906
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5825014710426331, train_loss: 0.42636317014694214
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5818138122558594, train_loss: 0.41257500648498535
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5819364786148071, train_loss: 0.3933740556240082
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.585462749004364, train_loss: 0.5769945383071899
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5264052748680115, train_loss: 0.4070248603820801
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.526604950428009, train_loss: 0.37523016333580017
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5269325971603394, train_loss: 0.363445520401001
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5277979969978333, train_loss: 0.37368521094322205
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7525964975357056, train_loss: 0.7613162398338318
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5337914228439331, train_loss: 0.504096269607544
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5177459120750427, train_loss: 0.45437026023864746
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.517719030380249, train_loss: 0.44193172454833984
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5176752209663391, train_loss: 0.44305428862571716
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4923136830329895, train_loss: 0.5526021122932434
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18972712755203247, train_loss: 0.13334441184997559
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1872296780347824, train_loss: 0.1119621992111206
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.187395840883255, train_loss: 0.10877591371536255
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18801142275333405, train_loss: 0.10540711879730225
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3303605616092682, train_loss: 0.34146708250045776
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21129299700260162, train_loss: 0.15720100700855255
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2080361247062683, train_loss: 0.13411477208137512
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20793141424655914, train_loss: 0.1267758458852768
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2077406793832779, train_loss: 0.12439566850662231
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:11<02:39, 11.39s/it]importance j:  13%|█▎        | 2/15 [00:22<02:27, 11.32s/it]importance j:  20%|██        | 3/15 [00:37<02:36, 13.03s/it]importance j:  27%|██▋       | 4/15 [00:48<02:13, 12.09s/it]importance j:  33%|███▎      | 5/15 [01:02<02:08, 12.82s/it]importance j:  40%|████      | 6/15 [01:13<01:50, 12.23s/it]importance j:  47%|████▋     | 7/15 [01:27<01:42, 12.83s/it]importance j:  53%|█████▎    | 8/15 [01:39<01:27, 12.50s/it]importance j:  60%|██████    | 9/15 [01:50<01:11, 11.97s/it]importance j:  67%|██████▋   | 10/15 [01:58<00:54, 10.91s/it]importance j:  73%|███████▎  | 11/15 [02:15<00:50, 12.54s/it]importance j:  80%|████████  | 12/15 [02:24<00:34, 11.57s/it]importance j:  87%|████████▋ | 13/15 [02:38<00:24, 12.28s/it]importance j:  93%|█████████▎| 14/15 [02:46<00:11, 11.20s/it]importance j: 100%|██████████| 15/15 [02:59<00:00, 11.53s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7121668457984924, train_loss: 0.73561692237854
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5318643450737, train_loss: 0.4561540484428406
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5246197581291199, train_loss: 0.4025896489620209
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5249932408332825, train_loss: 0.4049203395843506
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5255290865898132, train_loss: 0.3884127736091614
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7543888688087463, train_loss: 0.7604314088821411
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5942427515983582, train_loss: 0.5296932458877563
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5739771127700806, train_loss: 0.4583871066570282
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5712417364120483, train_loss: 0.4363139569759369
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5705526471138, train_loss: 0.42558416724205017
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5700110793113708, train_loss: 0.42955440282821655
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0870635509490967, train_loss: 1.0537867546081543
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.7015921473503113, train_loss: 0.6158543825149536
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5713273882865906, train_loss: 0.45141440629959106
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5303980708122253, train_loss: 0.3799838423728943
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5174726247787476, train_loss: 0.3256374001502991
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7436057925224304, train_loss: 0.7098903656005859
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5704537034034729, train_loss: 0.5144440531730652
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5560168623924255, train_loss: 0.45545828342437744
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5564865469932556, train_loss: 0.46221470832824707
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5567431449890137, train_loss: 0.44360360503196716
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37377241253852844, train_loss: 0.40265902876853943
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20901694893836975, train_loss: 0.14015376567840576
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20895767211914062, train_loss: 0.13934941589832306
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20875002443790436, train_loss: 0.1272687464952469
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20882347226142883, train_loss: 0.12271113693714142
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4998812973499298, train_loss: 0.5840066075325012
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22714000940322876, train_loss: 0.1584511250257492
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22602802515029907, train_loss: 0.1484895795583725
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22534295916557312, train_loss: 0.13934341073036194
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22581560909748077, train_loss: 0.1363472044467926
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6547295451164246, train_loss: 0.6429058313369751
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5368546843528748, train_loss: 0.4199291169643402
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5389817357063293, train_loss: 0.39516711235046387
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5409198999404907, train_loss: 0.38614147901535034
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.54317706823349, train_loss: 0.3893669843673706
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9277987480163574, train_loss: 0.9540106654167175
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6690497398376465, train_loss: 0.5425515174865723
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6259735822677612, train_loss: 0.43839511275291443
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6205371618270874, train_loss: 0.40319347381591797
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6194515228271484, train_loss: 0.38114917278289795
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.6188333630561829, train_loss: 0.38108396530151367
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6670706272125244, train_loss: 0.6725594401359558
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5396738052368164, train_loss: 0.4363532066345215
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5285943150520325, train_loss: 0.37505626678466797
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5284605622291565, train_loss: 0.37128591537475586
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5285322666168213, train_loss: 0.3675704598426819
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6695892214775085, train_loss: 0.6276977062225342
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5582654476165771, train_loss: 0.48989641666412354
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5532662272453308, train_loss: 0.4456443190574646
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5533132553100586, train_loss: 0.4239053726196289
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5537089705467224, train_loss: 0.4407108426094055
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4344354271888733, train_loss: 0.45318183302879333
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20535492897033691, train_loss: 0.13458183407783508
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20021969079971313, train_loss: 0.11883186548948288
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20003394782543182, train_loss: 0.11175916343927383
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1999477595090866, train_loss: 0.10943064838647842
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5801752209663391, train_loss: 0.5975953340530396
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20598936080932617, train_loss: 0.1522291749715805
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19823801517486572, train_loss: 0.11574263870716095
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19757284224033356, train_loss: 0.11723239719867706
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1975332647562027, train_loss: 0.1145801916718483
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6977647542953491, train_loss: 0.6960012912750244
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5174627304077148, train_loss: 0.42109984159469604
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5163444876670837, train_loss: 0.3749423921108246
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5171459913253784, train_loss: 0.3751440942287445
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5184972286224365, train_loss: 0.3627137541770935
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.865642249584198, train_loss: 0.940157413482666
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.621313214302063, train_loss: 0.532371461391449
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5864800214767456, train_loss: 0.44952934980392456
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5845020413398743, train_loss: 0.43087536096572876
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5846141576766968, train_loss: 0.41944217681884766
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7681992650032043, train_loss: 0.7639985084533691
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5803518295288086, train_loss: 0.4602435827255249
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5439029932022095, train_loss: 0.3887995183467865
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5391271710395813, train_loss: 0.3296911120414734
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5394892692565918, train_loss: 0.32896435260772705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7140378952026367, train_loss: 0.6801118850708008
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5530117750167847, train_loss: 0.5040432214736938
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.54036945104599, train_loss: 0.4431135058403015
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5406097173690796, train_loss: 0.436404824256897
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5406477451324463, train_loss: 0.42023295164108276
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9048134684562683, train_loss: 1.0035911798477173
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18389660120010376, train_loss: 0.1216759905219078
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18377554416656494, train_loss: 0.1030305027961731
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18420235812664032, train_loss: 0.10174353420734406
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1846369057893753, train_loss: 0.09941529482603073
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6383430361747742, train_loss: 0.6779933571815491
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2142035961151123, train_loss: 0.15958714485168457
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2130776345729828, train_loss: 0.1496458351612091
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21289628744125366, train_loss: 0.14231017231941223
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21291778981685638, train_loss: 0.1338408887386322
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7581970691680908, train_loss: 0.7981526851654053
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5218207240104675, train_loss: 0.4339277446269989
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5173999071121216, train_loss: 0.39049839973449707
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5179322957992554, train_loss: 0.3841419219970703
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5188508033752441, train_loss: 0.3756314218044281
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9380220174789429, train_loss: 0.963808536529541
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6648607850074768, train_loss: 0.5558485984802246
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6101307272911072, train_loss: 0.4407796859741211
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5967309474945068, train_loss: 0.3904813528060913
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5953347682952881, train_loss: 0.37495121359825134
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6302247643470764, train_loss: 0.6391468644142151
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5264033675193787, train_loss: 0.44988808035850525
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5173563361167908, train_loss: 0.37818455696105957
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5176146030426025, train_loss: 0.36505192518234253
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5182852149009705, train_loss: 0.3623776435852051
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7435317039489746, train_loss: 0.7078661918640137
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.586535632610321, train_loss: 0.49814051389694214
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5606369376182556, train_loss: 0.4386245906352997
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5580427050590515, train_loss: 0.407174289226532
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5583425164222717, train_loss: 0.4050973057746887
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5525462031364441, train_loss: 0.6417908668518066
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17400099337100983, train_loss: 0.1353921741247177
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1750538945198059, train_loss: 0.12559661269187927
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1758754998445511, train_loss: 0.11948168277740479
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.17634998261928558, train_loss: 0.11508788913488388
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9498723149299622, train_loss: 1.0383620262145996
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20677253603935242, train_loss: 0.16516219079494476
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20673902332782745, train_loss: 0.15253357589244843
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20699553191661835, train_loss: 0.1490415781736374
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20716850459575653, train_loss: 0.14440114796161652
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6340183019638062, train_loss: 0.6419227719306946
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5601550340652466, train_loss: 0.45218580961227417
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5616608262062073, train_loss: 0.43706291913986206
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5630730390548706, train_loss: 0.43335267901420593
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5648089051246643, train_loss: 0.42399972677230835
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7361350655555725, train_loss: 0.6942669749259949
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6095038652420044, train_loss: 0.4972187876701355
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5953226685523987, train_loss: 0.4480918347835541
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5952461361885071, train_loss: 0.4372422695159912
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5950039625167847, train_loss: 0.42417043447494507
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7053328156471252, train_loss: 0.7161024808883667
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5942532420158386, train_loss: 0.47753843665122986
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5913451313972473, train_loss: 0.4345863461494446
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5921667218208313, train_loss: 0.41606149077415466
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5934987664222717, train_loss: 0.4170619249343872
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6918839812278748, train_loss: 0.6843289136886597
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5931679606437683, train_loss: 0.5196771025657654
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5873674750328064, train_loss: 0.4752222001552582
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5870799422264099, train_loss: 0.46589764952659607
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.587234377861023, train_loss: 0.4534305930137634
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.734181821346283, train_loss: 0.7458869814872742
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22521011531352997, train_loss: 0.14656327664852142
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22385860979557037, train_loss: 0.13109160959720612
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22384022176265717, train_loss: 0.1260194629430771
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22404184937477112, train_loss: 0.12226875126361847
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3843907117843628, train_loss: 0.44266843795776367
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24159519374370575, train_loss: 0.17310450971126556
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.24162738025188446, train_loss: 0.16231080889701843
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.24235036969184875, train_loss: 0.16072797775268555
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.24275606870651245, train_loss: 0.15527582168579102
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6636784076690674, train_loss: 0.6739733219146729
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5273023247718811, train_loss: 0.4426720142364502
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5239802002906799, train_loss: 0.39796656370162964
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5246644616127014, train_loss: 0.3868672847747803
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5256417989730835, train_loss: 0.37746745347976685
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7447862029075623, train_loss: 0.7420910596847534
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5994205474853516, train_loss: 0.4804292321205139
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5981324911117554, train_loss: 0.4514760375022888
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5988882184028625, train_loss: 0.4481496810913086
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5997483730316162, train_loss: 0.43706661462783813
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7697257399559021, train_loss: 0.7678900957107544
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5289422273635864, train_loss: 0.4654066264629364
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5110780000686646, train_loss: 0.3894815444946289
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5112141966819763, train_loss: 0.3738347887992859
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5113604664802551, train_loss: 0.36486685276031494
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0208885669708252, train_loss: 0.9324002265930176
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.7035963535308838, train_loss: 0.5724594593048096
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5996748208999634, train_loss: 0.46220511198043823
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5663812756538391, train_loss: 0.4152851104736328
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5625845193862915, train_loss: 0.38218557834625244
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5823789238929749, train_loss: 0.6114676594734192
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20983822643756866, train_loss: 0.1252133697271347
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20568884909152985, train_loss: 0.09319795668125153
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2053987681865692, train_loss: 0.09172402322292328
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20569218695163727, train_loss: 0.08995958417654037
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5583919882774353, train_loss: 0.6172683835029602
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21523019671440125, train_loss: 0.14834363758563995
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21636368334293365, train_loss: 0.1339123547077179
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21639412641525269, train_loss: 0.12956488132476807
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.216932013630867, train_loss: 0.1297053098678589
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7586721181869507, train_loss: 0.7891973853111267
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5501515865325928, train_loss: 0.43157586455345154
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5374554991722107, train_loss: 0.36386236548423767
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5377342700958252, train_loss: 0.37098249793052673
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5379793047904968, train_loss: 0.35657626390457153
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6484394669532776, train_loss: 0.6607307195663452
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.591264545917511, train_loss: 0.46736904978752136
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5923251509666443, train_loss: 0.4535256624221802
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5935479998588562, train_loss: 0.457751989364624
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5948300957679749, train_loss: 0.44426247477531433
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6600852608680725, train_loss: 0.7005844116210938
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5293081998825073, train_loss: 0.4359630048274994
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5196231603622437, train_loss: 0.38026079535484314
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5199883580207825, train_loss: 0.36308348178863525
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5204522013664246, train_loss: 0.36453431844711304
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9208883047103882, train_loss: 0.8681301474571228
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.647320568561554, train_loss: 0.550357460975647
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5823025703430176, train_loss: 0.44631561636924744
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5699735283851624, train_loss: 0.39304524660110474
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5705979466438293, train_loss: 0.41920769214630127
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5502575635910034, train_loss: 0.6455132365226746
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.216648668050766, train_loss: 0.140332892537117
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21117433905601501, train_loss: 0.11343878507614136
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21121898293495178, train_loss: 0.11426620930433273
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21121233701705933, train_loss: 0.10642579942941666
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8904208540916443, train_loss: 0.8817922472953796
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19743837416172028, train_loss: 0.14636962115764618
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1969185471534729, train_loss: 0.13853608071804047
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19717200100421906, train_loss: 0.13102202117443085
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19689571857452393, train_loss: 0.12559543550014496
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8115703463554382, train_loss: 0.8561329245567322
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5584642887115479, train_loss: 0.5032373666763306
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5209322571754456, train_loss: 0.3943604826927185
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5197188258171082, train_loss: 0.37098583579063416
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5199321508407593, train_loss: 0.37152087688446045
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7216358780860901, train_loss: 0.6878163814544678
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6038552522659302, train_loss: 0.48113903403282166
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5961818099021912, train_loss: 0.430481493473053
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5960292816162109, train_loss: 0.42343032360076904
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5962674021720886, train_loss: 0.42516908049583435
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6053458452224731, train_loss: 0.6022053956985474
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5395511984825134, train_loss: 0.4218275249004364
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5364869236946106, train_loss: 0.3870542049407959
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5366582870483398, train_loss: 0.3802933096885681
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5366879105567932, train_loss: 0.3728918433189392
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7371228337287903, train_loss: 0.7737163305282593
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5761243104934692, train_loss: 0.5118476152420044
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5658519268035889, train_loss: 0.45830053091049194
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5657479166984558, train_loss: 0.4517554044723511
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5659675002098083, train_loss: 0.4409754276275635
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6711186170578003, train_loss: 0.6719080805778503
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1907501369714737, train_loss: 0.13007047772407532
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19079157710075378, train_loss: 0.11948613077402115
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1905308961868286, train_loss: 0.11874201148748398
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1906348615884781, train_loss: 0.11461889743804932
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5381377339363098, train_loss: 0.5153142213821411
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20326626300811768, train_loss: 0.15834271907806396
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19864541292190552, train_loss: 0.13613370060920715
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19874829053878784, train_loss: 0.12973757088184357
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1978381872177124, train_loss: 0.13072623312473297
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7292950749397278, train_loss: 0.7093138694763184
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5462860465049744, train_loss: 0.43412941694259644
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5385217666625977, train_loss: 0.38424763083457947
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5387219190597534, train_loss: 0.37905916571617126
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5392417311668396, train_loss: 0.377387136220932
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8489342331886292, train_loss: 0.8403270244598389
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6569766402244568, train_loss: 0.5188259482383728
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6212978959083557, train_loss: 0.43260860443115234
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6174138784408569, train_loss: 0.39380955696105957
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6172080039978027, train_loss: 0.3899464011192322
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.710144579410553, train_loss: 0.6749954223632812
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5672690868377686, train_loss: 0.4421638250350952
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.55275958776474, train_loss: 0.3790108859539032
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.553591787815094, train_loss: 0.353352427482605
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5541993975639343, train_loss: 0.35900402069091797
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9201409220695496, train_loss: 0.9069260954856873
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6181862950325012, train_loss: 0.5352082848548889
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5600302219390869, train_loss: 0.44280776381492615
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5507365465164185, train_loss: 0.4020859897136688
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5509876012802124, train_loss: 0.3824150562286377
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.34252724051475525, train_loss: 0.42398974299430847
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2039206176996231, train_loss: 0.13826853036880493
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20317207276821136, train_loss: 0.11478052288293839
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2031441479921341, train_loss: 0.10940100997686386
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20331113040447235, train_loss: 0.11119556427001953
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.43033525347709656, train_loss: 0.44137927889823914
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2059747576713562, train_loss: 0.14869819581508636
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2022838592529297, train_loss: 0.1304931938648224
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2023688107728958, train_loss: 0.1269790530204773
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20238949358463287, train_loss: 0.12234368175268173
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7594413161277771, train_loss: 0.7191174030303955
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.559633195400238, train_loss: 0.44767093658447266
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5494722127914429, train_loss: 0.3780542016029358
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.55019611120224, train_loss: 0.3788875937461853
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5511803030967712, train_loss: 0.37434324622154236
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7928051948547363, train_loss: 0.8764786720275879
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6030898094177246, train_loss: 0.5015329122543335
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5995747447013855, train_loss: 0.4529680907726288
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.599420428276062, train_loss: 0.4453783929347992
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.599994957447052, train_loss: 0.4385489821434021
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7725350856781006, train_loss: 0.7939012050628662
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5498191118240356, train_loss: 0.46601471304893494
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5245970487594604, train_loss: 0.37536412477493286
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5239455103874207, train_loss: 0.3517589271068573
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5244477987289429, train_loss: 0.34724411368370056
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8760547637939453, train_loss: 0.8405985832214355
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.602603554725647, train_loss: 0.5259820818901062
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5905582308769226, train_loss: 0.4533047080039978
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5871031880378723, train_loss: 0.4104275405406952
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5867795348167419, train_loss: 0.4200478494167328
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37811437249183655, train_loss: 0.39639145135879517
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21864789724349976, train_loss: 0.13278187811374664
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2190765142440796, train_loss: 0.12480559200048447
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21978503465652466, train_loss: 0.12101604789495468
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22012360394001007, train_loss: 0.11764683574438095
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35785603523254395, train_loss: 0.43423277139663696
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20915144681930542, train_loss: 0.1598023921251297
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20804278552532196, train_loss: 0.14597511291503906
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20806926488876343, train_loss: 0.14508111774921417
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20778337121009827, train_loss: 0.14007079601287842
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9002692699432373, train_loss: 0.9333252906799316
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5527650713920593, train_loss: 0.4620828628540039
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5444748997688293, train_loss: 0.3805415630340576
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5455445647239685, train_loss: 0.37645193934440613
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5467010736465454, train_loss: 0.37966498732566833
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7392117977142334, train_loss: 0.751365065574646
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6072419285774231, train_loss: 0.5012847185134888
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5932826399803162, train_loss: 0.426353394985199
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5935217142105103, train_loss: 0.41349369287490845
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5935073494911194, train_loss: 0.40757736563682556
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.758556604385376, train_loss: 0.736564040184021
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5820810794830322, train_loss: 0.4449649751186371
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5561732053756714, train_loss: 0.38267824053764343
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.555627703666687, train_loss: 0.3458714485168457
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.555538535118103, train_loss: 0.3410748243331909
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6904024481773376, train_loss: 0.6728135943412781
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5591803789138794, train_loss: 0.49104517698287964
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5464897751808167, train_loss: 0.4345066547393799
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5458930134773254, train_loss: 0.4219301640987396
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5460028052330017, train_loss: 0.4147336483001709
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6134017109870911, train_loss: 0.663909912109375
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20609736442565918, train_loss: 0.12411747127771378
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20629769563674927, train_loss: 0.109951451420784
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20655933022499084, train_loss: 0.11153049767017365
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20712430775165558, train_loss: 0.1078052744269371
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.432378351688385, train_loss: 0.5182297229766846
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2213260680437088, train_loss: 0.17018626630306244
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21480511128902435, train_loss: 0.13964274525642395
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2137748748064041, train_loss: 0.13273797929286957
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21344609558582306, train_loss: 0.1294991821050644
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6695199012756348, train_loss: 0.6783784627914429
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5323361158370972, train_loss: 0.43967384099960327
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5282024145126343, train_loss: 0.3792468309402466
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.52886962890625, train_loss: 0.3665120005607605
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.529660701751709, train_loss: 0.36336445808410645
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9535476565361023, train_loss: 0.9394421577453613
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6930718421936035, train_loss: 0.5579115152359009
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.622265636920929, train_loss: 0.4419148862361908
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6076216697692871, train_loss: 0.40874719619750977
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6062971949577332, train_loss: 0.3633941411972046
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7904256582260132, train_loss: 0.8079733848571777
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5741873383522034, train_loss: 0.4768097400665283
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5479686260223389, train_loss: 0.3974413573741913
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5475468039512634, train_loss: 0.36921972036361694
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5476205945014954, train_loss: 0.36401504278182983
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7550212144851685, train_loss: 0.7170902490615845
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5533260703086853, train_loss: 0.486428439617157
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5439767837524414, train_loss: 0.4419916570186615
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5443739891052246, train_loss: 0.43100854754447937
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5450443625450134, train_loss: 0.4297604560852051
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.46908068656921387, train_loss: 0.46859103441238403
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20814934372901917, train_loss: 0.13686199486255646
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2060943990945816, train_loss: 0.11371394246816635
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20592156052589417, train_loss: 0.11481262743473053
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20589816570281982, train_loss: 0.11226493120193481
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.44210416078567505, train_loss: 0.42353707551956177
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21402710676193237, train_loss: 0.15630631148815155
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21123570203781128, train_loss: 0.12494503706693649
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21099749207496643, train_loss: 0.11957277357578278
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2108442187309265, train_loss: 0.11544215679168701
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.741512656211853, train_loss: 0.7091635465621948
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5416706204414368, train_loss: 0.4344227910041809
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.539615273475647, train_loss: 0.3853209912776947
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5407015681266785, train_loss: 0.37955793738365173
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5420174598693848, train_loss: 0.36250337958335876
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7575684785842896, train_loss: 0.7147766351699829
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.613557755947113, train_loss: 0.4775218963623047
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5917280912399292, train_loss: 0.4092974066734314
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5889968872070312, train_loss: 0.39323315024375916
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5893476605415344, train_loss: 0.38590678572654724
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7482513189315796, train_loss: 0.664491593837738
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5942728519439697, train_loss: 0.4498767852783203
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5673378705978394, train_loss: 0.3861287534236908
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5658379197120667, train_loss: 0.35770559310913086
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5656090378761292, train_loss: 0.3452397286891937
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6952414512634277, train_loss: 0.6749067306518555
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.545974612236023, train_loss: 0.4906226098537445
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5448864698410034, train_loss: 0.4451748728752136
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5454582571983337, train_loss: 0.4391424059867859
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5459756851196289, train_loss: 0.440784752368927
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4274531304836273, train_loss: 0.4049515724182129
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21738353371620178, train_loss: 0.13059033453464508
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21567146480083466, train_loss: 0.10449016094207764
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2158089280128479, train_loss: 0.10377871245145798
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21607482433319092, train_loss: 0.10037384182214737
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45171448588371277, train_loss: 0.5912140011787415
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19901640713214874, train_loss: 0.1645282357931137
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19776135683059692, train_loss: 0.14957168698310852
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19717198610305786, train_loss: 0.14122840762138367
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19694580137729645, train_loss: 0.1412665843963623
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6969192624092102, train_loss: 0.701006293296814
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.548373281955719, train_loss: 0.40598368644714355
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5482892990112305, train_loss: 0.3666536509990692
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5494093298912048, train_loss: 0.36329516768455505
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5506861209869385, train_loss: 0.3575899004936218
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8785800337791443, train_loss: 0.8408976793289185
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6574674248695374, train_loss: 0.5209821462631226
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6200080513954163, train_loss: 0.4259178340435028
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.617046594619751, train_loss: 0.4097900390625
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6170028448104858, train_loss: 0.4070146083831787
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6298913955688477, train_loss: 0.666026771068573
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5340601801872253, train_loss: 0.4333270490169525
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5301698446273804, train_loss: 0.36834943294525146
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5308594107627869, train_loss: 0.36573362350463867
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5316925048828125, train_loss: 0.3725767135620117
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8175759315490723, train_loss: 0.7719516754150391
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5851066708564758, train_loss: 0.511835515499115
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5597150325775146, train_loss: 0.4367591142654419
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5594769716262817, train_loss: 0.41490042209625244
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5598117113113403, train_loss: 0.4095083177089691
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.679690420627594, train_loss: 0.7038165926933289
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19900760054588318, train_loss: 0.1334279477596283
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19937914609909058, train_loss: 0.12088431417942047
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19931960105895996, train_loss: 0.11518921703100204
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1994573026895523, train_loss: 0.11063768714666367
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.37365207076072693, train_loss: 0.44456416368484497
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20343069732189178, train_loss: 0.15604732930660248
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20191611349582672, train_loss: 0.14295655488967896
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2020024210214615, train_loss: 0.13489936292171478
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2019602209329605, train_loss: 0.13036541640758514
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.050356388092041, train_loss: 1.1736743450164795
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6666020154953003, train_loss: 0.6336202621459961
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5676180720329285, train_loss: 0.4326934814453125
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5465984344482422, train_loss: 0.35396504402160645
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5464942455291748, train_loss: 0.3286382555961609
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7293577790260315, train_loss: 0.7625012397766113
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5733795762062073, train_loss: 0.4952641427516937
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5733588933944702, train_loss: 0.46250683069229126
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5740379691123962, train_loss: 0.45512673258781433
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5749807357788086, train_loss: 0.43882691860198975
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6835120916366577, train_loss: 0.6785858869552612
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5334575772285461, train_loss: 0.43076783418655396
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5243815779685974, train_loss: 0.3666993975639343
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5254568457603455, train_loss: 0.37126827239990234
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5256823301315308, train_loss: 0.35495299100875854
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8624273538589478, train_loss: 0.8164345026016235
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.55135577917099, train_loss: 0.48070284724235535
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5379619598388672, train_loss: 0.4383276402950287
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5376434326171875, train_loss: 0.4280824661254883
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5377140641212463, train_loss: 0.4096662998199463
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7439123392105103, train_loss: 0.6831052899360657
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21040920913219452, train_loss: 0.12960128486156464
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20775175094604492, train_loss: 0.11341758072376251
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2071976512670517, train_loss: 0.11002446711063385
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2073054015636444, train_loss: 0.10382027924060822
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45107078552246094, train_loss: 0.5157135128974915
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.18163512647151947, train_loss: 0.16333997249603271
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.18060125410556793, train_loss: 0.13335511088371277
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.18056519329547882, train_loss: 0.13249634206295013
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.18109391629695892, train_loss: 0.12911398708820343
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8274035453796387, train_loss: 0.7974783778190613
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5153090357780457, train_loss: 0.4855644702911377
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.46160057187080383, train_loss: 0.401943564414978
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4435863792896271, train_loss: 0.36693382263183594
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4356888234615326, train_loss: 0.32927206158638
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.43544313311576843, train_loss: 0.3222324252128601
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6508520841598511, train_loss: 0.6267175674438477
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5778317451477051, train_loss: 0.4862850606441498
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5769951939582825, train_loss: 0.46056637167930603
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5773367285728455, train_loss: 0.4544907212257385
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5778783559799194, train_loss: 0.4355752468109131
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7805677652359009, train_loss: 0.8138994574546814
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5200831890106201, train_loss: 0.49590128660202026
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4742596745491028, train_loss: 0.41137003898620605
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.46641048789024353, train_loss: 0.36131906509399414
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.46679437160491943, train_loss: 0.35905084013938904
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6322287917137146, train_loss: 0.6245849132537842
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5597071051597595, train_loss: 0.4569928050041199
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5599498152732849, train_loss: 0.4425949454307556
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5607602596282959, train_loss: 0.4437694549560547
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5615779757499695, train_loss: 0.4346136450767517
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7120630145072937, train_loss: 0.6565665602684021
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19553756713867188, train_loss: 0.1319366991519928
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19085857272148132, train_loss: 0.10697297006845474
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18985264003276825, train_loss: 0.10326077044010162
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18960778415203094, train_loss: 0.10768101364374161
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5216619372367859, train_loss: 0.4957883358001709
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21811634302139282, train_loss: 0.16218088567256927
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2183353751897812, train_loss: 0.1452544927597046
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2190452665090561, train_loss: 0.13167208433151245
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21996676921844482, train_loss: 0.13382790982723236
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 477/15001 [00:00<00:15, 953.69it/s]Shapley Value Sampling attribution:   6%|▋         | 955/15001 [00:01<00:14, 954.56it/s]Shapley Value Sampling attribution:  10%|▉         | 1434/15001 [00:01<00:14, 955.35it/s]Shapley Value Sampling attribution:  13%|█▎        | 1912/15001 [00:02<00:13, 955.36it/s]Shapley Value Sampling attribution:  16%|█▌        | 2390/15001 [00:02<00:13, 955.28it/s]Shapley Value Sampling attribution:  19%|█▉        | 2868/15001 [00:03<00:12, 955.12it/s]Shapley Value Sampling attribution:  22%|██▏       | 3346/15001 [00:03<00:12, 955.23it/s]Shapley Value Sampling attribution:  25%|██▌       | 3825/15001 [00:04<00:11, 955.84it/s]Shapley Value Sampling attribution:  29%|██▊       | 4305/15001 [00:04<00:11, 956.74it/s]Shapley Value Sampling attribution:  32%|███▏      | 4784/15001 [00:05<00:11, 923.19it/s]Shapley Value Sampling attribution:  35%|███▍      | 5247/15001 [00:05<00:10, 901.59it/s]Shapley Value Sampling attribution:  38%|███▊      | 5699/15001 [00:06<00:10, 888.71it/s]Shapley Value Sampling attribution:  41%|████      | 6145/15001 [00:06<00:10, 880.22it/s]Shapley Value Sampling attribution:  44%|████▍     | 6586/15001 [00:07<00:10, 816.01it/s]Shapley Value Sampling attribution:  47%|████▋     | 6999/15001 [00:08<00:12, 661.59it/s]Shapley Value Sampling attribution:  49%|████▉     | 7355/15001 [00:08<00:12, 603.30it/s]Shapley Value Sampling attribution:  51%|█████     | 7676/15001 [00:09<00:11, 610.59it/s]Shapley Value Sampling attribution:  53%|█████▎    | 7996/15001 [00:09<00:11, 610.06it/s]Shapley Value Sampling attribution:  55%|█████▌    | 8311/15001 [00:10<00:11, 599.51it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8618/15001 [00:11<00:10, 588.99it/s]Shapley Value Sampling attribution:  59%|█████▉    | 8917/15001 [00:11<00:10, 581.25it/s]Shapley Value Sampling attribution:  61%|██████▏   | 9211/15001 [00:12<00:10, 577.19it/s]Shapley Value Sampling attribution:  63%|██████▎   | 9502/15001 [00:12<00:09, 574.93it/s]Shapley Value Sampling attribution:  65%|██████▌   | 9791/15001 [00:13<00:09, 573.18it/s]Shapley Value Sampling attribution:  67%|██████▋   | 10079/15001 [00:13<00:08, 571.75it/s]Shapley Value Sampling attribution:  69%|██████▉   | 10366/15001 [00:14<00:08, 571.48it/s]Shapley Value Sampling attribution:  71%|███████   | 10654/15001 [00:14<00:07, 572.41it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10942/15001 [00:15<00:07, 573.19it/s]Shapley Value Sampling attribution:  75%|███████▍  | 11229/15001 [00:15<00:06, 571.62it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11562/15001 [00:16<00:05, 599.44it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11965/15001 [00:16<00:04, 660.72it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12399/15001 [00:17<00:03, 722.15it/s]Shapley Value Sampling attribution:  86%|████████▌ | 12854/15001 [00:17<00:02, 778.15it/s]Shapley Value Sampling attribution:  89%|████████▉ | 13324/15001 [00:18<00:02, 826.48it/s]Shapley Value Sampling attribution:  92%|█████████▏| 13804/15001 [00:18<00:01, 866.08it/s]Shapley Value Sampling attribution:  95%|█████████▌| 14282/15001 [00:19<00:00, 892.64it/s]Shapley Value Sampling attribution:  98%|█████████▊| 14762/15001 [00:19<00:00, 912.81it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:19<00:00, 753.09it/s]
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 481/15001 [00:00<00:15, 960.83it/s]Shapley Value Sampling attribution:   6%|▋         | 963/15001 [00:01<00:14, 962.36it/s]Shapley Value Sampling attribution:  10%|▉         | 1445/15001 [00:01<00:14, 960.47it/s]Shapley Value Sampling attribution:  13%|█▎        | 1926/15001 [00:02<00:13, 960.28it/s]Shapley Value Sampling attribution:  16%|█▌        | 2408/15001 [00:02<00:13, 961.31it/s]Shapley Value Sampling attribution:  19%|█▉        | 2889/15001 [00:03<00:12, 960.67it/s]Shapley Value Sampling attribution:  22%|██▏       | 3371/15001 [00:03<00:12, 961.74it/s]Shapley Value Sampling attribution:  26%|██▌       | 3852/15001 [00:04<00:11, 961.76it/s]Shapley Value Sampling attribution:  29%|██▉       | 4334/15001 [00:04<00:11, 962.01it/s]Shapley Value Sampling attribution:  32%|███▏      | 4816/15001 [00:05<00:11, 873.12it/s]Shapley Value Sampling attribution:  35%|███▌      | 5261/15001 [00:05<00:11, 817.93it/s]Shapley Value Sampling attribution:  38%|███▊      | 5735/15001 [00:06<00:10, 853.55it/s]Shapley Value Sampling attribution:  41%|████▏     | 6216/15001 [00:06<00:09, 883.73it/s]Shapley Value Sampling attribution:  45%|████▍     | 6695/15001 [00:07<00:09, 905.01it/s]Shapley Value Sampling attribution:  48%|████▊     | 7173/15001 [00:07<00:08, 919.67it/s]Shapley Value Sampling attribution:  51%|█████     | 7653/15001 [00:08<00:07, 931.00it/s]Shapley Value Sampling attribution:  54%|█████▍    | 8132/15001 [00:08<00:07, 938.69it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8612/15001 [00:09<00:06, 944.56it/s]Shapley Value Sampling attribution:  61%|██████    | 9091/15001 [00:09<00:06, 948.27it/s]Shapley Value Sampling attribution:  64%|██████▍   | 9572/15001 [00:10<00:05, 951.81it/s]Shapley Value Sampling attribution:  67%|██████▋   | 10051/15001 [00:10<00:05, 953.57it/s]Shapley Value Sampling attribution:  70%|███████   | 10532/15001 [00:11<00:04, 955.82it/s]Shapley Value Sampling attribution:  73%|███████▎  | 11012/15001 [00:11<00:04, 956.58it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11491/15001 [00:12<00:03, 914.46it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11951/15001 [00:12<00:03, 883.41it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12395/15001 [00:13<00:03, 851.45it/s]Shapley Value Sampling attribution:  85%|████████▌ | 12823/15001 [00:14<00:02, 839.68it/s]Shapley Value Sampling attribution:  88%|████████▊ | 13245/15001 [00:14<00:02, 833.23it/s]Shapley Value Sampling attribution:  91%|█████████ | 13663/15001 [00:15<00:01, 771.17it/s]Shapley Value Sampling attribution:  94%|█████████▎| 14053/15001 [00:15<00:01, 681.32it/s]Shapley Value Sampling attribution:  96%|█████████▌| 14405/15001 [00:16<00:00, 627.93it/s]Shapley Value Sampling attribution:  98%|█████████▊| 14729/15001 [00:17<00:00, 606.84it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:17<00:00, 846.38it/s]
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:08<02:02,  8.74s/it]importance j:  13%|█▎        | 2/15 [00:22<02:31, 11.67s/it]importance j:  20%|██        | 3/15 [00:31<02:03, 10.30s/it]importance j:  27%|██▋       | 4/15 [00:46<02:13, 12.13s/it]importance j:  33%|███▎      | 5/15 [00:55<01:51, 11.11s/it]importance j:  40%|████      | 6/15 [01:05<01:35, 10.65s/it]importance j:  47%|████▋     | 7/15 [01:18<01:32, 11.62s/it]importance j:  53%|█████▎    | 8/15 [01:27<01:15, 10.79s/it]importance j:  60%|██████    | 9/15 [01:41<01:11, 11.86s/it]importance j:  67%|██████▋   | 10/15 [01:50<00:54, 10.86s/it]importance j:  73%|███████▎  | 11/15 [02:01<00:43, 11.00s/it]importance j:  80%|████████  | 12/15 [02:12<00:32, 10.83s/it]importance j:  87%|████████▋ | 13/15 [02:20<00:20, 10.10s/it]importance j:  93%|█████████▎| 14/15 [02:37<00:12, 12.01s/it]importance j: 100%|██████████| 15/15 [02:45<00:00, 11.01s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7955988645553589, train_loss: 0.83098304271698
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5432306528091431, train_loss: 0.47528308629989624
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5282443761825562, train_loss: 0.40814146399497986
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5285660028457642, train_loss: 0.39685583114624023
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5289338827133179, train_loss: 0.39293116331100464
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7849683165550232, train_loss: 0.8282942771911621
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6015449166297913, train_loss: 0.5380088090896606
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5750844478607178, train_loss: 0.47008955478668213
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5716519355773926, train_loss: 0.4477185010910034
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.571423351764679, train_loss: 0.4305874705314636
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7207598686218262, train_loss: 0.6963398456573486
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5471295118331909, train_loss: 0.48330920934677124
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5078558921813965, train_loss: 0.40603107213974
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5003389120101929, train_loss: 0.3631312847137451
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5003321170806885, train_loss: 0.35458749532699585
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7801422476768494, train_loss: 0.8334199786186218
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5367403626441956, train_loss: 0.5127243995666504
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5340188145637512, train_loss: 0.4714471697807312
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5347703099250793, train_loss: 0.4754749536514282
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5352544784545898, train_loss: 0.4625183045864105
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5399972796440125, train_loss: 0.6140102744102478
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19910196959972382, train_loss: 0.12949231266975403
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1996179074048996, train_loss: 0.12585929036140442
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19948594272136688, train_loss: 0.12433159351348877
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19968567788600922, train_loss: 0.11582001298666
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45005184412002563, train_loss: 0.4829493463039398
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19518649578094482, train_loss: 0.1614939570426941
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19383826851844788, train_loss: 0.14608712494373322
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19366765022277832, train_loss: 0.15246738493442535
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19448131322860718, train_loss: 0.1449698656797409
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6813486218452454, train_loss: 0.7144173383712769
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5312193632125854, train_loss: 0.44434115290641785
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5279712080955505, train_loss: 0.3935033082962036
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5285616517066956, train_loss: 0.3908781409263611
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5295413732528687, train_loss: 0.38414251804351807
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7637449502944946, train_loss: 0.7728314399719238
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5866348743438721, train_loss: 0.4957237243652344
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5827040076255798, train_loss: 0.44510596990585327
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.583114504814148, train_loss: 0.445371150970459
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5838534235954285, train_loss: 0.4350963234901428
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8885213732719421, train_loss: 0.9142720103263855
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5934933423995972, train_loss: 0.4950990676879883
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5523078441619873, train_loss: 0.4030190408229828
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5479342341423035, train_loss: 0.35843905806541443
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5482972264289856, train_loss: 0.3577520251274109
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7002012133598328, train_loss: 0.702728271484375
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5505446195602417, train_loss: 0.5026242733001709
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.546588659286499, train_loss: 0.45515626668930054
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5468417406082153, train_loss: 0.46762174367904663
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5474447011947632, train_loss: 0.45699378848075867
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4375840723514557, train_loss: 0.47827252745628357
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20301389694213867, train_loss: 0.13060292601585388
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19804567098617554, train_loss: 0.1040019541978836
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19792556762695312, train_loss: 0.10210869461297989
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19778883457183838, train_loss: 0.1007082462310791
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4926278591156006, train_loss: 0.5931206345558167
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19617241621017456, train_loss: 0.1546405404806137
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19581513106822968, train_loss: 0.1419192999601364
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1961110234260559, train_loss: 0.13837073743343353
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19600825011730194, train_loss: 0.13563315570354462
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7607823014259338, train_loss: 0.7660248279571533
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5586444139480591, train_loss: 0.4478631913661957
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5521716475486755, train_loss: 0.37642472982406616
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5527147650718689, train_loss: 0.36929425597190857
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5535669922828674, train_loss: 0.38277411460876465
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.656268835067749, train_loss: 0.6785295009613037
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5851909518241882, train_loss: 0.45628827810287476
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.586280345916748, train_loss: 0.45348256826400757
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5873339772224426, train_loss: 0.4377506673336029
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5883234143257141, train_loss: 0.4353472590446472
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7764406800270081, train_loss: 0.8107727766036987
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5545305013656616, train_loss: 0.4467047154903412
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5367965698242188, train_loss: 0.3760678172111511
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5372815132141113, train_loss: 0.3486385941505432
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5375455617904663, train_loss: 0.339372456073761
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8636264801025391, train_loss: 0.8079966902732849
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5867571830749512, train_loss: 0.5366519689559937
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5516935586929321, train_loss: 0.448621928691864
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5482138991355896, train_loss: 0.418672651052475
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5486642718315125, train_loss: 0.4073886275291443
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.816439151763916, train_loss: 0.7676615118980408
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22703340649604797, train_loss: 0.13536714017391205
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22350314259529114, train_loss: 0.10730793327093124
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2237468659877777, train_loss: 0.10699911415576935
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22380992770195007, train_loss: 0.10489069670438766
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6566688418388367, train_loss: 0.699725329875946
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20231571793556213, train_loss: 0.15827582776546478
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20145680010318756, train_loss: 0.14311935007572174
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2011195868253708, train_loss: 0.13938474655151367
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2012077420949936, train_loss: 0.13842152059078217
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6524087190628052, train_loss: 0.6560548543930054
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5317610502243042, train_loss: 0.4090196490287781
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.533255398273468, train_loss: 0.39295336604118347
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5344485640525818, train_loss: 0.3775565028190613
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.53586745262146, train_loss: 0.3728971481323242
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7283883094787598, train_loss: 0.7147373557090759
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5983509421348572, train_loss: 0.48922479152679443
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5869170427322388, train_loss: 0.4110141694545746
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5875855684280396, train_loss: 0.4087519645690918
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5883589386940002, train_loss: 0.40387576818466187
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7466632127761841, train_loss: 0.7384333610534668
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5569095611572266, train_loss: 0.456817626953125
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5409457683563232, train_loss: 0.3735073208808899
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5412421226501465, train_loss: 0.3667394518852234
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5414718985557556, train_loss: 0.3623529374599457
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7186792492866516, train_loss: 0.6979305148124695
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.570462167263031, train_loss: 0.4884999394416809
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5476316809654236, train_loss: 0.44070467352867126
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5468811392784119, train_loss: 0.4198031425476074
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5467314720153809, train_loss: 0.413754403591156
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6124563217163086, train_loss: 0.6048951148986816
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21138927340507507, train_loss: 0.13159747421741486
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20306502282619476, train_loss: 0.09839727729558945
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20257507264614105, train_loss: 0.097598135471344
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20246239006519318, train_loss: 0.09261008352041245
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.42061862349510193, train_loss: 0.38738003373146057
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21569885313510895, train_loss: 0.14913888275623322
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21242749691009521, train_loss: 0.132585346698761
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21191251277923584, train_loss: 0.13273756206035614
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21191808581352234, train_loss: 0.12892085313796997
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.857273280620575, train_loss: 0.9306581020355225
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6308990716934204, train_loss: 0.530130922794342
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6047718524932861, train_loss: 0.4330793023109436
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.605623722076416, train_loss: 0.4082742929458618
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6066149473190308, train_loss: 0.399635374546051
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.667770266532898, train_loss: 0.6648229956626892
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5902013778686523, train_loss: 0.49786728620529175
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5903483033180237, train_loss: 0.4708305299282074
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5907463431358337, train_loss: 0.4552287757396698
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5915333032608032, train_loss: 0.4513530433177948
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8724636435508728, train_loss: 0.8259696960449219
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6878863573074341, train_loss: 0.508391797542572
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6516119241714478, train_loss: 0.41061827540397644
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6508546471595764, train_loss: 0.3827054500579834
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6516075730323792, train_loss: 0.3963634967803955
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7856236696243286, train_loss: 0.8256356120109558
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5846431255340576, train_loss: 0.5567750930786133
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5677710771560669, train_loss: 0.4761699438095093
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5697545409202576, train_loss: 0.4641532897949219
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5707899332046509, train_loss: 0.4530310034751892
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.0954616069793701, train_loss: 1.1502230167388916
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.24414663016796112, train_loss: 0.14493215084075928
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2394886314868927, train_loss: 0.11845525354146957
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.23925600945949554, train_loss: 0.11566390097141266
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2395593822002411, train_loss: 0.11417515575885773
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4147321283817291, train_loss: 0.43626537919044495
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21960195899009705, train_loss: 0.1680542379617691
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21871864795684814, train_loss: 0.15298089385032654
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2189347892999649, train_loss: 0.1427658051252365
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21940681338310242, train_loss: 0.14125753939151764
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5935857892036438, train_loss: 0.5645995736122131
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5201701521873474, train_loss: 0.3932763934135437
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5212571620941162, train_loss: 0.4038507640361786
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5226515531539917, train_loss: 0.39153993129730225
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.524223268032074, train_loss: 0.38091301918029785
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7379879951477051, train_loss: 0.714068591594696
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6052866578102112, train_loss: 0.48410695791244507
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5960710644721985, train_loss: 0.42712244391441345
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5959648489952087, train_loss: 0.4273284375667572
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5958090424537659, train_loss: 0.42261791229248047
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6116349101066589, train_loss: 0.6218778491020203
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5316120386123657, train_loss: 0.4188171327114105
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5290666222572327, train_loss: 0.370322048664093
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5295034646987915, train_loss: 0.3685932159423828
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5303184390068054, train_loss: 0.358299195766449
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.777821958065033, train_loss: 0.7729583978652954
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5776988863945007, train_loss: 0.5139486789703369
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5563134551048279, train_loss: 0.4490832984447479
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5567247867584229, train_loss: 0.4294479787349701
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5572989583015442, train_loss: 0.42801469564437866
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5767192244529724, train_loss: 0.5583070516586304
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19943766295909882, train_loss: 0.12205109745264053
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19493672251701355, train_loss: 0.09445027261972427
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1951175034046173, train_loss: 0.09078844636678696
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1950693428516388, train_loss: 0.09426768124103546
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34051865339279175, train_loss: 0.4062638282775879
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2048414647579193, train_loss: 0.15153086185455322
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2035333663225174, train_loss: 0.13184328377246857
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2038046270608902, train_loss: 0.12984994053840637
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20425604283809662, train_loss: 0.12760011851787567
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6560328602790833, train_loss: 0.6789195537567139
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5263946652412415, train_loss: 0.4111928939819336
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5271140336990356, train_loss: 0.3848344683647156
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5280975699424744, train_loss: 0.3746328353881836
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5293384194374084, train_loss: 0.3748553991317749
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7276775240898132, train_loss: 0.7430052757263184
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.616310715675354, train_loss: 0.4921870231628418
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6120404601097107, train_loss: 0.43626707792282104
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6128007769584656, train_loss: 0.44647592306137085
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.613827109336853, train_loss: 0.43455106019973755
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.645557165145874, train_loss: 0.6867188215255737
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5146271586418152, train_loss: 0.43872007727622986
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5099107623100281, train_loss: 0.3747860789299011
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5104261636734009, train_loss: 0.37085896730422974
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5113124251365662, train_loss: 0.3697051405906677
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7408825755119324, train_loss: 0.7578889727592468
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5212619304656982, train_loss: 0.505579948425293
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5157288908958435, train_loss: 0.4606294631958008
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5163295269012451, train_loss: 0.4505116939544678
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5168703198432922, train_loss: 0.4436533451080322
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.35455814003944397, train_loss: 0.36125946044921875
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22088362276554108, train_loss: 0.12149856239557266
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.217527374625206, train_loss: 0.09986939281225204
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21796494722366333, train_loss: 0.10107841342687607
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21820591390132904, train_loss: 0.09926015138626099
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4132750332355499, train_loss: 0.49716541171073914
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.18773123621940613, train_loss: 0.14757607877254486
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.18626153469085693, train_loss: 0.12098586559295654
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1866201013326645, train_loss: 0.1244351863861084
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.18645621836185455, train_loss: 0.11836433410644531
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6923837661743164, train_loss: 0.7128929495811462
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5353263020515442, train_loss: 0.45055079460144043
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5244227647781372, train_loss: 0.3816559910774231
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5247329473495483, train_loss: 0.37727975845336914
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5252178907394409, train_loss: 0.36800727248191833
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6924623847007751, train_loss: 0.6734495162963867
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5911030769348145, train_loss: 0.4642368257045746
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.587299108505249, train_loss: 0.42110714316368103
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5877933502197266, train_loss: 0.41384217143058777
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5886867642402649, train_loss: 0.42184025049209595
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7551966309547424, train_loss: 0.7278734445571899
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5490943193435669, train_loss: 0.45040035247802734
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5257382392883301, train_loss: 0.3708662986755371
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5261402726173401, train_loss: 0.3632321357727051
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5265393853187561, train_loss: 0.346372127532959
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7260078191757202, train_loss: 0.6835588216781616
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5830809473991394, train_loss: 0.49764594435691833
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5764437317848206, train_loss: 0.450979083776474
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5768267512321472, train_loss: 0.4430033564567566
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5773999691009521, train_loss: 0.4539586901664734
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.572786271572113, train_loss: 0.6590723395347595
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17744408547878265, train_loss: 0.1365995705127716
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.17852699756622314, train_loss: 0.12430141121149063
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.17917267978191376, train_loss: 0.11796100437641144
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.17987915873527527, train_loss: 0.11183693259954453
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3929608464241028, train_loss: 0.5069603323936462
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2071622610092163, train_loss: 0.1585988998413086
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20771922171115875, train_loss: 0.13555102050304413
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20759448409080505, train_loss: 0.13068556785583496
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20777668058872223, train_loss: 0.1298626959323883
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6867609024047852, train_loss: 0.671907901763916
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5386608839035034, train_loss: 0.4441918730735779
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5368461012840271, train_loss: 0.3992469012737274
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5374453663825989, train_loss: 0.38656121492385864
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5381960868835449, train_loss: 0.38005703687667847
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7610353231430054, train_loss: 0.7293195128440857
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6090883016586304, train_loss: 0.4809587597846985
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5978174209594727, train_loss: 0.4133222997188568
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5983572006225586, train_loss: 0.4054064452648163
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5987640023231506, train_loss: 0.4073145389556885
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7112069725990295, train_loss: 0.6684927344322205
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5895247459411621, train_loss: 0.4416767954826355
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5783008933067322, train_loss: 0.36292120814323425
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5798263549804688, train_loss: 0.3493337631225586
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5803168416023254, train_loss: 0.34764915704727173
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8564653992652893, train_loss: 0.8168290853500366
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5743568539619446, train_loss: 0.507660984992981
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5564488172531128, train_loss: 0.45239076018333435
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5569835305213928, train_loss: 0.4471859335899353
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5575155019760132, train_loss: 0.42825478315353394
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5926979780197144, train_loss: 0.6004044413566589
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21792997419834137, train_loss: 0.13387422263622284
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21492189168930054, train_loss: 0.10559593886137009
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2146061360836029, train_loss: 0.10442574322223663
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21452976763248444, train_loss: 0.10019152611494064
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.36381009221076965, train_loss: 0.4142328202724457
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2034660428762436, train_loss: 0.15329284965991974
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20189669728279114, train_loss: 0.13329516351222992
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20198732614517212, train_loss: 0.12899130582809448
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20226427912712097, train_loss: 0.12776710093021393
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8474593162536621, train_loss: 0.898360013961792
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5604528188705444, train_loss: 0.47484272718429565
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5434945225715637, train_loss: 0.3990011215209961
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5442643761634827, train_loss: 0.37606632709503174
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5452667474746704, train_loss: 0.36355480551719666
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6122090220451355, train_loss: 0.6255190372467041
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5731761455535889, train_loss: 0.45387911796569824
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5733357071876526, train_loss: 0.4564474821090698
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5736011266708374, train_loss: 0.46491703391075134
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5737349390983582, train_loss: 0.44358500838279724
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9346736669540405, train_loss: 0.9289325475692749
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6686121225357056, train_loss: 0.5204651355743408
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5841598510742188, train_loss: 0.4016891419887543
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5601168870925903, train_loss: 0.3394467532634735
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5580725073814392, train_loss: 0.3156798779964447
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7783661484718323, train_loss: 0.7452136874198914
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5873720049858093, train_loss: 0.4957582354545593
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5667768120765686, train_loss: 0.44171881675720215
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5653131604194641, train_loss: 0.4174380302429199
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5654284358024597, train_loss: 0.40375369787216187
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9873152375221252, train_loss: 0.9690724611282349
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1963474601507187, train_loss: 0.12107344716787338
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19430646300315857, train_loss: 0.0993383452296257
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19479745626449585, train_loss: 0.09855099767446518
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1950387805700302, train_loss: 0.09459325671195984
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5771597027778625, train_loss: 0.6777306199073792
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22056758403778076, train_loss: 0.14829206466674805
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20983096957206726, train_loss: 0.1198122426867485
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20970065891742706, train_loss: 0.11563559621572495
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2100771963596344, train_loss: 0.11010225862264633
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7468016147613525, train_loss: 0.7764700651168823
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.553062379360199, train_loss: 0.45119404792785645
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5437360405921936, train_loss: 0.3901106119155884
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.544251024723053, train_loss: 0.3784199357032776
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5450841784477234, train_loss: 0.38374876976013184
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6867325901985168, train_loss: 0.7625514268875122
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5800413489341736, train_loss: 0.49247461557388306
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5757113695144653, train_loss: 0.4465489089488983
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5759902000427246, train_loss: 0.44997963309288025
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.576440155506134, train_loss: 0.4385168254375458
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7963832020759583, train_loss: 0.8443624377250671
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5465895533561707, train_loss: 0.47464555501937866
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5312079191207886, train_loss: 0.38435959815979004
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5314246416091919, train_loss: 0.3743510842323303
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5317786335945129, train_loss: 0.37919244170188904
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6144469976425171, train_loss: 0.6898877620697021
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5384991765022278, train_loss: 0.49571692943573
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5386731028556824, train_loss: 0.479419469833374
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5392186641693115, train_loss: 0.47835367918014526
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5395201444625854, train_loss: 0.4778655469417572
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40726879239082336, train_loss: 0.4799809455871582
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2058696150779724, train_loss: 0.13493292033672333
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19851088523864746, train_loss: 0.10049500316381454
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19875651597976685, train_loss: 0.09862031787633896
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19902491569519043, train_loss: 0.09622537344694138
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3132536709308624, train_loss: 0.32861486077308655
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20723512768745422, train_loss: 0.1541183739900589
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20731770992279053, train_loss: 0.13904313743114471
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20716996490955353, train_loss: 0.13809502124786377
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20752361416816711, train_loss: 0.1360958218574524
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6616025567054749, train_loss: 0.6243134140968323
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5320662260055542, train_loss: 0.40381869673728943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5334546566009521, train_loss: 0.37897443771362305
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5346634984016418, train_loss: 0.37200164794921875
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5361981391906738, train_loss: 0.3674613833427429
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6362934708595276, train_loss: 0.6429311633110046
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.591849684715271, train_loss: 0.46387219429016113
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5937907099723816, train_loss: 0.45596107840538025
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5947902202606201, train_loss: 0.4573500156402588
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5959374308586121, train_loss: 0.4498624801635742
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7869927287101746, train_loss: 0.7876828908920288
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.578879714012146, train_loss: 0.4772028923034668
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5489115118980408, train_loss: 0.3984423875808716
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5458053946495056, train_loss: 0.36388906836509705
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5461035966873169, train_loss: 0.3634417653083801
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7033803462982178, train_loss: 0.7127553820610046
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5695796012878418, train_loss: 0.5061997175216675
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5532054305076599, train_loss: 0.46051812171936035
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5526509284973145, train_loss: 0.4347914159297943
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5522652268409729, train_loss: 0.4237264096736908
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.32701292634010315, train_loss: 0.36123454570770264
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19160623848438263, train_loss: 0.12955842912197113
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1920526623725891, train_loss: 0.12448487430810928
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19243350625038147, train_loss: 0.12185762077569962
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19265255331993103, train_loss: 0.11764537543058395
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6598348021507263, train_loss: 0.6615380644798279
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2062615007162094, train_loss: 0.1621641367673874
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20405510067939758, train_loss: 0.13815104961395264
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20409531891345978, train_loss: 0.14035312831401825
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2038315087556839, train_loss: 0.1333753615617752
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6737838983535767, train_loss: 0.6624139547348022
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5296469926834106, train_loss: 0.4175884425640106
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5235570073127747, train_loss: 0.3732388913631439
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5238431692123413, train_loss: 0.3604847192764282
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5245604515075684, train_loss: 0.3593294322490692
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7555798292160034, train_loss: 0.7442973852157593
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6025241017341614, train_loss: 0.4917762279510498
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5901225805282593, train_loss: 0.4258994460105896
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5903105139732361, train_loss: 0.42605066299438477
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5909667015075684, train_loss: 0.4091258943080902
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.738024115562439, train_loss: 0.8004948496818542
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5444141030311584, train_loss: 0.4648815095424652
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5177943706512451, train_loss: 0.38101840019226074
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5114932656288147, train_loss: 0.34053918719291687
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5116008520126343, train_loss: 0.3388233184814453
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6360433101654053, train_loss: 0.7009560465812683
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5360202193260193, train_loss: 0.49328646063804626
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5353617668151855, train_loss: 0.467420756816864
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.535334587097168, train_loss: 0.45154452323913574
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5356349349021912, train_loss: 0.44513535499572754
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40921729803085327, train_loss: 0.3834260404109955
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1991858333349228, train_loss: 0.14051324129104614
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19498641788959503, train_loss: 0.11962516605854034
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19436964392662048, train_loss: 0.11605043709278107
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19407886266708374, train_loss: 0.11445964872837067
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5120605230331421, train_loss: 0.6358172297477722
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19908122718334198, train_loss: 0.15513387322425842
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19559091329574585, train_loss: 0.13510988652706146
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19536805152893066, train_loss: 0.13059616088867188
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1956552118062973, train_loss: 0.12642206251621246
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7561771273612976, train_loss: 0.7907624244689941
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5370020866394043, train_loss: 0.4547554850578308
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5320316553115845, train_loss: 0.4018537402153015
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5328208208084106, train_loss: 0.3926374912261963
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5338491201400757, train_loss: 0.3881443738937378
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6565161347389221, train_loss: 0.6746312379837036
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5891560316085815, train_loss: 0.48102670907974243
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.589284360408783, train_loss: 0.45173579454421997
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5897572636604309, train_loss: 0.44543129205703735
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5898431539535522, train_loss: 0.4249431788921356
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6693306565284729, train_loss: 0.7078208923339844
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5318365097045898, train_loss: 0.46675384044647217
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5170263648033142, train_loss: 0.4077945649623871
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5166834592819214, train_loss: 0.38776785135269165
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5165595412254333, train_loss: 0.3756491541862488
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7365808486938477, train_loss: 0.7242046594619751
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5795959830284119, train_loss: 0.48362264037132263
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5586969256401062, train_loss: 0.43061885237693787
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5587581396102905, train_loss: 0.41945454478263855
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5584549307823181, train_loss: 0.4044654369354248
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7238624691963196, train_loss: 0.7391316294670105
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.228178471326828, train_loss: 0.1290885955095291
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22511929273605347, train_loss: 0.10315268486738205
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22543199360370636, train_loss: 0.09439503401517868
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22611625492572784, train_loss: 0.09184957295656204
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9736584424972534, train_loss: 1.0072273015975952
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20207935571670532, train_loss: 0.14828334748744965
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19738243520259857, train_loss: 0.12079743295907974
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19705402851104736, train_loss: 0.113217294216156
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19721992313861847, train_loss: 0.11682479828596115
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7304351329803467, train_loss: 0.7958641052246094
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5139700174331665, train_loss: 0.4621410071849823
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5022904872894287, train_loss: 0.3832066059112549
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5031874179840088, train_loss: 0.37503594160079956
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5040518045425415, train_loss: 0.3681369423866272
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6463183760643005, train_loss: 0.6552333235740662
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5846969485282898, train_loss: 0.46589338779449463
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5850576162338257, train_loss: 0.45619210600852966
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5858778953552246, train_loss: 0.4431602954864502
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5866327881813049, train_loss: 0.43645572662353516
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6833493113517761, train_loss: 0.7062000036239624
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.543990969657898, train_loss: 0.4330729842185974
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5303065776824951, train_loss: 0.3690435290336609
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5301253199577332, train_loss: 0.3429429531097412
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5303151607513428, train_loss: 0.32620835304260254
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7730013132095337, train_loss: 0.7508845329284668
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.591553270816803, train_loss: 0.49014127254486084
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5745109915733337, train_loss: 0.4324300289154053
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5746923685073853, train_loss: 0.42678016424179077
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5747078657150269, train_loss: 0.4162345826625824
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2646517753601074, train_loss: 1.2803372144699097
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21306782960891724, train_loss: 0.1195409819483757
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2121974676847458, train_loss: 0.10720153152942657
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21227875351905823, train_loss: 0.1012740507721901
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2121741771697998, train_loss: 0.10067601501941681
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7613039016723633, train_loss: 0.8436141014099121
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23345300555229187, train_loss: 0.1646653562784195
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22484073042869568, train_loss: 0.1318632960319519
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22303682565689087, train_loss: 0.11731769889593124
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22298185527324677, train_loss: 0.12116918712854385
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:18<04:13, 18.08s/it]importance j:  13%|█▎        | 2/15 [00:27<02:49, 13.03s/it]importance j:  20%|██        | 3/15 [00:45<03:01, 15.11s/it]importance j:  27%|██▋       | 4/15 [00:53<02:18, 12.61s/it]importance j:  33%|███▎      | 5/15 [01:11<02:22, 14.27s/it]importance j:  40%|████      | 6/15 [01:19<01:51, 12.36s/it]importance j:  47%|████▋     | 7/15 [01:34<01:44, 13.02s/it]importance j:  53%|█████▎    | 8/15 [01:44<01:25, 12.20s/it]importance j:  60%|██████    | 9/15 [01:55<01:09, 11.64s/it]importance j:  67%|██████▋   | 10/15 [02:07<00:59, 11.81s/it]importance j:  73%|███████▎  | 11/15 [02:15<00:43, 10.82s/it]importance j:  80%|████████  | 12/15 [02:32<00:37, 12.52s/it]importance j:  87%|████████▋ | 13/15 [02:40<00:22, 11.28s/it]importance j:  93%|█████████▎| 14/15 [02:52<00:11, 11.45s/it]importance j: 100%|██████████| 15/15 [03:01<00:00, 10.86s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6806108355522156, train_loss: 0.67200767993927
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5472730994224548, train_loss: 0.43025705218315125
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5433385372161865, train_loss: 0.38973483443260193
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5437497496604919, train_loss: 0.3800077438354492
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5445308685302734, train_loss: 0.374839723110199
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6962828636169434, train_loss: 0.7132385969161987
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5908504128456116, train_loss: 0.5133666396141052
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5770034790039062, train_loss: 0.4570171535015106
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5776191353797913, train_loss: 0.44032639265060425
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5777899622917175, train_loss: 0.43305596709251404
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7283390164375305, train_loss: 0.7230644226074219
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5320953130722046, train_loss: 0.470752090215683
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4998340904712677, train_loss: 0.3972402811050415
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4912574291229248, train_loss: 0.35332220792770386
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.49105605483055115, train_loss: 0.3237215280532837
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.934238612651825, train_loss: 0.9616789817810059
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6259288191795349, train_loss: 0.5668219923973083
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5618273615837097, train_loss: 0.46497052907943726
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5537697672843933, train_loss: 0.4177972972393036
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.554266095161438, train_loss: 0.415839284658432
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9154274463653564, train_loss: 0.9637954831123352
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20777146518230438, train_loss: 0.13640064001083374
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20741212368011475, train_loss: 0.12699949741363525
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20739570260047913, train_loss: 0.11605465412139893
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20776744186878204, train_loss: 0.1114230528473854
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4656471908092499, train_loss: 0.6466924548149109
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21263399720191956, train_loss: 0.158164843916893
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21013282239437103, train_loss: 0.14037132263183594
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20967893302440643, train_loss: 0.13517270982265472
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20920103788375854, train_loss: 0.13144011795520782
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7740727066993713, train_loss: 0.7912631034851074
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.569771945476532, train_loss: 0.46429693698883057
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5616287589073181, train_loss: 0.39896953105926514
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5621961355209351, train_loss: 0.39373502135276794
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5629381537437439, train_loss: 0.3815452456474304
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7124929428100586, train_loss: 0.7320318222045898
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5870465040206909, train_loss: 0.4904967248439789
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5853798985481262, train_loss: 0.44982537627220154
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5858851075172424, train_loss: 0.43512940406799316
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5867459177970886, train_loss: 0.4383067786693573
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6484968066215515, train_loss: 0.6353650093078613
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5430089235305786, train_loss: 0.43969130516052246
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5294823050498962, train_loss: 0.3809562623500824
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5311005711555481, train_loss: 0.3519864082336426
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.532113254070282, train_loss: 0.35193130373954773
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.887428879737854, train_loss: 0.8696184158325195
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5898346900939941, train_loss: 0.5195297598838806
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5730168223381042, train_loss: 0.45577114820480347
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5729362964630127, train_loss: 0.4417787790298462
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5732130408287048, train_loss: 0.4382286071777344
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4726536273956299, train_loss: 0.5462910532951355
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20946559309959412, train_loss: 0.1370621770620346
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20865558087825775, train_loss: 0.12517483532428741
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20826023817062378, train_loss: 0.12544377148151398
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2080276757478714, train_loss: 0.12114884704351425
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6555168032646179, train_loss: 0.8166000247001648
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19938959181308746, train_loss: 0.14298978447914124
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2006095051765442, train_loss: 0.1310337632894516
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20165440440177917, train_loss: 0.13285915553569794
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20257630944252014, train_loss: 0.13031499087810516
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6539313197135925, train_loss: 0.698041558265686
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5174267888069153, train_loss: 0.4390179514884949
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5178371071815491, train_loss: 0.4051390588283539
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.518535852432251, train_loss: 0.4047492444515228
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.519580066204071, train_loss: 0.39689692854881287
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7541579008102417, train_loss: 0.7603520154953003
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6065739989280701, train_loss: 0.5073883533477783
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5849074125289917, train_loss: 0.4297751188278198
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5850269198417664, train_loss: 0.41921743750572205
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5855300426483154, train_loss: 0.4244306683540344
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.821582555770874, train_loss: 0.7730438113212585
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.593227744102478, train_loss: 0.46640223264694214
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5507873892784119, train_loss: 0.38277721405029297
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5472732782363892, train_loss: 0.33708280324935913
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5478941798210144, train_loss: 0.33417677879333496
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6997082233428955, train_loss: 0.8053447008132935
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5273556709289551, train_loss: 0.5113252401351929
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5107066035270691, train_loss: 0.452580988407135
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5106169581413269, train_loss: 0.4420721232891083
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5106053948402405, train_loss: 0.43347299098968506
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7745040059089661, train_loss: 0.8307075500488281
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20662131905555725, train_loss: 0.12365076690912247
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20535926520824432, train_loss: 0.11490914970636368
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2047882080078125, train_loss: 0.10874773561954498
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20443379878997803, train_loss: 0.10791871696710587
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45242074131965637, train_loss: 0.4877591133117676
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22816695272922516, train_loss: 0.16494396328926086
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.226777121424675, train_loss: 0.15526632964611053
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22609813511371613, train_loss: 0.14531922340393066
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22600333392620087, train_loss: 0.1463804543018341
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6659595966339111, train_loss: 0.679649293422699
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5436322689056396, train_loss: 0.4402845799922943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5422420501708984, train_loss: 0.399024099111557
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.543035089969635, train_loss: 0.3968461751937866
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5442066192626953, train_loss: 0.38407182693481445
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7336606979370117, train_loss: 0.7524276971817017
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5983322858810425, train_loss: 0.4850409924983978
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5945246815681458, train_loss: 0.43203815817832947
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5941041111946106, train_loss: 0.4191439151763916
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5939504504203796, train_loss: 0.4154044985771179
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6405537128448486, train_loss: 0.6590431928634644
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5305261611938477, train_loss: 0.4251992106437683
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5309767127037048, train_loss: 0.4010612964630127
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5320004224777222, train_loss: 0.38939225673675537
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5331677198410034, train_loss: 0.382709264755249
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7653407454490662, train_loss: 0.7395851016044617
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5582143664360046, train_loss: 0.4881381392478943
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5409700274467468, train_loss: 0.4360082149505615
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5424190759658813, train_loss: 0.4203399121761322
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.542663037776947, train_loss: 0.4172740876674652
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.35173237323760986, train_loss: 0.3592851459980011
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21538473665714264, train_loss: 0.13486364483833313
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21366791427135468, train_loss: 0.1188034638762474
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21393388509750366, train_loss: 0.11230874061584473
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2139454334974289, train_loss: 0.10652949661016464
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4196845591068268, train_loss: 0.49247390031814575
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21481989324092865, train_loss: 0.15690599381923676
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2123745083808899, train_loss: 0.1387540102005005
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2124190479516983, train_loss: 0.13412097096443176
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21207542717456818, train_loss: 0.13058462738990784
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7861083745956421, train_loss: 0.7854903936386108
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5923752188682556, train_loss: 0.49033480882644653
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5922717452049255, train_loss: 0.43629345297813416
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5933846235275269, train_loss: 0.42846331000328064
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5949301719665527, train_loss: 0.4346961975097656
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6736329197883606, train_loss: 0.7007907629013062
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5904600620269775, train_loss: 0.502056896686554
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5897989869117737, train_loss: 0.4785997271537781
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5897119641304016, train_loss: 0.46191519498825073
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5896033048629761, train_loss: 0.4697985351085663
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.908086359500885, train_loss: 0.9069911241531372
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6532325148582458, train_loss: 0.5261034965515137
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6245021224021912, train_loss: 0.42653927206993103
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.623412013053894, train_loss: 0.41038060188293457
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6237841248512268, train_loss: 0.4031747281551361
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6392350792884827, train_loss: 0.6639684438705444
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5814393758773804, train_loss: 0.5200362205505371
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5815033912658691, train_loss: 0.49955934286117554
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5816587209701538, train_loss: 0.49716028571128845
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5816502571105957, train_loss: 0.49077504873275757
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6095212697982788, train_loss: 0.7132282853126526
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2352093756198883, train_loss: 0.15188823640346527
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2354094535112381, train_loss: 0.1406276673078537
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.23544728755950928, train_loss: 0.1345619410276413
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.23636101186275482, train_loss: 0.1268366426229477
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.0630252361297607, train_loss: 1.1944395303726196
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23944225907325745, train_loss: 0.1632101982831955
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.23924186825752258, train_loss: 0.16037896275520325
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.23914998769760132, train_loss: 0.15083502233028412
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.23932375013828278, train_loss: 0.148665189743042
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8582760691642761, train_loss: 0.8732787370681763
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5972152948379517, train_loss: 0.4942319095134735
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5478679537773132, train_loss: 0.4008025527000427
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5396292209625244, train_loss: 0.34947943687438965
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.54060298204422, train_loss: 0.34540724754333496
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7817740440368652, train_loss: 0.7380673885345459
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6353915333747864, train_loss: 0.48476800322532654
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6076666712760925, train_loss: 0.4302346110343933
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6027941703796387, train_loss: 0.38679760694503784
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.603178083896637, train_loss: 0.3790263533592224
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7707248330116272, train_loss: 0.8030554056167603
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5810884237289429, train_loss: 0.4819157123565674
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5458391308784485, train_loss: 0.38611945509910583
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.539860725402832, train_loss: 0.34343695640563965
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5397488474845886, train_loss: 0.3431274890899658
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.689687967300415, train_loss: 0.6911625862121582
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5563392043113708, train_loss: 0.5052847862243652
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5545631051063538, train_loss: 0.47091421484947205
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5547410249710083, train_loss: 0.4611632823944092
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5549594759941101, train_loss: 0.4481378495693207
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5015521049499512, train_loss: 0.4913446009159088
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19609124958515167, train_loss: 0.13008694350719452
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19500590860843658, train_loss: 0.11752241849899292
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19538649916648865, train_loss: 0.1080237627029419
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19544969499111176, train_loss: 0.10874726623296738
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.945275068283081, train_loss: 0.948531448841095
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2191474288702011, train_loss: 0.1470368355512619
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2173408716917038, train_loss: 0.13188019394874573
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21668726205825806, train_loss: 0.12598378956317902
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21651248633861542, train_loss: 0.12115468829870224
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.797412097454071, train_loss: 0.8560632467269897
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5149025321006775, train_loss: 0.4629005789756775
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5041667819023132, train_loss: 0.3900531232357025
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5052165389060974, train_loss: 0.37497568130493164
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5064741373062134, train_loss: 0.3662465810775757
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.679625928401947, train_loss: 0.7334712743759155
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5705494284629822, train_loss: 0.4872332513332367
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5718384981155396, train_loss: 0.4536469578742981
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5729385614395142, train_loss: 0.44201335310935974
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5738268494606018, train_loss: 0.43678849935531616
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7761713266372681, train_loss: 0.7920950651168823
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5395399332046509, train_loss: 0.4610132575035095
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.520858645439148, train_loss: 0.3884459137916565
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5213844776153564, train_loss: 0.3603973984718323
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5223126411437988, train_loss: 0.3550146520137787
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6776320338249207, train_loss: 0.7130955457687378
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5130593776702881, train_loss: 0.4991178512573242
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5090017318725586, train_loss: 0.44336915016174316
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.509695827960968, train_loss: 0.44494158029556274
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5100575089454651, train_loss: 0.4411635398864746
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40719521045684814, train_loss: 0.42152857780456543
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19247028231620789, train_loss: 0.12497375160455704
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18653400242328644, train_loss: 0.10411248356103897
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18592806160449982, train_loss: 0.10100483894348145
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18591846525669098, train_loss: 0.09553699940443039
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7095016837120056, train_loss: 0.7435671091079712
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20686402916908264, train_loss: 0.1441565304994583
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.206394761800766, train_loss: 0.13842502236366272
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20676422119140625, train_loss: 0.1311282515525818
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2074965387582779, train_loss: 0.13053734600543976
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6613185405731201, train_loss: 0.6493432521820068
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.535278856754303, train_loss: 0.42389094829559326
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.535407543182373, train_loss: 0.3890168368816376
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5360792875289917, train_loss: 0.3978670537471771
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5368770360946655, train_loss: 0.3821069598197937
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8198044896125793, train_loss: 0.7969798445701599
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6344497799873352, train_loss: 0.5170933604240417
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5914284586906433, train_loss: 0.43659576773643494
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5864094495773315, train_loss: 0.39815235137939453
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5860745310783386, train_loss: 0.3880072832107544
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6691630482673645, train_loss: 0.6585376262664795
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.556160569190979, train_loss: 0.4385204017162323
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5515320897102356, train_loss: 0.3868853449821472
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5515571236610413, train_loss: 0.3705405592918396
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5517937541007996, train_loss: 0.3717339038848877
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7036544680595398, train_loss: 0.7621217966079712
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5517156720161438, train_loss: 0.499945729970932
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5509767532348633, train_loss: 0.4674355387687683
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.550717830657959, train_loss: 0.45823559165000916
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5508095622062683, train_loss: 0.4451150596141815
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.7899073362350464, train_loss: 1.9653797149658203
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2044631987810135, train_loss: 0.14203880727291107
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19978980720043182, train_loss: 0.11722882091999054
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19962003827095032, train_loss: 0.11626286804676056
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1995963603258133, train_loss: 0.10952550172805786
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3494449555873871, train_loss: 0.3881932199001312
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2005702555179596, train_loss: 0.1501287966966629
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1992175430059433, train_loss: 0.13413719832897186
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.198729008436203, train_loss: 0.13507241010665894
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1987457573413849, train_loss: 0.12697052955627441
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8021699786186218, train_loss: 0.8088903427124023
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5672709941864014, train_loss: 0.44339150190353394
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5528990030288696, train_loss: 0.37659740447998047
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5530431866645813, train_loss: 0.36891037225723267
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5533528923988342, train_loss: 0.36717623472213745
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6908139586448669, train_loss: 0.7030763626098633
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5880064964294434, train_loss: 0.47823572158813477
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5797712802886963, train_loss: 0.4163241386413574
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5803117156028748, train_loss: 0.41883596777915955
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5811182856559753, train_loss: 0.41218864917755127
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6443496942520142, train_loss: 0.6530826687812805
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5311076045036316, train_loss: 0.43679794669151306
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5316758751869202, train_loss: 0.4106888175010681
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5320673584938049, train_loss: 0.394865483045578
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5328277349472046, train_loss: 0.38578522205352783
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6870764493942261, train_loss: 0.6908614039421082
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5609691739082336, train_loss: 0.4841982126235962
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.557827353477478, train_loss: 0.43463119864463806
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.558040976524353, train_loss: 0.41574785113334656
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5581040978431702, train_loss: 0.40871188044548035
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7892296314239502, train_loss: 0.8346977233886719
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2011052370071411, train_loss: 0.14032235741615295
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20042017102241516, train_loss: 0.13218890130519867
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19995197653770447, train_loss: 0.12359297275543213
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19984038174152374, train_loss: 0.12606316804885864
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.847935140132904, train_loss: 0.9522770047187805
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20333164930343628, train_loss: 0.16777534782886505
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20278818905353546, train_loss: 0.16409526765346527
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20292501151561737, train_loss: 0.15273085236549377
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20315077900886536, train_loss: 0.15122845768928528
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8571180701255798, train_loss: 0.9086751341819763
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5501300096511841, train_loss: 0.48991841077804565
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5149863362312317, train_loss: 0.391628623008728
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5149677395820618, train_loss: 0.36124563217163086
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5154399275779724, train_loss: 0.34318968653678894
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7145847678184509, train_loss: 0.7163059711456299
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6077603697776794, train_loss: 0.4994684159755707
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5967685580253601, train_loss: 0.4320673942565918
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5973932147026062, train_loss: 0.4111666679382324
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.598078191280365, train_loss: 0.40490269660949707
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8066166043281555, train_loss: 0.8247820734977722
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5526302456855774, train_loss: 0.4782934784889221
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5222567915916443, train_loss: 0.38527488708496094
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5203286409378052, train_loss: 0.35326194763183594
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5203880667686462, train_loss: 0.3615970015525818
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7030472159385681, train_loss: 0.661081075668335
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.56292724609375, train_loss: 0.4804079234600067
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5525768995285034, train_loss: 0.43926021456718445
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5520204901695251, train_loss: 0.41607797145843506
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.551996111869812, train_loss: 0.4172322452068329
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4460098445415497, train_loss: 0.4999610483646393
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2123982161283493, train_loss: 0.12960222363471985
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2127142697572708, train_loss: 0.11538722366094589
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2128680795431137, train_loss: 0.11542067676782608
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21321171522140503, train_loss: 0.11255550384521484
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5845228433609009, train_loss: 0.6769425272941589
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.18680569529533386, train_loss: 0.15916211903095245
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.18417198956012726, train_loss: 0.12885130941867828
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1841692328453064, train_loss: 0.12588255107402802
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.18432730436325073, train_loss: 0.12135765701532364
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6851624846458435, train_loss: 0.7077897787094116
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5181299448013306, train_loss: 0.4341168999671936
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5166450142860413, train_loss: 0.3820512294769287
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5174452066421509, train_loss: 0.3854158818721771
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5184312462806702, train_loss: 0.37264299392700195
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7115318179130554, train_loss: 0.7016670107841492
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6072787046432495, train_loss: 0.48091840744018555
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6001431941986084, train_loss: 0.4352028965950012
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6002049446105957, train_loss: 0.43146225810050964
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6002792716026306, train_loss: 0.4207227826118469
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7077683806419373, train_loss: 0.6975744962692261
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5480995774269104, train_loss: 0.4495350122451782
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5379504561424255, train_loss: 0.386178582906723
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5381816029548645, train_loss: 0.37724995613098145
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5386844873428345, train_loss: 0.36907434463500977
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6948015093803406, train_loss: 0.7232645750045776
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5547874569892883, train_loss: 0.5098661184310913
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5375012755393982, train_loss: 0.4343923032283783
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5373606085777283, train_loss: 0.4184500575065613
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5376418828964233, train_loss: 0.4143669605255127
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3738135099411011, train_loss: 0.39950379729270935
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1825973391532898, train_loss: 0.13538409769535065
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18311551213264465, train_loss: 0.1308898776769638
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1835712194442749, train_loss: 0.12374210357666016
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1839037537574768, train_loss: 0.11966101080179214
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.38071656227111816, train_loss: 0.4173908233642578
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1937406212091446, train_loss: 0.1542285978794098
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1901424676179886, train_loss: 0.12800946831703186
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19017226994037628, train_loss: 0.13009802997112274
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19025395810604095, train_loss: 0.13004611432552338
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7089084386825562, train_loss: 0.722075343132019
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.540804386138916, train_loss: 0.4446438252925873
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5330398678779602, train_loss: 0.3692739009857178
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5336593985557556, train_loss: 0.3749709129333496
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5345779657363892, train_loss: 0.3820567727088928
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6976955533027649, train_loss: 0.6947778463363647
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5944304466247559, train_loss: 0.4946305751800537
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5867195129394531, train_loss: 0.44187426567077637
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5873079895973206, train_loss: 0.4337185025215149
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5878457427024841, train_loss: 0.43546581268310547
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5942236185073853, train_loss: 0.5960494875907898
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5189472436904907, train_loss: 0.4255542755126953
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5156692862510681, train_loss: 0.3890661895275116
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5160843729972839, train_loss: 0.3759220242500305
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.516630232334137, train_loss: 0.37102365493774414
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.815346896648407, train_loss: 0.7997142672538757
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5651108026504517, train_loss: 0.4995293617248535
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5465278625488281, train_loss: 0.43909725546836853
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5464662909507751, train_loss: 0.41723746061325073
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5466949939727783, train_loss: 0.4113715589046478
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.48016253113746643, train_loss: 0.5118644833564758
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1995587795972824, train_loss: 0.13166919350624084
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19796724617481232, train_loss: 0.11009452491998672
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1979171335697174, train_loss: 0.10813900083303452
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19831831753253937, train_loss: 0.10287406295537949
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3649829030036926, train_loss: 0.3723316490650177
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20512792468070984, train_loss: 0.14536471664905548
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2011282742023468, train_loss: 0.12820379436016083
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20137228071689606, train_loss: 0.12207289040088654
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20065850019454956, train_loss: 0.12150043249130249
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7263451814651489, train_loss: 0.6908442974090576
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.550484299659729, train_loss: 0.42508599162101746
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5471574664115906, train_loss: 0.3866453766822815
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5479472875595093, train_loss: 0.38065004348754883
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5490147471427917, train_loss: 0.38533639907836914
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6035515666007996, train_loss: 0.6203780174255371
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5686850547790527, train_loss: 0.48275327682495117
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5696277618408203, train_loss: 0.4770585894584656
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5704688429832458, train_loss: 0.47600433230400085
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5717197060585022, train_loss: 0.46078169345855713
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8032359480857849, train_loss: 0.8009443283081055
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5899142026901245, train_loss: 0.4512694478034973
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5692427754402161, train_loss: 0.36795616149902344
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5697320103645325, train_loss: 0.34585827589035034
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5701940059661865, train_loss: 0.3477957844734192
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8447492122650146, train_loss: 0.7871441841125488
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5811188220977783, train_loss: 0.5247066020965576
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5438917875289917, train_loss: 0.4572725296020508
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5406028032302856, train_loss: 0.41478782892227173
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5411095023155212, train_loss: 0.4146788716316223
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6909921765327454, train_loss: 0.766010046005249
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20044739544391632, train_loss: 0.12080686539411545
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.199819415807724, train_loss: 0.11752627044916153
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2001499980688095, train_loss: 0.11323020607233047
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19994667172431946, train_loss: 0.1072130799293518
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4038400650024414, train_loss: 0.4261419475078583
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21264463663101196, train_loss: 0.15301069617271423
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2119884490966797, train_loss: 0.14742998778820038
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21172329783439636, train_loss: 0.1453266441822052
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21111276745796204, train_loss: 0.1409531533718109
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6503949165344238, train_loss: 0.694023072719574
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5244058966636658, train_loss: 0.4455852508544922
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5206559300422668, train_loss: 0.3866177797317505
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5212582349777222, train_loss: 0.3836415708065033
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5220589637756348, train_loss: 0.36848482489585876
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.763473629951477, train_loss: 0.7113656997680664
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6388975381851196, train_loss: 0.4864632785320282
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.620434045791626, train_loss: 0.4213979244232178
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6195606589317322, train_loss: 0.39820846915245056
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6199032068252563, train_loss: 0.3934648036956787
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8163737654685974, train_loss: 0.861361026763916
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5582459568977356, train_loss: 0.4771258533000946
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5440791845321655, train_loss: 0.3953537940979004
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5443438291549683, train_loss: 0.3833589553833008
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5445020794868469, train_loss: 0.37959548830986023
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8480445146560669, train_loss: 0.7464971542358398
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6038535237312317, train_loss: 0.4983821511268616
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5813488960266113, train_loss: 0.4276055693626404
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5807244181632996, train_loss: 0.4012376666069031
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5807585120201111, train_loss: 0.4081058204174042
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3716425597667694, train_loss: 0.39039477705955505
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2000439465045929, train_loss: 0.14423273503780365
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19735829532146454, train_loss: 0.12208925932645798
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1966642141342163, train_loss: 0.12008818238973618
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1966426521539688, train_loss: 0.11172223091125488
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5713281631469727, train_loss: 0.7474279403686523
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19373798370361328, train_loss: 0.1551540344953537
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19094213843345642, train_loss: 0.13416258990764618
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19117912650108337, train_loss: 0.13592073321342468
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19126205146312714, train_loss: 0.125264510512352
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7598013877868652, train_loss: 0.7337384223937988
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.55732262134552, train_loss: 0.4412130117416382
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.550564706325531, train_loss: 0.3932271897792816
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5512955784797668, train_loss: 0.3890113830566406
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5522893071174622, train_loss: 0.38038215041160583
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.689547598361969, train_loss: 0.6914892196655273
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5983206629753113, train_loss: 0.4788149297237396
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5972535610198975, train_loss: 0.4627072513103485
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5971857309341431, train_loss: 0.44559019804000854
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5972747802734375, train_loss: 0.44716566801071167
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6418668031692505, train_loss: 0.6134991645812988
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5542383193969727, train_loss: 0.41282781958580017
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5527633428573608, train_loss: 0.3740841746330261
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5527760982513428, train_loss: 0.39068731665611267
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5527442097663879, train_loss: 0.3776683211326599
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.805904746055603, train_loss: 0.8047472834587097
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5902769565582275, train_loss: 0.5062054395675659
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5764373540878296, train_loss: 0.43900591135025024
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5764778852462769, train_loss: 0.42185157537460327
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5765551924705505, train_loss: 0.4207608699798584
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4146764278411865, train_loss: 0.5041643977165222
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18726889789104462, train_loss: 0.13460056483745575
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1868412345647812, train_loss: 0.11199497431516647
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1870211809873581, train_loss: 0.10766079276800156
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18730062246322632, train_loss: 0.10303157567977905
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3484441936016083, train_loss: 0.3705766201019287
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20407934486865997, train_loss: 0.15444910526275635
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19758084416389465, train_loss: 0.12211980670690536
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19745489954948425, train_loss: 0.1268257349729538
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19700683653354645, train_loss: 0.1179133877158165
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.790172815322876, train_loss: 0.8245872259140015
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5175514817237854, train_loss: 0.4881307780742645
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4920433759689331, train_loss: 0.407611221075058
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4894978106021881, train_loss: 0.37580808997154236
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.48930567502975464, train_loss: 0.38074344396591187
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6899056434631348, train_loss: 0.6842470169067383
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5249607563018799, train_loss: 0.49037179350852966
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.517268717288971, train_loss: 0.4489440321922302
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5175029635429382, train_loss: 0.4300346374511719
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5181232690811157, train_loss: 0.43014034628868103
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7123394012451172, train_loss: 0.7433474063873291
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47927841544151306, train_loss: 0.4786568284034729
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.45101678371429443, train_loss: 0.403903067111969
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4463428258895874, train_loss: 0.3656770586967468
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.44616076350212097, train_loss: 0.35314688086509705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6753134727478027, train_loss: 0.7046689987182617
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5237780809402466, train_loss: 0.5179567933082581
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.520815908908844, train_loss: 0.47614598274230957
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5212190747261047, train_loss: 0.4658324122428894
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.521933376789093, train_loss: 0.4781964421272278
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6031932234764099, train_loss: 0.6433359980583191
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20608173310756683, train_loss: 0.13472673296928406
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19571827352046967, train_loss: 0.09555770456790924
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19481682777404785, train_loss: 0.09802406281232834
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1947527378797531, train_loss: 0.09497298300266266
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4855453670024872, train_loss: 0.49983254075050354
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23728744685649872, train_loss: 0.15186631679534912
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.23735293745994568, train_loss: 0.14082671701908112
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.237625852227211, train_loss: 0.13689742982387543
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2375234067440033, train_loss: 0.13383711874485016
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 497/15001 [00:00<00:14, 992.76it/s]Shapley Value Sampling attribution:   7%|▋         | 996/15001 [00:01<00:14, 995.70it/s]Shapley Value Sampling attribution:  10%|▉         | 1497/15001 [00:01<00:13, 997.75it/s]Shapley Value Sampling attribution:  13%|█▎        | 1997/15001 [00:02<00:13, 998.23it/s]Shapley Value Sampling attribution:  17%|█▋        | 2497/15001 [00:02<00:12, 998.77it/s]Shapley Value Sampling attribution:  20%|█▉        | 2997/15001 [00:03<00:12, 998.47it/s]Shapley Value Sampling attribution:  23%|██▎       | 3497/15001 [00:03<00:11, 997.31it/s]Shapley Value Sampling attribution:  27%|██▋       | 3996/15001 [00:04<00:11, 997.24it/s]Shapley Value Sampling attribution:  30%|██▉       | 4495/15001 [00:04<00:10, 987.08it/s]Shapley Value Sampling attribution:  33%|███▎      | 4989/15001 [00:05<00:10, 987.33it/s]Shapley Value Sampling attribution:  37%|███▋      | 5488/15001 [00:05<00:09, 990.55it/s]Shapley Value Sampling attribution:  40%|███▉      | 5984/15001 [00:06<00:12, 749.98it/s]Shapley Value Sampling attribution:  43%|████▎     | 6442/15001 [00:07<00:10, 790.94it/s]Shapley Value Sampling attribution:  46%|████▋     | 6939/15001 [00:07<00:09, 843.50it/s]Shapley Value Sampling attribution:  50%|████▉     | 7434/15001 [00:08<00:08, 883.08it/s]Shapley Value Sampling attribution:  53%|█████▎    | 7930/15001 [00:08<00:07, 913.25it/s]Shapley Value Sampling attribution:  56%|█████▌    | 8426/15001 [00:09<00:07, 935.17it/s]Shapley Value Sampling attribution:  59%|█████▉    | 8923/15001 [00:09<00:06, 951.86it/s]Shapley Value Sampling attribution:  63%|██████▎   | 9419/15001 [00:10<00:05, 963.06it/s]Shapley Value Sampling attribution:  66%|██████▌   | 9915/15001 [00:10<00:05, 971.12it/s]Shapley Value Sampling attribution:  69%|██████▉   | 10411/15001 [00:11<00:04, 977.08it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10908/15001 [00:11<00:04, 981.61it/s]Shapley Value Sampling attribution:  76%|███████▌  | 11403/15001 [00:12<00:03, 983.88it/s]Shapley Value Sampling attribution:  79%|███████▉  | 11897/15001 [00:12<00:03, 966.44it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12382/15001 [00:13<00:02, 928.43it/s]Shapley Value Sampling attribution:  86%|████████▌ | 12849/15001 [00:13<00:02, 907.20it/s]Shapley Value Sampling attribution:  89%|████████▊ | 13305/15001 [00:14<00:01, 893.47it/s]Shapley Value Sampling attribution:  92%|█████████▏| 13753/15001 [00:14<00:01, 884.01it/s]Shapley Value Sampling attribution:  95%|█████████▍| 14196/15001 [00:15<00:00, 875.70it/s]Shapley Value Sampling attribution:  98%|█████████▊| 14635/15001 [00:15<00:00, 865.73it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:16<00:00, 903.74it/s]
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   1%|▏         | 199/15001 [00:00<00:37, 396.92it/s]Shapley Value Sampling attribution:   3%|▎         | 398/15001 [00:01<00:36, 395.25it/s]Shapley Value Sampling attribution:   4%|▍         | 596/15001 [00:01<00:36, 393.86it/s]Shapley Value Sampling attribution:   5%|▌         | 793/15001 [00:02<00:36, 393.03it/s]Shapley Value Sampling attribution:   7%|▋         | 990/15001 [00:02<00:35, 392.70it/s]Shapley Value Sampling attribution:   8%|▊         | 1188/15001 [00:03<00:35, 393.34it/s]Shapley Value Sampling attribution:   9%|▉         | 1386/15001 [00:03<00:34, 393.82it/s]Shapley Value Sampling attribution:  11%|█         | 1583/15001 [00:04<00:34, 393.42it/s]Shapley Value Sampling attribution:  12%|█▏        | 1780/15001 [00:04<00:33, 393.09it/s]Shapley Value Sampling attribution:  13%|█▎        | 1977/15001 [00:05<00:33, 392.82it/s]Shapley Value Sampling attribution:  14%|█▍        | 2175/15001 [00:05<00:32, 393.62it/s]Shapley Value Sampling attribution:  16%|█▌        | 2373/15001 [00:06<00:32, 393.96it/s]Shapley Value Sampling attribution:  17%|█▋        | 2604/15001 [00:06<00:29, 414.25it/s]Shapley Value Sampling attribution:  19%|█▉        | 2867/15001 [00:07<00:27, 447.69it/s]Shapley Value Sampling attribution:  21%|██        | 3150/15001 [00:07<00:24, 482.86it/s]Shapley Value Sampling attribution:  24%|██▎       | 3533/15001 [00:08<00:20, 567.54it/s]Shapley Value Sampling attribution:  27%|██▋       | 3988/15001 [00:08<00:16, 670.29it/s]Shapley Value Sampling attribution:  30%|██▉       | 4488/15001 [00:09<00:13, 769.20it/s]Shapley Value Sampling attribution:  33%|███▎      | 4990/15001 [00:09<00:11, 839.25it/s]Shapley Value Sampling attribution:  36%|███▋      | 5471/15001 [00:10<00:10, 875.55it/s]Shapley Value Sampling attribution:  40%|███▉      | 5969/15001 [00:10<00:09, 911.53it/s]Shapley Value Sampling attribution:  43%|████▎     | 6470/15001 [00:11<00:09, 938.64it/s]Shapley Value Sampling attribution:  46%|████▋     | 6972/15001 [00:11<00:08, 958.00it/s]Shapley Value Sampling attribution:  50%|████▉     | 7473/15001 [00:12<00:07, 971.00it/s]Shapley Value Sampling attribution:  53%|█████▎    | 7975/15001 [00:12<00:07, 980.88it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8477/15001 [00:13<00:06, 987.59it/s]Shapley Value Sampling attribution:  60%|█████▉    | 8979/15001 [00:13<00:06, 992.10it/s]Shapley Value Sampling attribution:  63%|██████▎   | 9481/15001 [00:14<00:05, 995.45it/s]Shapley Value Sampling attribution:  67%|██████▋   | 9980/15001 [00:14<00:05, 995.82it/s]Shapley Value Sampling attribution:  70%|██████▉   | 10480/15001 [00:15<00:04, 997.03it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10981/15001 [00:15<00:04, 998.44it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11481/15001 [00:16<00:03, 939.38it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11955/15001 [00:17<00:04, 757.47it/s]Shapley Value Sampling attribution:  83%|████████▎ | 12436/15001 [00:17<00:03, 808.09it/s]Shapley Value Sampling attribution:  86%|████████▌ | 12933/15001 [00:18<00:02, 856.55it/s]Shapley Value Sampling attribution:  90%|████████▉ | 13431/15001 [00:18<00:01, 894.32it/s]Shapley Value Sampling attribution:  93%|█████████▎| 13929/15001 [00:19<00:01, 922.32it/s]Shapley Value Sampling attribution:  96%|█████████▌| 14427/15001 [00:19<00:00, 942.94it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14924/15001 [00:20<00:00, 957.24it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:20<00:00, 744.50it/s]
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:09<02:19,  9.98s/it]importance j:  13%|█▎        | 2/15 [00:18<02:01,  9.35s/it]importance j:  20%|██        | 3/15 [00:33<02:18, 11.53s/it]importance j:  27%|██▋       | 4/15 [00:41<01:53, 10.28s/it]importance j:  33%|███▎      | 5/15 [00:55<01:57, 11.79s/it]importance j:  40%|████      | 6/15 [01:04<01:36, 10.73s/it]importance j:  47%|████▋     | 7/15 [01:14<01:23, 10.47s/it]importance j:  53%|█████▎    | 8/15 [01:29<01:22, 11.80s/it]importance j:  60%|██████    | 9/15 [01:37<01:04, 10.70s/it]importance j:  67%|██████▋   | 10/15 [01:51<00:59, 11.90s/it]importance j:  73%|███████▎  | 11/15 [02:00<00:43, 10.78s/it]importance j:  80%|████████  | 12/15 [02:12<00:33, 11.18s/it]importance j:  87%|████████▋ | 13/15 [02:20<00:20, 10.42s/it]importance j:  93%|█████████▎| 14/15 [02:29<00:09,  9.76s/it]importance j: 100%|██████████| 15/15 [02:41<00:00, 10.63s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6377717852592468, train_loss: 0.6499512791633606
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5209877490997314, train_loss: 0.44763267040252686
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5174655318260193, train_loss: 0.4130876958370209
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5181026458740234, train_loss: 0.4021430015563965
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5188465118408203, train_loss: 0.38982853293418884
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7925357222557068, train_loss: 0.805469274520874
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.607787013053894, train_loss: 0.5363010764122009
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5827145576477051, train_loss: 0.4674610495567322
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5813634395599365, train_loss: 0.428526371717453
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5816130042076111, train_loss: 0.4285392165184021
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6225261688232422, train_loss: 0.6880382299423218
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47711583971977234, train_loss: 0.45367711782455444
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.474770724773407, train_loss: 0.39961087703704834
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4747893810272217, train_loss: 0.40588849782943726
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.474842369556427, train_loss: 0.4056473672389984
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.603040874004364, train_loss: 0.6510734558105469
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5369217991828918, train_loss: 0.4779855012893677
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5379793047904968, train_loss: 0.47573983669281006
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5391789078712463, train_loss: 0.4639638066291809
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5406275391578674, train_loss: 0.4623708724975586
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8097866177558899, train_loss: 0.792646586894989
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.216371089220047, train_loss: 0.13287751376628876
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21433629095554352, train_loss: 0.12039172649383545
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21411292254924774, train_loss: 0.11365050077438354
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21421891450881958, train_loss: 0.10776271671056747
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3888128697872162, train_loss: 0.47912541031837463
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.212117537856102, train_loss: 0.17341665923595428
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21045809984207153, train_loss: 0.14762896299362183
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2105979025363922, train_loss: 0.14662955701351166
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21078947186470032, train_loss: 0.14339867234230042
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7749068140983582, train_loss: 0.7663706541061401
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5411695837974548, train_loss: 0.4511995315551758
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5360650420188904, train_loss: 0.3953973650932312
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5369196534156799, train_loss: 0.38630640506744385
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5379486083984375, train_loss: 0.37681591510772705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.709707498550415, train_loss: 0.7215615510940552
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5779795050621033, train_loss: 0.494149774312973
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5631527900695801, train_loss: 0.43078216910362244
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.563410222530365, train_loss: 0.42278191447257996
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5637850761413574, train_loss: 0.41314375400543213
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7266787886619568, train_loss: 0.7783712148666382
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5465745329856873, train_loss: 0.46792030334472656
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5310221314430237, train_loss: 0.39505037665367126
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5324195027351379, train_loss: 0.3806409239768982
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5330432057380676, train_loss: 0.3763011693954468
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7751550674438477, train_loss: 0.76198410987854
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5671070218086243, train_loss: 0.5167287588119507
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5538857579231262, train_loss: 0.4455137252807617
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5539067387580872, train_loss: 0.43803974986076355
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5541129112243652, train_loss: 0.44637078046798706
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5099987983703613, train_loss: 0.656770646572113
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19100821018218994, train_loss: 0.14663925766944885
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18764787912368774, train_loss: 0.12132614105939865
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1877812147140503, train_loss: 0.11966588348150253
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18752941489219666, train_loss: 0.11352428048849106
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.33195623755455017, train_loss: 0.3699163496494293
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19587522745132446, train_loss: 0.15595753490924835
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1953057050704956, train_loss: 0.14699098467826843
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1949106603860855, train_loss: 0.14755699038505554
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19529016315937042, train_loss: 0.14190471172332764
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7620123624801636, train_loss: 0.7704927325248718
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5447412729263306, train_loss: 0.4485050141811371
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5344920754432678, train_loss: 0.39309191703796387
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5349138975143433, train_loss: 0.3881113529205322
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5354698300361633, train_loss: 0.37587547302246094
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7857940793037415, train_loss: 0.7765480279922485
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6223548054695129, train_loss: 0.4981992840766907
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6137330532073975, train_loss: 0.4258473515510559
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6141589283943176, train_loss: 0.4258720874786377
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6151332855224609, train_loss: 0.4269065260887146
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7527124285697937, train_loss: 0.7869269251823425
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5393593907356262, train_loss: 0.47782647609710693
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5208268761634827, train_loss: 0.4013262391090393
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5205357074737549, train_loss: 0.3679797351360321
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5207592844963074, train_loss: 0.3646939694881439
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8259247541427612, train_loss: 0.7913262248039246
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5814575552940369, train_loss: 0.5208803415298462
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5472174882888794, train_loss: 0.4503725469112396
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5453703999519348, train_loss: 0.40678471326828003
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5456454753875732, train_loss: 0.41862210631370544
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4857977330684662, train_loss: 0.5264257788658142
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21335144340991974, train_loss: 0.13321268558502197
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.210969015955925, train_loss: 0.1045064851641655
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2106063961982727, train_loss: 0.10134484618902206
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21048514544963837, train_loss: 0.10235819965600967
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.0298644304275513, train_loss: 1.200989842414856
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19354234635829926, train_loss: 0.14045722782611847
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19414503872394562, train_loss: 0.13307498395442963
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1942349076271057, train_loss: 0.12956225872039795
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1943480223417282, train_loss: 0.12562638521194458
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7563783526420593, train_loss: 0.7840716242790222
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5199829936027527, train_loss: 0.4278408885002136
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5159386396408081, train_loss: 0.39411914348602295
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5163772702217102, train_loss: 0.3957962691783905
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5171514749526978, train_loss: 0.3865654468536377
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6493590474128723, train_loss: 0.7103909254074097
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.56951504945755, train_loss: 0.4678970277309418
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5692022442817688, train_loss: 0.45040687918663025
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5690169930458069, train_loss: 0.44962355494499207
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5689719319343567, train_loss: 0.44259214401245117
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7378104329109192, train_loss: 0.7491985559463501
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5625308156013489, train_loss: 0.45585379004478455
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5460266470909119, train_loss: 0.3658004701137543
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5453054308891296, train_loss: 0.34677523374557495
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5453119874000549, train_loss: 0.34929025173187256
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8505746722221375, train_loss: 0.8524980545043945
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.573235809803009, train_loss: 0.5052870512008667
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.53812575340271, train_loss: 0.44143909215927124
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5305289626121521, train_loss: 0.3989107310771942
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5312459468841553, train_loss: 0.3896869122982025
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2130634784698486, train_loss: 1.232847809791565
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21473121643066406, train_loss: 0.12244933098554611
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21321797370910645, train_loss: 0.1029956266283989
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2136317640542984, train_loss: 0.10028300434350967
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2136121690273285, train_loss: 0.09768848866224289
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3942926824092865, train_loss: 0.4940413534641266
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20137238502502441, train_loss: 0.1576099544763565
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19798436760902405, train_loss: 0.1334468275308609
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19762484729290009, train_loss: 0.13137055933475494
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19736766815185547, train_loss: 0.12620839476585388
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8046455979347229, train_loss: 0.8610600233078003
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5829423069953918, train_loss: 0.48496994376182556
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5801882743835449, train_loss: 0.4382288455963135
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5812727212905884, train_loss: 0.42289456725120544
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5826907157897949, train_loss: 0.4168606698513031
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.738476037979126, train_loss: 0.7367483377456665
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6175954937934875, train_loss: 0.511076807975769
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6062742471694946, train_loss: 0.4428682327270508
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6060984134674072, train_loss: 0.44430479407310486
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6057775020599365, train_loss: 0.44367700815200806
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7568572759628296, train_loss: 0.7604109644889832
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6218185424804688, train_loss: 0.4841872453689575
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6210022568702698, train_loss: 0.4481043219566345
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6212628483772278, train_loss: 0.4415419101715088
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6217517256736755, train_loss: 0.43158406019210815
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8068047165870667, train_loss: 0.780102014541626
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6030768156051636, train_loss: 0.5387031435966492
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5746330618858337, train_loss: 0.480116069316864
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5720838904380798, train_loss: 0.4447891116142273
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5721806883811951, train_loss: 0.44443759322166443
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.43286582827568054, train_loss: 0.3897852897644043
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.23098398745059967, train_loss: 0.14762814342975616
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.22759653627872467, train_loss: 0.12060742825269699
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.22778618335723877, train_loss: 0.11966054886579514
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22786685824394226, train_loss: 0.11950645595788956
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.42937764525413513, train_loss: 0.4018438458442688
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24173660576343536, train_loss: 0.16646139323711395
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.23676224052906036, train_loss: 0.13495272397994995
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.23697617650032043, train_loss: 0.13556618988513947
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.23737631738185883, train_loss: 0.13208921253681183
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.665466845035553, train_loss: 0.6524906158447266
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5150020122528076, train_loss: 0.39584070444107056
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5155506730079651, train_loss: 0.3921754062175751
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5164665579795837, train_loss: 0.376869797706604
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5175482034683228, train_loss: 0.3747158944606781
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7577757239341736, train_loss: 0.778512179851532
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6100992560386658, train_loss: 0.49556320905685425
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6008991599082947, train_loss: 0.4318503141403198
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6013885140419006, train_loss: 0.4421374797821045
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6020236015319824, train_loss: 0.4141685366630554
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6021740436553955, train_loss: 0.63252854347229
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5252200365066528, train_loss: 0.4325540065765381
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5248688459396362, train_loss: 0.39845550060272217
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.524883508682251, train_loss: 0.3966621160507202
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.525054931640625, train_loss: 0.3848955035209656
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8701398968696594, train_loss: 0.8626708984375
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5980987548828125, train_loss: 0.5228469371795654
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.552209734916687, train_loss: 0.44482919573783875
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5450206995010376, train_loss: 0.4058726727962494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5441340804100037, train_loss: 0.39971280097961426
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8613055348396301, train_loss: 0.9689050912857056
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19241221249103546, train_loss: 0.12749560177326202
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19328893721103668, train_loss: 0.11157911270856857
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1938435584306717, train_loss: 0.11392247676849365
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19431018829345703, train_loss: 0.11040399223566055
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9354917407035828, train_loss: 1.068807601928711
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19230620563030243, train_loss: 0.13841693103313446
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19121761620044708, train_loss: 0.12098970264196396
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1907680481672287, train_loss: 0.12107867002487183
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19118720293045044, train_loss: 0.11804918199777603
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7720410227775574, train_loss: 0.8439432978630066
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5465771555900574, train_loss: 0.47279804944992065
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.528161883354187, train_loss: 0.3821962773799896
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5284280776977539, train_loss: 0.3618299663066864
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5287806391716003, train_loss: 0.3587513864040375
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7501818537712097, train_loss: 0.7314733266830444
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6204023957252502, train_loss: 0.4913226068019867
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6163691282272339, train_loss: 0.4329843521118164
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.616970956325531, train_loss: 0.4323524832725525
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6178450584411621, train_loss: 0.4295085668563843
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8415524959564209, train_loss: 0.8623753786087036
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.58346027135849, train_loss: 0.4818911552429199
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.54561448097229, train_loss: 0.3869190216064453
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5340853333473206, train_loss: 0.3448718786239624
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5312001705169678, train_loss: 0.31328898668289185
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7108418941497803, train_loss: 0.6889273524284363
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5318762063980103, train_loss: 0.4768093526363373
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5279534459114075, train_loss: 0.43712061643600464
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5281330943107605, train_loss: 0.4399201571941376
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5284967422485352, train_loss: 0.4302406311035156
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7079625725746155, train_loss: 0.7762770056724548
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20071129500865936, train_loss: 0.12728342413902283
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20087310671806335, train_loss: 0.11130341142416
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2010750025510788, train_loss: 0.11071473360061646
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20125336945056915, train_loss: 0.10546348243951797
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3449881970882416, train_loss: 0.43050533533096313
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19901013374328613, train_loss: 0.16218216717243195
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19918014109134674, train_loss: 0.1488211750984192
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19925200939178467, train_loss: 0.15036390721797943
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20018108189105988, train_loss: 0.14220574498176575
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7279157638549805, train_loss: 0.7196054458618164
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5359717607498169, train_loss: 0.436328262090683
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5317149758338928, train_loss: 0.3962406814098358
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5321769118309021, train_loss: 0.38524293899536133
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5329354405403137, train_loss: 0.38860535621643066
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7949815392494202, train_loss: 0.8208600878715515
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6286022663116455, train_loss: 0.4918219745159149
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6154276728630066, train_loss: 0.4370582699775696
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6148584485054016, train_loss: 0.4227465093135834
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.61469966173172, train_loss: 0.4235756993293762
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7380106449127197, train_loss: 0.7210676670074463
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5695828199386597, train_loss: 0.4772488474845886
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5396291613578796, train_loss: 0.39603209495544434
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5377330183982849, train_loss: 0.3642687201499939
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5377041697502136, train_loss: 0.3626297414302826
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6857303977012634, train_loss: 0.7466489672660828
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5734727382659912, train_loss: 0.4933425784111023
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.565825879573822, train_loss: 0.4427342116832733
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5637957453727722, train_loss: 0.42746323347091675
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5634533762931824, train_loss: 0.4183199405670166
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.49478378891944885, train_loss: 0.5573799014091492
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2009274661540985, train_loss: 0.1277463734149933
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19756649434566498, train_loss: 0.10984428226947784
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19747282564640045, train_loss: 0.10184686630964279
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19758310914039612, train_loss: 0.10087133944034576
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7189636826515198, train_loss: 0.7688761949539185
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20001208782196045, train_loss: 0.15628014504909515
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2008146345615387, train_loss: 0.14986854791641235
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20074109733104706, train_loss: 0.13690058887004852
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20041173696517944, train_loss: 0.13700750470161438
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7912281155586243, train_loss: 0.805092990398407
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5356858372688293, train_loss: 0.4256495237350464
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5317394137382507, train_loss: 0.38811254501342773
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5323375463485718, train_loss: 0.36992257833480835
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5332295894622803, train_loss: 0.3779454231262207
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7323440313339233, train_loss: 0.7069655656814575
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6035736203193665, train_loss: 0.4943484961986542
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5787038803100586, train_loss: 0.4357243478298187
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5764531493186951, train_loss: 0.4082736372947693
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5761013031005859, train_loss: 0.38394492864608765
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0025782585144043, train_loss: 1.0119404792785645
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6442939639091492, train_loss: 0.5509307384490967
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5692247748374939, train_loss: 0.4203886389732361
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5549260973930359, train_loss: 0.3467291593551636
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5543535947799683, train_loss: 0.34522518515586853
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8522766828536987, train_loss: 0.8119093775749207
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.589015781879425, train_loss: 0.49964579939842224
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5522803664207458, train_loss: 0.43072232604026794
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5501417517662048, train_loss: 0.4054906368255615
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5505694150924683, train_loss: 0.4022984206676483
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5686779022216797, train_loss: 0.5336138606071472
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1909799873828888, train_loss: 0.13669408857822418
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18604566156864166, train_loss: 0.1112624928355217
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18558983504772186, train_loss: 0.1044582948088646
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18544869124889374, train_loss: 0.10232660919427872
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5221074223518372, train_loss: 0.6106019616127014
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21437516808509827, train_loss: 0.1561736911535263
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2095065414905548, train_loss: 0.1375085413455963
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20892634987831116, train_loss: 0.13358518481254578
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20849497616291046, train_loss: 0.13405244052410126
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6827134490013123, train_loss: 0.7137109637260437
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5489278435707092, train_loss: 0.4279858469963074
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.55037522315979, train_loss: 0.40499627590179443
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5517414808273315, train_loss: 0.3970740735530853
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5532895922660828, train_loss: 0.3888112008571625
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9391876459121704, train_loss: 0.9105430841445923
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6788936853408813, train_loss: 0.5539547204971313
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6157801151275635, train_loss: 0.44168907403945923
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6056360602378845, train_loss: 0.3980139195919037
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6061586141586304, train_loss: 0.38298720121383667
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8963570594787598, train_loss: 0.8494638800621033
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6076085567474365, train_loss: 0.48968908190727234
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5535073280334473, train_loss: 0.40123748779296875
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5398349165916443, train_loss: 0.34758561849594116
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5402616262435913, train_loss: 0.3386692404747009
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6432874202728271, train_loss: 0.6800976991653442
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.526250958442688, train_loss: 0.4801589250564575
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5250023007392883, train_loss: 0.4585278034210205
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5257189869880676, train_loss: 0.46005794405937195
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5265859365463257, train_loss: 0.4393988847732544
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44344428181648254, train_loss: 0.5544854998588562
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2410978078842163, train_loss: 0.13062219321727753
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2398766279220581, train_loss: 0.11492973566055298
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.23914018273353577, train_loss: 0.11538415402173996
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.23876221477985382, train_loss: 0.11229028552770615
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5339891910552979, train_loss: 0.5545670390129089
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2150060385465622, train_loss: 0.15714691579341888
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21284084022045135, train_loss: 0.14854589104652405
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21254944801330566, train_loss: 0.13826601207256317
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21218104660511017, train_loss: 0.13682909309864044
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7358223795890808, train_loss: 0.6638637185096741
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5634514689445496, train_loss: 0.4255215525627136
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5631579756736755, train_loss: 0.38434475660324097
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5643015503883362, train_loss: 0.3693733811378479
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5655395984649658, train_loss: 0.3775794506072998
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.70361328125, train_loss: 0.7372375726699829
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5905025005340576, train_loss: 0.47701525688171387
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5894585847854614, train_loss: 0.4312642812728882
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5901005268096924, train_loss: 0.42433416843414307
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5906700491905212, train_loss: 0.4286586046218872
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.779528796672821, train_loss: 0.7501004934310913
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5592538714408875, train_loss: 0.44545412063598633
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5479337573051453, train_loss: 0.3697102963924408
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5495375990867615, train_loss: 0.3545202910900116
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.550076961517334, train_loss: 0.35679471492767334
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7197225093841553, train_loss: 0.691626250743866
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5624058842658997, train_loss: 0.4938511252403259
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5471413731575012, train_loss: 0.4296244978904724
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5478856563568115, train_loss: 0.4117349088191986
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5483442544937134, train_loss: 0.39742374420166016
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7372146844863892, train_loss: 0.9180248379707336
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19213268160820007, train_loss: 0.13535748422145844
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19200262427330017, train_loss: 0.12556564807891846
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19214452803134918, train_loss: 0.12381742149591446
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1923021525144577, train_loss: 0.12071921676397324
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.37568148970603943, train_loss: 0.41234150528907776
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1970418095588684, train_loss: 0.15793152153491974
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.197588711977005, train_loss: 0.14695625007152557
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19785022735595703, train_loss: 0.14507782459259033
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1984959989786148, train_loss: 0.1418125182390213
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7849392890930176, train_loss: 0.8208787441253662
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5323952436447144, train_loss: 0.45285749435424805
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5185145735740662, train_loss: 0.37866100668907166
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5192232728004456, train_loss: 0.37351223826408386
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5200955867767334, train_loss: 0.3644406199455261
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.753363847732544, train_loss: 0.7527083158493042
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6022956371307373, train_loss: 0.5019395351409912
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5949963331222534, train_loss: 0.4309180676937103
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5952545404434204, train_loss: 0.4223104417324066
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.595744252204895, train_loss: 0.4256720244884491
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7705236077308655, train_loss: 0.8200437426567078
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5765528082847595, train_loss: 0.4896392226219177
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5494064688682556, train_loss: 0.385492742061615
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5486925840377808, train_loss: 0.35634490847587585
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5487746000289917, train_loss: 0.35611724853515625
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9061964750289917, train_loss: 0.8840953707695007
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5909968614578247, train_loss: 0.5136207342147827
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5673056840896606, train_loss: 0.4380316436290741
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5677029490470886, train_loss: 0.4300493597984314
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5687350630760193, train_loss: 0.411686509847641
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6228786706924438, train_loss: 0.6623880863189697
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21460409462451935, train_loss: 0.12970148026943207
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21025070548057556, train_loss: 0.10420633852481842
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20988242328166962, train_loss: 0.09918244928121567
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20951488614082336, train_loss: 0.10292734950780869
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.0632330179214478, train_loss: 1.20175302028656
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21616217494010925, train_loss: 0.14927026629447937
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21528659760951996, train_loss: 0.13337528705596924
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21509204804897308, train_loss: 0.13173024356365204
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2151469886302948, train_loss: 0.12800610065460205
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7893298268318176, train_loss: 0.7661651968955994
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5559117794036865, train_loss: 0.43639037013053894
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5501570105552673, train_loss: 0.366028368473053
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5510216355323792, train_loss: 0.36384648084640503
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5521141886711121, train_loss: 0.3692854344844818
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6791179180145264, train_loss: 0.6800479888916016
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6119308471679688, train_loss: 0.4677742123603821
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6118711233139038, train_loss: 0.43518614768981934
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6125088930130005, train_loss: 0.4318265914916992
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6136022806167603, train_loss: 0.4266582429409027
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.712688684463501, train_loss: 0.7201959490776062
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5393394827842712, train_loss: 0.464555561542511
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5184456706047058, train_loss: 0.3926648497581482
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5192166566848755, train_loss: 0.35400986671447754
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5195865035057068, train_loss: 0.3477570414543152
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8119000792503357, train_loss: 0.8450829386711121
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5561830401420593, train_loss: 0.5064257383346558
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5474280118942261, train_loss: 0.4377036988735199
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5476685762405396, train_loss: 0.4337587356567383
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5482145547866821, train_loss: 0.42602264881134033
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5617693662643433, train_loss: 0.5812448263168335
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21721792221069336, train_loss: 0.1292353868484497
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21386437118053436, train_loss: 0.10899732261896133
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21395888924598694, train_loss: 0.10837209224700928
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21405191719532013, train_loss: 0.10254903137683868
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5205516219139099, train_loss: 0.6549324989318848
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22186237573623657, train_loss: 0.1714402586221695
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21436449885368347, train_loss: 0.1392640322446823
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21363073587417603, train_loss: 0.13331100344657898
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21373845636844635, train_loss: 0.12901456654071808
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7821482419967651, train_loss: 0.8157634139060974
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5688139200210571, train_loss: 0.45463263988494873
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5555158853530884, train_loss: 0.3857346177101135
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5562779903411865, train_loss: 0.37923115491867065
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5567488074302673, train_loss: 0.3722609877586365
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8074934482574463, train_loss: 0.7985435724258423
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6257132887840271, train_loss: 0.5095527768135071
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5950718522071838, train_loss: 0.42078590393066406
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.592046856880188, train_loss: 0.3879520893096924
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5915324091911316, train_loss: 0.38677090406417847
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5979090332984924, train_loss: 0.6224097013473511
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5292877554893494, train_loss: 0.4451926350593567
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5296168923377991, train_loss: 0.4249105453491211
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.530282735824585, train_loss: 0.4060857892036438
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5313063263893127, train_loss: 0.4051991403102875
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8321337699890137, train_loss: 0.8002867698669434
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.586089551448822, train_loss: 0.5006759166717529
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.557242214679718, train_loss: 0.4193699359893799
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5579221248626709, train_loss: 0.4055182933807373
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5575799942016602, train_loss: 0.40892112255096436
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3134530484676361, train_loss: 0.36186105012893677
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1982472687959671, train_loss: 0.12900255620479584
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19756470620632172, train_loss: 0.11598129570484161
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1977476328611374, train_loss: 0.11184225231409073
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1977953463792801, train_loss: 0.10546858608722687
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8330179452896118, train_loss: 0.9096919894218445
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21328331530094147, train_loss: 0.14259456098079681
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21344545483589172, train_loss: 0.13057924807071686
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21321527659893036, train_loss: 0.12501303851604462
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2131846845149994, train_loss: 0.1256825178861618
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7498936653137207, train_loss: 0.7774314880371094
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5413662791252136, train_loss: 0.44787073135375977
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.531116783618927, train_loss: 0.3791904151439667
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.531879186630249, train_loss: 0.37594348192214966
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5326598882675171, train_loss: 0.3662247657775879
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7895197868347168, train_loss: 0.7802783846855164
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6213869452476501, train_loss: 0.5109561681747437
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5897100567817688, train_loss: 0.4278263449668884
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5848753452301025, train_loss: 0.4028759002685547
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5843670964241028, train_loss: 0.39688950777053833
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7691079378128052, train_loss: 0.7808421850204468
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5527076125144958, train_loss: 0.47995805740356445
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5291634202003479, train_loss: 0.3935263752937317
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5295411348342896, train_loss: 0.3781666159629822
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5295008420944214, train_loss: 0.36746129393577576
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6803242564201355, train_loss: 0.7619414329528809
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5251712203025818, train_loss: 0.5031155943870544
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5243518948554993, train_loss: 0.4735356271266937
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5247989296913147, train_loss: 0.4611535966396332
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5253552198410034, train_loss: 0.4705390930175781
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6490128040313721, train_loss: 0.5988234281539917
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21080204844474792, train_loss: 0.13193969428539276
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20944291353225708, train_loss: 0.10526179522275925
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20956392586231232, train_loss: 0.10177037864923477
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2096184641122818, train_loss: 0.10041828453540802
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8019679188728333, train_loss: 0.8656813502311707
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23541860282421112, train_loss: 0.15570436418056488
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.23250740766525269, train_loss: 0.13285879790782928
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2325056940317154, train_loss: 0.13536123931407928
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2317800372838974, train_loss: 0.12836886942386627
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:08<02:02,  8.73s/it]importance j:  13%|█▎        | 2/15 [00:18<02:04,  9.57s/it]importance j:  20%|██        | 3/15 [00:32<02:15, 11.29s/it]importance j:  27%|██▋       | 4/15 [00:40<01:52, 10.21s/it]importance j:  33%|███▎      | 5/15 [00:53<01:51, 11.13s/it]importance j:  40%|████      | 6/15 [01:02<01:32, 10.29s/it]importance j:  47%|████▋     | 7/15 [01:13<01:23, 10.47s/it]importance j:  53%|█████▎    | 8/15 [01:23<01:14, 10.61s/it]importance j:  60%|██████    | 9/15 [01:32<00:59,  9.88s/it]importance j:  67%|██████▋   | 10/15 [01:45<00:54, 10.81s/it]importance j:  73%|███████▎  | 11/15 [01:53<00:40, 10.11s/it]importance j:  80%|████████  | 12/15 [02:04<00:30, 10.28s/it]importance j:  87%|████████▋ | 13/15 [02:15<00:20, 10.45s/it]importance j:  93%|█████████▎| 14/15 [02:24<00:09,  9.98s/it]importance j: 100%|██████████| 15/15 [02:37<00:00, 10.92s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7071857452392578, train_loss: 0.6991610527038574
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5416804552078247, train_loss: 0.45434772968292236
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.528326153755188, train_loss: 0.39351242780685425
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5292616486549377, train_loss: 0.3810579776763916
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5297829508781433, train_loss: 0.3663565516471863
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6796969175338745, train_loss: 0.6513432264328003
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5988743305206299, train_loss: 0.4995453357696533
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5930013060569763, train_loss: 0.45532363653182983
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5933241248130798, train_loss: 0.44237780570983887
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5935813188552856, train_loss: 0.43162602186203003
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9707820415496826, train_loss: 0.9304270148277283
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6702073216438293, train_loss: 0.5572690963745117
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5714857578277588, train_loss: 0.4323687255382538
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5382806062698364, train_loss: 0.3659989833831787
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5241258144378662, train_loss: 0.3344821333885193
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.5213459730148315, train_loss: 0.30362468957901
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9133023619651794, train_loss: 0.8701326251029968
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6091966032981873, train_loss: 0.5332987308502197
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5771824717521667, train_loss: 0.4455105662345886
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5773711204528809, train_loss: 0.43075448274612427
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5782807469367981, train_loss: 0.4219914376735687
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5194958448410034, train_loss: 0.5351013541221619
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21464043855667114, train_loss: 0.13427017629146576
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20760327577590942, train_loss: 0.10401629656553268
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20693263411521912, train_loss: 0.10481660813093185
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20659565925598145, train_loss: 0.10006959736347198
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5448203682899475, train_loss: 0.6544675827026367
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21131624281406403, train_loss: 0.15522274374961853
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20941121876239777, train_loss: 0.1351325809955597
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20959562063217163, train_loss: 0.139615997672081
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20972494781017303, train_loss: 0.134323850274086
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7525069117546082, train_loss: 0.7928924560546875
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5584307312965393, train_loss: 0.46587011218070984
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5408974289894104, train_loss: 0.3967565894126892
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.541215181350708, train_loss: 0.3783760070800781
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5418519973754883, train_loss: 0.3677389621734619
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6852965354919434, train_loss: 0.6963717341423035
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5853663086891174, train_loss: 0.4882102608680725
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.579868733882904, train_loss: 0.43282684683799744
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5800464749336243, train_loss: 0.42107757925987244
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5802947282791138, train_loss: 0.42033952474594116
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.849486768245697, train_loss: 0.8551637530326843
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.592261016368866, train_loss: 0.4994088411331177
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5462872982025146, train_loss: 0.4206247329711914
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5319364070892334, train_loss: 0.36379918456077576
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5305321216583252, train_loss: 0.3372572362422943
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8399189710617065, train_loss: 0.828315019607544
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5921997427940369, train_loss: 0.5223830938339233
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5700507164001465, train_loss: 0.449117511510849
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5692247152328491, train_loss: 0.4193386733531952
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5695681571960449, train_loss: 0.4127858281135559
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.6104460954666138, train_loss: 1.6335598230361938
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18739470839500427, train_loss: 0.13292397558689117
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18654721975326538, train_loss: 0.1262543648481369
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18642863631248474, train_loss: 0.12712369859218597
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18706488609313965, train_loss: 0.11707872152328491
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3683243691921234, train_loss: 0.43229684233665466
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20856407284736633, train_loss: 0.16436617076396942
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.207362100481987, train_loss: 0.14697973430156708
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20668019354343414, train_loss: 0.13845638930797577
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2062835395336151, train_loss: 0.13976262509822845
[te_estimator_1_xnet] Epoch: 250, current validation loss: 0.20544418692588806, train_loss: 0.13854098320007324
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7136181592941284, train_loss: 0.6917769312858582
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5203754901885986, train_loss: 0.4099259376525879
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5195389986038208, train_loss: 0.3963034152984619
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5202068090438843, train_loss: 0.3888443410396576
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5212270617485046, train_loss: 0.3914221227169037
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7362993955612183, train_loss: 0.6904306411743164
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6142683029174805, train_loss: 0.4810311496257782
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6095009446144104, train_loss: 0.4403763711452484
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6108193397521973, train_loss: 0.4202924370765686
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6116397976875305, train_loss: 0.4187917113304138
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7322440147399902, train_loss: 0.7712216377258301
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5183337926864624, train_loss: 0.4482920169830322
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5095638632774353, train_loss: 0.37989720702171326
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.510019063949585, train_loss: 0.3739306330680847
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5107308030128479, train_loss: 0.3695269525051117
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7756213545799255, train_loss: 0.7742287516593933
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5591394305229187, train_loss: 0.5086352229118347
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5384544730186462, train_loss: 0.4439127445220947
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5370049476623535, train_loss: 0.43024104833602905
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5368875861167908, train_loss: 0.41938647627830505
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5165941119194031, train_loss: 0.5063824653625488
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19495762884616852, train_loss: 0.12778058648109436
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19315621256828308, train_loss: 0.11433394253253937
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19288158416748047, train_loss: 0.11243929713964462
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19262269139289856, train_loss: 0.10836727917194366
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.49441057443618774, train_loss: 0.49327704310417175
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21350936591625214, train_loss: 0.14943678677082062
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21226666867733002, train_loss: 0.1297028809785843
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21186242997646332, train_loss: 0.12552140653133392
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21184799075126648, train_loss: 0.1267428994178772
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7254469394683838, train_loss: 0.6752073168754578
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5432188510894775, train_loss: 0.4146708846092224
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5394103527069092, train_loss: 0.38460415601730347
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.540010392665863, train_loss: 0.36886054277420044
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5407475829124451, train_loss: 0.3644281029701233
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6469426155090332, train_loss: 0.6499148607254028
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5866273045539856, train_loss: 0.4605437219142914
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5874285697937012, train_loss: 0.4411254823207855
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5878698229789734, train_loss: 0.4465746283531189
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.588608980178833, train_loss: 0.4256743788719177
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9487683176994324, train_loss: 0.9772090315818787
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6267400979995728, train_loss: 0.5164453983306885
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5636193156242371, train_loss: 0.3955044150352478
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5500438213348389, train_loss: 0.3314555585384369
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5511630177497864, train_loss: 0.31763672828674316
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6659530401229858, train_loss: 0.6816505193710327
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5328811407089233, train_loss: 0.4775662422180176
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5333266258239746, train_loss: 0.4524286389350891
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.534033477306366, train_loss: 0.44962143898010254
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5349693298339844, train_loss: 0.4438004195690155
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6376124620437622, train_loss: 0.7625991106033325
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20069286227226257, train_loss: 0.1384599655866623
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19581568241119385, train_loss: 0.11086439341306686
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1953839361667633, train_loss: 0.10485925525426865
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1954704374074936, train_loss: 0.10338734835386276
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6395938992500305, train_loss: 0.6028609275817871
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23751388490200043, train_loss: 0.1596793383359909
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22285136580467224, train_loss: 0.1308724731206894
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22185446321964264, train_loss: 0.12306857109069824
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22147759795188904, train_loss: 0.11760786920785904
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7435011267662048, train_loss: 0.7877192497253418
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.588599443435669, train_loss: 0.4871205687522888
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5853782892227173, train_loss: 0.4315565228462219
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5861312747001648, train_loss: 0.42738640308380127
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5874350666999817, train_loss: 0.42538535594940186
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7009573578834534, train_loss: 0.681275486946106
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5994776487350464, train_loss: 0.501167893409729
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5838198661804199, train_loss: 0.4458216428756714
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5798901319503784, train_loss: 0.4120287299156189
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5794773697853088, train_loss: 0.40539878606796265
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.5791110396385193, train_loss: 0.3924348056316376
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.775141179561615, train_loss: 0.7779927253723145
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.630206823348999, train_loss: 0.49761176109313965
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6281251311302185, train_loss: 0.44920799136161804
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6285902857780457, train_loss: 0.44074898958206177
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6296758651733398, train_loss: 0.4306736886501312
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7038126587867737, train_loss: 0.6793908476829529
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6079113483428955, train_loss: 0.5166056156158447
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6002663373947144, train_loss: 0.47908493876457214
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.600856363773346, train_loss: 0.47710472345352173
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6010258793830872, train_loss: 0.4686172902584076
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5010035634040833, train_loss: 0.48968249559402466
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.23989088833332062, train_loss: 0.1497235745191574
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2383144050836563, train_loss: 0.14029744267463684
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.23776119947433472, train_loss: 0.1376630812883377
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.23754654824733734, train_loss: 0.12911872565746307
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7041385769844055, train_loss: 0.8394779562950134
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24697406589984894, train_loss: 0.17276933789253235
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.24020254611968994, train_loss: 0.13603220880031586
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.24038968980312347, train_loss: 0.1323614865541458
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.23954389989376068, train_loss: 0.13062642514705658
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7614620327949524, train_loss: 0.7963651418685913
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.557947039604187, train_loss: 0.4742727279663086
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5377728939056396, train_loss: 0.37772807478904724
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5381993055343628, train_loss: 0.38043880462646484
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5386708378791809, train_loss: 0.370574414730072
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6777728199958801, train_loss: 0.7005124092102051
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5898360013961792, train_loss: 0.47995075583457947
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5859330892562866, train_loss: 0.4434421956539154
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.586523175239563, train_loss: 0.4312359094619751
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.58756422996521, train_loss: 0.42510995268821716
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7432913184165955, train_loss: 0.7364964485168457
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5516757369041443, train_loss: 0.463200181722641
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5356781482696533, train_loss: 0.37997063994407654
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5360269546508789, train_loss: 0.36547422409057617
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5361319780349731, train_loss: 0.35571157932281494
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7849403619766235, train_loss: 0.777774453163147
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5598376393318176, train_loss: 0.5032370090484619
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5387946367263794, train_loss: 0.43990129232406616
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5395581722259521, train_loss: 0.4194101095199585
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5393507480621338, train_loss: 0.4319239556789398
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39923691749572754, train_loss: 0.4040032923221588
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2023494988679886, train_loss: 0.1301804780960083
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1972774714231491, train_loss: 0.11096940189599991
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19657869637012482, train_loss: 0.10578155517578125
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1961182951927185, train_loss: 0.10653048008680344
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7937565445899963, train_loss: 0.8641582727432251
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2003859132528305, train_loss: 0.16134797036647797
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1975201815366745, train_loss: 0.1384437382221222
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19770735502243042, train_loss: 0.1299019157886505
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1977739930152893, train_loss: 0.1304687261581421
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7068109512329102, train_loss: 0.7712723016738892
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.518866777420044, train_loss: 0.43814176321029663
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5163779258728027, train_loss: 0.38439783453941345
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5171047449111938, train_loss: 0.375169575214386
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5180357694625854, train_loss: 0.36554384231567383
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6848030686378479, train_loss: 0.7260955572128296
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5802610516548157, train_loss: 0.4908164441585541
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5806912779808044, train_loss: 0.45708200335502625
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5813608169555664, train_loss: 0.45014649629592896
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5826334357261658, train_loss: 0.453521192073822
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7875545024871826, train_loss: 0.8261498808860779
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5881658792495728, train_loss: 0.5028660297393799
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5301680564880371, train_loss: 0.4040909707546234
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5130016207695007, train_loss: 0.35586294531822205
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5133005976676941, train_loss: 0.34174081683158875
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6820859909057617, train_loss: 0.7206918597221375
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5315964818000793, train_loss: 0.515544056892395
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5250260829925537, train_loss: 0.44876837730407715
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.524830162525177, train_loss: 0.45660829544067383
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5246044993400574, train_loss: 0.44367823004722595
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45460665225982666, train_loss: 0.4688262939453125
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20120562613010406, train_loss: 0.1255035400390625
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19744367897510529, train_loss: 0.10458304733037949
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19724322855472565, train_loss: 0.09919403493404388
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19748209416866302, train_loss: 0.09496291726827621
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.603878378868103, train_loss: 0.6583832502365112
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20227034389972687, train_loss: 0.14773719012737274
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2016102373600006, train_loss: 0.12570179998874664
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20157328248023987, train_loss: 0.12505793571472168
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20149140059947968, train_loss: 0.1212521344423294
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8037040829658508, train_loss: 0.7505294680595398
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5735049843788147, train_loss: 0.4292498230934143
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5556837916374207, train_loss: 0.37632447481155396
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5565023422241211, train_loss: 0.35893601179122925
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5573486089706421, train_loss: 0.3564178943634033
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7270641326904297, train_loss: 0.7468754649162292
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5947913527488708, train_loss: 0.4921608865261078
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5951975584030151, train_loss: 0.4729273319244385
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5958494544029236, train_loss: 0.4621260166168213
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5963700413703918, train_loss: 0.4638868570327759
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7744193077087402, train_loss: 0.7722529768943787
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5667179822921753, train_loss: 0.48420578241348267
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5290499329566956, train_loss: 0.3900466859340668
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5262851119041443, train_loss: 0.3555687367916107
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5262914896011353, train_loss: 0.34843239188194275
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6799939274787903, train_loss: 0.6958402395248413
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5682015419006348, train_loss: 0.5026648044586182
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5667959451675415, train_loss: 0.46746981143951416
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5676394104957581, train_loss: 0.47737056016921997
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5684329271316528, train_loss: 0.45993971824645996
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4390120804309845, train_loss: 0.4796513020992279
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1997809112071991, train_loss: 0.12932227551937103
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1988437920808792, train_loss: 0.11666031181812286
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19854989647865295, train_loss: 0.11556651443243027
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19847169518470764, train_loss: 0.11231239885091782
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4438704252243042, train_loss: 0.4828673303127289
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20318156480789185, train_loss: 0.1626124382019043
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20285344123840332, train_loss: 0.1400957703590393
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20287474989891052, train_loss: 0.1433877795934677
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20294557511806488, train_loss: 0.13816118240356445
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.700899064540863, train_loss: 0.7066798210144043
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5131596922874451, train_loss: 0.42492812871932983
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5112078785896301, train_loss: 0.39145559072494507
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5119314193725586, train_loss: 0.3756175935268402
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5127162933349609, train_loss: 0.37700343132019043
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7665660381317139, train_loss: 0.8013757467269897
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.599774956703186, train_loss: 0.5103365778923035
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5920395255088806, train_loss: 0.4428928792476654
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5924985408782959, train_loss: 0.4377218186855316
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5929931998252869, train_loss: 0.424098938703537
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7101134657859802, train_loss: 0.7527929544448853
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5505049824714661, train_loss: 0.47037380933761597
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5247798562049866, train_loss: 0.39287668466567993
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5218835473060608, train_loss: 0.3745189905166626
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5221051573753357, train_loss: 0.354892373085022
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6552608013153076, train_loss: 0.6756893992424011
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5641735792160034, train_loss: 0.49689221382141113
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5624107718467712, train_loss: 0.4483075737953186
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5625718832015991, train_loss: 0.44688117504119873
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5628809332847595, train_loss: 0.4488404393196106
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5791376829147339, train_loss: 0.6293487548828125
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21193736791610718, train_loss: 0.1333509385585785
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2111964076757431, train_loss: 0.11709519475698471
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2109799087047577, train_loss: 0.11002539843320847
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2109994739294052, train_loss: 0.10758297890424728
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6181079149246216, train_loss: 0.6429761052131653
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20860998332500458, train_loss: 0.1501135677099228
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20586588978767395, train_loss: 0.13074679672718048
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20605245232582092, train_loss: 0.12531012296676636
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20612965524196625, train_loss: 0.1286982148885727
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6141476631164551, train_loss: 0.6061948537826538
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5204188823699951, train_loss: 0.4001635015010834
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5216599702835083, train_loss: 0.3788670003414154
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5225108861923218, train_loss: 0.3775410056114197
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.523722231388092, train_loss: 0.3688102662563324
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7398832440376282, train_loss: 0.7257976531982422
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6171349287033081, train_loss: 0.5132862329483032
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6060691475868225, train_loss: 0.4457976222038269
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6074618697166443, train_loss: 0.41476792097091675
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.608289897441864, train_loss: 0.4127902686595917
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6010226607322693, train_loss: 0.6426531672477722
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.503970205783844, train_loss: 0.4285292625427246
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5041373372077942, train_loss: 0.3962390124797821
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5048201084136963, train_loss: 0.40020546317100525
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5058890581130981, train_loss: 0.386760413646698
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7442352771759033, train_loss: 0.75679612159729
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5545446872711182, train_loss: 0.5015933513641357
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5433205366134644, train_loss: 0.4281476140022278
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5427001714706421, train_loss: 0.43674778938293457
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5425699353218079, train_loss: 0.420103520154953
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42677757143974304, train_loss: 0.46951746940612793
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2064911127090454, train_loss: 0.13573330640792847
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20540396869182587, train_loss: 0.12617473304271698
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20518726110458374, train_loss: 0.11506843566894531
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20544274151325226, train_loss: 0.1185939833521843
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4656934142112732, train_loss: 0.5209043025970459
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21941204369068146, train_loss: 0.1714259684085846
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21227730810642242, train_loss: 0.14160065352916718
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21177536249160767, train_loss: 0.13571956753730774
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21171310544013977, train_loss: 0.13280554115772247
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7148163914680481, train_loss: 0.7431159019470215
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5322666764259338, train_loss: 0.4301386773586273
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5318281650543213, train_loss: 0.39417657256126404
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.532796323299408, train_loss: 0.38984107971191406
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5341156721115112, train_loss: 0.39122629165649414
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7272125482559204, train_loss: 0.7275519371032715
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6048691868782043, train_loss: 0.5006762742996216
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5993626117706299, train_loss: 0.4295281767845154
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6001800894737244, train_loss: 0.4284908175468445
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6011159420013428, train_loss: 0.4264650046825409
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6310310959815979, train_loss: 0.6575329303741455
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5516995787620544, train_loss: 0.44172510504722595
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5505416989326477, train_loss: 0.3849857747554779
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5515719652175903, train_loss: 0.3807139992713928
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5528854727745056, train_loss: 0.375319242477417
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6899353265762329, train_loss: 0.6833170652389526
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5653607845306396, train_loss: 0.4896259307861328
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5591169595718384, train_loss: 0.4324362874031067
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5594045519828796, train_loss: 0.432261198759079
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5596171021461487, train_loss: 0.42022356390953064
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45220595598220825, train_loss: 0.524049699306488
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20565132796764374, train_loss: 0.1280706226825714
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.198039710521698, train_loss: 0.09856747835874557
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1982256919145584, train_loss: 0.08596612513065338
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19850750267505646, train_loss: 0.08774157613515854
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7200490236282349, train_loss: 0.6957980394363403
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22784875333309174, train_loss: 0.16205070912837982
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22200091183185577, train_loss: 0.14417676627635956
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2213335931301117, train_loss: 0.13727204501628876
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22108685970306396, train_loss: 0.13332204520702362
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7936456799507141, train_loss: 0.8448404669761658
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5662946701049805, train_loss: 0.4769565761089325
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5449246764183044, train_loss: 0.3935697078704834
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5454510450363159, train_loss: 0.36735257506370544
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5461220741271973, train_loss: 0.37445777654647827
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7300418019294739, train_loss: 0.7239116430282593
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5998164415359497, train_loss: 0.4947583079338074
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5925005674362183, train_loss: 0.42491549253463745
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5937926173210144, train_loss: 0.4154791235923767
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5944682359695435, train_loss: 0.41467389464378357
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7488785982131958, train_loss: 0.7814318537712097
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5569407939910889, train_loss: 0.4822768568992615
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5230823755264282, train_loss: 0.36983007192611694
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5205460786819458, train_loss: 0.3396250009536743
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5204296112060547, train_loss: 0.34650880098342896
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.627936601638794, train_loss: 0.6966667175292969
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5542078614234924, train_loss: 0.49283647537231445
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5538684725761414, train_loss: 0.4836965501308441
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5542176961898804, train_loss: 0.47563546895980835
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5549776554107666, train_loss: 0.4622746407985687
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.49999457597732544, train_loss: 0.5450040102005005
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19038231670856476, train_loss: 0.12810412049293518
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19134685397148132, train_loss: 0.12100584805011749
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19178710877895355, train_loss: 0.11020749062299728
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19270391762256622, train_loss: 0.11121612787246704
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6340405344963074, train_loss: 0.6564955115318298
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21386530995368958, train_loss: 0.14963288605213165
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21055442094802856, train_loss: 0.12340117990970612
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21060919761657715, train_loss: 0.11910586804151535
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21023441851139069, train_loss: 0.1156042143702507
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7184445261955261, train_loss: 0.6861927509307861
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5524435043334961, train_loss: 0.4351155161857605
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5499401688575745, train_loss: 0.38427823781967163
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5509541034698486, train_loss: 0.3900211453437805
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5522654056549072, train_loss: 0.3760955333709717
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.891991376876831, train_loss: 0.8981789350509644
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6467661261558533, train_loss: 0.5327136516571045
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6028875112533569, train_loss: 0.42968642711639404
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5969521403312683, train_loss: 0.37883493304252625
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5975556969642639, train_loss: 0.3820270299911499
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8086831569671631, train_loss: 0.8194867968559265
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5849942564964294, train_loss: 0.4761011004447937
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5484015941619873, train_loss: 0.38443025946617126
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5402415990829468, train_loss: 0.33933699131011963
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.540373682975769, train_loss: 0.3157467544078827
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6815049648284912, train_loss: 0.6887583136558533
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.552944540977478, train_loss: 0.5012694001197815
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5523236393928528, train_loss: 0.46986064314842224
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5530393719673157, train_loss: 0.4595608413219452
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5541229844093323, train_loss: 0.45305225253105164
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42171239852905273, train_loss: 0.4694039821624756
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20434533059597015, train_loss: 0.1301138699054718
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20197997987270355, train_loss: 0.1070735976099968
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20204240083694458, train_loss: 0.10693579912185669
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20241941511631012, train_loss: 0.10440869629383087
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6692429184913635, train_loss: 0.7396131753921509
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21895532310009003, train_loss: 0.16037273406982422
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21847763657569885, train_loss: 0.14440803229808807
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21839360892772675, train_loss: 0.13827824592590332
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2180243283510208, train_loss: 0.1316714733839035
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7855546474456787, train_loss: 0.8089878559112549
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5306494832038879, train_loss: 0.44602689146995544
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5192582607269287, train_loss: 0.3847115933895111
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5197423696517944, train_loss: 0.3760731816291809
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5206401348114014, train_loss: 0.3691784739494324
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7540944814682007, train_loss: 0.7159004211425781
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.614680290222168, train_loss: 0.48595666885375977
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5838419198989868, train_loss: 0.4244052767753601
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5795023441314697, train_loss: 0.39098939299583435
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5799069404602051, train_loss: 0.38107389211654663
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6131267547607422, train_loss: 0.5919409990310669
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5446850061416626, train_loss: 0.43287786841392517
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5432363748550415, train_loss: 0.3943192660808563
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5433706641197205, train_loss: 0.39955103397369385
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5435178279876709, train_loss: 0.38337206840515137
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6191102862358093, train_loss: 0.659252941608429
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5298174619674683, train_loss: 0.4708364009857178
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5305601954460144, train_loss: 0.46582064032554626
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5304904580116272, train_loss: 0.4528018832206726
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5314956903457642, train_loss: 0.4434538781642914
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5906971096992493, train_loss: 0.5719477534294128
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2033262699842453, train_loss: 0.132510706782341
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20270071923732758, train_loss: 0.11004272848367691
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20239956676959991, train_loss: 0.11056669801473618
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20259253680706024, train_loss: 0.10863073170185089
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5107080936431885, train_loss: 0.5406422019004822
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22083018720149994, train_loss: 0.16017462313175201
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2141394466161728, train_loss: 0.13344930112361908
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2137492299079895, train_loss: 0.12359984219074249
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21367530524730682, train_loss: 0.12379211187362671
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8133453726768494, train_loss: 0.8068447113037109
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5844246745109558, train_loss: 0.4701728820800781
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5696263909339905, train_loss: 0.38541626930236816
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5703243017196655, train_loss: 0.3669646382331848
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5710511207580566, train_loss: 0.3578227758407593
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7544822096824646, train_loss: 0.7248286008834839
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6270753741264343, train_loss: 0.4791599214076996
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6232805848121643, train_loss: 0.42934808135032654
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6234849095344543, train_loss: 0.4272344708442688
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6239596009254456, train_loss: 0.42493730783462524
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7226665616035461, train_loss: 0.7391830682754517
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5455875396728516, train_loss: 0.46494346857070923
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5190212726593018, train_loss: 0.3907548189163208
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5128759741783142, train_loss: 0.3506847321987152
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5133432149887085, train_loss: 0.3237130045890808
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7553306221961975, train_loss: 0.715437650680542
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5829482078552246, train_loss: 0.5013600587844849
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5714208483695984, train_loss: 0.43188929557800293
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5719735026359558, train_loss: 0.4280093312263489
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5722435712814331, train_loss: 0.42518335580825806
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5153111219406128, train_loss: 0.5917380452156067
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18936403095722198, train_loss: 0.14008411765098572
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18757480382919312, train_loss: 0.1152770072221756
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1877068281173706, train_loss: 0.11737978458404541
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18810632824897766, train_loss: 0.10860548168420792
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.553297758102417, train_loss: 0.5961835384368896
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22478032112121582, train_loss: 0.15611232817173004
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22479389607906342, train_loss: 0.14952149987220764
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22501905262470245, train_loss: 0.1465272158384323
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2246437519788742, train_loss: 0.13889141380786896
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7711786031723022, train_loss: 0.7794110178947449
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5196036100387573, train_loss: 0.5096466541290283
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4781520366668701, train_loss: 0.43834346532821655
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4668138027191162, train_loss: 0.3842349648475647
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4649081230163574, train_loss: 0.3629108667373657
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6988959312438965, train_loss: 0.7241394519805908
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5703524947166443, train_loss: 0.4975587725639343
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5654147863388062, train_loss: 0.44335970282554626
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5656566619873047, train_loss: 0.44098353385925293
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5661932229995728, train_loss: 0.4242355525493622
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6883252263069153, train_loss: 0.7389000654220581
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47265562415122986, train_loss: 0.4646417498588562
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4415450990200043, train_loss: 0.41107702255249023
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.4320746958255768, train_loss: 0.36643099784851074
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.4312450587749481, train_loss: 0.3392591178417206
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6002006530761719, train_loss: 0.7854002714157104
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5671486258506775, train_loss: 0.5348469018936157
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5721263289451599, train_loss: 0.5190052390098572
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5779101252555847, train_loss: 0.492600679397583
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5839377641677856, train_loss: 0.4844714105129242
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.31948065757751465, train_loss: 0.3106788098812103
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2133713811635971, train_loss: 0.13671043515205383
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2116558849811554, train_loss: 0.11667376011610031
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21157057583332062, train_loss: 0.11672790348529816
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2120215743780136, train_loss: 0.1091708168387413
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45042383670806885, train_loss: 0.4633033871650696
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2290390431880951, train_loss: 0.15738661587238312
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22235199809074402, train_loss: 0.12554140388965607
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2225087285041809, train_loss: 0.12442141771316528
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22241948544979095, train_loss: 0.11634590476751328
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 481/15001 [00:00<00:15, 961.73it/s]Shapley Value Sampling attribution:   6%|▋         | 962/15001 [00:01<00:16, 859.25it/s]Shapley Value Sampling attribution:   9%|▉         | 1396/15001 [00:01<00:16, 810.42it/s]Shapley Value Sampling attribution:  12%|█▏        | 1804/15001 [00:02<00:16, 792.49it/s]Shapley Value Sampling attribution:  15%|█▍        | 2202/15001 [00:02<00:16, 781.31it/s]Shapley Value Sampling attribution:  17%|█▋        | 2594/15001 [00:03<00:16, 765.38it/s]Shapley Value Sampling attribution:  20%|█▉        | 2977/15001 [00:04<00:18, 636.91it/s]Shapley Value Sampling attribution:  22%|██▏       | 3311/15001 [00:04<00:19, 587.69it/s]Shapley Value Sampling attribution:  24%|██▍       | 3617/15001 [00:05<00:19, 571.82it/s]Shapley Value Sampling attribution:  26%|██▌       | 3911/15001 [00:05<00:19, 561.66it/s]Shapley Value Sampling attribution:  28%|██▊       | 4197/15001 [00:06<00:19, 553.32it/s]Shapley Value Sampling attribution:  30%|██▉       | 4477/15001 [00:06<00:19, 546.72it/s]Shapley Value Sampling attribution:  32%|███▏      | 4753/15001 [00:07<00:18, 542.41it/s]Shapley Value Sampling attribution:  34%|███▎      | 5026/15001 [00:07<00:18, 541.36it/s]Shapley Value Sampling attribution:  35%|███▌      | 5310/15001 [00:08<00:17, 548.89it/s]Shapley Value Sampling attribution:  37%|███▋      | 5604/15001 [00:08<00:16, 560.13it/s]Shapley Value Sampling attribution:  39%|███▉      | 5903/15001 [00:09<00:15, 571.09it/s]Shapley Value Sampling attribution:  41%|████▏     | 6201/15001 [00:09<00:15, 578.10it/s]Shapley Value Sampling attribution:  43%|████▎     | 6497/15001 [00:10<00:14, 581.78it/s]Shapley Value Sampling attribution:  46%|████▌     | 6837/15001 [00:10<00:13, 610.58it/s]Shapley Value Sampling attribution:  48%|████▊     | 7232/15001 [00:11<00:11, 663.78it/s]Shapley Value Sampling attribution:  51%|█████     | 7666/15001 [00:11<00:10, 724.27it/s]Shapley Value Sampling attribution:  54%|█████▍    | 8106/15001 [00:12<00:08, 770.67it/s]Shapley Value Sampling attribution:  57%|█████▋    | 8541/15001 [00:12<00:08, 799.94it/s]Shapley Value Sampling attribution:  60%|█████▉    | 8988/15001 [00:13<00:07, 827.96it/s]Shapley Value Sampling attribution:  63%|██████▎   | 9445/15001 [00:13<00:06, 853.61it/s]Shapley Value Sampling attribution:  66%|██████▌   | 9918/15001 [00:14<00:05, 880.88it/s]Shapley Value Sampling attribution:  69%|██████▉   | 10401/15001 [00:15<00:05, 906.29it/s]Shapley Value Sampling attribution:  73%|███████▎  | 10883/15001 [00:15<00:04, 923.49it/s]Shapley Value Sampling attribution:  76%|███████▌  | 11366/15001 [00:16<00:03, 936.17it/s]Shapley Value Sampling attribution:  79%|███████▉  | 11848/15001 [00:16<00:03, 944.29it/s]Shapley Value Sampling attribution:  82%|████████▏ | 12330/15001 [00:17<00:02, 950.14it/s]Shapley Value Sampling attribution:  85%|████████▌ | 12810/15001 [00:17<00:02, 953.03it/s]Shapley Value Sampling attribution:  89%|████████▊ | 13293/15001 [00:18<00:01, 956.78it/s]Shapley Value Sampling attribution:  92%|█████████▏| 13775/15001 [00:18<00:01, 958.75it/s]Shapley Value Sampling attribution:  95%|█████████▌| 14258/15001 [00:19<00:00, 960.64it/s]Shapley Value Sampling attribution:  98%|█████████▊| 14739/15001 [00:19<00:00, 960.70it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:19<00:00, 758.59it/s]
Shapley Value Sampling attribution:   0%|          | 0/15001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   3%|▎         | 484/15001 [00:00<00:15, 966.98it/s]Shapley Value Sampling attribution:   6%|▋         | 968/15001 [00:01<00:14, 966.20it/s]Shapley Value Sampling attribution:  10%|▉         | 1455/15001 [00:01<00:13, 969.42it/s]Shapley Value Sampling attribution:  13%|█▎        | 1940/15001 [00:02<00:14, 894.92it/s]Shapley Value Sampling attribution:  16%|█▌        | 2392/15001 [00:02<00:15, 816.98it/s]Shapley Value Sampling attribution:  19%|█▉        | 2833/15001 [00:03<00:14, 836.69it/s]Shapley Value Sampling attribution:  22%|██▏       | 3317/15001 [00:03<00:13, 876.47it/s]Shapley Value Sampling attribution:  25%|██▌       | 3800/15001 [00:04<00:12, 903.37it/s]Shapley Value Sampling attribution:  29%|██▊       | 4282/15001 [00:04<00:11, 921.69it/s]Shapley Value Sampling attribution:  32%|███▏      | 4767/15001 [00:05<00:10, 935.86it/s]Shapley Value Sampling attribution:  35%|███▍      | 5250/15001 [00:05<00:10, 944.39it/s]Shapley Value Sampling attribution:  38%|███▊      | 5735/15001 [00:06<00:09, 951.82it/s]Shapley Value Sampling attribution:  41%|████▏     | 6218/15001 [00:06<00:09, 956.01it/s]Shapley Value Sampling attribution:  45%|████▍     | 6703/15001 [00:07<00:08, 959.92it/s]Shapley Value Sampling attribution:  48%|████▊     | 7188/15001 [00:07<00:08, 962.37it/s]Shapley Value Sampling attribution:  51%|█████     | 7674/15001 [00:08<00:07, 964.99it/s]Shapley Value Sampling attribution:  54%|█████▍    | 8160/15001 [00:08<00:07, 966.58it/s]Shapley Value Sampling attribution:  58%|█████▊    | 8644/15001 [00:09<00:06, 924.48it/s]Shapley Value Sampling attribution:  61%|██████    | 9109/15001 [00:09<00:06, 891.70it/s]Shapley Value Sampling attribution:  64%|██████▎   | 9558/15001 [00:10<00:06, 876.73it/s]Shapley Value Sampling attribution:  67%|██████▋   | 9998/15001 [00:10<00:05, 869.12it/s]Shapley Value Sampling attribution:  70%|██████▉   | 10434/15001 [00:11<00:05, 861.13it/s]Shapley Value Sampling attribution:  72%|███████▏  | 10866/15001 [00:12<00:05, 764.15it/s]Shapley Value Sampling attribution:  75%|███████▌  | 11258/15001 [00:12<00:05, 703.36it/s]Shapley Value Sampling attribution:  77%|███████▋  | 11620/15001 [00:13<00:04, 683.58it/s]Shapley Value Sampling attribution:  80%|███████▉  | 11968/15001 [00:13<00:04, 667.49it/s]Shapley Value Sampling attribution:  82%|████████▏ | 12306/15001 [00:14<00:04, 660.10it/s]Shapley Value Sampling attribution:  84%|████████▍ | 12639/15001 [00:15<00:03, 653.77it/s]Shapley Value Sampling attribution:  86%|████████▋ | 12968/15001 [00:15<00:03, 651.71it/s]Shapley Value Sampling attribution:  89%|████████▊ | 13295/15001 [00:16<00:02, 649.96it/s]Shapley Value Sampling attribution:  91%|█████████ | 13621/15001 [00:16<00:02, 646.14it/s]Shapley Value Sampling attribution:  93%|█████████▎| 13945/15001 [00:17<00:01, 645.64it/s]Shapley Value Sampling attribution:  95%|█████████▌| 14269/15001 [00:17<00:01, 645.59it/s]Shapley Value Sampling attribution:  97%|█████████▋| 14592/15001 [00:18<00:00, 642.90it/s]Shapley Value Sampling attribution:  99%|█████████▉| 14916/15001 [00:18<00:00, 644.01it/s]Shapley Value Sampling attribution: 100%|██████████| 15001/15001 [00:18<00:00, 801.50it/s]
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:08<01:56,  8.30s/it]importance j:  13%|█▎        | 2/15 [00:23<02:37, 12.11s/it]importance j:  20%|██        | 3/15 [00:32<02:11, 10.96s/it]importance j:  27%|██▋       | 4/15 [00:45<02:06, 11.51s/it]importance j:  33%|███▎      | 5/15 [00:53<01:44, 10.49s/it]importance j:  40%|████      | 6/15 [01:01<01:27,  9.70s/it]importance j:  47%|████▋     | 7/15 [01:15<01:28, 11.11s/it]importance j:  53%|█████▎    | 8/15 [01:25<01:14, 10.58s/it]importance j:  60%|██████    | 9/15 [01:36<01:05, 10.90s/it]importance j:  67%|██████▋   | 10/15 [01:46<00:51, 10.34s/it]importance j:  73%|███████▎  | 11/15 [01:54<00:38,  9.62s/it]importance j:  80%|████████  | 12/15 [02:07<00:32, 10.82s/it]importance j:  87%|████████▋ | 13/15 [02:17<00:21, 10.70s/it]importance j:  93%|█████████▎| 14/15 [02:27<00:10, 10.27s/it]importance j: 100%|██████████| 15/15 [02:39<00:00, 10.77s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7057833075523376, train_loss: 0.7355982661247253
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5463499426841736, train_loss: 0.4439561069011688
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5444681644439697, train_loss: 0.4034530520439148
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5449672341346741, train_loss: 0.40874332189559937
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5455791354179382, train_loss: 0.3958683907985687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7370089292526245, train_loss: 0.7389843463897705
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5880226492881775, train_loss: 0.49714648723602295
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5779720544815063, train_loss: 0.44381582736968994
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5783294439315796, train_loss: 0.4485465884208679
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5785818099975586, train_loss: 0.43709561228752136
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6845304369926453, train_loss: 0.707435131072998
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5193908214569092, train_loss: 0.45422860980033875
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.502344012260437, train_loss: 0.3737383782863617
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5018320679664612, train_loss: 0.3650452494621277
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5016565918922424, train_loss: 0.3555775582790375
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7559269070625305, train_loss: 0.7781260013580322
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5865938663482666, train_loss: 0.5107767581939697
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5727590322494507, train_loss: 0.45377635955810547
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.573428750038147, train_loss: 0.4379224181175232
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5741288661956787, train_loss: 0.4423559606075287
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8850681781768799, train_loss: 0.8835573196411133
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1894996017217636, train_loss: 0.12517023086547852
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19033563137054443, train_loss: 0.1133498102426529
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19050803780555725, train_loss: 0.11162864416837692
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.191399946808815, train_loss: 0.10951832681894302
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9489069581031799, train_loss: 1.0073455572128296
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22138644754886627, train_loss: 0.16156931221485138
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21818959712982178, train_loss: 0.13619554042816162
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21777355670928955, train_loss: 0.13352425396442413
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21773511171340942, train_loss: 0.125472292304039
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8627145290374756, train_loss: 0.923558235168457
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5580935478210449, train_loss: 0.49260568618774414
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5330744385719299, train_loss: 0.39656513929367065
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5340716242790222, train_loss: 0.3849529027938843
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5349307060241699, train_loss: 0.3706378638744354
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6120660901069641, train_loss: 0.6368674039840698
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5650102496147156, train_loss: 0.47118276357650757
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5661107301712036, train_loss: 0.4585971236228943
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5676751136779785, train_loss: 0.45820045471191406
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5686617493629456, train_loss: 0.447654664516449
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7162560224533081, train_loss: 0.6931523084640503
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5493452548980713, train_loss: 0.4626217782497406
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5252214670181274, train_loss: 0.3993850648403168
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5249955654144287, train_loss: 0.36329931020736694
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5250688195228577, train_loss: 0.3610367476940155
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7618536949157715, train_loss: 0.8100322484970093
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5531129240989685, train_loss: 0.5260521173477173
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5278903841972351, train_loss: 0.46005892753601074
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5249053835868835, train_loss: 0.4191575050354004
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5249364376068115, train_loss: 0.4210980534553528
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5780853033065796, train_loss: 0.6953118443489075
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22057901322841644, train_loss: 0.14976084232330322
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21287374198436737, train_loss: 0.11002439260482788
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2124878168106079, train_loss: 0.10833877325057983
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21227209270000458, train_loss: 0.10465098917484283
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5818518400192261, train_loss: 0.7044546008110046
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19766297936439514, train_loss: 0.1522471159696579
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19577309489250183, train_loss: 0.14008285105228424
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19551563262939453, train_loss: 0.13756504654884338
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19525980949401855, train_loss: 0.13637715578079224
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8001353740692139, train_loss: 0.8894261121749878
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5411525368690491, train_loss: 0.4595097303390503
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5328941345214844, train_loss: 0.3972698450088501
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.533584713935852, train_loss: 0.37827277183532715
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5345218777656555, train_loss: 0.38192078471183777
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7368523478507996, train_loss: 0.7693499326705933
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.618060290813446, train_loss: 0.49434465169906616
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6038994789123535, train_loss: 0.4271506667137146
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6049640774726868, train_loss: 0.4171604514122009
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6051607728004456, train_loss: 0.41312310099601746
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7546593546867371, train_loss: 0.7694811820983887
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5406994819641113, train_loss: 0.4628911018371582
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5266413688659668, train_loss: 0.3822920024394989
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5264559984207153, train_loss: 0.3677641749382019
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.526780903339386, train_loss: 0.3622417449951172
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7935343384742737, train_loss: 0.8324100375175476
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5576139688491821, train_loss: 0.5120612382888794
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5334907174110413, train_loss: 0.4468473792076111
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.529796838760376, train_loss: 0.4052562415599823
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5308154225349426, train_loss: 0.4036996364593506
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7755193710327148, train_loss: 0.7858373522758484
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17240597307682037, train_loss: 0.12623374164104462
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.17083941400051117, train_loss: 0.10708673298358917
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.17138735949993134, train_loss: 0.10503359138965607
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1718415766954422, train_loss: 0.10397922992706299
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4253426492214203, train_loss: 0.46853193640708923
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19351458549499512, train_loss: 0.1635565161705017
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.18584631383419037, train_loss: 0.13961203396320343
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.18526878952980042, train_loss: 0.13418488204479218
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.18479929864406586, train_loss: 0.1342727392911911
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6525360345840454, train_loss: 0.5676738619804382
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5723404288291931, train_loss: 0.3948875367641449
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5729585886001587, train_loss: 0.3903437554836273
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5737525224685669, train_loss: 0.3812895715236664
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5749464631080627, train_loss: 0.3833594024181366
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8872928023338318, train_loss: 0.9068679213523865
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6235813498497009, train_loss: 0.5290584564208984
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5840568542480469, train_loss: 0.4375006854534149
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5824509263038635, train_loss: 0.4089120030403137
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5822155475616455, train_loss: 0.3925827443599701
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5945487022399902, train_loss: 0.5954973101615906
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5029162168502808, train_loss: 0.41892504692077637
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5015461444854736, train_loss: 0.37863001227378845
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5020924806594849, train_loss: 0.3757476508617401
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5028985738754272, train_loss: 0.3798816204071045
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6481354832649231, train_loss: 0.7337333559989929
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5233414769172668, train_loss: 0.49411338567733765
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5228124856948853, train_loss: 0.46774137020111084
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5234326124191284, train_loss: 0.4699992537498474
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5238294005393982, train_loss: 0.44673556089401245
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6509503126144409, train_loss: 0.6738249659538269
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2065962851047516, train_loss: 0.13156758248806
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19904489815235138, train_loss: 0.102643683552742
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19851720333099365, train_loss: 0.10099615901708603
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1984570175409317, train_loss: 0.09460370987653732
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5099601149559021, train_loss: 0.5102246999740601
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19705092906951904, train_loss: 0.1520853340625763
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19704888761043549, train_loss: 0.1423802226781845
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1972334384918213, train_loss: 0.1402820646762848
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19769905507564545, train_loss: 0.131860613822937
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7400763630867004, train_loss: 0.7902412414550781
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5758751630783081, train_loss: 0.5005999803543091
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5739889144897461, train_loss: 0.4401799142360687
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5748780369758606, train_loss: 0.43754202127456665
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5763760805130005, train_loss: 0.42963188886642456
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7047373652458191, train_loss: 0.7411805987358093
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5893515944480896, train_loss: 0.5135904550552368
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5819054245948792, train_loss: 0.4535556733608246
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5822975039482117, train_loss: 0.4404374063014984
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.582128643989563, train_loss: 0.4429780840873718
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7168037295341492, train_loss: 0.7296714186668396
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6162525415420532, train_loss: 0.4722503423690796
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.615060567855835, train_loss: 0.4383279085159302
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6155633330345154, train_loss: 0.4316771626472473
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6165453791618347, train_loss: 0.4202077388763428
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7344940900802612, train_loss: 0.7889675498008728
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5775784850120544, train_loss: 0.5474554300308228
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5728898644447327, train_loss: 0.49422651529312134
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5736239552497864, train_loss: 0.4969196915626526
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5741589665412903, train_loss: 0.4919224679470062
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4785394072532654, train_loss: 0.44142064452171326
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2416759580373764, train_loss: 0.14850589632987976
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.24034008383750916, train_loss: 0.1279878467321396
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.24062402546405792, train_loss: 0.12913355231285095
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2407287359237671, train_loss: 0.11960887163877487
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5800594687461853, train_loss: 0.8007544875144958
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.23051483929157257, train_loss: 0.18133676052093506
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2256719022989273, train_loss: 0.13382720947265625
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22517141699790955, train_loss: 0.13667725026607513
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22527247667312622, train_loss: 0.13115282356739044
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6478137373924255, train_loss: 0.6557780504226685
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5300529599189758, train_loss: 0.4306377172470093
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5259087681770325, train_loss: 0.382800430059433
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5261968374252319, train_loss: 0.36610209941864014
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5267395377159119, train_loss: 0.36830711364746094
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7595369815826416, train_loss: 0.7124851942062378
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6461139917373657, train_loss: 0.4830198287963867
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6310179233551025, train_loss: 0.4252305030822754
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6315354108810425, train_loss: 0.405154287815094
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6319802403450012, train_loss: 0.40401244163513184
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5988362431526184, train_loss: 0.6159869432449341
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5122154951095581, train_loss: 0.4249834716320038
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5093531012535095, train_loss: 0.37180739641189575
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5097910761833191, train_loss: 0.3539276719093323
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5104537010192871, train_loss: 0.36318835616111755
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6403065323829651, train_loss: 0.690868079662323
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5184133648872375, train_loss: 0.47375327348709106
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5145172476768494, train_loss: 0.4376471936702728
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5145620107650757, train_loss: 0.4340232312679291
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5147765874862671, train_loss: 0.42788100242614746
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5765933394432068, train_loss: 0.6473724842071533
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20755444467067719, train_loss: 0.13333839178085327
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20175334811210632, train_loss: 0.09830930829048157
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2017364203929901, train_loss: 0.09032756835222244
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20190033316612244, train_loss: 0.08887141197919846
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7074905037879944, train_loss: 0.8329572677612305
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2301749289035797, train_loss: 0.15970991551876068
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22991125285625458, train_loss: 0.14060312509536743
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2299490123987198, train_loss: 0.1365162879228592
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22994062304496765, train_loss: 0.12818555533885956
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7448229789733887, train_loss: 0.7391237020492554
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5366975665092468, train_loss: 0.45025524497032166
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5248963236808777, train_loss: 0.38460707664489746
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5251060128211975, train_loss: 0.3616398274898529
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5256826877593994, train_loss: 0.36576613783836365
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8254430294036865, train_loss: 0.8180204629898071
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6007524132728577, train_loss: 0.5022351145744324
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5867619514465332, train_loss: 0.4263302683830261
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5875587463378906, train_loss: 0.41669386625289917
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5880518555641174, train_loss: 0.4108824133872986
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6098554730415344, train_loss: 0.60648512840271
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5342434644699097, train_loss: 0.4318063259124756
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5293663740158081, train_loss: 0.3755304217338562
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5300079584121704, train_loss: 0.37280821800231934
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5308697819709778, train_loss: 0.3714500367641449
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.676698625087738, train_loss: 0.7228460311889648
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5324710607528687, train_loss: 0.4926903247833252
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5338993668556213, train_loss: 0.4604056775569916
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5345055460929871, train_loss: 0.45402902364730835
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5353243947029114, train_loss: 0.4371879994869232
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.500044584274292, train_loss: 0.5071042776107788
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19476830959320068, train_loss: 0.11969923228025436
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1916036158800125, train_loss: 0.10072338581085205
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1915178894996643, train_loss: 0.10058881342411041
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19161862134933472, train_loss: 0.09451284259557724
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.49358323216438293, train_loss: 0.47612568736076355
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21477535367012024, train_loss: 0.15687356889247894
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20579296350479126, train_loss: 0.1223849281668663
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20579884946346283, train_loss: 0.12454624474048615
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20575790107250214, train_loss: 0.11861163377761841
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7201517224311829, train_loss: 0.7161852121353149
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5520936250686646, train_loss: 0.4138568043708801
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5502265095710754, train_loss: 0.3905692994594574
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5512056946754456, train_loss: 0.37871965765953064
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5524898171424866, train_loss: 0.3719903826713562
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7260523438453674, train_loss: 0.7338361740112305
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6018731594085693, train_loss: 0.509543776512146
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5873027443885803, train_loss: 0.42918774485588074
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5879838466644287, train_loss: 0.4233778715133667
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5883769989013672, train_loss: 0.4126872420310974
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8539917469024658, train_loss: 0.8524672389030457
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6084142923355103, train_loss: 0.5157774686813354
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5634187459945679, train_loss: 0.4120100438594818
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5559256672859192, train_loss: 0.35359930992126465
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5561988353729248, train_loss: 0.35527560114860535
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7031192183494568, train_loss: 0.6851507425308228
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5706142783164978, train_loss: 0.5146742463111877
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5610505938529968, train_loss: 0.4407910704612732
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5621512532234192, train_loss: 0.42702528834342957
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5628723502159119, train_loss: 0.43583428859710693
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5162393450737, train_loss: 0.572201669216156
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2048804610967636, train_loss: 0.122658371925354
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20516760647296906, train_loss: 0.09850995987653732
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2056453377008438, train_loss: 0.09836139529943466
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20616444945335388, train_loss: 0.09255672991275787
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6893130540847778, train_loss: 0.8198956847190857
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24205762147903442, train_loss: 0.16039063036441803
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2349017709493637, train_loss: 0.13261643052101135
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2342747449874878, train_loss: 0.12628917396068573
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.23388871550559998, train_loss: 0.12913784384727478
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9110393524169922, train_loss: 0.9662771224975586
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5575301647186279, train_loss: 0.49100232124328613
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5287880301475525, train_loss: 0.3861728608608246
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5287113785743713, train_loss: 0.3667697310447693
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5291906595230103, train_loss: 0.35355862975120544
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7776349186897278, train_loss: 0.8028696775436401
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6087290048599243, train_loss: 0.49566763639450073
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5968573689460754, train_loss: 0.41886159777641296
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5969383716583252, train_loss: 0.4042411744594574
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5973637104034424, train_loss: 0.403654545545578
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8079954981803894, train_loss: 0.8253672122955322
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5921146869659424, train_loss: 0.47907790541648865
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5601483583450317, train_loss: 0.38005155324935913
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5574018359184265, train_loss: 0.33849620819091797
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.556881308555603, train_loss: 0.33706578612327576
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6311878561973572, train_loss: 0.7161872386932373
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.520321786403656, train_loss: 0.5019872188568115
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.521176278591156, train_loss: 0.5068928599357605
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5225439667701721, train_loss: 0.4862078130245209
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5240347981452942, train_loss: 0.49335527420043945
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6554099321365356, train_loss: 0.6382641196250916
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.214569091796875, train_loss: 0.13309092819690704
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2053033411502838, train_loss: 0.10171525925397873
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20496788620948792, train_loss: 0.09658356010913849
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20478232204914093, train_loss: 0.09467501193284988
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8537137508392334, train_loss: 0.9386933445930481
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2089727818965912, train_loss: 0.16168369352817535
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20674249529838562, train_loss: 0.13563643395900726
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20733530819416046, train_loss: 0.13353639841079712
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20779238641262054, train_loss: 0.12986429035663605
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.719864010810852, train_loss: 0.6634811162948608
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5761200785636902, train_loss: 0.41795867681503296
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5773102641105652, train_loss: 0.3974686563014984
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5784208178520203, train_loss: 0.38426119089126587
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5797688961029053, train_loss: 0.37668466567993164
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6970493793487549, train_loss: 0.7650070190429688
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.572566568851471, train_loss: 0.49425268173217773
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5695015788078308, train_loss: 0.44244641065597534
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5692893266677856, train_loss: 0.4455246329307556
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.569931149482727, train_loss: 0.4243484437465668
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6952774524688721, train_loss: 0.6749914884567261
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5521542429924011, train_loss: 0.4410456418991089
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.527313768863678, train_loss: 0.37655648589134216
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5263220071792603, train_loss: 0.35224926471710205
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5265226364135742, train_loss: 0.3473111093044281
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7570455074310303, train_loss: 0.7691789865493774
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.560992956161499, train_loss: 0.4966614842414856
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.546691358089447, train_loss: 0.43560492992401123
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5463660359382629, train_loss: 0.42227303981781006
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5463190078735352, train_loss: 0.42393240332603455
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7136791944503784, train_loss: 0.8173199892044067
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1770329624414444, train_loss: 0.12820176780223846
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.17584623396396637, train_loss: 0.12019658088684082
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.17601853609085083, train_loss: 0.11419784277677536
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.17658957839012146, train_loss: 0.10767068713903427
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5445179343223572, train_loss: 0.6947189569473267
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21878549456596375, train_loss: 0.15828824043273926
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2133937031030655, train_loss: 0.12912915647029877
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21320781111717224, train_loss: 0.12256019562482834
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.21318931877613068, train_loss: 0.11822562664747238
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6843144297599792, train_loss: 0.6588283777236938
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5406622886657715, train_loss: 0.41096779704093933
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5401705503463745, train_loss: 0.39794492721557617
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5408266186714172, train_loss: 0.3783723711967468
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5416763424873352, train_loss: 0.3809778690338135
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7244148254394531, train_loss: 0.7165728807449341
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6153465509414673, train_loss: 0.49339473247528076
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6110785007476807, train_loss: 0.4477510452270508
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6113442182540894, train_loss: 0.43583378195762634
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6116703748703003, train_loss: 0.45259004831314087
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6117551922798157, train_loss: 0.6160582304000854
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5380920171737671, train_loss: 0.4215712547302246
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5395817160606384, train_loss: 0.4063582420349121
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.54056316614151, train_loss: 0.410693496465683
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5419723391532898, train_loss: 0.3902824819087982
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.681158185005188, train_loss: 0.6958861351013184
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.554821252822876, train_loss: 0.49283379316329956
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5550406575202942, train_loss: 0.4677128195762634
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5555806756019592, train_loss: 0.46133726835250854
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5563386082649231, train_loss: 0.4512568712234497
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42040443420410156, train_loss: 0.4863196909427643
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18986459076404572, train_loss: 0.13631941378116608
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19060730934143066, train_loss: 0.12323515862226486
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19097615778446198, train_loss: 0.1171109676361084
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19147685170173645, train_loss: 0.11240575462579727
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.1749632358551025, train_loss: 1.1619844436645508
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20400592684745789, train_loss: 0.15855911374092102
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20464496314525604, train_loss: 0.14713814854621887
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20448993146419525, train_loss: 0.14803573489189148
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20439937710762024, train_loss: 0.14362859725952148
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6293841004371643, train_loss: 0.6404834389686584
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5387489199638367, train_loss: 0.4228089451789856
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.539771556854248, train_loss: 0.4161556363105774
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5408981442451477, train_loss: 0.40156179666519165
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5423979759216309, train_loss: 0.39035308361053467
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6706781983375549, train_loss: 0.653716504573822
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5979138612747192, train_loss: 0.48636752367019653
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5919464230537415, train_loss: 0.4261809289455414
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5919293165206909, train_loss: 0.42014169692993164
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.591910719871521, train_loss: 0.4157900810241699
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8492316007614136, train_loss: 0.877631664276123
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.57776939868927, train_loss: 0.49577099084854126
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5300388932228088, train_loss: 0.39624691009521484
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5217334032058716, train_loss: 0.35484617948532104
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5216488838195801, train_loss: 0.32931625843048096
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7288608551025391, train_loss: 0.7828482985496521
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5472292304039001, train_loss: 0.5060233473777771
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5395135283470154, train_loss: 0.44174909591674805
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5396618843078613, train_loss: 0.43803900480270386
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5396190285682678, train_loss: 0.4402347803115845
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3806619942188263, train_loss: 0.445137083530426
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1857820451259613, train_loss: 0.13985101878643036
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18567997217178345, train_loss: 0.12928210198879242
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18574927747249603, train_loss: 0.1217711940407753
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1860366314649582, train_loss: 0.12007210403680801
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6053363084793091, train_loss: 0.670323371887207
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.24027962982654572, train_loss: 0.1618744432926178
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2302708625793457, train_loss: 0.13213907182216644
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22983184456825256, train_loss: 0.12141557782888412
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2298506647348404, train_loss: 0.12014975398778915
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7948033809661865, train_loss: 0.7872895002365112
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5369109511375427, train_loss: 0.43659716844558716
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5295264720916748, train_loss: 0.3727586269378662
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.530083954334259, train_loss: 0.3778073489665985
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5307908654212952, train_loss: 0.37243518233299255
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.685992956161499, train_loss: 0.6478630900382996
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6037659049034119, train_loss: 0.4771972596645355
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5959863662719727, train_loss: 0.42183786630630493
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5964197516441345, train_loss: 0.4174673557281494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5963029265403748, train_loss: 0.41113436222076416
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7257485389709473, train_loss: 0.7192413806915283
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5683223605155945, train_loss: 0.4509623944759369
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5527598857879639, train_loss: 0.38332897424697876
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5523350238800049, train_loss: 0.37658262252807617
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5524361729621887, train_loss: 0.36638879776000977
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7221665382385254, train_loss: 0.7432694435119629
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5593344569206238, train_loss: 0.5010154247283936
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5519706010818481, train_loss: 0.4395279288291931
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5528359413146973, train_loss: 0.42197704315185547
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5535220503807068, train_loss: 0.4219331443309784
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7775921821594238, train_loss: 0.8284258246421814
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20515155792236328, train_loss: 0.1290658712387085
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20573292672634125, train_loss: 0.1135592982172966
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20584237575531006, train_loss: 0.11123142391443253
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20581451058387756, train_loss: 0.11328151077032089
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41080227494239807, train_loss: 0.4874146580696106
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.17894184589385986, train_loss: 0.15945091843605042
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.17573264241218567, train_loss: 0.12899985909461975
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1758636087179184, train_loss: 0.1235266923904419
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.17642764747142792, train_loss: 0.12138485908508301
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.848564863204956, train_loss: 0.9453226923942566
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5318676233291626, train_loss: 0.4678393006324768
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5134429931640625, train_loss: 0.3812507092952728
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5141573548316956, train_loss: 0.3708880841732025
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5148976445198059, train_loss: 0.3666137158870697
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6589681506156921, train_loss: 0.6648721098899841
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5823072791099548, train_loss: 0.47651228308677673
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5805863738059998, train_loss: 0.4409045875072479
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5806589126586914, train_loss: 0.43295592069625854
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5809639692306519, train_loss: 0.4404074549674988
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6172252893447876, train_loss: 0.6341031789779663
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5317200422286987, train_loss: 0.42791494727134705
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5266741514205933, train_loss: 0.3687779903411865
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5274948477745056, train_loss: 0.3545912206172943
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5282407999038696, train_loss: 0.3494589328765869
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7163664102554321, train_loss: 0.7141250371932983
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5774411559104919, train_loss: 0.4884781241416931
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5711588263511658, train_loss: 0.44035574793815613
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5716966986656189, train_loss: 0.4435367286205292
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.572257399559021, train_loss: 0.4307595491409302
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9870572090148926, train_loss: 1.0527442693710327
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19714808464050293, train_loss: 0.12553809583187103
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19547660648822784, train_loss: 0.10304712504148483
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19524091482162476, train_loss: 0.0986538827419281
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1956014633178711, train_loss: 0.10147123783826828
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9289199709892273, train_loss: 0.9046074151992798
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20417992770671844, train_loss: 0.15223045647144318
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1992209106683731, train_loss: 0.12163364887237549
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1985330581665039, train_loss: 0.11744997650384903
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19791316986083984, train_loss: 0.11572785675525665
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6610966324806213, train_loss: 0.6383603811264038
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5317763090133667, train_loss: 0.4037075936794281
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5325539708137512, train_loss: 0.38408708572387695
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5331493616104126, train_loss: 0.37416285276412964
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5340906381607056, train_loss: 0.3807554841041565
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8031630516052246, train_loss: 0.8036238551139832
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6107330322265625, train_loss: 0.5062114000320435
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5788754224777222, train_loss: 0.42026054859161377
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5750212669372559, train_loss: 0.38990479707717896
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5753874182701111, train_loss: 0.3799092173576355
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.641071617603302, train_loss: 0.6561431288719177
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5459009408950806, train_loss: 0.44106292724609375
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5349761247634888, train_loss: 0.36601418256759644
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.535658061504364, train_loss: 0.3543030917644501
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.535868763923645, train_loss: 0.34381312131881714
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7433646321296692, train_loss: 0.7757657766342163
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5531904697418213, train_loss: 0.5031930208206177
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5430628061294556, train_loss: 0.4372187554836273
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5441984534263611, train_loss: 0.4190438687801361
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5449970960617065, train_loss: 0.41133666038513184
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5607107281684875, train_loss: 0.5701212882995605
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20578831434249878, train_loss: 0.1254264861345291
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20537561178207397, train_loss: 0.11959309875965118
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20517803728580475, train_loss: 0.11985334008932114
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2047041356563568, train_loss: 0.11169929802417755
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.44016221165657043, train_loss: 0.4893239140510559
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21164828538894653, train_loss: 0.16100624203681946
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2080014944076538, train_loss: 0.1387760192155838
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20795315504074097, train_loss: 0.13904979825019836
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2078041136264801, train_loss: 0.12931276857852936
importance j:   0%|          | 0/15 [00:00<?, ?it/s]importance j:   7%|▋         | 1/15 [00:09<02:14,  9.64s/it]importance j:  13%|█▎        | 2/15 [00:22<02:26, 11.25s/it]importance j:  20%|██        | 3/15 [00:32<02:12, 11.08s/it]importance j:  27%|██▋       | 4/15 [00:42<01:53, 10.35s/it]importance j:  33%|███▎      | 5/15 [00:53<01:48, 10.81s/it]importance j:  40%|████      | 6/15 [01:02<01:30, 10.03s/it]importance j:  47%|████▋     | 7/15 [01:14<01:26, 10.86s/it]importance j:  53%|█████▎    | 8/15 [01:26<01:18, 11.16s/it]importance j:  60%|██████    | 9/15 [01:34<01:01, 10.23s/it]importance j:  67%|██████▋   | 10/15 [01:49<00:57, 11.47s/it]importance j:  73%|███████▎  | 11/15 [01:57<00:41, 10.47s/it]importance j:  80%|████████  | 12/15 [02:08<00:32, 10.72s/it]importance j:  87%|████████▋ | 13/15 [02:21<00:22, 11.49s/it]importance j:  93%|█████████▎| 14/15 [02:35<00:12, 12.06s/it]importance j: 100%|██████████| 15/15 [02:44<00:00, 11.15s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7507608532905579, train_loss: 0.7085437774658203
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5600473880767822, train_loss: 0.432679146528244
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5493982434272766, train_loss: 0.38546222448349
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5495464205741882, train_loss: 0.3695589303970337
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5499687194824219, train_loss: 0.3602268099784851
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7939983606338501, train_loss: 0.77830570936203
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6211574673652649, train_loss: 0.5043134689331055
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.603355348110199, train_loss: 0.4445176124572754
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6026577949523926, train_loss: 0.44274163246154785
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.602377712726593, train_loss: 0.4170862138271332
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8974361419677734, train_loss: 0.892508864402771
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6044021844863892, train_loss: 0.512451708316803
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5401543974876404, train_loss: 0.3988384008407593
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.524996817111969, train_loss: 0.3488690257072449
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5242527723312378, train_loss: 0.3234034776687622
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7537664771080017, train_loss: 0.764225959777832
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5823903679847717, train_loss: 0.5074731111526489
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5687249898910522, train_loss: 0.4463556706905365
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.56936115026474, train_loss: 0.4525282382965088
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5695292353630066, train_loss: 0.43301844596862793
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.612747073173523, train_loss: 0.5683385729789734
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.22288304567337036, train_loss: 0.14011965692043304
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.21999792754650116, train_loss: 0.12238689512014389
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21989832818508148, train_loss: 0.12085425853729248
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.22002266347408295, train_loss: 0.11264081299304962
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5191247463226318, train_loss: 0.5841347575187683
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2231529802083969, train_loss: 0.1718127578496933
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.21903005242347717, train_loss: 0.13751263916492462
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.21856896579265594, train_loss: 0.1276378482580185
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2184123992919922, train_loss: 0.12494798749685287
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7457744479179382, train_loss: 0.7558887004852295
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5503105521202087, train_loss: 0.45673686265945435
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5427761077880859, train_loss: 0.3878246247768402
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.543484091758728, train_loss: 0.38249194622039795
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5446634888648987, train_loss: 0.37948328256607056
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8971195816993713, train_loss: 0.8804394602775574
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6430666446685791, train_loss: 0.5221104621887207
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6066997051239014, train_loss: 0.4224451184272766
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6030453443527222, train_loss: 0.4032468795776367
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6028270125389099, train_loss: 0.3959236145019531
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6808705925941467, train_loss: 0.6591334342956543
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5584404468536377, train_loss: 0.4509415030479431
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5424692034721375, train_loss: 0.3881886899471283
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5427815914154053, train_loss: 0.3737645745277405
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5431439876556396, train_loss: 0.3743465542793274
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6457411646842957, train_loss: 0.6345409750938416
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5497922897338867, train_loss: 0.4852036237716675
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5455320477485657, train_loss: 0.43818265199661255
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5457941293716431, train_loss: 0.4337814748287201
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5463915467262268, train_loss: 0.4299190044403076
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4404813051223755, train_loss: 0.4138839840888977
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20056314766407013, train_loss: 0.12473960220813751
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1997201144695282, train_loss: 0.11117192357778549
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20007207989692688, train_loss: 0.10677317529916763
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2001250982284546, train_loss: 0.10266361385583878
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.37257689237594604, train_loss: 0.4357185959815979
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1960981786251068, train_loss: 0.15446467697620392
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19707463681697845, train_loss: 0.14405451714992523
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19731011986732483, train_loss: 0.1330306977033615
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1974647045135498, train_loss: 0.1359672099351883
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.755476176738739, train_loss: 0.7773181200027466
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5364055037498474, train_loss: 0.43091773986816406
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5350741744041443, train_loss: 0.3878122568130493
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5356430411338806, train_loss: 0.39284417033195496
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5364083647727966, train_loss: 0.3865186870098114
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6848891973495483, train_loss: 0.6263736486434937
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6037191152572632, train_loss: 0.4673212170600891
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.601818859577179, train_loss: 0.4273049533367157
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6022480726242065, train_loss: 0.42719221115112305
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6026719212532043, train_loss: 0.4187330901622772
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6468887329101562, train_loss: 0.6774300932884216
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5364587903022766, train_loss: 0.4530187249183655
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5274486541748047, train_loss: 0.37547022104263306
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5276163220405579, train_loss: 0.37267667055130005
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5278576612472534, train_loss: 0.3608337342739105
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7230148911476135, train_loss: 0.7578768134117126
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5206651091575623, train_loss: 0.5025755167007446
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5111081004142761, train_loss: 0.4550999104976654
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5111819505691528, train_loss: 0.4449196457862854
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5113304853439331, train_loss: 0.43986043334007263
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.542606770992279, train_loss: 0.5865196585655212
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18880349397659302, train_loss: 0.12712045013904572
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18645213544368744, train_loss: 0.11318492144346237
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1854209303855896, train_loss: 0.10594439506530762
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18469513952732086, train_loss: 0.10449576377868652
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6186025738716125, train_loss: 0.6960375905036926
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19329054653644562, train_loss: 0.15201739966869354
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19080525636672974, train_loss: 0.1341812163591385
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19087815284729004, train_loss: 0.13286614418029785
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19116273522377014, train_loss: 0.12673640251159668
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7595570683479309, train_loss: 0.7675009965896606
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5192868709564209, train_loss: 0.4350830912590027
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5178720951080322, train_loss: 0.38969191908836365
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5189638733863831, train_loss: 0.3938673436641693
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5204859375953674, train_loss: 0.38182806968688965
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7067211270332336, train_loss: 0.7352700233459473
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6063477396965027, train_loss: 0.5004746317863464
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6070963144302368, train_loss: 0.478800505399704
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.60801762342453, train_loss: 0.4734257161617279
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6090676188468933, train_loss: 0.4635244607925415
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7873176336288452, train_loss: 0.7242621183395386
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5738059282302856, train_loss: 0.44057807326316833
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5335208773612976, train_loss: 0.36453744769096375
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5281713008880615, train_loss: 0.32694360613822937
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5284762382507324, train_loss: 0.3202889859676361
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7713513374328613, train_loss: 0.7390468120574951
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6007586121559143, train_loss: 0.49143296480178833
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5721059441566467, train_loss: 0.4343335032463074
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5694225430488586, train_loss: 0.37562164664268494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5706988573074341, train_loss: 0.37038999795913696
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4982137382030487, train_loss: 0.48658761382102966
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.2122405618429184, train_loss: 0.12466348707675934
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.2131950706243515, train_loss: 0.11518068611621857
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.21328039467334747, train_loss: 0.10933760553598404
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.21367147564888, train_loss: 0.10580074042081833
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.40696972608566284, train_loss: 0.49090680480003357
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20395460724830627, train_loss: 0.15826547145843506
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2045336365699768, train_loss: 0.15300410985946655
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2052067369222641, train_loss: 0.15424522757530212
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2054355889558792, train_loss: 0.14509890973567963
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6520959734916687, train_loss: 0.6730002164840698
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5715718865394592, train_loss: 0.48352545499801636
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5731209516525269, train_loss: 0.4649016261100769
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5746622681617737, train_loss: 0.44937676191329956
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5765633583068848, train_loss: 0.4432881772518158
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6797209978103638, train_loss: 0.693092942237854
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5933331251144409, train_loss: 0.4975987374782562
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5937395691871643, train_loss: 0.47858166694641113
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5942847728729248, train_loss: 0.47519955039024353
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5946725010871887, train_loss: 0.4683426320552826
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7197058796882629, train_loss: 0.7488473653793335
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6135063767433167, train_loss: 0.48278743028640747
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.6140789985656738, train_loss: 0.4503648281097412
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.6152660250663757, train_loss: 0.44528794288635254
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.6164290308952332, train_loss: 0.44339486956596375
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6332765221595764, train_loss: 0.6959592700004578
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5789200067520142, train_loss: 0.5351383686065674
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5799063444137573, train_loss: 0.5284429788589478
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.580909013748169, train_loss: 0.507098376750946
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5817234516143799, train_loss: 0.5025125741958618
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6176709532737732, train_loss: 0.6706442832946777
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.24709482491016388, train_loss: 0.14836490154266357
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.24649401009082794, train_loss: 0.12145864963531494
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.24686886370182037, train_loss: 0.1227407231926918
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.24699193239212036, train_loss: 0.11529918760061264
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6066244840621948, train_loss: 0.7932560443878174
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2225610762834549, train_loss: 0.15384376049041748
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22243867814540863, train_loss: 0.15302927792072296
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22229959070682526, train_loss: 0.14388668537139893
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22242003679275513, train_loss: 0.145477756857872
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.706947922706604, train_loss: 0.6973284482955933
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5518378615379333, train_loss: 0.4318121373653412
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5498844981193542, train_loss: 0.38787445425987244
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5507302284240723, train_loss: 0.37719783186912537
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5517950057983398, train_loss: 0.3697670102119446
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6804198026657104, train_loss: 0.6726071238517761
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5990142226219177, train_loss: 0.4642091989517212
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5994325280189514, train_loss: 0.4341251254081726
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5997198224067688, train_loss: 0.44185373187065125
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6004891395568848, train_loss: 0.4380410313606262
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9540344476699829, train_loss: 0.9651035070419312
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6100198030471802, train_loss: 0.5014140009880066
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.550104558467865, train_loss: 0.39061588048934937
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5425563454627991, train_loss: 0.3375212550163269
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5424589514732361, train_loss: 0.31298622488975525
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6840850710868835, train_loss: 0.7303177714347839
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.523318350315094, train_loss: 0.4840894639492035
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5230181217193604, train_loss: 0.4612390398979187
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5233436226844788, train_loss: 0.4480162560939789
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5234575271606445, train_loss: 0.4435966908931732
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.170189619064331, train_loss: 1.1892668008804321
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.21629279851913452, train_loss: 0.12018759548664093
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20851510763168335, train_loss: 0.09111901372671127
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.20815409719944, train_loss: 0.08248221129179001
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20837578177452087, train_loss: 0.08631280064582825
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3752109110355377, train_loss: 0.4433750808238983
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.17879565060138702, train_loss: 0.16531848907470703
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.17895065248012543, train_loss: 0.15453150868415833
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1790890246629715, train_loss: 0.15038348734378815
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.17927782237529755, train_loss: 0.15090952813625336
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.742303192615509, train_loss: 0.7369720339775085
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5183446407318115, train_loss: 0.4509255886077881
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.511180579662323, train_loss: 0.38351401686668396
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5117668509483337, train_loss: 0.3861504793167114
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5125072002410889, train_loss: 0.38028210401535034
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6759156584739685, train_loss: 0.6700178980827332
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5980643630027771, train_loss: 0.4817922115325928
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5954977869987488, train_loss: 0.4314976930618286
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5960063338279724, train_loss: 0.42058825492858887
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5968034863471985, train_loss: 0.42646893858909607
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8944603800773621, train_loss: 0.866100013256073
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6179571151733398, train_loss: 0.502083420753479
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5601810216903687, train_loss: 0.40435898303985596
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5480018258094788, train_loss: 0.34444889426231384
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5490888953208923, train_loss: 0.3386707305908203
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6708475351333618, train_loss: 0.6760494112968445
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5334821343421936, train_loss: 0.4692082107067108
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5267196893692017, train_loss: 0.4146680235862732
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5271065831184387, train_loss: 0.4010412096977234
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5275875926017761, train_loss: 0.3907860517501831
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.584221601486206, train_loss: 0.6452971696853638
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18886151909828186, train_loss: 0.1260869801044464
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18727031350135803, train_loss: 0.10741326957941055
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18736742436885834, train_loss: 0.10870368778705597
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1870959997177124, train_loss: 0.10672099888324738
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6951484084129333, train_loss: 0.747255265712738
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19124075770378113, train_loss: 0.1634920835494995
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19194355607032776, train_loss: 0.14682886004447937
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.19189222157001495, train_loss: 0.14145325124263763
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19225341081619263, train_loss: 0.14110080897808075
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8610073924064636, train_loss: 0.9404323101043701
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5529045462608337, train_loss: 0.4814773201942444
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5235229730606079, train_loss: 0.38003915548324585
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.525084376335144, train_loss: 0.36927056312561035
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5259931087493896, train_loss: 0.36755236983299255
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8061942458152771, train_loss: 0.7655830383300781
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6338818073272705, train_loss: 0.5045642852783203
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.604179859161377, train_loss: 0.4270176887512207
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6032527089118958, train_loss: 0.41176795959472656
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6029772758483887, train_loss: 0.4036938548088074
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7581480741500854, train_loss: 0.8339471817016602
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5601272583007812, train_loss: 0.46837759017944336
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5484647154808044, train_loss: 0.39557600021362305
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.548774003982544, train_loss: 0.3809100091457367
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5491486191749573, train_loss: 0.38040632009506226
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7857972979545593, train_loss: 0.732271671295166
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5873429775238037, train_loss: 0.48456668853759766
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5802226662635803, train_loss: 0.4465816020965576
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5799288749694824, train_loss: 0.44237956404685974
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5801666378974915, train_loss: 0.4414566457271576
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7098923921585083, train_loss: 0.8177700042724609
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20603184401988983, train_loss: 0.14190924167633057
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20284037292003632, train_loss: 0.11532918363809586
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2027568519115448, train_loss: 0.11226785182952881
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.20302481949329376, train_loss: 0.10947263240814209
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5932562351226807, train_loss: 0.73941570520401
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.19640323519706726, train_loss: 0.1699858158826828
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.19427792727947235, train_loss: 0.153390035033226
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1937507539987564, train_loss: 0.14656643569469452
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.19359835982322693, train_loss: 0.14425484836101532
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7028133869171143, train_loss: 0.7187365293502808
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.53834068775177, train_loss: 0.4361778497695923
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5349956154823303, train_loss: 0.3878439664840698
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5355936288833618, train_loss: 0.3953513503074646
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5363354682922363, train_loss: 0.3809189796447754
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.767737627029419, train_loss: 0.7668401598930359
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5976256132125854, train_loss: 0.4844812750816345
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5911771655082703, train_loss: 0.4385978579521179
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5914132595062256, train_loss: 0.43347597122192383
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.591621994972229, train_loss: 0.4245782494544983
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6561794877052307, train_loss: 0.6661815643310547
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5186381340026855, train_loss: 0.44090914726257324
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5118829607963562, train_loss: 0.37377581000328064
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5126196146011353, train_loss: 0.3717864155769348
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5134336948394775, train_loss: 0.3604830205440521
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6664592623710632, train_loss: 0.6503622531890869
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5639038681983948, train_loss: 0.4998430907726288
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.556099534034729, train_loss: 0.4429451823234558
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.557150661945343, train_loss: 0.43490859866142273
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5579407215118408, train_loss: 0.4293782711029053
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4759999215602875, train_loss: 0.5349017381668091
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20459215342998505, train_loss: 0.1339949369430542
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19793972373008728, train_loss: 0.10945866256952286
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19782176613807678, train_loss: 0.10273696482181549
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1974460929632187, train_loss: 0.10090462118387222
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6051963567733765, train_loss: 0.6236506104469299
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.21653106808662415, train_loss: 0.1615094244480133
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20367340743541718, train_loss: 0.1262488216161728
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20361270010471344, train_loss: 0.12053747475147247
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20340074598789215, train_loss: 0.1186056137084961
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7467284202575684, train_loss: 0.803929328918457
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5369084477424622, train_loss: 0.4479837417602539
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5328844785690308, train_loss: 0.3910354971885681
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5338051915168762, train_loss: 0.3867703378200531
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5351834893226624, train_loss: 0.3786483705043793
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7075110673904419, train_loss: 0.703528642654419
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6052770614624023, train_loss: 0.49064716696739197
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5965039134025574, train_loss: 0.42779338359832764
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.59661865234375, train_loss: 0.4158472716808319
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5965344905853271, train_loss: 0.4185751676559448
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7531430125236511, train_loss: 0.730148196220398
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5680645108222961, train_loss: 0.45562228560447693
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5505334138870239, train_loss: 0.38532066345214844
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5504375696182251, train_loss: 0.3658076524734497
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5506818890571594, train_loss: 0.3555210530757904
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.888656497001648, train_loss: 0.9095491170883179
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6173748970031738, train_loss: 0.551385760307312
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5697520971298218, train_loss: 0.45418447256088257
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5599583387374878, train_loss: 0.422504186630249
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5592777132987976, train_loss: 0.40997350215911865
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8368732929229736, train_loss: 0.8591963052749634
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.19530701637268066, train_loss: 0.12787948548793793
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19566020369529724, train_loss: 0.11376035213470459
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1957509070634842, train_loss: 0.10425541549921036
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19634878635406494, train_loss: 0.10154854506254196
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9199750423431396, train_loss: 1.0715649127960205
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20243209600448608, train_loss: 0.1490580290555954
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20193298161029816, train_loss: 0.13973349332809448
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20188364386558533, train_loss: 0.1341748684644699
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20198895037174225, train_loss: 0.131840780377388
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0029851198196411, train_loss: 1.0262168645858765
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5560930967330933, train_loss: 0.4953839182853699
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5247206687927246, train_loss: 0.3979436159133911
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5249385833740234, train_loss: 0.3756544589996338
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5253352522850037, train_loss: 0.3683475852012634
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8821901082992554, train_loss: 0.9239321947097778
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6586382985115051, train_loss: 0.5400079488754272
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6168419718742371, train_loss: 0.43521448969841003
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6094802618026733, train_loss: 0.39198192954063416
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6096622943878174, train_loss: 0.38642507791519165
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.716415524482727, train_loss: 0.7373270988464355
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5590195655822754, train_loss: 0.45258092880249023
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5536072850227356, train_loss: 0.38272953033447266
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5541787147521973, train_loss: 0.39628419280052185
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5551561117172241, train_loss: 0.3780066967010498
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7417908906936646, train_loss: 0.8239614367485046
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5291445851325989, train_loss: 0.5185461640357971
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5116873979568481, train_loss: 0.45244789123535156
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5124862194061279, train_loss: 0.43661051988601685
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5125073790550232, train_loss: 0.4341304898262024
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44307950139045715, train_loss: 0.5342500805854797
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.18970291316509247, train_loss: 0.1293054223060608
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19001848995685577, train_loss: 0.11887451261281967
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19067740440368652, train_loss: 0.11200372129678726
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19143298268318176, train_loss: 0.11182906478643417
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4717083275318146, train_loss: 0.5362014770507812
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2304123342037201, train_loss: 0.15797297656536102
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2301659882068634, train_loss: 0.14356522262096405
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22986018657684326, train_loss: 0.1361846923828125
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.2297784835100174, train_loss: 0.13714678585529327
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7297149300575256, train_loss: 0.7706853151321411
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.54410719871521, train_loss: 0.449664831161499
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.535520076751709, train_loss: 0.38273918628692627
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5357092618942261, train_loss: 0.3703891634941101
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5362579226493835, train_loss: 0.36005347967147827
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0839145183563232, train_loss: 1.0959440469741821
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.7494094967842102, train_loss: 0.5937111377716064
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.6552268266677856, train_loss: 0.45897817611694336
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.6274910569190979, train_loss: 0.40633293986320496
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.6264173984527588, train_loss: 0.38552016019821167
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7498486042022705, train_loss: 0.787387490272522
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5358301401138306, train_loss: 0.4760604798793793
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5041025280952454, train_loss: 0.3876081705093384
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5028777122497559, train_loss: 0.35658225417137146
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5034027695655823, train_loss: 0.3613681197166443
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9040358066558838, train_loss: 0.8964328169822693
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.597867488861084, train_loss: 0.5353817343711853
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5579580068588257, train_loss: 0.45154833793640137
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5572738647460938, train_loss: 0.43020686507225037
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5571125745773315, train_loss: 0.4276300370693207
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.154497504234314, train_loss: 1.2574964761734009
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20327216386795044, train_loss: 0.13333828747272491
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.20092079043388367, train_loss: 0.10732372105121613
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.2008114904165268, train_loss: 0.10620919615030289
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.2008478045463562, train_loss: 0.10325869172811508
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.039130687713623, train_loss: 1.1685233116149902
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20519481599330902, train_loss: 0.14980502426624298
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.20331205427646637, train_loss: 0.11295130103826523
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.20399662852287292, train_loss: 0.11238165944814682
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20494800806045532, train_loss: 0.11075033992528915
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7964007258415222, train_loss: 0.8680171370506287
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5221484303474426, train_loss: 0.4502177834510803
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5161606073379517, train_loss: 0.3820596933364868
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5169179439544678, train_loss: 0.3923735022544861
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5178591012954712, train_loss: 0.37145981192588806
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7641814947128296, train_loss: 0.8023523688316345
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6032881736755371, train_loss: 0.5037898421287537
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5912142395973206, train_loss: 0.4371241331100464
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5907837152481079, train_loss: 0.42499440908432007
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.590969979763031, train_loss: 0.4233870208263397
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7957063317298889, train_loss: 0.7766530513763428
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5646739602088928, train_loss: 0.47551393508911133
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5347461104393005, train_loss: 0.3916686475276947
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5333970189094543, train_loss: 0.3644627034664154
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5337139964103699, train_loss: 0.3523896634578705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.622984766960144, train_loss: 0.6174801588058472
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5718649625778198, train_loss: 0.4690133333206177
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5688486695289612, train_loss: 0.4368532598018646
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.568747878074646, train_loss: 0.44556427001953125
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5690702795982361, train_loss: 0.42121025919914246
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4993106424808502, train_loss: 0.5146343111991882
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.20406022667884827, train_loss: 0.14122717082500458
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.19947214424610138, train_loss: 0.11106709390878677
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.19954504072666168, train_loss: 0.11173076927661896
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.19927947223186493, train_loss: 0.10493359714746475
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5231477618217468, train_loss: 0.598044216632843
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.2073708325624466, train_loss: 0.1652621179819107
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2045455127954483, train_loss: 0.13718442618846893
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2041430026292801, train_loss: 0.13106220960617065
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20393580198287964, train_loss: 0.12922537326812744
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7220418453216553, train_loss: 0.7557291984558105
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5320302248001099, train_loss: 0.4513375759124756
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5241767168045044, train_loss: 0.38656505942344666
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5246658325195312, train_loss: 0.38324791193008423
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5254102945327759, train_loss: 0.3740987181663513
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7356997132301331, train_loss: 0.7284454107284546
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5854635834693909, train_loss: 0.4874454438686371
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5856007933616638, train_loss: 0.44867509603500366
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5865437984466553, train_loss: 0.4499776363372803
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5875126719474792, train_loss: 0.4314258098602295
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7022317051887512, train_loss: 0.7068425416946411
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5401452779769897, train_loss: 0.45848745107650757
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5201259851455688, train_loss: 0.3945351839065552
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5192275047302246, train_loss: 0.36163586378097534
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5197623372077942, train_loss: 0.3512697219848633
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6804917454719543, train_loss: 0.7142772674560547
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5304868817329407, train_loss: 0.48401302099227905
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.528121292591095, train_loss: 0.46642178297042847
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5285500884056091, train_loss: 0.4499998092651367
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5291076898574829, train_loss: 0.44731688499450684
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7692330479621887, train_loss: 0.8226674199104309
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1893787384033203, train_loss: 0.1351315826177597
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18837577104568481, train_loss: 0.12365006655454636
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18811604380607605, train_loss: 0.11640738695859909
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18813146650791168, train_loss: 0.11378432810306549
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5265595316886902, train_loss: 0.5656242370605469
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.22748377919197083, train_loss: 0.16466550529003143
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.22428637742996216, train_loss: 0.1377989500761032
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.22369694709777832, train_loss: 0.13993065059185028
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.22328758239746094, train_loss: 0.1338655948638916
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7804948687553406, train_loss: 0.7683496475219727
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5458393692970276, train_loss: 0.4409146308898926
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5416316986083984, train_loss: 0.39479565620422363
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5419014692306519, train_loss: 0.38531264662742615
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5425750017166138, train_loss: 0.37755507230758667
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8242201209068298, train_loss: 0.7949585914611816
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6183323264122009, train_loss: 0.5105717182159424
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5938352942466736, train_loss: 0.43903571367263794
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5925538539886475, train_loss: 0.43336591124534607
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5926304459571838, train_loss: 0.41749686002731323
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7547532916069031, train_loss: 0.7835711240768433
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5625113248825073, train_loss: 0.46823081374168396
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.5496082901954651, train_loss: 0.38487911224365234
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.5500023365020752, train_loss: 0.3852672278881073
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.5505678653717041, train_loss: 0.3692736029624939
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6033772826194763, train_loss: 0.6590340733528137
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5424715876579285, train_loss: 0.49851930141448975
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.5428229570388794, train_loss: 0.47252339124679565
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.5433254241943359, train_loss: 0.463113397359848
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.5442439317703247, train_loss: 0.47327181696891785
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6084363460540771, train_loss: 0.6640678644180298
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1973239928483963, train_loss: 0.13406811654567719
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.18812747299671173, train_loss: 0.10869231075048447
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.18730930984020233, train_loss: 0.10125287622213364
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.18658988177776337, train_loss: 0.09939803928136826
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.999000608921051, train_loss: 1.0999037027359009
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.20335356891155243, train_loss: 0.15381281077861786
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.2041631042957306, train_loss: 0.14126652479171753
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.2046075463294983, train_loss: 0.13693885505199432
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.20522540807724, train_loss: 0.1370473951101303
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.  0%|          | 0/15 [00:00<?, ?it/s] 40%|████      | 6/15 [00:00<00:00, 58.68it/s] 80%|████████  | 12/15 [00:00<00:00, 58.11it/s]100%|██████████| 15/15 [00:00<00:00, 57.78it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 39.93it/s] 53%|█████▎    | 8/15 [00:00<00:00, 39.79it/s] 80%|████████  | 12/15 [00:00<00:00, 39.53it/s]100%|██████████| 15/15 [00:00<00:00, 39.36it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 39.30it/s] 53%|█████▎    | 8/15 [00:00<00:00, 36.61it/s] 80%|████████  | 12/15 [00:00<00:00, 35.23it/s]100%|██████████| 15/15 [00:00<00:00, 36.09it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 38.81it/s] 60%|██████    | 9/15 [00:00<00:00, 40.44it/s] 93%|█████████▎| 14/15 [00:00<00:00, 40.67it/s]100%|██████████| 15/15 [00:00<00:00, 40.49it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 33%|███▎      | 5/15 [00:00<00:00, 43.48it/s] 67%|██████▋   | 10/15 [00:00<00:00, 40.46it/s]100%|██████████| 15/15 [00:00<00:00, 39.18it/s]100%|██████████| 15/15 [00:00<00:00, 39.75it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 33%|███▎      | 5/15 [00:00<00:00, 40.55it/s] 67%|██████▋   | 10/15 [00:00<00:00, 39.37it/s] 93%|█████████▎| 14/15 [00:00<00:00, 38.77it/s]100%|██████████| 15/15 [00:00<00:00, 38.92it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 39.00it/s] 53%|█████▎    | 8/15 [00:00<00:00, 38.46it/s] 80%|████████  | 12/15 [00:00<00:00, 38.28it/s]100%|██████████| 15/15 [00:00<00:00, 38.20it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 33%|███▎      | 5/15 [00:00<00:00, 40.52it/s] 67%|██████▋   | 10/15 [00:00<00:00, 39.20it/s] 93%|█████████▎| 14/15 [00:00<00:00, 38.62it/s]100%|██████████| 15/15 [00:00<00:00, 38.79it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 34.49it/s] 53%|█████▎    | 8/15 [00:00<00:00, 34.70it/s] 80%|████████  | 12/15 [00:00<00:00, 34.80it/s]100%|██████████| 15/15 [00:00<00:00, 34.74it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 27%|██▋       | 4/15 [00:00<00:00, 36.64it/s] 53%|█████▎    | 8/15 [00:00<00:00, 35.92it/s] 80%|████████  | 12/15 [00:00<00:00, 35.52it/s]100%|██████████| 15/15 [00:00<00:00, 35.47it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
  0%|          | 0/15 [00:00<?, ?it/s] 33%|███▎      | 5/15 [00:00<00:00, 40.06it/s] 67%|██████▋   | 10/15 [00:00<00:00, 38.84it/s] 93%|█████████▎| 14/15 [00:00<00:00, 38.13it/s]100%|██████████| 15/15 [00:00<00:00, 38.33it/s]
Computing distillation loss for ensemble with feature 1
Computing distillation loss for ensemble with feature 2
Computing distillation loss for ensemble with feature 3
Computing distillation loss for ensemble with feature 4
Computing distillation loss for ensemble with feature 5
Computing distillation loss for ensemble with feature 6
Computing distillation loss for ensemble with feature 7
Computing distillation loss for ensemble with feature 8
Computing distillation loss for ensemble with feature 9
Computing distillation loss for ensemble with feature 10
Computing distillation loss for ensemble with feature 11
Computing distillation loss for ensemble with feature 12
Computing distillation loss for ensemble with feature 13
Computing distillation loss for ensemble with feature 14
Computing distillation loss for ensemble with feature 15
