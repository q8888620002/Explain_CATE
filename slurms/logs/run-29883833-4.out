python run_clinical_experiments.py -d accord -t 5 -n 10 -l XLearner -device cuda
True
shuffle dataset:  True
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6542437672615051, train_loss: 0.6608250141143799
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4499305188655853, train_loss: 0.3681623935699463
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3908478617668152, train_loss: 0.2745858430862427
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3765338063240051, train_loss: 0.225920170545578
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.37663033604621887, train_loss: 0.20414617657661438
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0025076866149902, train_loss: 1.0088732242584229
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5508091449737549, train_loss: 0.5153802633285522
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.353657066822052, train_loss: 0.31437674164772034
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.29228898882865906, train_loss: 0.23416000604629517
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.269483357667923, train_loss: 0.18872228264808655
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.26151707768440247, train_loss: 0.15883395075798035
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6469092965126038, train_loss: 0.6325473189353943
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3965734541416168, train_loss: 0.3119630515575409
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34060150384902954, train_loss: 0.212582066655159
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32934272289276123, train_loss: 0.163068950176239
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32946088910102844, train_loss: 0.14492064714431763
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6642327904701233, train_loss: 0.6564587354660034
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4205048084259033, train_loss: 0.36703407764434814
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36706995964050293, train_loss: 0.26614975929260254
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35508179664611816, train_loss: 0.21548207104206085
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3559567630290985, train_loss: 0.20466065406799316
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9129215478897095, train_loss: 0.9778659343719482
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16384486854076385, train_loss: 0.08201585710048676
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.154547780752182, train_loss: 0.058102719485759735
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15464860200881958, train_loss: 0.05328045040369034
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1541057527065277, train_loss: 0.05274025350809097
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5354282259941101, train_loss: 0.6180253624916077
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13314016163349152, train_loss: 0.07618026435375214
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13135170936584473, train_loss: 0.05076644569635391
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13178279995918274, train_loss: 0.05075075849890709
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13242487609386444, train_loss: 0.04961898922920227
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   0%|          | 6/26001 [00:00<36:08, 11.99it/s]Shapley Value Sampling attribution:   1%|          | 227/26001 [00:01<01:37, 264.59it/s]Shapley Value Sampling attribution:   2%|▏         | 466/26001 [00:01<01:10, 361.33it/s]Shapley Value Sampling attribution:   3%|▎         | 705/26001 [00:02<01:02, 406.78it/s]Shapley Value Sampling attribution:   4%|▎         | 944/26001 [00:02<00:57, 432.09it/s]Shapley Value Sampling attribution:   5%|▍         | 1184/26001 [00:03<00:55, 447.86it/s]Shapley Value Sampling attribution:   6%|▌         | 1442/26001 [00:03<00:52, 470.05it/s]Shapley Value Sampling attribution:   7%|▋         | 1723/26001 [00:04<00:48, 498.98it/s]Shapley Value Sampling attribution:   8%|▊         | 2017/26001 [00:04<00:45, 526.58it/s]Shapley Value Sampling attribution:   9%|▉         | 2362/26001 [00:05<00:40, 576.85it/s]Shapley Value Sampling attribution:  11%|█         | 2782/26001 [00:05<00:35, 657.04it/s]Shapley Value Sampling attribution:  12%|█▏        | 3247/26001 [00:06<00:30, 739.85it/s]Shapley Value Sampling attribution:  14%|█▍        | 3734/26001 [00:06<00:27, 810.45it/s]Shapley Value Sampling attribution:  16%|█▌        | 4220/26001 [00:07<00:25, 859.11it/s]Shapley Value Sampling attribution:  18%|█▊        | 4707/26001 [00:07<00:23, 893.22it/s]Shapley Value Sampling attribution:  20%|█▉        | 5193/26001 [00:08<00:22, 916.85it/s]Shapley Value Sampling attribution:  22%|██▏       | 5681/26001 [00:08<00:21, 934.61it/s]Shapley Value Sampling attribution:  24%|██▎       | 6170/26001 [00:09<00:20, 947.37it/s]Shapley Value Sampling attribution:  26%|██▌       | 6659/26001 [00:09<00:20, 956.28it/s]Shapley Value Sampling attribution:  27%|██▋       | 7144/26001 [00:10<00:19, 959.89it/s]Shapley Value Sampling attribution:  29%|██▉       | 7632/26001 [00:10<00:19, 964.19it/s]Shapley Value Sampling attribution:  31%|███       | 8121/26001 [00:11<00:18, 968.26it/s]Shapley Value Sampling attribution:  33%|███▎      | 8609/26001 [00:11<00:17, 970.48it/s]Shapley Value Sampling attribution:  35%|███▍      | 9095/26001 [00:12<00:17, 957.21it/s]Shapley Value Sampling attribution:  37%|███▋      | 9574/26001 [00:12<00:19, 828.03it/s]Shapley Value Sampling attribution:  38%|███▊      | 10004/26001 [00:13<00:19, 830.93it/s]Shapley Value Sampling attribution:  40%|████      | 10493/26001 [00:13<00:17, 871.19it/s]Shapley Value Sampling attribution:  42%|████▏     | 10980/26001 [00:14<00:16, 900.15it/s]Shapley Value Sampling attribution:  44%|████▍     | 11468/26001 [00:14<00:15, 921.55it/s]Shapley Value Sampling attribution:  46%|████▌     | 11956/26001 [00:15<00:14, 937.30it/s]Shapley Value Sampling attribution:  48%|████▊     | 12444/26001 [00:15<00:14, 948.41it/s]Shapley Value Sampling attribution:  50%|████▉     | 12933/26001 [00:16<00:13, 956.74it/s]Shapley Value Sampling attribution:  52%|█████▏    | 13422/26001 [00:16<00:13, 962.70it/s]Shapley Value Sampling attribution:  54%|█████▎    | 13912/26001 [00:17<00:12, 967.55it/s]Shapley Value Sampling attribution:  55%|█████▌    | 14401/26001 [00:17<00:11, 970.65it/s]Shapley Value Sampling attribution:  57%|█████▋    | 14891/26001 [00:18<00:11, 973.27it/s]Shapley Value Sampling attribution:  59%|█████▉    | 15379/26001 [00:18<00:10, 968.21it/s]Shapley Value Sampling attribution:  61%|██████    | 15864/26001 [00:19<00:10, 950.76it/s]Shapley Value Sampling attribution:  63%|██████▎   | 16340/26001 [00:19<00:10, 938.87it/s]Shapley Value Sampling attribution:  65%|██████▍   | 16810/26001 [00:20<00:09, 924.93it/s]Shapley Value Sampling attribution:  66%|██████▋   | 17273/26001 [00:20<00:09, 921.34it/s]Shapley Value Sampling attribution:  68%|██████▊   | 17734/26001 [00:21<00:08, 918.81it/s]Shapley Value Sampling attribution:  70%|██████▉   | 18194/26001 [00:21<00:08, 917.64it/s]Shapley Value Sampling attribution:  72%|███████▏  | 18653/26001 [00:22<00:09, 801.67it/s]Shapley Value Sampling attribution:  73%|███████▎  | 19067/26001 [00:23<00:10, 683.60it/s]Shapley Value Sampling attribution:  75%|███████▍  | 19431/26001 [00:24<00:10, 612.37it/s]Shapley Value Sampling attribution:  76%|███████▌  | 19757/26001 [00:24<00:10, 570.52it/s]Shapley Value Sampling attribution:  77%|███████▋  | 20056/26001 [00:25<00:10, 542.41it/s]Shapley Value Sampling attribution:  78%|███████▊  | 20336/26001 [00:26<00:10, 523.80it/s]Shapley Value Sampling attribution:  79%|███████▉  | 20603/26001 [00:26<00:10, 507.20it/s]Shapley Value Sampling attribution:  80%|████████  | 20860/26001 [00:27<00:10, 498.01it/s]Shapley Value Sampling attribution:  81%|████████  | 21114/26001 [00:27<00:09, 500.57it/s]Shapley Value Sampling attribution:  82%|████████▏ | 21385/26001 [00:28<00:09, 511.49it/s]Shapley Value Sampling attribution:  83%|████████▎ | 21689/26001 [00:28<00:08, 538.40it/s]Shapley Value Sampling attribution:  85%|████████▍ | 22028/26001 [00:29<00:06, 578.11it/s]Shapley Value Sampling attribution:  86%|████████▋ | 22435/26001 [00:29<00:05, 646.08it/s]Shapley Value Sampling attribution:  88%|████████▊ | 22903/26001 [00:30<00:04, 730.85it/s]Shapley Value Sampling attribution:  90%|████████▉ | 23389/26001 [00:30<00:03, 801.71it/s]Shapley Value Sampling attribution:  92%|█████████▏| 23880/26001 [00:31<00:02, 854.72it/s]Shapley Value Sampling attribution:  94%|█████████▎| 24372/26001 [00:31<00:01, 892.74it/s]Shapley Value Sampling attribution:  96%|█████████▌| 24861/26001 [00:32<00:01, 918.12it/s]Shapley Value Sampling attribution:  97%|█████████▋| 25349/26001 [00:32<00:00, 935.09it/s]Shapley Value Sampling attribution:  99%|█████████▉| 25839/26001 [00:33<00:00, 947.96it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:33<00:00, 776.39it/s]
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 492/26001 [00:00<00:25, 983.09it/s]Shapley Value Sampling attribution:   4%|▍         | 984/26001 [00:01<00:25, 981.21it/s]Shapley Value Sampling attribution:   6%|▌         | 1476/26001 [00:01<00:24, 981.60it/s]Shapley Value Sampling attribution:   8%|▊         | 1967/26001 [00:02<00:24, 981.68it/s]Shapley Value Sampling attribution:   9%|▉         | 2458/26001 [00:02<00:23, 981.28it/s]Shapley Value Sampling attribution:  11%|█▏        | 2949/26001 [00:03<00:23, 981.27it/s]Shapley Value Sampling attribution:  13%|█▎        | 3440/26001 [00:03<00:26, 841.83it/s]Shapley Value Sampling attribution:  15%|█▍        | 3877/26001 [00:04<00:26, 822.41it/s]Shapley Value Sampling attribution:  17%|█▋        | 4367/26001 [00:04<00:24, 866.69it/s]Shapley Value Sampling attribution:  19%|█▊        | 4858/26001 [00:05<00:23, 899.38it/s]Shapley Value Sampling attribution:  21%|██        | 5348/26001 [00:05<00:22, 922.79it/s]Shapley Value Sampling attribution:  22%|██▏       | 5838/26001 [00:06<00:21, 939.05it/s]Shapley Value Sampling attribution:  24%|██▍       | 6328/26001 [00:06<00:20, 951.06it/s]Shapley Value Sampling attribution:  26%|██▌       | 6820/26001 [00:07<00:19, 960.48it/s]Shapley Value Sampling attribution:  28%|██▊       | 7312/26001 [00:07<00:19, 967.31it/s]Shapley Value Sampling attribution:  30%|███       | 7805/26001 [00:08<00:18, 972.37it/s]Shapley Value Sampling attribution:  32%|███▏      | 8298/26001 [00:08<00:18, 976.07it/s]Shapley Value Sampling attribution:  34%|███▍      | 8790/26001 [00:09<00:17, 977.91it/s]Shapley Value Sampling attribution:  36%|███▌      | 9283/26001 [00:09<00:17, 980.12it/s]Shapley Value Sampling attribution:  38%|███▊      | 9774/26001 [00:10<00:16, 970.10it/s]Shapley Value Sampling attribution:  39%|███▉      | 10260/26001 [00:10<00:16, 956.28it/s]Shapley Value Sampling attribution:  41%|████▏     | 10739/26001 [00:11<00:16, 947.37it/s]Shapley Value Sampling attribution:  43%|████▎     | 11214/26001 [00:11<00:15, 939.94it/s]Shapley Value Sampling attribution:  45%|████▍     | 11685/26001 [00:12<00:15, 936.06it/s]Shapley Value Sampling attribution:  47%|████▋     | 12154/26001 [00:12<00:14, 933.44it/s]Shapley Value Sampling attribution:  49%|████▊     | 12621/26001 [00:13<00:15, 872.98it/s]Shapley Value Sampling attribution:  50%|█████     | 13062/26001 [00:14<00:16, 769.12it/s]Shapley Value Sampling attribution:  52%|█████▏    | 13460/26001 [00:14<00:18, 694.99it/s]Shapley Value Sampling attribution:  53%|█████▎    | 13821/26001 [00:15<00:19, 628.16it/s]Shapley Value Sampling attribution:  54%|█████▍    | 14148/26001 [00:16<00:20, 588.06it/s]Shapley Value Sampling attribution:  56%|█████▌    | 14451/26001 [00:17<00:20, 560.61it/s]Shapley Value Sampling attribution:  57%|█████▋    | 14737/26001 [00:17<00:20, 541.68it/s]Shapley Value Sampling attribution:  58%|█████▊    | 15011/26001 [00:18<00:20, 528.28it/s]Shapley Value Sampling attribution:  59%|█████▉    | 15277/26001 [00:18<00:20, 524.65it/s]Shapley Value Sampling attribution:  60%|█████▉    | 15553/26001 [00:19<00:19, 531.59it/s]Shapley Value Sampling attribution:  61%|██████    | 15840/26001 [00:19<00:18, 543.13it/s]Shapley Value Sampling attribution:  62%|██████▏   | 16158/26001 [00:20<00:17, 569.20it/s]Shapley Value Sampling attribution:  64%|██████▍   | 16591/26001 [00:20<00:14, 654.84it/s]Shapley Value Sampling attribution:  66%|██████▌   | 17067/26001 [00:21<00:12, 741.24it/s]Shapley Value Sampling attribution:  67%|██████▋   | 17543/26001 [00:21<00:10, 803.23it/s]Shapley Value Sampling attribution:  69%|██████▉   | 18037/26001 [00:22<00:09, 857.58it/s]Shapley Value Sampling attribution:  71%|███████▏  | 18530/26001 [00:22<00:08, 895.57it/s]Shapley Value Sampling attribution:  73%|███████▎  | 19015/26001 [00:23<00:07, 917.69it/s]Shapley Value Sampling attribution:  75%|███████▌  | 19509/26001 [00:23<00:06, 938.27it/s]Shapley Value Sampling attribution:  77%|███████▋  | 20004/26001 [00:24<00:06, 953.25it/s]Shapley Value Sampling attribution:  79%|███████▉  | 20497/26001 [00:24<00:05, 962.95it/s]Shapley Value Sampling attribution:  81%|████████  | 20992/26001 [00:25<00:05, 970.58it/s]Shapley Value Sampling attribution:  83%|████████▎ | 21478/26001 [00:25<00:04, 961.34it/s]Shapley Value Sampling attribution:  85%|████████▍ | 21972/26001 [00:26<00:04, 969.06it/s]Shapley Value Sampling attribution:  86%|████████▋ | 22465/26001 [00:26<00:03, 973.75it/s]Shapley Value Sampling attribution:  88%|████████▊ | 22959/26001 [00:27<00:03, 977.92it/s]Shapley Value Sampling attribution:  90%|█████████ | 23453/26001 [00:27<00:02, 980.75it/s]Shapley Value Sampling attribution:  92%|█████████▏| 23948/26001 [00:28<00:02, 982.99it/s]Shapley Value Sampling attribution:  94%|█████████▍| 24442/26001 [00:28<00:01, 984.28it/s]Shapley Value Sampling attribution:  96%|█████████▌| 24936/26001 [00:29<00:01, 985.16it/s]Shapley Value Sampling attribution:  98%|█████████▊| 25429/26001 [00:29<00:00, 984.95it/s]Shapley Value Sampling attribution: 100%|█████████▉| 25924/26001 [00:30<00:00, 985.88it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:30<00:00, 858.87it/s]
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:11<04:56, 11.85s/it]importance j:   8%|▊         | 2/26 [00:28<05:48, 14.53s/it]importance j:  12%|█▏        | 3/26 [00:41<05:24, 14.11s/it]importance j:  15%|█▌        | 4/26 [00:57<05:27, 14.87s/it]importance j:  19%|█▉        | 5/26 [01:13<05:17, 15.10s/it]importance j:  23%|██▎       | 6/26 [01:26<04:45, 14.28s/it]importance j:  27%|██▋       | 7/26 [01:43<04:53, 15.45s/it]importance j:  31%|███       | 8/26 [01:58<04:34, 15.26s/it]importance j:  35%|███▍      | 9/26 [02:13<04:17, 15.13s/it]importance j:  38%|███▊      | 10/26 [02:30<04:08, 15.54s/it]importance j:  42%|████▏     | 11/26 [02:42<03:37, 14.50s/it]importance j:  46%|████▌     | 12/26 [02:59<03:35, 15.37s/it]importance j:  50%|█████     | 13/26 [03:13<03:15, 15.01s/it]importance j:  54%|█████▍    | 14/26 [03:28<02:59, 14.94s/it]importance j:  58%|█████▊    | 15/26 [03:45<02:51, 15.55s/it]importance j:  62%|██████▏   | 16/26 [03:57<02:25, 14.59s/it]importance j:  65%|██████▌   | 17/26 [04:13<02:14, 14.92s/it]importance j:  69%|██████▉   | 18/26 [04:28<01:58, 14.86s/it]importance j:  73%|███████▎  | 19/26 [04:44<01:46, 15.27s/it]importance j:  77%|███████▋  | 20/26 [05:01<01:33, 15.66s/it]importance j:  81%|████████  | 21/26 [05:12<01:12, 14.46s/it]importance j:  85%|████████▍ | 22/26 [05:30<01:01, 15.50s/it]importance j:  88%|████████▊ | 23/26 [05:42<00:43, 14.34s/it]importance j:  92%|█████████▏| 24/26 [05:58<00:29, 14.85s/it]importance j:  96%|█████████▌| 25/26 [06:14<00:15, 15.12s/it]importance j: 100%|██████████| 26/26 [06:26<00:00, 14.31s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9432767629623413, train_loss: 0.9464316964149475
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5287937521934509, train_loss: 0.47965008020401
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3580576777458191, train_loss: 0.3029768764972687
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2990308105945587, train_loss: 0.23790070414543152
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27515313029289246, train_loss: 0.1966986358165741
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26508647203445435, train_loss: 0.1582036316394806
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6973616480827332, train_loss: 0.7114874720573425
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43820008635520935, train_loss: 0.37613555788993835
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3728030025959015, train_loss: 0.2606210708618164
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3603265583515167, train_loss: 0.20578207075595856
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3607330620288849, train_loss: 0.19792790710926056
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7592942118644714, train_loss: 0.7704407572746277
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4546021521091461, train_loss: 0.39107149839401245
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36521413922309875, train_loss: 0.2520003318786621
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3406040072441101, train_loss: 0.19426000118255615
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33850619196891785, train_loss: 0.16040754318237305
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5872702598571777, train_loss: 0.5779858827590942
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.393357515335083, train_loss: 0.3357996344566345
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3470965325832367, train_loss: 0.25451621413230896
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3390428423881531, train_loss: 0.2120738923549652
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3391864597797394, train_loss: 0.19931907951831818
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2950054109096527, train_loss: 0.27459195256233215
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14521920680999756, train_loss: 0.06915462017059326
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14179064333438873, train_loss: 0.05357009172439575
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14125734567642212, train_loss: 0.052743181586265564
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14150705933570862, train_loss: 0.051412440836429596
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.46824052929878235, train_loss: 0.5092132091522217
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12169637531042099, train_loss: 0.08177857100963593
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11812131851911545, train_loss: 0.05494419112801552
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11743449419736862, train_loss: 0.05206140875816345
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11733854562044144, train_loss: 0.052543748170137405
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8319387435913086, train_loss: 0.842163622379303
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47782936692237854, train_loss: 0.43669769167900085
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3500865399837494, train_loss: 0.3002110719680786
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3059333264827728, train_loss: 0.24054139852523804
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2894168496131897, train_loss: 0.19620943069458008
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2850232422351837, train_loss: 0.16827251017093658
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.555325984954834, train_loss: 0.5505203008651733
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3970722556114197, train_loss: 0.3147430717945099
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3566605746746063, train_loss: 0.2326471507549286
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34726598858833313, train_loss: 0.19026750326156616
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34592750668525696, train_loss: 0.16296720504760742
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6914551854133606, train_loss: 0.6655929684638977
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42365285754203796, train_loss: 0.3476433753967285
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3577268421649933, train_loss: 0.24135300517082214
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3443824052810669, train_loss: 0.19130688905715942
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3443765938282013, train_loss: 0.17202872037887573
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8787363767623901, train_loss: 0.873017430305481
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5080851316452026, train_loss: 0.4386313855648041
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38686099648475647, train_loss: 0.2776063084602356
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3563077747821808, train_loss: 0.2113434225320816
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3530110716819763, train_loss: 0.17390239238739014
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6611109972000122, train_loss: 0.6873089075088501
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1680378019809723, train_loss: 0.08343792706727982
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.16057251393795013, train_loss: 0.056286368519067764
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.16044291853904724, train_loss: 0.051040880382061005
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.160344660282135, train_loss: 0.05349067971110344
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6323028802871704, train_loss: 0.6252502202987671
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13155587017536163, train_loss: 0.08081591129302979
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.129323810338974, train_loss: 0.06285028904676437
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12875968217849731, train_loss: 0.06335107237100601
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1289781779050827, train_loss: 0.05924126133322716
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7813994884490967, train_loss: 0.7754648923873901
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.44535887241363525, train_loss: 0.3988431692123413
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32999056577682495, train_loss: 0.28154700994491577
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28673967719078064, train_loss: 0.22286440432071686
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26838111877441406, train_loss: 0.18241509795188904
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2606687545776367, train_loss: 0.15636533498764038
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9100781679153442, train_loss: 0.9259635210037231
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.525644838809967, train_loss: 0.4713696241378784
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39034950733184814, train_loss: 0.28591954708099365
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36001959443092346, train_loss: 0.2106187343597412
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35489240288734436, train_loss: 0.1782466471195221
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7387703657150269, train_loss: 0.6845287084579468
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42587387561798096, train_loss: 0.3445558547973633
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35433346033096313, train_loss: 0.23816600441932678
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33459222316741943, train_loss: 0.19073425233364105
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33322250843048096, train_loss: 0.1627279669046402
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9141521453857422, train_loss: 0.9576448202133179
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5373345017433167, train_loss: 0.4724651575088501
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.388759046792984, train_loss: 0.28637784719467163
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3516492545604706, train_loss: 0.21401014924049377
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3449227511882782, train_loss: 0.1734859198331833
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7740435600280762, train_loss: 0.5498528480529785
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1689939796924591, train_loss: 0.07492681592702866
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1584765911102295, train_loss: 0.05094568803906441
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15503455698490143, train_loss: 0.04198635369539261
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15444478392601013, train_loss: 0.041487082839012146
[te_estimator_0_xnet] Epoch: 250, current validation loss: 0.15396107733249664, train_loss: 0.040389612317085266
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.28180405497550964, train_loss: 0.3395105302333832
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11913498491048813, train_loss: 0.07927314192056656
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11541545391082764, train_loss: 0.05978066846728325
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1155170425772667, train_loss: 0.05358930677175522
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11541309207677841, train_loss: 0.05335612967610359
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7890548706054688, train_loss: 0.7788629531860352
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4696729779243469, train_loss: 0.4137623906135559
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3494800925254822, train_loss: 0.2878793179988861
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30766019225120544, train_loss: 0.23409953713417053
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2902471423149109, train_loss: 0.19285783171653748
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2850836515426636, train_loss: 0.1618240922689438
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.28371384739875793, train_loss: 0.15551987290382385
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9864564538002014, train_loss: 1.0332393646240234
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5760089159011841, train_loss: 0.534327507019043
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4029630422592163, train_loss: 0.2934335172176361
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36480712890625, train_loss: 0.2191886156797409
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35919925570487976, train_loss: 0.17440158128738403
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6089851260185242, train_loss: 0.6498708128929138
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4040014147758484, train_loss: 0.3542628288269043
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3488023281097412, train_loss: 0.2502475380897522
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33314457535743713, train_loss: 0.2040606439113617
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33113783597946167, train_loss: 0.16570986807346344
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7150569558143616, train_loss: 0.7086877822875977
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43626734614372253, train_loss: 0.36700308322906494
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36311665177345276, train_loss: 0.25198328495025635
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3457840085029602, train_loss: 0.19375936686992645
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34480392932891846, train_loss: 0.17086298763751984
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37600040435791016, train_loss: 0.36353543400764465
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15182623267173767, train_loss: 0.07325486093759537
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1454571783542633, train_loss: 0.05250529199838638
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1450432986021042, train_loss: 0.049698639661073685
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14484171569347382, train_loss: 0.04820510745048523
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3983144164085388, train_loss: 0.44555342197418213
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12811468541622162, train_loss: 0.08554250001907349
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12030268460512161, train_loss: 0.05815700814127922
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12083946168422699, train_loss: 0.05218295380473137
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1207299456000328, train_loss: 0.05223715677857399
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6180973649024963, train_loss: 0.6742756962776184
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3752587139606476, train_loss: 0.37290236353874207
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30251672863960266, train_loss: 0.2826562821865082
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2748275399208069, train_loss: 0.23468586802482605
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2644691467285156, train_loss: 0.19748865067958832
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7273889183998108, train_loss: 0.7630711197853088
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44803762435913086, train_loss: 0.3980664908885956
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37198102474212646, train_loss: 0.26448243856430054
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3587544560432434, train_loss: 0.21213027834892273
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3584621846675873, train_loss: 0.18878836929798126
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7568584680557251, train_loss: 0.7817451357841492
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4412977397441864, train_loss: 0.4036855101585388
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34360411763191223, train_loss: 0.2679559588432312
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3151841163635254, train_loss: 0.20364201068878174
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30745309591293335, train_loss: 0.16401135921478271
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8008551597595215, train_loss: 0.8038138747215271
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47253093123435974, train_loss: 0.39022862911224365
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38624468445777893, train_loss: 0.26103729009628296
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3659575879573822, train_loss: 0.20424576103687286
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36442315578460693, train_loss: 0.18297988176345825
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37555167078971863, train_loss: 0.3943159580230713
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13144566118717194, train_loss: 0.0733993649482727
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12753568589687347, train_loss: 0.05545443296432495
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12743882834911346, train_loss: 0.05288533866405487
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12755201756954193, train_loss: 0.054436132311820984
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45231544971466064, train_loss: 0.4768911600112915
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11966648697853088, train_loss: 0.07635080069303513
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11964045464992523, train_loss: 0.061531104147434235
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1201636865735054, train_loss: 0.05990578979253769
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1205921620130539, train_loss: 0.05591977760195732
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7392953038215637, train_loss: 0.713908314704895
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4265266954898834, train_loss: 0.38484686613082886
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3282044529914856, train_loss: 0.27594614028930664
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2915540933609009, train_loss: 0.22437430918216705
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2758241891860962, train_loss: 0.18734818696975708
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7819917798042297, train_loss: 0.8102036118507385
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46499305963516235, train_loss: 0.41515541076660156
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3755708634853363, train_loss: 0.27506160736083984
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35547730326652527, train_loss: 0.21105797588825226
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35247310996055603, train_loss: 0.18174566328525543
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7407460808753967, train_loss: 0.7266619205474854
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.44095489382743835, train_loss: 0.3812941908836365
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3505222797393799, train_loss: 0.25810572504997253
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3249744474887848, train_loss: 0.19530528783798218
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31898221373558044, train_loss: 0.1680375188589096
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7418392300605774, train_loss: 0.7594194412231445
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4431447386741638, train_loss: 0.3789113759994507
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36394426226615906, train_loss: 0.26303860545158386
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3453836441040039, train_loss: 0.20274850726127625
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3441750705242157, train_loss: 0.18465404212474823
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5769587755203247, train_loss: 0.5983262062072754
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1404697448015213, train_loss: 0.06717094033956528
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13748040795326233, train_loss: 0.051770731806755066
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1372509002685547, train_loss: 0.05057578533887863
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1373172551393509, train_loss: 0.048452429473400116
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3746933937072754, train_loss: 0.43198925256729126
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11663247644901276, train_loss: 0.08449804782867432
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10934888571500778, train_loss: 0.05761616304516792
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10870394855737686, train_loss: 0.048061225563287735
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10858562588691711, train_loss: 0.04735070839524269
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9508664608001709, train_loss: 0.9096873998641968
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5531877875328064, train_loss: 0.4520011842250824
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38244694471359253, train_loss: 0.2884646952152252
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31823161244392395, train_loss: 0.21677792072296143
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28795626759529114, train_loss: 0.18294230103492737
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2710593640804291, train_loss: 0.15244503319263458
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26272666454315186, train_loss: 0.12738865613937378
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2594521641731262, train_loss: 0.10909279435873032
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.2577669620513916, train_loss: 0.10018202662467957
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6721640229225159, train_loss: 0.6663428544998169
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.417739599943161, train_loss: 0.3472282588481903
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3648008406162262, train_loss: 0.25106364488601685
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3524281978607178, train_loss: 0.19483181834220886
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35200345516204834, train_loss: 0.17873024940490723
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7533382177352905, train_loss: 0.8082436323165894
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4310235381126404, train_loss: 0.3937408924102783
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3443901240825653, train_loss: 0.2508291006088257
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3255945146083832, train_loss: 0.19194994866847992
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3242531418800354, train_loss: 0.1675853729248047
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7686741948127747, train_loss: 0.7578195333480835
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4568377435207367, train_loss: 0.3863413333892822
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36304840445518494, train_loss: 0.25479626655578613
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3383283019065857, train_loss: 0.2014617621898651
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33332470059394836, train_loss: 0.17077858746051788
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3999480903148651, train_loss: 0.4310566484928131
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1417839378118515, train_loss: 0.07764653116464615
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13248910009860992, train_loss: 0.0523429811000824
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13125614821910858, train_loss: 0.04746408015489578
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13111203908920288, train_loss: 0.04530433565378189
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5622997283935547, train_loss: 0.6179980039596558
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1162005215883255, train_loss: 0.07813212275505066
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11439016461372375, train_loss: 0.06993822008371353
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11411327868700027, train_loss: 0.06437812745571136
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11384174227714539, train_loss: 0.05972745269536972
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5226554870605469, train_loss: 0.5663983225822449
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3520609438419342, train_loss: 0.345844566822052
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29466474056243896, train_loss: 0.26759040355682373
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27272164821624756, train_loss: 0.21862182021141052
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26422661542892456, train_loss: 0.18248862028121948
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5547678470611572, train_loss: 0.5570636987686157
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38746094703674316, train_loss: 0.3117891848087311
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3556627333164215, train_loss: 0.2333672046661377
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3516751229763031, train_loss: 0.1911192536354065
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.351791650056839, train_loss: 0.1898946464061737
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7152491807937622, train_loss: 0.6702732443809509
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40181806683540344, train_loss: 0.34285610914230347
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33766910433769226, train_loss: 0.24075880646705627
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32200267910957336, train_loss: 0.19172286987304688
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3210192918777466, train_loss: 0.17335909605026245
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7059978246688843, train_loss: 0.7169498205184937
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40610963106155396, train_loss: 0.34547245502471924
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3500599265098572, train_loss: 0.23772014677524567
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3412780165672302, train_loss: 0.1931348443031311
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3409634232521057, train_loss: 0.1832614690065384
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6197248101234436, train_loss: 0.7863224148750305
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13733096420764923, train_loss: 0.06871561706066132
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1366705596446991, train_loss: 0.06251723319292068
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13668927550315857, train_loss: 0.05880801007151604
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13670039176940918, train_loss: 0.055177945643663406
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5012021064758301, train_loss: 0.532630205154419
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12576280534267426, train_loss: 0.07367832958698273
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1229574903845787, train_loss: 0.05762193351984024
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12303026765584946, train_loss: 0.05676181614398956
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1226501315832138, train_loss: 0.054886557161808014
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7183080315589905, train_loss: 0.7303121089935303
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41112029552459717, train_loss: 0.3877211809158325
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3104236423969269, train_loss: 0.2759818434715271
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2744225561618805, train_loss: 0.2215634137392044
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2604072690010071, train_loss: 0.18006932735443115
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2561773955821991, train_loss: 0.14768821001052856
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25584718585014343, train_loss: 0.13709664344787598
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5926116108894348, train_loss: 0.5662022829055786
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40310296416282654, train_loss: 0.31193792819976807
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3607204854488373, train_loss: 0.22786767780780792
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35440218448638916, train_loss: 0.18043670058250427
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35425156354904175, train_loss: 0.17131993174552917
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7182738184928894, train_loss: 0.7233949899673462
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4366561770439148, train_loss: 0.38438767194747925
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35596877336502075, train_loss: 0.2575283646583557
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3331194818019867, train_loss: 0.2033175528049469
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33093276619911194, train_loss: 0.17667093873023987
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9947966933250427, train_loss: 1.0234750509262085
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5745182633399963, train_loss: 0.5170460939407349
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39857175946235657, train_loss: 0.3008403182029724
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35535991191864014, train_loss: 0.21620768308639526
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34679314494132996, train_loss: 0.1693102866411209
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7044067978858948, train_loss: 0.7499659657478333
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14883092045783997, train_loss: 0.06975018978118896
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.144417867064476, train_loss: 0.050166547298431396
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14426864683628082, train_loss: 0.04773249104619026
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14394739270210266, train_loss: 0.04689689725637436
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2329583317041397, train_loss: 0.26419323682785034
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11678549647331238, train_loss: 0.08630993962287903
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11381048709154129, train_loss: 0.06513643264770508
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11415127664804459, train_loss: 0.06041606515645981
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11391749233007431, train_loss: 0.05931118130683899
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.53594970703125, train_loss: 0.5567289590835571
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.34263384342193604, train_loss: 0.3298354148864746
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.28815025091171265, train_loss: 0.24717481434345245
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2693520784378052, train_loss: 0.20256538689136505
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26267772912979126, train_loss: 0.16993065178394318
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.690468966960907, train_loss: 0.678281307220459
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4409322738647461, train_loss: 0.3625505268573761
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3758537471294403, train_loss: 0.2534392774105072
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3590335547924042, train_loss: 0.19532379508018494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3568880558013916, train_loss: 0.16958293318748474
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7552778720855713, train_loss: 0.8147395253181458
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4558965563774109, train_loss: 0.39820992946624756
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36402514576911926, train_loss: 0.2572574019432068
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3412288427352905, train_loss: 0.19490569829940796
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.337657630443573, train_loss: 0.16183936595916748
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8190219402313232, train_loss: 0.8237031698226929
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46718689799308777, train_loss: 0.4183014929294586
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36348211765289307, train_loss: 0.27600136399269104
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33588799834251404, train_loss: 0.21411368250846863
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33078181743621826, train_loss: 0.1746116578578949
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3658178448677063, train_loss: 0.38952746987342834
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1447637677192688, train_loss: 0.07720688730478287
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14290006458759308, train_loss: 0.06441321969032288
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14236968755722046, train_loss: 0.06298978626728058
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14214278757572174, train_loss: 0.062214236706495285
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2633262276649475, train_loss: 0.30190593004226685
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11337398737668991, train_loss: 0.08078248798847198
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11310210824012756, train_loss: 0.06737684458494186
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11341675370931625, train_loss: 0.0627867802977562
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11379724740982056, train_loss: 0.06035124510526657
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.908684492111206, train_loss: 0.9149640798568726
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5168611407279968, train_loss: 0.4550325274467468
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36242470145225525, train_loss: 0.2875972390174866
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3128085136413574, train_loss: 0.21904852986335754
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29471200704574585, train_loss: 0.18278202414512634
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.29046157002449036, train_loss: 0.15826945006847382
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9126698970794678, train_loss: 0.9666966199874878
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5337592363357544, train_loss: 0.48011359572410583
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3942281901836395, train_loss: 0.28414422273635864
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3623523414134979, train_loss: 0.21168917417526245
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3574133813381195, train_loss: 0.16839562356472015
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6653545498847961, train_loss: 0.6874690055847168
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40688958764076233, train_loss: 0.347059965133667
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33594709634780884, train_loss: 0.234749898314476
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31612202525138855, train_loss: 0.1808287650346756
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31295260787010193, train_loss: 0.14918263256549835
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7507383823394775, train_loss: 0.7691388130187988
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4419243037700653, train_loss: 0.38221368193626404
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3655713200569153, train_loss: 0.2570226192474365
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34985169768333435, train_loss: 0.1949852705001831
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35008877515792847, train_loss: 0.18410135805606842
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4034104645252228, train_loss: 0.35756969451904297
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14146167039871216, train_loss: 0.060926564037799835
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13947798311710358, train_loss: 0.04555564373731613
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13923333585262299, train_loss: 0.04798567295074463
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13904094696044922, train_loss: 0.044345274567604065
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.28110671043395996, train_loss: 0.3677993416786194
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12086258083581924, train_loss: 0.07948397099971771
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12006307393312454, train_loss: 0.07029850780963898
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1202809140086174, train_loss: 0.0670943409204483
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12021751701831818, train_loss: 0.06634648144245148
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6703835129737854, train_loss: 0.6839638948440552
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4020533561706543, train_loss: 0.3639669716358185
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3212181329727173, train_loss: 0.26495397090911865
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28992289304733276, train_loss: 0.2103898823261261
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27881690859794617, train_loss: 0.18210896849632263
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9765944480895996, train_loss: 1.0168633460998535
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5683057904243469, train_loss: 0.5032401084899902
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4127362072467804, train_loss: 0.2928473949432373
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3798256814479828, train_loss: 0.21481087803840637
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37691935896873474, train_loss: 0.17843389511108398
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.3766545355319977, train_loss: 0.17967922985553741
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8984300494194031, train_loss: 0.9105250835418701
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5217042565345764, train_loss: 0.4548974633216858
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3867504596710205, train_loss: 0.272693932056427
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3548987805843353, train_loss: 0.20424658060073853
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3475458323955536, train_loss: 0.16149038076400757
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5011489391326904, train_loss: 0.4938669800758362
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3575187921524048, train_loss: 0.29434895515441895
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.32420167326927185, train_loss: 0.22581735253334045
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3188723623752594, train_loss: 0.18250210583209991
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3188680410385132, train_loss: 0.18359912931919098
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.41717252135276794, train_loss: 0.4286646842956543
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16560062766075134, train_loss: 0.08025218546390533
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1556919813156128, train_loss: 0.051630131900310516
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15435627102851868, train_loss: 0.042259883135557175
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15436312556266785, train_loss: 0.04113982617855072
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4179942011833191, train_loss: 0.4317552447319031
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12130363285541534, train_loss: 0.07828451693058014
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12016693502664566, train_loss: 0.06371602416038513
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12025043368339539, train_loss: 0.058825548738241196
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12037354707717896, train_loss: 0.05539310351014137
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.42903560400009155, train_loss: 0.4797828793525696
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.30490466952323914, train_loss: 0.3018210530281067
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2736148238182068, train_loss: 0.24792712926864624
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26295438408851624, train_loss: 0.20224905014038086
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2610825300216675, train_loss: 0.1715584546327591
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5563653707504272, train_loss: 0.5370088219642639
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39427649974823, train_loss: 0.3107632100582123
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3715202510356903, train_loss: 0.2325962781906128
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3712635934352875, train_loss: 0.21655428409576416
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37156909704208374, train_loss: 0.20803266763687134
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6448947191238403, train_loss: 0.5884667038917542
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3900584578514099, train_loss: 0.3125388026237488
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.344533234834671, train_loss: 0.22250205278396606
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3366924226284027, train_loss: 0.17889386415481567
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3365718126296997, train_loss: 0.17000439763069153
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5418780446052551, train_loss: 0.5563668012619019
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37193381786346436, train_loss: 0.32270562648773193
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33894404768943787, train_loss: 0.23550525307655334
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3360847532749176, train_loss: 0.1986648440361023
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33657515048980713, train_loss: 0.1958576738834381
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5491453409194946, train_loss: 0.5479366779327393
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16313546895980835, train_loss: 0.06970462203025818
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15598319470882416, train_loss: 0.04755745083093643
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1553008109331131, train_loss: 0.046795375645160675
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15505079925060272, train_loss: 0.042411379516124725
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.39892712235450745, train_loss: 0.4445280432701111
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12930020689964294, train_loss: 0.07956379652023315
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12433482706546783, train_loss: 0.05347738042473793
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12441787868738174, train_loss: 0.051597610116004944
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12475109845399857, train_loss: 0.047968264669179916
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5985257625579834, train_loss: 0.6215387582778931
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.36837121844291687, train_loss: 0.3318935036659241
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30242711305618286, train_loss: 0.2492116540670395
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27831950783729553, train_loss: 0.1971072107553482
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2688656747341156, train_loss: 0.16239261627197266
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2644752860069275, train_loss: 0.13902774453163147
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7422432899475098, train_loss: 0.7392463088035583
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44255879521369934, train_loss: 0.37805771827697754
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36505126953125, train_loss: 0.25260478258132935
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3464568853378296, train_loss: 0.20288723707199097
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34498366713523865, train_loss: 0.1680406630039215
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9329637289047241, train_loss: 0.9469363689422607
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5292184948921204, train_loss: 0.4812476634979248
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3753752112388611, train_loss: 0.27571266889572144
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3346196413040161, train_loss: 0.1978859305381775
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32702285051345825, train_loss: 0.15455126762390137
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9053221940994263, train_loss: 0.9002062678337097
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5272228717803955, train_loss: 0.44670143723487854
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39713767170906067, train_loss: 0.28108224272727966
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36567559838294983, train_loss: 0.2133255898952484
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3617808222770691, train_loss: 0.17574059963226318
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44856297969818115, train_loss: 0.46753209829330444
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15182629227638245, train_loss: 0.0712667852640152
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14869984984397888, train_loss: 0.053629569709300995
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14794595539569855, train_loss: 0.04908638447523117
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14813414216041565, train_loss: 0.04989432916045189
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4775027334690094, train_loss: 0.5039737224578857
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12786172330379486, train_loss: 0.08261746168136597
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12039349973201752, train_loss: 0.05687982589006424
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12060694396495819, train_loss: 0.05339805781841278
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12042981386184692, train_loss: 0.05228449031710625
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.626643717288971, train_loss: 0.6061854362487793
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3711146116256714, train_loss: 0.34233182668685913
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29619717597961426, train_loss: 0.2589973211288452
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2665746212005615, train_loss: 0.2080879509449005
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25628864765167236, train_loss: 0.16821911931037903
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2525487542152405, train_loss: 0.14735320210456848
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6476095914840698, train_loss: 0.645866870880127
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4134013056755066, train_loss: 0.3492805063724518
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3578326404094696, train_loss: 0.25944414734840393
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3443014621734619, train_loss: 0.20671719312667847
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34356316924095154, train_loss: 0.19341595470905304
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5948057770729065, train_loss: 0.5865250825881958
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38091084361076355, train_loss: 0.3202987313270569
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33367428183555603, train_loss: 0.22961780428886414
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32074010372161865, train_loss: 0.1831769049167633
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31948307156562805, train_loss: 0.165886789560318
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7707509398460388, train_loss: 0.7829252481460571
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47382453083992004, train_loss: 0.402193546295166
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3800540268421173, train_loss: 0.2677011787891388
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3582565188407898, train_loss: 0.20294678211212158
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35585999488830566, train_loss: 0.17697611451148987
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3984292149543762, train_loss: 0.420344740152359
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14264047145843506, train_loss: 0.07514898478984833
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1379290074110031, train_loss: 0.05580286681652069
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13767537474632263, train_loss: 0.052430495619773865
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13770698010921478, train_loss: 0.05221962928771973
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.576921284198761, train_loss: 0.5832273960113525
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14386266469955444, train_loss: 0.08236675709486008
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1399245262145996, train_loss: 0.06401142477989197
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13885922729969025, train_loss: 0.06044386327266693
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1387932300567627, train_loss: 0.05765235424041748
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7879647016525269, train_loss: 0.7854023575782776
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4620473384857178, train_loss: 0.419658899307251
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34234416484832764, train_loss: 0.29337891936302185
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.296085387468338, train_loss: 0.23159557580947876
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2759186327457428, train_loss: 0.19880220293998718
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2665296196937561, train_loss: 0.16970522701740265
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26299265027046204, train_loss: 0.1394297480583191
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6875218749046326, train_loss: 0.7036244869232178
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4291227161884308, train_loss: 0.36589187383651733
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3624269366264343, train_loss: 0.25428181886672974
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3465443253517151, train_loss: 0.19723379611968994
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34553825855255127, train_loss: 0.17811045050621033
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7706000208854675, train_loss: 0.779172956943512
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4481165409088135, train_loss: 0.39605340361595154
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.366872638463974, train_loss: 0.2673146724700928
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3477742671966553, train_loss: 0.20725968480110168
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3462733328342438, train_loss: 0.18729472160339355
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5368794202804565, train_loss: 0.5256953239440918
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37094828486442566, train_loss: 0.31206050515174866
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3385147452354431, train_loss: 0.2398282289505005
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3340608775615692, train_loss: 0.19985032081604004
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3341250717639923, train_loss: 0.1987500935792923
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.383454293012619, train_loss: 0.3280310034751892
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14933829009532928, train_loss: 0.06639911234378815
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14625807106494904, train_loss: 0.05291398614645004
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14600399136543274, train_loss: 0.051915448158979416
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14612022042274475, train_loss: 0.04765203967690468
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.47383496165275574, train_loss: 0.5012409687042236
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12595780193805695, train_loss: 0.08753609657287598
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12095420807600021, train_loss: 0.05983284115791321
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12092360854148865, train_loss: 0.05097058415412903
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12090544402599335, train_loss: 0.048184700310230255
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7039104700088501, train_loss: 0.6774690747261047
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42260849475860596, train_loss: 0.37314021587371826
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33405473828315735, train_loss: 0.27369460463523865
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29847562313079834, train_loss: 0.23032556474208832
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2843579053878784, train_loss: 0.18993133306503296
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5172163248062134, train_loss: 0.5335086584091187
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37712058424949646, train_loss: 0.30771785974502563
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35386380553245544, train_loss: 0.23327961564064026
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.352906197309494, train_loss: 0.20462413132190704
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35320836305618286, train_loss: 0.19487535953521729
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7172009944915771, train_loss: 0.7195698022842407
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4289391338825226, train_loss: 0.3701948821544647
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3546145260334015, train_loss: 0.24736136198043823
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34026405215263367, train_loss: 0.19535893201828003
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3397209346294403, train_loss: 0.1822054088115692
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8066286444664001, train_loss: 0.805709958076477
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4738233983516693, train_loss: 0.3938979208469391
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38424041867256165, train_loss: 0.2587437927722931
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3597124218940735, train_loss: 0.2008930891752243
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3536524176597595, train_loss: 0.1607917696237564
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7765036225318909, train_loss: 0.8333455920219421
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1578248143196106, train_loss: 0.07466110587120056
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15061579644680023, train_loss: 0.058826543390750885
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14989066123962402, train_loss: 0.052226535975933075
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15044011175632477, train_loss: 0.054414018988609314
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7264601588249207, train_loss: 0.7944720983505249
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11991151422262192, train_loss: 0.08183092623949051
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11481494456529617, train_loss: 0.052484311163425446
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11476761102676392, train_loss: 0.05301278829574585
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1149355098605156, train_loss: 0.05032274127006531
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6474862098693848, train_loss: 0.6668462753295898
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.404528945684433, train_loss: 0.38157063722610474
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32406124472618103, train_loss: 0.28436458110809326
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29335224628448486, train_loss: 0.2349977195262909
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27988409996032715, train_loss: 0.2031124234199524
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2748602330684662, train_loss: 0.1646084189414978
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8485421538352966, train_loss: 0.8836987018585205
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5037252902984619, train_loss: 0.4523748755455017
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37904831767082214, train_loss: 0.27561894059181213
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34819474816322327, train_loss: 0.20337000489234924
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3420877754688263, train_loss: 0.16758014261722565
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7771060466766357, train_loss: 0.8097926378250122
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4353659152984619, train_loss: 0.39889711141586304
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3379316031932831, train_loss: 0.2602382302284241
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3091444671154022, train_loss: 0.19767796993255615
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2996756434440613, train_loss: 0.1609083116054535
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9840622544288635, train_loss: 1.001484751701355
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5748239755630493, train_loss: 0.5230193138122559
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39947184920310974, train_loss: 0.3047459125518799
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35225576162338257, train_loss: 0.23325428366661072
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3423207998275757, train_loss: 0.18282680213451385
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6524383425712585, train_loss: 0.632071316242218
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16775333881378174, train_loss: 0.07671655714511871
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1536746621131897, train_loss: 0.05256275087594986
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15144182741641998, train_loss: 0.04388163983821869
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1507520228624344, train_loss: 0.044533416628837585
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5401219725608826, train_loss: 0.5910007953643799
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11558050662279129, train_loss: 0.0787859708070755
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11560431867837906, train_loss: 0.06915652751922607
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11569476872682571, train_loss: 0.06574360281229019
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.115814208984375, train_loss: 0.0626382976770401
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.774884045124054, train_loss: 0.7782524824142456
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45666226744651794, train_loss: 0.4190700054168701
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3405489921569824, train_loss: 0.29730167984962463
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29602155089378357, train_loss: 0.23760171234607697
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2762005627155304, train_loss: 0.1936262547969818
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2680019736289978, train_loss: 0.1649608016014099
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.265448659658432, train_loss: 0.13862645626068115
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2648236155509949, train_loss: 0.1279418021440506
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.2643749415874481, train_loss: 0.12704679369926453
[po_estimator_0_impute_pos] Epoch: 450, current validation loss: 0.26415517926216125, train_loss: 0.12247952073812485
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8349737524986267, train_loss: 0.8333317041397095
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4841584861278534, train_loss: 0.4214480519294739
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3797529637813568, train_loss: 0.27181077003479004
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3549724519252777, train_loss: 0.2024281919002533
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35123246908187866, train_loss: 0.1722143292427063
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5425278544425964, train_loss: 0.5493489503860474
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.36695244908332825, train_loss: 0.31370851397514343
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3317248821258545, train_loss: 0.23098576068878174
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32785993814468384, train_loss: 0.19270160794258118
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32828179001808167, train_loss: 0.18151551485061646
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9018290042877197, train_loss: 0.846387505531311
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.502902090549469, train_loss: 0.4094146490097046
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3883465826511383, train_loss: 0.2667481601238251
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35859808325767517, train_loss: 0.2064216583967209
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3560907542705536, train_loss: 0.171010822057724
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3300935924053192, train_loss: 0.30746522545814514
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13941319286823273, train_loss: 0.07146349549293518
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13646309077739716, train_loss: 0.051003631204366684
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13636869192123413, train_loss: 0.047207675874233246
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13669799268245697, train_loss: 0.0460146889090538
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.134345531463623, train_loss: 1.2121142148971558
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11958047747612, train_loss: 0.07295484840869904
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11856633424758911, train_loss: 0.05900893360376358
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11867997795343399, train_loss: 0.05581379309296608
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11866330355405807, train_loss: 0.05584196746349335
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7646098136901855, train_loss: 0.7976272106170654
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45154768228530884, train_loss: 0.3994714021682739
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3467523753643036, train_loss: 0.28383100032806396
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3052126169204712, train_loss: 0.221189484000206
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28823474049568176, train_loss: 0.18448232114315033
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2820233404636383, train_loss: 0.15441378951072693
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7810965776443481, train_loss: 0.8036987781524658
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46434253454208374, train_loss: 0.4106237590312958
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37491270899772644, train_loss: 0.2756798565387726
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3527474105358124, train_loss: 0.2151988446712494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3501167893409729, train_loss: 0.18184247612953186
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7174879312515259, train_loss: 0.7276747822761536
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.433531790971756, train_loss: 0.3831530809402466
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3474719822406769, train_loss: 0.25391048192977905
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32354581356048584, train_loss: 0.20140521228313446
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3205687999725342, train_loss: 0.16672249138355255
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5797638893127441, train_loss: 0.5898354649543762
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38584205508232117, train_loss: 0.3247104287147522
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33934855461120605, train_loss: 0.23759694397449493
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33144885301589966, train_loss: 0.19725829362869263
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3315722644329071, train_loss: 0.18696419894695282
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.757803738117218, train_loss: 0.7168751955032349
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16119347512722015, train_loss: 0.06760069727897644
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15528468787670135, train_loss: 0.05604543164372444
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15442028641700745, train_loss: 0.05271966755390167
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1541021317243576, train_loss: 0.049207329750061035
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3434433937072754, train_loss: 0.39195722341537476
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11593379080295563, train_loss: 0.07680448889732361
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11234869807958603, train_loss: 0.05500791221857071
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11205553263425827, train_loss: 0.049186691641807556
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11221424490213394, train_loss: 0.04772748798131943
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5353122353553772, train_loss: 0.5496596097946167
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3594040274620056, train_loss: 0.34082186222076416
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30880582332611084, train_loss: 0.26841506361961365
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2923433482646942, train_loss: 0.21241946518421173
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28723761439323425, train_loss: 0.18469418585300446
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6633108854293823, train_loss: 0.6387761831283569
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4176658093929291, train_loss: 0.3425474166870117
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36882761120796204, train_loss: 0.2493344098329544
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3588391840457916, train_loss: 0.19362014532089233
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35850653052330017, train_loss: 0.16936443746089935
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7481313943862915, train_loss: 0.7362850308418274
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4346262812614441, train_loss: 0.3627942204475403
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3614566922187805, train_loss: 0.2393898367881775
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34509027004241943, train_loss: 0.1807359755039215
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3448612689971924, train_loss: 0.17052322626113892
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6823424696922302, train_loss: 0.6670999526977539
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4277910888195038, train_loss: 0.3464447855949402
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36590859293937683, train_loss: 0.24775883555412292
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35529205203056335, train_loss: 0.19594267010688782
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.354854017496109, train_loss: 0.1888606995344162
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.31716594099998474, train_loss: 0.4230744242668152
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14433173835277557, train_loss: 0.07736752182245255
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1417439579963684, train_loss: 0.06573347002267838
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14164410531520844, train_loss: 0.061092764139175415
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14151212573051453, train_loss: 0.06086016446352005
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34135910868644714, train_loss: 0.4136900007724762
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.10596204549074173, train_loss: 0.08459220081567764
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10580745339393616, train_loss: 0.07360020279884338
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10581237077713013, train_loss: 0.071133092045784
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1060376688838005, train_loss: 0.06855680048465729
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8591474294662476, train_loss: 0.8458889722824097
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4847840964794159, train_loss: 0.4213804602622986
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3495192229747772, train_loss: 0.28523266315460205
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2999083995819092, train_loss: 0.23071041703224182
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.274983674287796, train_loss: 0.18662212789058685
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2611241936683655, train_loss: 0.16186466813087463
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25292763113975525, train_loss: 0.1334197074174881
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.25043314695358276, train_loss: 0.11572708934545517
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.2500055134296417, train_loss: 0.10898304730653763
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6270344257354736, train_loss: 0.6207178831100464
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3966231942176819, train_loss: 0.3324018716812134
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3472425043582916, train_loss: 0.24652279913425446
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3389642834663391, train_loss: 0.1943170428276062
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3388887047767639, train_loss: 0.18923445045948029
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6815903782844543, train_loss: 0.6239718198776245
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4199742078781128, train_loss: 0.3360224962234497
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3598676919937134, train_loss: 0.2374509572982788
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3441089689731598, train_loss: 0.19189685583114624
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3427833914756775, train_loss: 0.1627483069896698
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8418689966201782, train_loss: 0.854478120803833
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.49983060359954834, train_loss: 0.43337008357048035
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3856232166290283, train_loss: 0.28047096729278564
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3563949763774872, train_loss: 0.21343760192394257
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35060471296310425, train_loss: 0.17754369974136353
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.525000274181366, train_loss: 0.49937617778778076
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1607428938150406, train_loss: 0.07901135087013245
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1465025246143341, train_loss: 0.052868857979774475
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14369042217731476, train_loss: 0.042516548186540604
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14302892982959747, train_loss: 0.04305531084537506
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.38367825746536255, train_loss: 0.42315658926963806
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12761546671390533, train_loss: 0.08961713314056396
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11895556002855301, train_loss: 0.061767928302288055
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11820843815803528, train_loss: 0.04942834749817848
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1183314397931099, train_loss: 0.0493972972035408
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.664721667766571, train_loss: 0.6788673400878906
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3958389163017273, train_loss: 0.36445045471191406
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3085043728351593, train_loss: 0.2698192000389099
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27735504508018494, train_loss: 0.2120126336812973
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2657158076763153, train_loss: 0.17793649435043335
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26319533586502075, train_loss: 0.15611782670021057
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7170423865318298, train_loss: 0.7115768790245056
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4391878545284271, train_loss: 0.36833491921424866
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3692149221897125, train_loss: 0.26028913259506226
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35284048318862915, train_loss: 0.201787531375885
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35213059186935425, train_loss: 0.1841326653957367
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9662346243858337, train_loss: 0.971718966960907
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5138534903526306, train_loss: 0.4692904055118561
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3742976188659668, train_loss: 0.27877917885780334
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3397902548313141, train_loss: 0.20757447183132172
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33140769600868225, train_loss: 0.16872598230838776
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6031256318092346, train_loss: 0.6452564001083374
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3952197730541229, train_loss: 0.3365119695663452
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3503552973270416, train_loss: 0.24168597161769867
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34306463599205017, train_loss: 0.19638827443122864
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3432561159133911, train_loss: 0.18914812803268433
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.35465899109840393, train_loss: 0.38849687576293945
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1507539004087448, train_loss: 0.07119668275117874
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14522328972816467, train_loss: 0.04883524775505066
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14479409158229828, train_loss: 0.04476003348827362
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.145086869597435, train_loss: 0.0455109179019928
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8614751696586609, train_loss: 0.936677098274231
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12025623023509979, train_loss: 0.07620635628700256
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1191289946436882, train_loss: 0.060370493680238724
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11914144456386566, train_loss: 0.056403398513793945
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11936208605766296, train_loss: 0.054103318601846695
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6637237071990967, train_loss: 0.6864094734191895
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4058397114276886, train_loss: 0.3708977699279785
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3245341181755066, train_loss: 0.27255773544311523
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29462388157844543, train_loss: 0.22061192989349365
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2827712297439575, train_loss: 0.1880093216896057
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2796030044555664, train_loss: 0.1609342396259308
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8462134599685669, train_loss: 0.8854343891143799
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4935753047466278, train_loss: 0.4421895742416382
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38299086689949036, train_loss: 0.2745644748210907
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36131051182746887, train_loss: 0.2047765552997589
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35890480875968933, train_loss: 0.17167675495147705
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5790472030639648, train_loss: 0.5555263757705688
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.363262802362442, train_loss: 0.2990739345550537
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3244466781616211, train_loss: 0.21842139959335327
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3146440088748932, train_loss: 0.1758667379617691
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3143862187862396, train_loss: 0.15597626566886902
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.898260235786438, train_loss: 0.9370564818382263
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5310921669006348, train_loss: 0.46959272027015686
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38848358392715454, train_loss: 0.2854982912540436
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35166484117507935, train_loss: 0.2183200865983963
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3452479839324951, train_loss: 0.1757332682609558
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.384045273065567, train_loss: 0.4331396818161011
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13831689953804016, train_loss: 0.07410193979740143
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13552235066890717, train_loss: 0.05266948416829109
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1354733109474182, train_loss: 0.051444120705127716
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13547006249427795, train_loss: 0.05102681741118431
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.47901201248168945, train_loss: 0.4806849956512451
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13766345381736755, train_loss: 0.07585553079843521
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13390004634857178, train_loss: 0.06232442334294319
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13350850343704224, train_loss: 0.06037326157093048
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13338717818260193, train_loss: 0.05806684494018555
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9060425162315369, train_loss: 0.8983268737792969
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5033594965934753, train_loss: 0.44434699416160583
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.354320228099823, train_loss: 0.2917952537536621
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3022962212562561, train_loss: 0.23671171069145203
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28068074584007263, train_loss: 0.19844989478588104
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27270784974098206, train_loss: 0.165611132979393
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6501809358596802, train_loss: 0.6585285067558289
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4250716269016266, train_loss: 0.3452683389186859
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3736327588558197, train_loss: 0.2455214411020279
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3635825216770172, train_loss: 0.19231998920440674
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3644058108329773, train_loss: 0.1784924417734146
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6815030574798584, train_loss: 0.7029454708099365
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4180910587310791, train_loss: 0.36207616329193115
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3475090563297272, train_loss: 0.24391832947731018
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3341546356678009, train_loss: 0.1878364533185959
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3346301019191742, train_loss: 0.1741448938846588
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9858608841896057, train_loss: 1.013245940208435
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5719243884086609, train_loss: 0.512737512588501
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3963059186935425, train_loss: 0.2991213798522949
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34975236654281616, train_loss: 0.2245454490184784
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3339354693889618, train_loss: 0.17904753983020782
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.33736759424209595, train_loss: 0.387020468711853
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14324231445789337, train_loss: 0.07248036563396454
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13845989108085632, train_loss: 0.054665714502334595
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13786853849887848, train_loss: 0.055219437927007675
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13789881765842438, train_loss: 0.05531696230173111
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3617894649505615, train_loss: 0.35602453351020813
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12609528005123138, train_loss: 0.08159640431404114
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12204673886299133, train_loss: 0.06399919092655182
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12170685827732086, train_loss: 0.05900443345308304
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12161297351121902, train_loss: 0.05859672278165817
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9747491478919983, train_loss: 0.961764931678772
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5371963381767273, train_loss: 0.4864687919616699
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3578493893146515, train_loss: 0.30963653326034546
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2987724840641022, train_loss: 0.23922070860862732
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27625975012779236, train_loss: 0.19645260274410248
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2695278227329254, train_loss: 0.16873185336589813
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5689606070518494, train_loss: 0.5620458126068115
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39450153708457947, train_loss: 0.3200308680534363
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3595845699310303, train_loss: 0.23374632000923157
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35731208324432373, train_loss: 0.19881391525268555
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3573521077632904, train_loss: 0.1918429285287857
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8069655895233154, train_loss: 0.8624398708343506
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.46728989481925964, train_loss: 0.4271540939807892
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35748517513275146, train_loss: 0.2664450407028198
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32882237434387207, train_loss: 0.20216481387615204
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3253137767314911, train_loss: 0.17032086849212646
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7305189371109009, train_loss: 0.7576389312744141
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4420187473297119, train_loss: 0.37663841247558594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36346200108528137, train_loss: 0.25482603907585144
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34663599729537964, train_loss: 0.1961984932422638
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3469194173812866, train_loss: 0.17301443219184875
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3587363064289093, train_loss: 0.38808849453926086
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14689470827579498, train_loss: 0.07213030010461807
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1442326456308365, train_loss: 0.05795524641871452
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14382007718086243, train_loss: 0.05349528416991234
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14382140338420868, train_loss: 0.053076911717653275
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7493560314178467, train_loss: 0.864161491394043
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14188027381896973, train_loss: 0.0791548490524292
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13549001514911652, train_loss: 0.05267488211393356
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.135317862033844, train_loss: 0.04874444752931595
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1354846954345703, train_loss: 0.04627639800310135
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:16<06:48, 16.32s/it]importance j:   8%|▊         | 2/26 [00:28<05:28, 13.69s/it]importance j:  12%|█▏        | 3/26 [00:44<05:47, 15.10s/it]importance j:  15%|█▌        | 4/26 [00:56<05:05, 13.89s/it]importance j:  19%|█▉        | 5/26 [01:12<05:05, 14.56s/it]importance j:  23%|██▎       | 6/26 [01:25<04:41, 14.09s/it]importance j:  27%|██▋       | 7/26 [01:42<04:40, 14.76s/it]importance j:  31%|███       | 8/26 [01:57<04:29, 14.98s/it]importance j:  35%|███▍      | 9/26 [02:09<03:58, 14.02s/it]importance j:  38%|███▊      | 10/26 [02:25<03:54, 14.64s/it]importance j:  42%|████▏     | 11/26 [02:37<03:29, 13.98s/it]importance j:  46%|████▌     | 12/26 [02:53<03:24, 14.62s/it]importance j:  50%|█████     | 13/26 [03:06<03:00, 13.89s/it]importance j:  54%|█████▍    | 14/26 [03:22<02:56, 14.73s/it]importance j:  58%|█████▊    | 15/26 [03:34<02:32, 13.90s/it]importance j:  62%|██████▏   | 16/26 [03:51<02:25, 14.59s/it]importance j:  65%|██████▌   | 17/26 [04:02<02:03, 13.75s/it]importance j:  69%|██████▉   | 18/26 [04:20<01:58, 14.82s/it]importance j:  73%|███████▎  | 19/26 [04:34<01:43, 14.77s/it]importance j:  77%|███████▋  | 20/26 [04:49<01:28, 14.68s/it]importance j:  81%|████████  | 21/26 [05:05<01:16, 15.27s/it]importance j:  85%|████████▍ | 22/26 [05:18<00:57, 14.44s/it]importance j:  88%|████████▊ | 23/26 [05:36<00:46, 15.43s/it]importance j:  92%|█████████▏| 24/26 [05:48<00:29, 14.64s/it]importance j:  96%|█████████▌| 25/26 [06:05<00:15, 15.07s/it]importance j: 100%|██████████| 26/26 [06:18<00:00, 14.54s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7981637120246887, train_loss: 0.8267773389816284
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4739164710044861, train_loss: 0.4419032335281372
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3406185209751129, train_loss: 0.294047087430954
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2899523973464966, train_loss: 0.2352917492389679
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2666712701320648, train_loss: 0.19128990173339844
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.25692126154899597, train_loss: 0.16323822736740112
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6502401828765869, train_loss: 0.647534966468811
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4010273814201355, train_loss: 0.3425489366054535
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34720972180366516, train_loss: 0.24582022428512573
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3347577452659607, train_loss: 0.19637379050254822
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33382269740104675, train_loss: 0.17877055704593658
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5600906014442444, train_loss: 0.5789813995361328
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38805505633354187, train_loss: 0.32661402225494385
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33947837352752686, train_loss: 0.23737122118473053
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3248203694820404, train_loss: 0.18498237431049347
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32454541325569153, train_loss: 0.17262420058250427
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7158126831054688, train_loss: 0.7273988723754883
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.436631977558136, train_loss: 0.3842335343360901
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.362888365983963, train_loss: 0.27023395895957947
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34572356939315796, train_loss: 0.21431639790534973
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34500133991241455, train_loss: 0.19796213507652283
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6713961362838745, train_loss: 0.7316416501998901
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13181333243846893, train_loss: 0.06188559904694557
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13286162912845612, train_loss: 0.06059013679623604
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13329236209392548, train_loss: 0.055991820991039276
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13442867994308472, train_loss: 0.05520987510681152
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.47256767749786377, train_loss: 0.5073962211608887
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13069908320903778, train_loss: 0.0806349366903305
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12645667791366577, train_loss: 0.05733277276158333
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1262761354446411, train_loss: 0.05436604097485542
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12579669058322906, train_loss: 0.05531458556652069
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6252112984657288, train_loss: 0.6430948376655579
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39874428510665894, train_loss: 0.358278751373291
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3287142515182495, train_loss: 0.263796865940094
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30227532982826233, train_loss: 0.21851946413516998
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2907963991165161, train_loss: 0.1830095648765564
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2872259318828583, train_loss: 0.15165430307388306
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7554153800010681, train_loss: 0.7431958317756653
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4678972363471985, train_loss: 0.38138842582702637
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3871877193450928, train_loss: 0.2553577721118927
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3711096942424774, train_loss: 0.1973680853843689
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3702535629272461, train_loss: 0.1777808666229248
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7832306623458862, train_loss: 0.7532427906990051
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4555228352546692, train_loss: 0.38104191422462463
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3672073483467102, train_loss: 0.2580260634422302
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3446778953075409, train_loss: 0.20659911632537842
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.34269389510154724, train_loss: 0.17469970881938934
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5822587013244629, train_loss: 0.5552351474761963
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38948044180870056, train_loss: 0.3116702139377594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3528914451599121, train_loss: 0.2369992882013321
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34694141149520874, train_loss: 0.1924440562725067
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34719088673591614, train_loss: 0.18798531591892242
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.32752400636672974, train_loss: 0.37965816259384155
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13218452036380768, train_loss: 0.0748852789402008
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1282082498073578, train_loss: 0.052861180156469345
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12849467992782593, train_loss: 0.05228069797158241
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12841223180294037, train_loss: 0.04945049434900284
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4159183204174042, train_loss: 0.43924760818481445
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12164722383022308, train_loss: 0.08025258779525757
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11950527131557465, train_loss: 0.06357631087303162
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11938408762216568, train_loss: 0.061393190175294876
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11925116926431656, train_loss: 0.05799928307533264
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7114116549491882, train_loss: 0.7016490697860718
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4252476394176483, train_loss: 0.3958654999732971
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32651716470718384, train_loss: 0.2874017655849457
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28617063164711, train_loss: 0.2451653927564621
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2680739462375641, train_loss: 0.20273596048355103
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.25955086946487427, train_loss: 0.1713942587375641
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25571176409721375, train_loss: 0.1446574628353119
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6899175047874451, train_loss: 0.6602981090545654
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43273696303367615, train_loss: 0.356747567653656
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37472155690193176, train_loss: 0.2467796504497528
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3653317987918854, train_loss: 0.2016301155090332
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3652641475200653, train_loss: 0.19079063832759857
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8470014929771423, train_loss: 0.8580678701400757
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47994375228881836, train_loss: 0.4351327419281006
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.361766517162323, train_loss: 0.2768278121948242
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3309275507926941, train_loss: 0.21542800962924957
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32401132583618164, train_loss: 0.17338241636753082
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.665557324886322, train_loss: 0.6737721562385559
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4149475693702698, train_loss: 0.353171706199646
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3507266640663147, train_loss: 0.2551949620246887
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3364698588848114, train_loss: 0.2031136453151703
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3357768654823303, train_loss: 0.1856551617383957
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.49896112084388733, train_loss: 0.5366379618644714
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15566587448120117, train_loss: 0.0713254064321518
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15171265602111816, train_loss: 0.05548840016126633
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15114158391952515, train_loss: 0.05784410610795021
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1510525792837143, train_loss: 0.05238132178783417
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4928975999355316, train_loss: 0.5900788307189941
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1342407613992691, train_loss: 0.08225713670253754
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1289380043745041, train_loss: 0.057297151535749435
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1288592517375946, train_loss: 0.0574122816324234
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12848889827728271, train_loss: 0.05601346492767334
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6828784942626953, train_loss: 0.6975454092025757
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39801931381225586, train_loss: 0.37759825587272644
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3097352683544159, train_loss: 0.28135302662849426
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2795362174510956, train_loss: 0.2227562963962555
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26910048723220825, train_loss: 0.19395259022712708
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.875137984752655, train_loss: 0.8899845480918884
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5150439739227295, train_loss: 0.45365703105926514
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3902590870857239, train_loss: 0.2794978618621826
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3612462878227234, train_loss: 0.209174245595932
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3575551211833954, train_loss: 0.1715337336063385
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6547425389289856, train_loss: 0.6587861180305481
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3936142325401306, train_loss: 0.33058688044548035
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3338448107242584, train_loss: 0.2293955683708191
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3186699450016022, train_loss: 0.17833766341209412
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31688180565834045, train_loss: 0.14547963440418243
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8319090604782104, train_loss: 0.8259466290473938
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.49541303515434265, train_loss: 0.4229942560195923
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3892349600791931, train_loss: 0.2726570963859558
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3628171384334564, train_loss: 0.21495464444160461
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3602234423160553, train_loss: 0.18529343605041504
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6568717956542969, train_loss: 0.6293420791625977
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15770787000656128, train_loss: 0.07447216659784317
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15299105644226074, train_loss: 0.060053661465644836
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15239021182060242, train_loss: 0.05932212248444557
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15206672251224518, train_loss: 0.05689201503992081
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6418145895004272, train_loss: 0.6221596002578735
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12305242568254471, train_loss: 0.08158038556575775
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11781525611877441, train_loss: 0.057439662516117096
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11777812242507935, train_loss: 0.051775772124528885
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11740539222955704, train_loss: 0.05226648598909378
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6537112593650818, train_loss: 0.6581377387046814
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3950513005256653, train_loss: 0.36693310737609863
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31734150648117065, train_loss: 0.27194276452064514
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2925991415977478, train_loss: 0.22541594505310059
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2855573296546936, train_loss: 0.19970765709877014
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0181388854980469, train_loss: 1.0306668281555176
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5861180424690247, train_loss: 0.5208280086517334
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41087689995765686, train_loss: 0.29693612456321716
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3678801953792572, train_loss: 0.21055597066879272
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3602837026119232, train_loss: 0.16892556846141815
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8264015316963196, train_loss: 0.8299962282180786
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47561362385749817, train_loss: 0.4229135513305664
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3678540289402008, train_loss: 0.2764500081539154
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33929643034935, train_loss: 0.2171759456396103
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33413976430892944, train_loss: 0.17957936227321625
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6735522747039795, train_loss: 0.6850457787513733
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41876327991485596, train_loss: 0.35959291458129883
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3535054624080658, train_loss: 0.2429123818874359
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33910298347473145, train_loss: 0.19156739115715027
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3376956284046173, train_loss: 0.16210053861141205
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5797548294067383, train_loss: 0.6136133670806885
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1659146100282669, train_loss: 0.07249055802822113
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15937496721744537, train_loss: 0.054680731147527695
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15945833921432495, train_loss: 0.0522221103310585
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15845490992069244, train_loss: 0.051373597234487534
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3198694586753845, train_loss: 0.36666151881217957
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11288046091794968, train_loss: 0.08063235133886337
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11032013595104218, train_loss: 0.060816049575805664
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1100238710641861, train_loss: 0.06077352166175842
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10990685969591141, train_loss: 0.05836143344640732
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5519739389419556, train_loss: 0.5764350891113281
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35695406794548035, train_loss: 0.34157365560531616
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2944939434528351, train_loss: 0.261556476354599
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26786288619041443, train_loss: 0.22352609038352966
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25510406494140625, train_loss: 0.18848171830177307
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.246658593416214, train_loss: 0.16175663471221924
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.24058249592781067, train_loss: 0.13330677151679993
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6496440172195435, train_loss: 0.6693001985549927
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41109853982925415, train_loss: 0.34607189893722534
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35436734557151794, train_loss: 0.24456501007080078
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3436482548713684, train_loss: 0.19374863803386688
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34333354234695435, train_loss: 0.171001136302948
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5863268375396729, train_loss: 0.5931106209754944
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3676288425922394, train_loss: 0.3252760171890259
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31100213527679443, train_loss: 0.23198246955871582
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2944352328777313, train_loss: 0.18432673811912537
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29172027111053467, train_loss: 0.1568913459777832
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6968532204627991, train_loss: 0.7100554704666138
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4236912131309509, train_loss: 0.3717009425163269
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3556092381477356, train_loss: 0.2594296336174011
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.341770738363266, train_loss: 0.20295073091983795
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3422048091888428, train_loss: 0.18308347463607788
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37023138999938965, train_loss: 0.3816101551055908
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1460934728384018, train_loss: 0.07676205039024353
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13893675804138184, train_loss: 0.05178464949131012
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.138459712266922, train_loss: 0.048053376376628876
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13801109790802002, train_loss: 0.04497173801064491
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.37632980942726135, train_loss: 0.48484787344932556
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12373297661542892, train_loss: 0.08338850736618042
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11881759017705917, train_loss: 0.0574493482708931
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11900588124990463, train_loss: 0.054881200194358826
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11888737231492996, train_loss: 0.050449736416339874
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6382812261581421, train_loss: 0.6727869510650635
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37748798727989197, train_loss: 0.36494189500808716
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3027689456939697, train_loss: 0.26674509048461914
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27682220935821533, train_loss: 0.22027337551116943
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.268271803855896, train_loss: 0.19218145310878754
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.266335129737854, train_loss: 0.1640249788761139
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6056939363479614, train_loss: 0.6074720621109009
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4113052487373352, train_loss: 0.3327158987522125
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3691997826099396, train_loss: 0.24447491765022278
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36369964480400085, train_loss: 0.19968560338020325
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3636934161186218, train_loss: 0.19351576268672943
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7621318101882935, train_loss: 0.7864839434623718
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4415854513645172, train_loss: 0.3938656747341156
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3547341823577881, train_loss: 0.25723564624786377
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33291369676589966, train_loss: 0.19506362080574036
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3285943865776062, train_loss: 0.16692888736724854
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7607603073120117, train_loss: 0.7779615521430969
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4647124707698822, train_loss: 0.3924441337585449
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36790308356285095, train_loss: 0.25974297523498535
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34423235058784485, train_loss: 0.20059999823570251
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34177014231681824, train_loss: 0.17796377837657928
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.544691264629364, train_loss: 0.5172467231750488
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15026845037937164, train_loss: 0.07318475842475891
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1450599730014801, train_loss: 0.05793536454439163
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1455155313014984, train_loss: 0.05016243830323219
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14553172886371613, train_loss: 0.05007795989513397
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.651191771030426, train_loss: 0.7634980082511902
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11067719757556915, train_loss: 0.07976864278316498
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10963035374879837, train_loss: 0.06614823639392853
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1099110096693039, train_loss: 0.062338992953300476
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10979455709457397, train_loss: 0.06262844800949097
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7074709534645081, train_loss: 0.714259684085846
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4105141758918762, train_loss: 0.371762216091156
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3170262277126312, train_loss: 0.26114964485168457
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2826545834541321, train_loss: 0.20518887042999268
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2688402831554413, train_loss: 0.16889327764511108
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7613123059272766, train_loss: 0.7779204845428467
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4638582468032837, train_loss: 0.402144193649292
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38016536831855774, train_loss: 0.2657562494277954
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.362930029630661, train_loss: 0.2092374563217163
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36272767186164856, train_loss: 0.19122125208377838
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.750742495059967, train_loss: 0.69856858253479
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.425260990858078, train_loss: 0.353346586227417
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3488907217979431, train_loss: 0.24461279809474945
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3302910625934601, train_loss: 0.19257909059524536
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32862231135368347, train_loss: 0.17075315117835999
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1140966415405273, train_loss: 1.1470363140106201
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6316255331039429, train_loss: 0.5779348015785217
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4140072762966156, train_loss: 0.317193865776062
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35877203941345215, train_loss: 0.23171508312225342
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.345210999250412, train_loss: 0.18154127895832062
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.25338882207870483, train_loss: 0.2699820101261139
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14531289041042328, train_loss: 0.06900372356176376
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14423136413097382, train_loss: 0.06392482668161392
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1438879817724228, train_loss: 0.06078274920582771
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14398474991321564, train_loss: 0.05752921104431152
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.49827712774276733, train_loss: 0.6202881336212158
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11313192546367645, train_loss: 0.09115137159824371
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11088402569293976, train_loss: 0.06872272491455078
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11089704930782318, train_loss: 0.06686908006668091
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11090455949306488, train_loss: 0.06429818272590637
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7808786034584045, train_loss: 0.7867124676704407
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4438300132751465, train_loss: 0.40743666887283325
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32493242621421814, train_loss: 0.28154051303863525
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2825617492198944, train_loss: 0.21816331148147583
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26676294207572937, train_loss: 0.18069204688072205
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5460577011108398, train_loss: 0.546405017375946
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3847198486328125, train_loss: 0.3174609839916229
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35586127638816833, train_loss: 0.23965781927108765
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3542795181274414, train_loss: 0.19692149758338928
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35471880435943604, train_loss: 0.19708268344402313
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8612385392189026, train_loss: 0.868545413017273
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4724887013435364, train_loss: 0.43324244022369385
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36038777232170105, train_loss: 0.2778182923793793
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3290688395500183, train_loss: 0.21326103806495667
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.322439581155777, train_loss: 0.17573750019073486
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9667585492134094, train_loss: 0.9847632050514221
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5383058786392212, train_loss: 0.4696331024169922
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3883252441883087, train_loss: 0.27631568908691406
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34986039996147156, train_loss: 0.20606395602226257
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3404424488544464, train_loss: 0.16403038799762726
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3733842968940735, train_loss: 0.42387866973876953
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15023456513881683, train_loss: 0.07406588643789291
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1457219123840332, train_loss: 0.056915730237960815
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14469784498214722, train_loss: 0.05190519243478775
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14387290179729462, train_loss: 0.054158810526132584
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.43133875727653503, train_loss: 0.4298752546310425
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12471572309732437, train_loss: 0.0801907330751419
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11745768785476685, train_loss: 0.05812609940767288
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11756448447704315, train_loss: 0.05401882156729698
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11778660863637924, train_loss: 0.05087919905781746
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5616707801818848, train_loss: 0.5883787870407104
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3498937785625458, train_loss: 0.3485696613788605
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2864799499511719, train_loss: 0.25937479734420776
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2635763883590698, train_loss: 0.21982824802398682
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25342175364494324, train_loss: 0.18770445883274078
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.694719672203064, train_loss: 0.6743897199630737
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4289686381816864, train_loss: 0.3495495915412903
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3739924728870392, train_loss: 0.2461819350719452
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3661544919013977, train_loss: 0.1981130987405777
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36604321002960205, train_loss: 0.1885514259338379
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5255182981491089, train_loss: 0.4367672801017761
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3388296365737915, train_loss: 0.27191054821014404
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3209349513053894, train_loss: 0.2188277244567871
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3202415406703949, train_loss: 0.20556768774986267
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31960076093673706, train_loss: 0.21158713102340698
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8068027496337891, train_loss: 0.8196066617965698
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4716455936431885, train_loss: 0.4174221158027649
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3626333475112915, train_loss: 0.2701396942138672
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3343091905117035, train_loss: 0.2143535614013672
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3293571174144745, train_loss: 0.173672154545784
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6227959990501404, train_loss: 0.5865117907524109
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14814350008964539, train_loss: 0.07469313591718674
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1446220576763153, train_loss: 0.05679900944232941
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1442393958568573, train_loss: 0.05299710854887962
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1438039094209671, train_loss: 0.054556310176849365
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4494820833206177, train_loss: 0.6052242517471313
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12270456552505493, train_loss: 0.08195237815380096
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12088402360677719, train_loss: 0.06173919513821602
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12092936038970947, train_loss: 0.05800505727529526
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1213754415512085, train_loss: 0.05471867322921753
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7671274542808533, train_loss: 0.7651039361953735
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4585278034210205, train_loss: 0.42188382148742676
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3414398729801178, train_loss: 0.29375606775283813
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29514193534851074, train_loss: 0.23696808516979218
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2759553790092468, train_loss: 0.19894617795944214
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26758453249931335, train_loss: 0.16424129903316498
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.264674574136734, train_loss: 0.14418095350265503
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.634019672870636, train_loss: 0.6380323171615601
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4112315773963928, train_loss: 0.3490257263183594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3584631085395813, train_loss: 0.25151464343070984
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3473546504974365, train_loss: 0.20005351305007935
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3472025394439697, train_loss: 0.18490543961524963
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9158445596694946, train_loss: 0.9736348390579224
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5107890367507935, train_loss: 0.4761136472225189
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3668351173400879, train_loss: 0.2820666432380676
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33048540353775024, train_loss: 0.21302318572998047
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32291993498802185, train_loss: 0.1636287271976471
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6735697984695435, train_loss: 0.6664444208145142
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43982595205307007, train_loss: 0.3578900694847107
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37518802285194397, train_loss: 0.2478320449590683
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3591515123844147, train_loss: 0.1961601972579956
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35784587264060974, train_loss: 0.17424234747886658
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4743393659591675, train_loss: 0.6178487539291382
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14864441752433777, train_loss: 0.06671574711799622
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1431812047958374, train_loss: 0.05084715038537979
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.142021045088768, train_loss: 0.04628840833902359
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14182648062705994, train_loss: 0.04590076953172684
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5992484092712402, train_loss: 0.722205400466919
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1357780396938324, train_loss: 0.08674014359712601
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13087435066699982, train_loss: 0.05555745214223862
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13034588098526, train_loss: 0.052122168242931366
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13034822046756744, train_loss: 0.050389617681503296
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8011983036994934, train_loss: 0.8096851110458374
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.44833412766456604, train_loss: 0.4153813123703003
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33180859684944153, train_loss: 0.28467243909835815
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2890966236591339, train_loss: 0.23260995745658875
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2702803611755371, train_loss: 0.18909789621829987
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26126858592033386, train_loss: 0.15897972881793976
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25767213106155396, train_loss: 0.1352202594280243
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9932500720024109, train_loss: 1.0065430402755737
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5787615180015564, train_loss: 0.5174166560173035
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4105837047100067, train_loss: 0.2976778745651245
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37378719449043274, train_loss: 0.2148842215538025
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3688541054725647, train_loss: 0.17331096529960632
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6864064931869507, train_loss: 0.7161710262298584
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41627538204193115, train_loss: 0.3633132576942444
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3405633866786957, train_loss: 0.2449275553226471
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3207017481327057, train_loss: 0.19137820601463318
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3188752233982086, train_loss: 0.16647092998027802
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5500322580337524, train_loss: 0.5509735345840454
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3680466115474701, train_loss: 0.30450934171676636
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3397195041179657, train_loss: 0.2305203527212143
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33814358711242676, train_loss: 0.20114043354988098
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3381263017654419, train_loss: 0.20005369186401367
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3766027092933655, train_loss: 0.37672385573387146
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1466677486896515, train_loss: 0.07154783606529236
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14307129383087158, train_loss: 0.05869331955909729
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14301545917987823, train_loss: 0.05334208533167839
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14306114614009857, train_loss: 0.05039922893047333
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7225865721702576, train_loss: 0.8127773404121399
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11112147569656372, train_loss: 0.07612330466508865
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10798008739948273, train_loss: 0.05583883449435234
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10805944353342056, train_loss: 0.056238166987895966
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10827255249023438, train_loss: 0.05290907621383667
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8040480017662048, train_loss: 0.8155472874641418
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4653370678424835, train_loss: 0.43664491176605225
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3454636037349701, train_loss: 0.3015241026878357
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.300597220659256, train_loss: 0.24607102572917938
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2820967435836792, train_loss: 0.20407523214817047
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2767627537250519, train_loss: 0.17154838144779205
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9832729697227478, train_loss: 0.9760115146636963
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5633228421211243, train_loss: 0.4824996292591095
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4137051999568939, train_loss: 0.2856692969799042
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37958887219429016, train_loss: 0.21005432307720184
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3734000325202942, train_loss: 0.16687442362308502
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6031724214553833, train_loss: 0.5970023274421692
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3820864260196686, train_loss: 0.3237573802471161
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33245202898979187, train_loss: 0.2329070121049881
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32211947441101074, train_loss: 0.18641397356987
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32204312086105347, train_loss: 0.1741544008255005
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6088657379150391, train_loss: 0.6231008172035217
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3968563377857208, train_loss: 0.3322523236274719
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3472754657268524, train_loss: 0.2377118468284607
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3374945819377899, train_loss: 0.19211825728416443
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3374817371368408, train_loss: 0.1782928705215454
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44389596581459045, train_loss: 0.4287932813167572
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15478093922138214, train_loss: 0.07141926884651184
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1465156376361847, train_loss: 0.050303973257541656
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14608751237392426, train_loss: 0.04953118786215782
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1456345170736313, train_loss: 0.045724958181381226
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8421353101730347, train_loss: 0.9847899675369263
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14223064482212067, train_loss: 0.08280038833618164
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13439474999904633, train_loss: 0.049151718616485596
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13396920263767242, train_loss: 0.04548224061727524
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13377366960048676, train_loss: 0.04556183144450188
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7961450815200806, train_loss: 0.8135430812835693
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4541935324668884, train_loss: 0.4244174361228943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32713624835014343, train_loss: 0.2815624177455902
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2847558856010437, train_loss: 0.2241704910993576
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26790642738342285, train_loss: 0.18242821097373962
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26016765832901, train_loss: 0.1518974006175995
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5939205884933472, train_loss: 0.6121159791946411
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3907872438430786, train_loss: 0.32871901988983154
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3479227125644684, train_loss: 0.238247811794281
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3437015414237976, train_loss: 0.19606560468673706
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.343940407037735, train_loss: 0.18909892439842224
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8046548366546631, train_loss: 0.8308098912239075
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.482827365398407, train_loss: 0.42150866985321045
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3705584704875946, train_loss: 0.26192861795425415
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3399037718772888, train_loss: 0.20189809799194336
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3344416916370392, train_loss: 0.16535687446594238
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7021750211715698, train_loss: 0.6925770044326782
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43282467126846313, train_loss: 0.3574032187461853
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3635807931423187, train_loss: 0.24543142318725586
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3523372411727905, train_loss: 0.19568932056427002
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3524487316608429, train_loss: 0.18334341049194336
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3678964674472809, train_loss: 0.4291902184486389
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1483476459980011, train_loss: 0.07750406861305237
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14534157514572144, train_loss: 0.06047671288251877
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14397594332695007, train_loss: 0.06006055325269699
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14409568905830383, train_loss: 0.05484120547771454
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4467056095600128, train_loss: 0.5014433264732361
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1263897866010666, train_loss: 0.08822089433670044
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11984094232320786, train_loss: 0.059723448008298874
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11973494291305542, train_loss: 0.05376831442117691
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11973568052053452, train_loss: 0.052887801080942154
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5645168423652649, train_loss: 0.594169557094574
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3636637330055237, train_loss: 0.3344452381134033
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30588841438293457, train_loss: 0.2571444511413574
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28550687432289124, train_loss: 0.2013857066631317
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2769026756286621, train_loss: 0.16828766465187073
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2753591537475586, train_loss: 0.14952053129673004
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.029657244682312, train_loss: 1.0496184825897217
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5867047309875488, train_loss: 0.5387142896652222
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41042929887771606, train_loss: 0.30640384554862976
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3676789402961731, train_loss: 0.21927960216999054
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35844799876213074, train_loss: 0.17490020394325256
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6520407199859619, train_loss: 0.6324585676193237
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4059300124645233, train_loss: 0.32409724593162537
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35279205441474915, train_loss: 0.2348172664642334
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34205618500709534, train_loss: 0.18584048748016357
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3420789837837219, train_loss: 0.17113596200942993
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7885025143623352, train_loss: 0.8141279220581055
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46625444293022156, train_loss: 0.4063319265842438
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3681929111480713, train_loss: 0.2537080943584442
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3445139527320862, train_loss: 0.2011362612247467
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3423604369163513, train_loss: 0.1691378355026245
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3346388638019562, train_loss: 0.4287984073162079
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1258116513490677, train_loss: 0.07295945286750793
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1252869814634323, train_loss: 0.0561993271112442
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12488414347171783, train_loss: 0.05584285780787468
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12528522312641144, train_loss: 0.05542757362127304
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5310458540916443, train_loss: 0.5713510513305664
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12416373193264008, train_loss: 0.08089525997638702
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12086936086416245, train_loss: 0.06032673269510269
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12074794620275497, train_loss: 0.05900820344686508
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12082700431346893, train_loss: 0.054204151034355164
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6975319981575012, train_loss: 0.6981625556945801
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42690613865852356, train_loss: 0.38762545585632324
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33741751313209534, train_loss: 0.27485382556915283
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30286386609077454, train_loss: 0.22837068140506744
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28831252455711365, train_loss: 0.1850202977657318
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.285796582698822, train_loss: 0.16368088126182556
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7847087383270264, train_loss: 0.8039289116859436
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4679425060749054, train_loss: 0.4163724482059479
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3703291118144989, train_loss: 0.27387577295303345
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3481087386608124, train_loss: 0.2124728262424469
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34568527340888977, train_loss: 0.1768958866596222
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9314656257629395, train_loss: 0.9686305522918701
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5249013900756836, train_loss: 0.4709324836730957
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38606026768684387, train_loss: 0.275205135345459
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3520593047142029, train_loss: 0.200752392411232
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.345805287361145, train_loss: 0.15777985751628876
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7860113978385925, train_loss: 0.7731733322143555
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46455299854278564, train_loss: 0.38412413001060486
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3749493658542633, train_loss: 0.25407180190086365
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3528612554073334, train_loss: 0.19737479090690613
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.350551038980484, train_loss: 0.17375978827476501
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7017146944999695, train_loss: 0.6408757567405701
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16620399057865143, train_loss: 0.07270032167434692
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15857355296611786, train_loss: 0.04799831286072731
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15720504522323608, train_loss: 0.04075225442647934
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15708856284618378, train_loss: 0.03990842401981354
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3986673653125763, train_loss: 0.4908081591129303
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12168996781110764, train_loss: 0.08089885115623474
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12032780051231384, train_loss: 0.06874018907546997
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12051641941070557, train_loss: 0.066887266933918
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12079139053821564, train_loss: 0.062284138053655624
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6686775088310242, train_loss: 0.68718022108078
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39231690764427185, train_loss: 0.3721468448638916
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3105282485485077, train_loss: 0.2724476456642151
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2806422710418701, train_loss: 0.22021320462226868
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2684823274612427, train_loss: 0.1870613694190979
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26426464319229126, train_loss: 0.16236749291419983
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6515810489654541, train_loss: 0.651556134223938
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42430299520492554, train_loss: 0.34058085083961487
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3823143243789673, train_loss: 0.24460339546203613
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37815114855766296, train_loss: 0.19476161897182465
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37848207354545593, train_loss: 0.18836909532546997
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7644544243812561, train_loss: 0.8154746890068054
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.44190582633018494, train_loss: 0.4093645513057709
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3476945459842682, train_loss: 0.2657540440559387
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32124051451683044, train_loss: 0.20430681109428406
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31588828563690186, train_loss: 0.16111594438552856
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9278793334960938, train_loss: 0.9282323122024536
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5314133167266846, train_loss: 0.45344114303588867
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38780462741851807, train_loss: 0.27361801266670227
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3531503677368164, train_loss: 0.20503999292850494
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34727323055267334, train_loss: 0.16540999710559845
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4427225589752197, train_loss: 0.4632346034049988
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1519927978515625, train_loss: 0.07466454803943634
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1444038450717926, train_loss: 0.05342574045062065
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14418339729309082, train_loss: 0.049464523792266846
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14412687718868256, train_loss: 0.046148888766765594
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.29734188318252563, train_loss: 0.3566139042377472
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11663907766342163, train_loss: 0.07733997702598572
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11010877788066864, train_loss: 0.05253549665212631
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1098564937710762, train_loss: 0.04680624231696129
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10994458943605423, train_loss: 0.04678187146782875
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7225649952888489, train_loss: 0.7374840974807739
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43105486035346985, train_loss: 0.3950292766094208
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3314116895198822, train_loss: 0.2885197401046753
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2910096347332001, train_loss: 0.23689861595630646
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2713049054145813, train_loss: 0.20132514834403992
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26099228858947754, train_loss: 0.16730622947216034
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25637853145599365, train_loss: 0.14399947226047516
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6933859586715698, train_loss: 0.6902130842208862
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44131091237068176, train_loss: 0.35172605514526367
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.383476197719574, train_loss: 0.2430795580148697
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3746953010559082, train_loss: 0.1929875910282135
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3747324049472809, train_loss: 0.17270079255104065
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6840306520462036, train_loss: 0.708522379398346
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43441763520240784, train_loss: 0.36895501613616943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3613035976886749, train_loss: 0.24984556436538696
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34044426679611206, train_loss: 0.1927582025527954
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33548858761787415, train_loss: 0.16866430640220642
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4706418514251709, train_loss: 0.4767017066478729
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.34146860241889954, train_loss: 0.29831811785697937
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3251645267009735, train_loss: 0.22184422612190247
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.32518166303634644, train_loss: 0.2210630178451538
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3254055678844452, train_loss: 0.2097562849521637
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40202152729034424, train_loss: 0.43198099732398987
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1625036746263504, train_loss: 0.07827986776828766
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15281639993190765, train_loss: 0.06609444320201874
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15089571475982666, train_loss: 0.06125102937221527
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15001997351646423, train_loss: 0.05586954951286316
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5275546908378601, train_loss: 0.5891883373260498
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11142534762620926, train_loss: 0.07497242838144302
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11036200076341629, train_loss: 0.054897844791412354
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11055382341146469, train_loss: 0.05276193097233772
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11096849292516708, train_loss: 0.05305570363998413
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6783700585365295, train_loss: 0.7119441032409668
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40029627084732056, train_loss: 0.37351301312446594
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31784042716026306, train_loss: 0.27343928813934326
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2895749807357788, train_loss: 0.22281579673290253
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27886632084846497, train_loss: 0.18478429317474365
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5168982148170471, train_loss: 0.46681731939315796
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37406760454177856, train_loss: 0.28931689262390137
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3584643602371216, train_loss: 0.21837976574897766
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3585222363471985, train_loss: 0.20550322532653809
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35901975631713867, train_loss: 0.19729124009609222
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9609435200691223, train_loss: 0.9891098737716675
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5226031541824341, train_loss: 0.49821117520332336
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.365175724029541, train_loss: 0.2910096347332001
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32388511300086975, train_loss: 0.213123619556427
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3134588301181793, train_loss: 0.17232176661491394
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6568693518638611, train_loss: 0.6467805504798889
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41347742080688477, train_loss: 0.34517166018486023
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35924017429351807, train_loss: 0.2522802948951721
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3455035984516144, train_loss: 0.2012721300125122
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3456827998161316, train_loss: 0.1813133805990219
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.35214003920555115, train_loss: 0.3498595356941223
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15030105412006378, train_loss: 0.07022830098867416
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14832620322704315, train_loss: 0.05850369855761528
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14740097522735596, train_loss: 0.05611903965473175
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1467021107673645, train_loss: 0.05456370860338211
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.3276424407958984, train_loss: 1.4898303747177124
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12826278805732727, train_loss: 0.08486642688512802
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1250576674938202, train_loss: 0.06335561722517014
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12491732835769653, train_loss: 0.06084645912051201
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12472278624773026, train_loss: 0.060421109199523926
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7123661637306213, train_loss: 0.7256035804748535
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42966052889823914, train_loss: 0.3870377540588379
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32877808809280396, train_loss: 0.27647703886032104
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29257529973983765, train_loss: 0.2212156355381012
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27604562044143677, train_loss: 0.18782827258110046
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7357679605484009, train_loss: 0.7249200344085693
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4423723518848419, train_loss: 0.37735843658447266
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37277156114578247, train_loss: 0.2552871108055115
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3579553961753845, train_loss: 0.2012704461812973
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35815104842185974, train_loss: 0.18467417359352112
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7143415212631226, train_loss: 0.7278795838356018
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4347308874130249, train_loss: 0.3754414916038513
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3560987710952759, train_loss: 0.24703919887542725
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3342743515968323, train_loss: 0.19627827405929565
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3314427435398102, train_loss: 0.1652994602918625
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6769200563430786, train_loss: 0.6923485994338989
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4209836721420288, train_loss: 0.3587075173854828
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.358288437128067, train_loss: 0.25368088483810425
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3468034565448761, train_loss: 0.19946154952049255
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.346833199262619, train_loss: 0.19255465269088745
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40376317501068115, train_loss: 0.39286869764328003
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14313562214374542, train_loss: 0.07004483044147491
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13406017422676086, train_loss: 0.04842108115553856
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13331934809684753, train_loss: 0.04219742864370346
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13303470611572266, train_loss: 0.04070952534675598
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3238682448863983, train_loss: 0.3315805196762085
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13152766227722168, train_loss: 0.07996079325675964
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12723778188228607, train_loss: 0.059037115424871445
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12669947743415833, train_loss: 0.05643385648727417
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12656792998313904, train_loss: 0.05402332916855812
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5740627646446228, train_loss: 0.6009811758995056
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37643224000930786, train_loss: 0.3451058864593506
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.311718225479126, train_loss: 0.25988924503326416
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28778427839279175, train_loss: 0.21998412907123566
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2789880633354187, train_loss: 0.18197976052761078
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27712196111679077, train_loss: 0.1625646948814392
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6581822037696838, train_loss: 0.6457706689834595
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4208904802799225, train_loss: 0.35049015283584595
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36516857147216797, train_loss: 0.2514759600162506
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3542969524860382, train_loss: 0.1989496350288391
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35427558422088623, train_loss: 0.18367457389831543
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.524175763130188, train_loss: 0.4750688076019287
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3398692011833191, train_loss: 0.2812348008155823
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3156804144382477, train_loss: 0.2191927134990692
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3127189874649048, train_loss: 0.18172751367092133
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31274333596229553, train_loss: 0.18219172954559326
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6478278040885925, train_loss: 0.6432393193244934
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4092258810997009, train_loss: 0.3380638360977173
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3539349138736725, train_loss: 0.24324065446853638
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3455514907836914, train_loss: 0.19463267922401428
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3457682430744171, train_loss: 0.1972551792860031
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.9229187965393066, train_loss: 1.950451135635376
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1592082977294922, train_loss: 0.0743519514799118
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.159281924366951, train_loss: 0.06680350005626678
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1594126671552658, train_loss: 0.06417547166347504
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15941764414310455, train_loss: 0.06116638332605362
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34334301948547363, train_loss: 0.38353782892227173
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1134243831038475, train_loss: 0.07652462273836136
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10884259641170502, train_loss: 0.054599784314632416
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10866855829954147, train_loss: 0.05219818651676178
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10863596200942993, train_loss: 0.04928552731871605
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6829255819320679, train_loss: 0.7070083618164062
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39595526456832886, train_loss: 0.38113969564437866
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3110179007053375, train_loss: 0.28202855587005615
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2784530222415924, train_loss: 0.22663646936416626
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2657286524772644, train_loss: 0.1936127245426178
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2600380480289459, train_loss: 0.16628609597682953
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6839394569396973, train_loss: 0.6929433345794678
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4378499388694763, train_loss: 0.3587888181209564
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37372133135795593, train_loss: 0.2494150698184967
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3612537682056427, train_loss: 0.19467326998710632
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36154690384864807, train_loss: 0.1806904822587967
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7175548672676086, train_loss: 0.7358905076980591
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4392699897289276, train_loss: 0.38455837965011597
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3505600392818451, train_loss: 0.25457605719566345
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3270236551761627, train_loss: 0.1934516727924347
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3250563442707062, train_loss: 0.161213219165802
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7708513140678406, train_loss: 0.770098865032196
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.45236116647720337, train_loss: 0.38087549805641174
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37027111649513245, train_loss: 0.25939130783081055
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3492119610309601, train_loss: 0.20475263893604279
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3443926274776459, train_loss: 0.17122583091259003
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.32335036993026733, train_loss: 0.3128070533275604
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1479269564151764, train_loss: 0.07113774120807648
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14471712708473206, train_loss: 0.057883840054273605
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14456123113632202, train_loss: 0.054838720709085464
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1442277878522873, train_loss: 0.0540519617497921
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.48307666182518005, train_loss: 0.5060677528381348
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12278923392295837, train_loss: 0.07540033012628555
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11610004305839539, train_loss: 0.04890140891075134
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11591465771198273, train_loss: 0.04651708900928497
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11579282581806183, train_loss: 0.047112010419368744
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6134080290794373, train_loss: 0.6357086896896362
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3774772882461548, train_loss: 0.34996894001960754
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30842992663383484, train_loss: 0.2697845697402954
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2807564437389374, train_loss: 0.22298601269721985
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2671128511428833, train_loss: 0.1892995685338974
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2621667981147766, train_loss: 0.1548335701227188
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26165640354156494, train_loss: 0.14297457039356232
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.26129966974258423, train_loss: 0.14275071024894714
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6028223037719727, train_loss: 0.5839158892631531
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3996567130088806, train_loss: 0.3256429433822632
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3587753176689148, train_loss: 0.2373732030391693
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3518318235874176, train_loss: 0.19354701042175293
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35218486189842224, train_loss: 0.17520581185817719
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6468489170074463, train_loss: 0.6158255338668823
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3906508684158325, train_loss: 0.333999365568161
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33455175161361694, train_loss: 0.2447887808084488
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32023555040359497, train_loss: 0.19723263382911682
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3203345239162445, train_loss: 0.17112819850444794
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4676252603530884, train_loss: 0.47632336616516113
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3416440784931183, train_loss: 0.2854997515678406
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.32738053798675537, train_loss: 0.21528416872024536
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.327438086271286, train_loss: 0.2036854326725006
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.32790786027908325, train_loss: 0.2017776519060135
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5108432173728943, train_loss: 0.4841189980506897
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15340670943260193, train_loss: 0.0703527182340622
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14704854786396027, train_loss: 0.05239367485046387
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14631739258766174, train_loss: 0.05327170342206955
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14611445367336273, train_loss: 0.049128562211990356
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4798170328140259, train_loss: 0.5826045274734497
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14416208863258362, train_loss: 0.08289778232574463
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13801661133766174, train_loss: 0.06009437143802643
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13741321861743927, train_loss: 0.05347937345504761
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1373821198940277, train_loss: 0.05282849818468094
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0055197477340698, train_loss: 1.0197705030441284
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5784119963645935, train_loss: 0.5124036073684692
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3865557312965393, train_loss: 0.31290167570114136
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.318385511636734, train_loss: 0.23701588809490204
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2894551455974579, train_loss: 0.19942721724510193
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27664071321487427, train_loss: 0.1652366816997528
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.27311113476753235, train_loss: 0.14520475268363953
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7456976175308228, train_loss: 0.7589689493179321
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4567662477493286, train_loss: 0.377966970205307
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38657069206237793, train_loss: 0.2599891424179077
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37269464135169983, train_loss: 0.2015770673751831
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37202420830726624, train_loss: 0.1785745918750763
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8730366230010986, train_loss: 0.9000124931335449
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4950007200241089, train_loss: 0.44359081983566284
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36637938022613525, train_loss: 0.26869136095046997
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3338428735733032, train_loss: 0.198198139667511
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3271596431732178, train_loss: 0.15529677271842957
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7917441129684448, train_loss: 0.8137666583061218
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4595637321472168, train_loss: 0.40899384021759033
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35634011030197144, train_loss: 0.26728135347366333
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33098578453063965, train_loss: 0.2041153609752655
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.32768911123275757, train_loss: 0.1745111495256424
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3545355796813965, train_loss: 0.38883447647094727
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14428114891052246, train_loss: 0.07595465332269669
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1369074285030365, train_loss: 0.05219057947397232
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13653817772865295, train_loss: 0.04350722208619118
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13672976195812225, train_loss: 0.04465431347489357
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.33455947041511536, train_loss: 0.36754363775253296
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11999748647212982, train_loss: 0.08045736700296402
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11508405953645706, train_loss: 0.060350097715854645
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11497019976377487, train_loss: 0.056336045265197754
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11471212655305862, train_loss: 0.05523661524057388
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.630780041217804, train_loss: 0.6340963840484619
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3916585147380829, train_loss: 0.3566322922706604
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32006847858428955, train_loss: 0.2686311602592468
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29362136125564575, train_loss: 0.22158466279506683
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28353753685951233, train_loss: 0.1821633130311966
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.28037893772125244, train_loss: 0.16039223968982697
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7697523236274719, train_loss: 0.7921253442764282
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4649401009082794, train_loss: 0.4190330505371094
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37520870566368103, train_loss: 0.279025673866272
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3550838232040405, train_loss: 0.2167053371667862
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35276395082473755, train_loss: 0.1813596487045288
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9819944500923157, train_loss: 0.994928240776062
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5308932662010193, train_loss: 0.4878361225128174
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38341236114501953, train_loss: 0.2799622416496277
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3492386043071747, train_loss: 0.20752334594726562
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3447689712047577, train_loss: 0.16689632833003998
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7797102928161621, train_loss: 0.7621368169784546
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4691687226295471, train_loss: 0.38760751485824585
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38123565912246704, train_loss: 0.2654317021369934
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35981056094169617, train_loss: 0.20173171162605286
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35662680864334106, train_loss: 0.17086416482925415
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3029174208641052, train_loss: 0.25436165928840637
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15010394155979156, train_loss: 0.06942057609558105
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1458558291196823, train_loss: 0.04945917800068855
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14529122412204742, train_loss: 0.04979447275400162
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1451481729745865, train_loss: 0.045434556901454926
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3559821546077728, train_loss: 0.4256993532180786
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13158701360225677, train_loss: 0.08652634173631668
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13030239939689636, train_loss: 0.06250447034835815
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1302052140235901, train_loss: 0.05781562626361847
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13048182427883148, train_loss: 0.056796297430992126
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7114666104316711, train_loss: 0.7118154764175415
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4379933774471283, train_loss: 0.3870882987976074
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3418177664279938, train_loss: 0.2796477675437927
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30576860904693604, train_loss: 0.22570137679576874
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2906489372253418, train_loss: 0.18998414278030396
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2848367393016815, train_loss: 0.15805989503860474
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5672675371170044, train_loss: 0.5823533535003662
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3918498158454895, train_loss: 0.33176684379577637
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35951483249664307, train_loss: 0.23990872502326965
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35766345262527466, train_loss: 0.2133968025445938
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3581223487854004, train_loss: 0.2091083973646164
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8007979989051819, train_loss: 0.8364980220794678
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45602908730506897, train_loss: 0.40848636627197266
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36164841055870056, train_loss: 0.2655000686645508
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33636674284935, train_loss: 0.20611572265625
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33094826340675354, train_loss: 0.16498830914497375
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7269677519798279, train_loss: 0.6965541839599609
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4316258430480957, train_loss: 0.34483861923217773
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3706362545490265, train_loss: 0.24380925297737122
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3571009039878845, train_loss: 0.19052013754844666
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3569979667663574, train_loss: 0.17153753340244293
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39156803488731384, train_loss: 0.39031702280044556
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16196121275424957, train_loss: 0.07629908621311188
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15377336740493774, train_loss: 0.05249364674091339
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15311288833618164, train_loss: 0.048353418707847595
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15308862924575806, train_loss: 0.050538260489702225
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.23928934335708618, train_loss: 0.2834652066230774
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.114326611161232, train_loss: 0.08277352154254913
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1117592453956604, train_loss: 0.06515643000602722
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11190425604581833, train_loss: 0.06224866211414337
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1118788942694664, train_loss: 0.06059204787015915
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.obtaining subgroup results for loco, feature_num: 16.obtaining subgroup results for loco, feature_num: 17.obtaining subgroup results for loco, feature_num: 18.obtaining subgroup results for loco, feature_num: 19.obtaining subgroup results for loco, feature_num: 20.obtaining subgroup results for loco, feature_num: 21.obtaining subgroup results for loco, feature_num: 22.obtaining subgroup results for loco, feature_num: 23.obtaining subgroup results for loco, feature_num: 24.obtaining subgroup results for loco, feature_num: 25.obtaining subgroup results for loco, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.obtaining subgroup results for permucate, feature_num: 16.obtaining subgroup results for permucate, feature_num: 17.obtaining subgroup results for permucate, feature_num: 18.obtaining subgroup results for permucate, feature_num: 19.obtaining subgroup results for permucate, feature_num: 20.obtaining subgroup results for permucate, feature_num: 21.obtaining subgroup results for permucate, feature_num: 22.obtaining subgroup results for permucate, feature_num: 23.obtaining subgroup results for permucate, feature_num: 24.obtaining subgroup results for permucate, feature_num: 25.obtaining subgroup results for permucate, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.obtaining subgroup results for saliency, feature_num: 16.obtaining subgroup results for saliency, feature_num: 17.obtaining subgroup results for saliency, feature_num: 18.obtaining subgroup results for saliency, feature_num: 19.obtaining subgroup results for saliency, feature_num: 20.obtaining subgroup results for saliency, feature_num: 21.obtaining subgroup results for saliency, feature_num: 22.obtaining subgroup results for saliency, feature_num: 23.obtaining subgroup results for saliency, feature_num: 24.obtaining subgroup results for saliency, feature_num: 25.obtaining subgroup results for saliency, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.obtaining subgroup results for smooth_grad, feature_num: 16.obtaining subgroup results for smooth_grad, feature_num: 17.obtaining subgroup results for smooth_grad, feature_num: 18.obtaining subgroup results for smooth_grad, feature_num: 19.obtaining subgroup results for smooth_grad, feature_num: 20.obtaining subgroup results for smooth_grad, feature_num: 21.obtaining subgroup results for smooth_grad, feature_num: 22.obtaining subgroup results for smooth_grad, feature_num: 23.obtaining subgroup results for smooth_grad, feature_num: 24.obtaining subgroup results for smooth_grad, feature_num: 25.obtaining subgroup results for smooth_grad, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.obtaining subgroup results for gradient_shap, feature_num: 16.obtaining subgroup results for gradient_shap, feature_num: 17.obtaining subgroup results for gradient_shap, feature_num: 18.obtaining subgroup results for gradient_shap, feature_num: 19.obtaining subgroup results for gradient_shap, feature_num: 20.obtaining subgroup results for gradient_shap, feature_num: 21.obtaining subgroup results for gradient_shap, feature_num: 22.obtaining subgroup results for gradient_shap, feature_num: 23.obtaining subgroup results for gradient_shap, feature_num: 24.obtaining subgroup results for gradient_shap, feature_num: 25.obtaining subgroup results for gradient_shap, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.obtaining subgroup results for lime, feature_num: 16.obtaining subgroup results for lime, feature_num: 17.obtaining subgroup results for lime, feature_num: 18.obtaining subgroup results for lime, feature_num: 19.obtaining subgroup results for lime, feature_num: 20.obtaining subgroup results for lime, feature_num: 21.obtaining subgroup results for lime, feature_num: 22.obtaining subgroup results for lime, feature_num: 23.obtaining subgroup results for lime, feature_num: 24.obtaining subgroup results for lime, feature_num: 25.obtaining subgroup results for lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.obtaining subgroup results for baseline_lime, feature_num: 16.obtaining subgroup results for baseline_lime, feature_num: 17.obtaining subgroup results for baseline_lime, feature_num: 18.obtaining subgroup results for baseline_lime, feature_num: 19.obtaining subgroup results for baseline_lime, feature_num: 20.obtaining subgroup results for baseline_lime, feature_num: 21.obtaining subgroup results for baseline_lime, feature_num: 22.obtaining subgroup results for baseline_lime, feature_num: 23.obtaining subgroup results for baseline_lime, feature_num: 24.obtaining subgroup results for baseline_lime, feature_num: 25.obtaining subgroup results for baseline_lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 16.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 17.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 18.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 19.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 20.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 21.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 22.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 23.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 24.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 25.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 16.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 17.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 18.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 19.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 20.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 21.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 22.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 23.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 24.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 25.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.obtaining subgroup results for integrated_gradients, feature_num: 16.obtaining subgroup results for integrated_gradients, feature_num: 17.obtaining subgroup results for integrated_gradients, feature_num: 18.obtaining subgroup results for integrated_gradients, feature_num: 19.obtaining subgroup results for integrated_gradients, feature_num: 20.obtaining subgroup results for integrated_gradients, feature_num: 21.obtaining subgroup results for integrated_gradients, feature_num: 22.obtaining subgroup results for integrated_gradients, feature_num: 23.obtaining subgroup results for integrated_gradients, feature_num: 24.obtaining subgroup results for integrated_gradients, feature_num: 25.obtaining subgroup results for integrated_gradients, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.obtaining subgroup results for baseline_integrated_gradients, feature_num: 16.obtaining subgroup results for baseline_integrated_gradients, feature_num: 17.obtaining subgroup results for baseline_integrated_gradients, feature_num: 18.obtaining subgroup results for baseline_integrated_gradients, feature_num: 19.obtaining subgroup results for baseline_integrated_gradients, feature_num: 20.obtaining subgroup results for baseline_integrated_gradients, feature_num: 21.obtaining subgroup results for baseline_integrated_gradients, feature_num: 22.obtaining subgroup results for baseline_integrated_gradients, feature_num: 23.obtaining subgroup results for baseline_integrated_gradients, feature_num: 24.obtaining subgroup results for baseline_integrated_gradients, feature_num: 25.obtaining subgroup results for baseline_integrated_gradients, feature_num: 26.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9298346042633057, train_loss: 0.9482473731040955
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5347700119018555, train_loss: 0.48974037170410156
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3759171664714813, train_loss: 0.29470884799957275
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3312225341796875, train_loss: 0.22049781680107117
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3174571990966797, train_loss: 0.17569801211357117
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3142068684101105, train_loss: 0.1450483798980713
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5655497908592224, train_loss: 0.5444074273109436
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39802664518356323, train_loss: 0.2962910234928131
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3624938428401947, train_loss: 0.20332080125808716
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3599380850791931, train_loss: 0.16775065660476685
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3604288101196289, train_loss: 0.16565868258476257
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8328834176063538, train_loss: 0.8508795499801636
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.49145546555519104, train_loss: 0.409080445766449
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3949859142303467, train_loss: 0.2605324983596802
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3733195960521698, train_loss: 0.1987474262714386
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3719806373119354, train_loss: 0.1773175597190857
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.862047016620636, train_loss: 0.8450597524642944
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5293596386909485, train_loss: 0.42186081409454346
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.42642942070961, train_loss: 0.27042123675346375
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.407900333404541, train_loss: 0.2056322693824768
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.40721070766448975, train_loss: 0.17855587601661682
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.38525235652923584, train_loss: 0.4864664375782013
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.12432318180799484, train_loss: 0.08595384657382965
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.11659333109855652, train_loss: 0.060250237584114075
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.11603078246116638, train_loss: 0.0547715425491333
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.11591126769781113, train_loss: 0.05295943468809128
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5772897601127625, train_loss: 0.6933969259262085
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.15149468183517456, train_loss: 0.06845179200172424
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.14927609264850616, train_loss: 0.053579069674015045
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.14894139766693115, train_loss: 0.05044582486152649
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.14899307489395142, train_loss: 0.05019472539424896
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 497/26001 [00:00<00:25, 992.59it/s]Shapley Value Sampling attribution:   4%|▍         | 1003/26001 [00:01<00:24, 1002.96it/s]Shapley Value Sampling attribution:   6%|▌         | 1511/26001 [00:01<00:24, 1008.65it/s]Shapley Value Sampling attribution:   8%|▊         | 2019/26001 [00:02<00:23, 1010.88it/s]Shapley Value Sampling attribution:  10%|▉         | 2527/26001 [00:02<00:23, 1012.64it/s]Shapley Value Sampling attribution:  12%|█▏        | 3034/26001 [00:03<00:22, 1012.20it/s]Shapley Value Sampling attribution:  14%|█▎        | 3541/26001 [00:03<00:22, 1010.80it/s]Shapley Value Sampling attribution:  16%|█▌        | 4050/26001 [00:04<00:21, 1012.47it/s]Shapley Value Sampling attribution:  18%|█▊        | 4559/26001 [00:04<00:21, 1014.11it/s]Shapley Value Sampling attribution:  19%|█▉        | 5067/26001 [00:05<00:20, 1005.39it/s]Shapley Value Sampling attribution:  21%|██▏       | 5577/26001 [00:05<00:20, 1009.38it/s]Shapley Value Sampling attribution:  23%|██▎       | 6086/26001 [00:06<00:19, 1011.93it/s]Shapley Value Sampling attribution:  25%|██▌       | 6595/26001 [00:06<00:19, 1013.72it/s]Shapley Value Sampling attribution:  27%|██▋       | 7104/26001 [00:07<00:18, 1014.99it/s]Shapley Value Sampling attribution:  29%|██▉       | 7612/26001 [00:07<00:18, 1008.23it/s]Shapley Value Sampling attribution:  31%|███       | 8118/26001 [00:08<00:17, 1009.24it/s]Shapley Value Sampling attribution:  33%|███▎      | 8624/26001 [00:08<00:17, 1009.78it/s]Shapley Value Sampling attribution:  35%|███▌      | 9133/26001 [00:09<00:16, 1011.86it/s]Shapley Value Sampling attribution:  37%|███▋      | 9643/26001 [00:09<00:16, 1013.86it/s]Shapley Value Sampling attribution:  39%|███▉      | 10150/26001 [00:10<00:15, 1007.52it/s]Shapley Value Sampling attribution:  41%|████      | 10656/26001 [00:10<00:15, 1008.57it/s]Shapley Value Sampling attribution:  43%|████▎     | 11162/26001 [00:11<00:14, 1009.11it/s]Shapley Value Sampling attribution:  45%|████▍     | 11668/26001 [00:11<00:14, 1009.72it/s]Shapley Value Sampling attribution:  47%|████▋     | 12173/26001 [00:12<00:13, 1009.71it/s]Shapley Value Sampling attribution:  49%|████▉     | 12679/26001 [00:12<00:13, 1010.26it/s]Shapley Value Sampling attribution:  51%|█████     | 13186/26001 [00:13<00:12, 1011.26it/s]Shapley Value Sampling attribution:  53%|█████▎    | 13692/26001 [00:13<00:12, 1010.57it/s]Shapley Value Sampling attribution:  55%|█████▍    | 14198/26001 [00:14<00:11, 1004.04it/s]Shapley Value Sampling attribution:  57%|█████▋    | 14702/26001 [00:14<00:11, 1004.87it/s]Shapley Value Sampling attribution:  58%|█████▊    | 15208/26001 [00:15<00:10, 1006.47it/s]Shapley Value Sampling attribution:  60%|██████    | 15713/26001 [00:15<00:10, 1007.42it/s]Shapley Value Sampling attribution:  62%|██████▏   | 16219/26001 [00:16<00:09, 1008.21it/s]Shapley Value Sampling attribution:  64%|██████▍   | 16726/26001 [00:16<00:09, 1009.73it/s]Shapley Value Sampling attribution:  66%|██████▋   | 17231/26001 [00:17<00:08, 1009.39it/s]Shapley Value Sampling attribution:  68%|██████▊   | 17736/26001 [00:17<00:08, 1008.85it/s]Shapley Value Sampling attribution:  70%|███████   | 18243/26001 [00:18<00:07, 1009.98it/s]Shapley Value Sampling attribution:  72%|███████▏  | 18748/26001 [00:18<00:07, 1008.25it/s]Shapley Value Sampling attribution:  74%|███████▍  | 19254/26001 [00:19<00:06, 1009.37it/s]Shapley Value Sampling attribution:  76%|███████▌  | 19759/26001 [00:19<00:06, 1008.87it/s]Shapley Value Sampling attribution:  78%|███████▊  | 20265/26001 [00:20<00:05, 1009.58it/s]Shapley Value Sampling attribution:  80%|███████▉  | 20773/26001 [00:20<00:05, 1011.05it/s]Shapley Value Sampling attribution:  82%|████████▏ | 21280/26001 [00:21<00:04, 1011.75it/s]Shapley Value Sampling attribution:  84%|████████▍ | 21787/26001 [00:21<00:04, 1012.16it/s]Shapley Value Sampling attribution:  86%|████████▌ | 22294/26001 [00:22<00:03, 1012.28it/s]Shapley Value Sampling attribution:  88%|████████▊ | 22801/26001 [00:22<00:03, 1012.19it/s]Shapley Value Sampling attribution:  90%|████████▉ | 23308/26001 [00:23<00:02, 1012.62it/s]Shapley Value Sampling attribution:  92%|█████████▏| 23815/26001 [00:23<00:02, 1009.59it/s]Shapley Value Sampling attribution:  94%|█████████▎| 24321/26001 [00:24<00:01, 1010.23it/s]Shapley Value Sampling attribution:  95%|█████████▌| 24827/26001 [00:24<00:01, 995.19it/s] Shapley Value Sampling attribution:  97%|█████████▋| 25333/26001 [00:25<00:00, 999.91it/s]Shapley Value Sampling attribution:  99%|█████████▉| 25838/26001 [00:25<00:00, 1002.50it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:25<00:00, 1008.88it/s]
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 501/26001 [00:00<00:25, 1000.99it/s]Shapley Value Sampling attribution:   4%|▍         | 1003/26001 [00:01<00:24, 1002.61it/s]Shapley Value Sampling attribution:   6%|▌         | 1509/26001 [00:01<00:24, 1006.48it/s]Shapley Value Sampling attribution:   8%|▊         | 2014/26001 [00:02<00:23, 1007.64it/s]Shapley Value Sampling attribution:  10%|▉         | 2522/26001 [00:02<00:23, 1010.05it/s]Shapley Value Sampling attribution:  12%|█▏        | 3028/26001 [00:03<00:22, 1010.52it/s]Shapley Value Sampling attribution:  14%|█▎        | 3534/26001 [00:03<00:22, 1010.41it/s]Shapley Value Sampling attribution:  16%|█▌        | 4042/26001 [00:04<00:21, 1011.91it/s]Shapley Value Sampling attribution:  17%|█▋        | 4548/26001 [00:04<00:21, 1011.56it/s]Shapley Value Sampling attribution:  19%|█▉        | 5056/26001 [00:05<00:20, 1012.89it/s]Shapley Value Sampling attribution:  21%|██▏       | 5563/26001 [00:05<00:20, 1010.62it/s]Shapley Value Sampling attribution:  23%|██▎       | 6069/26001 [00:06<00:19, 1003.50it/s]Shapley Value Sampling attribution:  25%|██▌       | 6571/26001 [00:06<00:19, 999.64it/s] Shapley Value Sampling attribution:  27%|██▋       | 7071/26001 [00:07<00:18, 997.35it/s]Shapley Value Sampling attribution:  29%|██▉       | 7570/26001 [00:07<00:18, 996.88it/s]Shapley Value Sampling attribution:  31%|███       | 8069/26001 [00:08<00:18, 972.57it/s]Shapley Value Sampling attribution:  33%|███▎      | 8556/26001 [00:08<00:18, 965.66it/s]Shapley Value Sampling attribution:  35%|███▍      | 9040/26001 [00:09<00:17, 952.98it/s]Shapley Value Sampling attribution:  37%|███▋      | 9535/26001 [00:09<00:17, 963.35it/s]Shapley Value Sampling attribution:  39%|███▊      | 10030/26001 [00:10<00:16, 970.69it/s]Shapley Value Sampling attribution:  40%|████      | 10516/26001 [00:10<00:15, 968.88it/s]Shapley Value Sampling attribution:  42%|████▏     | 11001/26001 [00:11<00:16, 936.24it/s]Shapley Value Sampling attribution:  44%|████▍     | 11471/26001 [00:11<00:16, 905.71it/s]Shapley Value Sampling attribution:  46%|████▌     | 11926/26001 [00:12<00:16, 879.31it/s]Shapley Value Sampling attribution:  48%|████▊     | 12369/26001 [00:12<00:15, 880.97it/s]Shapley Value Sampling attribution:  49%|████▉     | 12811/26001 [00:13<00:15, 836.79it/s]Shapley Value Sampling attribution:  51%|█████     | 13232/26001 [00:13<00:16, 792.14it/s]Shapley Value Sampling attribution:  52%|█████▏    | 13632/26001 [00:14<00:16, 745.50it/s]Shapley Value Sampling attribution:  54%|█████▍    | 14009/26001 [00:15<00:16, 735.98it/s]Shapley Value Sampling attribution:  56%|█████▌    | 14504/26001 [00:15<00:14, 805.43it/s]Shapley Value Sampling attribution:  58%|█████▊    | 14994/26001 [00:16<00:12, 854.44it/s]Shapley Value Sampling attribution:  60%|█████▉    | 15486/26001 [00:16<00:11, 891.11it/s]Shapley Value Sampling attribution:  61%|██████▏   | 15977/26001 [00:17<00:10, 917.46it/s]Shapley Value Sampling attribution:  63%|██████▎   | 16469/26001 [00:17<00:10, 936.55it/s]Shapley Value Sampling attribution:  65%|██████▌   | 16954/26001 [00:18<00:09, 946.33it/s]Shapley Value Sampling attribution:  67%|██████▋   | 17446/26001 [00:18<00:08, 957.50it/s]Shapley Value Sampling attribution:  69%|██████▉   | 17927/26001 [00:19<00:08, 957.32it/s]Shapley Value Sampling attribution:  71%|███████   | 18419/26001 [00:19<00:07, 965.10it/s]Shapley Value Sampling attribution:  73%|███████▎  | 18911/26001 [00:20<00:07, 970.69it/s]Shapley Value Sampling attribution:  75%|███████▍  | 19402/26001 [00:20<00:06, 973.48it/s]Shapley Value Sampling attribution:  76%|███████▋  | 19890/26001 [00:21<00:06, 955.52it/s]Shapley Value Sampling attribution:  78%|███████▊  | 20369/26001 [00:21<00:05, 954.13it/s]Shapley Value Sampling attribution:  80%|████████  | 20847/26001 [00:22<00:05, 952.75it/s]Shapley Value Sampling attribution:  82%|████████▏ | 21324/26001 [00:22<00:04, 951.80it/s]Shapley Value Sampling attribution:  84%|████████▍ | 21801/26001 [00:23<00:04, 949.43it/s]Shapley Value Sampling attribution:  86%|████████▌ | 22276/26001 [00:23<00:03, 949.35it/s]Shapley Value Sampling attribution:  88%|████████▊ | 22751/26001 [00:24<00:03, 932.95it/s]Shapley Value Sampling attribution:  89%|████████▉ | 23218/26001 [00:25<00:03, 777.13it/s]Shapley Value Sampling attribution:  91%|█████████ | 23629/26001 [00:26<00:03, 640.41it/s]Shapley Value Sampling attribution:  92%|█████████▏| 23982/26001 [00:26<00:03, 574.13it/s]Shapley Value Sampling attribution:  93%|█████████▎| 24295/26001 [00:27<00:03, 531.68it/s]Shapley Value Sampling attribution:  95%|█████████▍| 24579/26001 [00:28<00:02, 503.76it/s]Shapley Value Sampling attribution:  96%|█████████▌| 24842/26001 [00:28<00:02, 484.40it/s]Shapley Value Sampling attribution:  97%|█████████▋| 25091/26001 [00:29<00:01, 470.27it/s]Shapley Value Sampling attribution:  97%|█████████▋| 25330/26001 [00:29<00:01, 463.41it/s]Shapley Value Sampling attribution:  99%|█████████▊| 25617/26001 [00:30<00:00, 491.78it/s]Shapley Value Sampling attribution: 100%|█████████▉| 25959/26001 [00:30<00:00, 543.47it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:30<00:00, 839.11it/s]
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:16<06:45, 16.21s/it]importance j:   8%|▊         | 2/26 [00:27<05:23, 13.47s/it]importance j:  12%|█▏        | 3/26 [00:44<05:39, 14.77s/it]importance j:  15%|█▌        | 4/26 [00:56<05:05, 13.91s/it]importance j:  19%|█▉        | 5/26 [01:11<05:02, 14.39s/it]importance j:  23%|██▎       | 6/26 [01:28<05:00, 15.02s/it]importance j:  27%|██▋       | 7/26 [01:40<04:27, 14.05s/it]importance j:  31%|███       | 8/26 [01:55<04:22, 14.58s/it]importance j:  35%|███▍      | 9/26 [02:07<03:51, 13.60s/it]importance j:  38%|███▊      | 10/26 [02:23<03:50, 14.43s/it]importance j:  42%|████▏     | 11/26 [02:35<03:22, 13.53s/it]importance j:  46%|████▌     | 12/26 [02:50<03:19, 14.22s/it]importance j:  50%|█████     | 13/26 [03:02<02:55, 13.51s/it]importance j:  54%|█████▍    | 14/26 [03:18<02:50, 14.18s/it]importance j:  58%|█████▊    | 15/26 [03:30<02:28, 13.53s/it]importance j:  62%|██████▏   | 16/26 [03:46<02:23, 14.35s/it]importance j:  65%|██████▌   | 17/26 [03:58<02:02, 13.59s/it]importance j:  69%|██████▉   | 18/26 [04:15<01:56, 14.59s/it]importance j:  73%|███████▎  | 19/26 [04:27<01:37, 13.87s/it]importance j:  77%|███████▋  | 20/26 [04:45<01:30, 15.14s/it]importance j:  81%|████████  | 21/26 [04:58<01:11, 14.34s/it]importance j:  85%|████████▍ | 22/26 [05:17<01:03, 15.86s/it]importance j:  88%|████████▊ | 23/26 [05:37<00:50, 16.93s/it]importance j:  92%|█████████▏| 24/26 [05:49<00:31, 15.62s/it]importance j:  96%|█████████▌| 25/26 [06:11<00:17, 17.36s/it]importance j: 100%|██████████| 26/26 [06:29<00:00, 17.56s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7537567019462585, train_loss: 0.7633345127105713
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43861326575279236, train_loss: 0.40541303157806396
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33083802461624146, train_loss: 0.2933775782585144
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28816479444503784, train_loss: 0.2374717891216278
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2681552469730377, train_loss: 0.20115159451961517
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2586781680583954, train_loss: 0.16820064187049866
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2551572620868683, train_loss: 0.13643574714660645
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2548157274723053, train_loss: 0.137222021818161
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6686397194862366, train_loss: 0.6364900469779968
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4327159523963928, train_loss: 0.3332846760749817
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3826523423194885, train_loss: 0.24195310473442078
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3737594783306122, train_loss: 0.19163918495178223
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37372851371765137, train_loss: 0.17631441354751587
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7346840500831604, train_loss: 0.7345001101493835
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43286338448524475, train_loss: 0.3784148097038269
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35634300112724304, train_loss: 0.25402146577835083
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3372785747051239, train_loss: 0.19677387177944183
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33508923649787903, train_loss: 0.16993264853954315
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7953125238418579, train_loss: 0.8240477442741394
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46048858761787415, train_loss: 0.4165544807910919
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35913053154945374, train_loss: 0.274283766746521
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33202213048934937, train_loss: 0.20907947421073914
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3269136846065521, train_loss: 0.1724911630153656
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4671437442302704, train_loss: 0.4762723445892334
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1435890644788742, train_loss: 0.07488621771335602
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13755375146865845, train_loss: 0.05128992348909378
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1372801810503006, train_loss: 0.0475492961704731
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13732881844043732, train_loss: 0.04742655158042908
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4158734381198883, train_loss: 0.4270889461040497
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12161677330732346, train_loss: 0.07770179212093353
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1202302798628807, train_loss: 0.06527414172887802
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12022306025028229, train_loss: 0.06226281449198723
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12052956223487854, train_loss: 0.06196140497922897
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7065085172653198, train_loss: 0.7176225185394287
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41917794942855835, train_loss: 0.37984949350357056
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33074867725372314, train_loss: 0.27641743421554565
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29827454686164856, train_loss: 0.2249947488307953
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2816959023475647, train_loss: 0.18662968277931213
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2723233699798584, train_loss: 0.15675486624240875
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.620531439781189, train_loss: 0.6030375957489014
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38895711302757263, train_loss: 0.3264034390449524
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34662288427352905, train_loss: 0.23778362572193146
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33985912799835205, train_loss: 0.1861134171485901
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3403182923793793, train_loss: 0.16960585117340088
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6741874814033508, train_loss: 0.6555256247520447
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4111637473106384, train_loss: 0.3494589924812317
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3461226224899292, train_loss: 0.2526789903640747
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3305063247680664, train_loss: 0.19435010850429535
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32818925380706787, train_loss: 0.16646866500377655
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6037186980247498, train_loss: 0.6346577405929565
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3883543312549591, train_loss: 0.34429270029067993
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3348647356033325, train_loss: 0.24579742550849915
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3229047358036041, train_loss: 0.19589227437973022
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.32206299901008606, train_loss: 0.1700192093849182
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.535446286201477, train_loss: 0.5687470436096191
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14906129240989685, train_loss: 0.07383975386619568
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14537779986858368, train_loss: 0.05949902534484863
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14483143389225006, train_loss: 0.05553538352251053
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14450375735759735, train_loss: 0.05131860822439194
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2995612919330597, train_loss: 0.3399064540863037
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11232516169548035, train_loss: 0.0782587006688118
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10999258607625961, train_loss: 0.05967599153518677
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10999893397092819, train_loss: 0.06055670231580734
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10992297530174255, train_loss: 0.05893760174512863
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.958407461643219, train_loss: 0.9460645914077759
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5390086770057678, train_loss: 0.4778097867965698
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3688277006149292, train_loss: 0.3102472424507141
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31203579902648926, train_loss: 0.23800519108772278
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28659382462501526, train_loss: 0.19696399569511414
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2740185856819153, train_loss: 0.16471914947032928
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26755648851394653, train_loss: 0.13877108693122864
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2661712169647217, train_loss: 0.12704147398471832
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.265685498714447, train_loss: 0.1277218759059906
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6400629878044128, train_loss: 0.6174447536468506
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41361203789711, train_loss: 0.33727124333381653
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3605814278125763, train_loss: 0.24477586150169373
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3498024642467499, train_loss: 0.1936812549829483
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35015469789505005, train_loss: 0.1801915466785431
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6056177616119385, train_loss: 0.5843859910964966
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38434579968452454, train_loss: 0.3209550380706787
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32970380783081055, train_loss: 0.2362617552280426
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3148777484893799, train_loss: 0.18791091442108154
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3128912150859833, train_loss: 0.16323907673358917
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5425675511360168, train_loss: 0.5428363084793091
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3778456151485443, train_loss: 0.3068971037864685
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3476821184158325, train_loss: 0.2291399985551834
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3447948098182678, train_loss: 0.19036896526813507
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3453638255596161, train_loss: 0.17666955292224884
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3077479600906372, train_loss: 0.36844301223754883
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1509510576725006, train_loss: 0.06887245178222656
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1490437537431717, train_loss: 0.062038734555244446
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14850187301635742, train_loss: 0.05964459851384163
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1483767181634903, train_loss: 0.05675365403294563
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6862407922744751, train_loss: 0.800333559513092
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.10910389572381973, train_loss: 0.07998089492321014
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10577789694070816, train_loss: 0.06254515051841736
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1053924411535263, train_loss: 0.06048755347728729
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10531577467918396, train_loss: 0.057459473609924316
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0436897277832031, train_loss: 0.9994721412658691
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6044434309005737, train_loss: 0.49959278106689453
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.40185096859931946, train_loss: 0.3081560730934143
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3364177644252777, train_loss: 0.2364215850830078
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3089860677719116, train_loss: 0.19412072002887726
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.29864272475242615, train_loss: 0.1628502458333969
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.82041335105896, train_loss: 0.8702829480171204
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.48630255460739136, train_loss: 0.4443713426589966
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3749619722366333, train_loss: 0.28101998567581177
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3497791886329651, train_loss: 0.22085648775100708
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3486623167991638, train_loss: 0.18317633867263794
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6222550272941589, train_loss: 0.6311241984367371
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39512112736701965, train_loss: 0.3276403546333313
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3426560163497925, train_loss: 0.23459704220294952
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33054879307746887, train_loss: 0.19129163026809692
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33036333322525024, train_loss: 0.17038393020629883
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5569204688072205, train_loss: 0.5392710566520691
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.373020201921463, train_loss: 0.30514082312583923
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33999794721603394, train_loss: 0.23172026872634888
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33776381611824036, train_loss: 0.18918678164482117
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.338206022977829, train_loss: 0.18721126019954681
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5083603858947754, train_loss: 0.5865424871444702
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13912533223628998, train_loss: 0.07257076352834702
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13302376866340637, train_loss: 0.05161274969577789
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1321600377559662, train_loss: 0.05109827220439911
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1319703310728073, train_loss: 0.04757751151919365
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.32354971766471863, train_loss: 0.36745086312294006
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11600922048091888, train_loss: 0.0837431326508522
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11158566921949387, train_loss: 0.05632374808192253
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11141228675842285, train_loss: 0.05312371253967285
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11152233183383942, train_loss: 0.05142543092370033
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8754479289054871, train_loss: 0.8442687392234802
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5159836411476135, train_loss: 0.44495099782943726
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37531590461730957, train_loss: 0.3073021471500397
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3272504508495331, train_loss: 0.24473312497138977
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30939337611198425, train_loss: 0.20419183373451233
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.30294525623321533, train_loss: 0.17564883828163147
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9029290080070496, train_loss: 0.9436355829238892
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5223792791366577, train_loss: 0.4753715991973877
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38857144117355347, train_loss: 0.2856544256210327
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3615437150001526, train_loss: 0.21746709942817688
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3597565293312073, train_loss: 0.1864120066165924
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8060945868492126, train_loss: 0.8326908349990845
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.46535524725914, train_loss: 0.41503527760505676
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36292722821235657, train_loss: 0.2668924629688263
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3365950286388397, train_loss: 0.2007921040058136
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3337348699569702, train_loss: 0.16830132901668549
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.842039167881012, train_loss: 0.8108255863189697
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4738915264606476, train_loss: 0.39873331785202026
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3849716782569885, train_loss: 0.2617872953414917
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37030088901519775, train_loss: 0.20017749071121216
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3710673451423645, train_loss: 0.18775567412376404
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5432456731796265, train_loss: 0.6015517711639404
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13587366044521332, train_loss: 0.07080859690904617
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13482016324996948, train_loss: 0.05839807167649269
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1345508098602295, train_loss: 0.056812308728694916
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1346052885055542, train_loss: 0.04955573379993439
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.32023856043815613, train_loss: 0.390077143907547
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.10743057727813721, train_loss: 0.08321234583854675
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10630635172128677, train_loss: 0.07193908095359802
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10650196671485901, train_loss: 0.06640733778476715
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1065235584974289, train_loss: 0.06551551073789597
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6526498794555664, train_loss: 0.6468770503997803
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3934868574142456, train_loss: 0.3649299740791321
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3080981373786926, train_loss: 0.267902672290802
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2757536768913269, train_loss: 0.21928814053535461
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2602865993976593, train_loss: 0.17999936640262604
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2531696557998657, train_loss: 0.15699502825737
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2504848539829254, train_loss: 0.14788603782653809
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.643907904624939, train_loss: 0.6601496934890747
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4120963215827942, train_loss: 0.35486137866973877
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3545241951942444, train_loss: 0.2491861879825592
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34373268485069275, train_loss: 0.19715642929077148
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3439790606498718, train_loss: 0.17682939767837524
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6724090576171875, train_loss: 0.6617653965950012
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4038219451904297, train_loss: 0.3433617353439331
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34045663475990295, train_loss: 0.23999789357185364
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32692956924438477, train_loss: 0.1879923790693283
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32686614990234375, train_loss: 0.16596846282482147
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1066721677780151, train_loss: 1.1234594583511353
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6395063996315002, train_loss: 0.582111120223999
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41608235239982605, train_loss: 0.33696413040161133
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3494405746459961, train_loss: 0.24473796784877777
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3288381099700928, train_loss: 0.190475195646286
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.41299742460250854, train_loss: 0.3986995816230774
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14210914075374603, train_loss: 0.07305805385112762
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1363227665424347, train_loss: 0.05771281197667122
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13566149771213531, train_loss: 0.052138395607471466
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13518260419368744, train_loss: 0.052237723022699356
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8739987015724182, train_loss: 1.0494530200958252
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14486272633075714, train_loss: 0.0800497829914093
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13958659768104553, train_loss: 0.05406202748417854
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13864123821258545, train_loss: 0.052211157977581024
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13807813823223114, train_loss: 0.04821658134460449
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.777807354927063, train_loss: 0.7628679871559143
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45615723729133606, train_loss: 0.4049094319343567
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33859026432037354, train_loss: 0.28229501843452454
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2931588888168335, train_loss: 0.22795012593269348
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27197664976119995, train_loss: 0.19010648131370544
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26061758399009705, train_loss: 0.16574597358703613
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2557169497013092, train_loss: 0.13588590919971466
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9145969748497009, train_loss: 0.943163275718689
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5449360013008118, train_loss: 0.4964563846588135
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3968317210674286, train_loss: 0.29783618450164795
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3599684238433838, train_loss: 0.2269790917634964
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3510276973247528, train_loss: 0.18490630388259888
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7017207145690918, train_loss: 0.6989626288414001
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4292967915534973, train_loss: 0.37160488963127136
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3567129373550415, train_loss: 0.2518933415412903
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3379262387752533, train_loss: 0.20073923468589783
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33652183413505554, train_loss: 0.17191842198371887
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6219085454940796, train_loss: 0.6179835796356201
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3828488290309906, train_loss: 0.3261684477329254
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3386005759239197, train_loss: 0.23783157765865326
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3322807550430298, train_loss: 0.19553814828395844
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33252790570259094, train_loss: 0.195561945438385
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4475732147693634, train_loss: 0.44868290424346924
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13554194569587708, train_loss: 0.07433917373418808
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1311950981616974, train_loss: 0.04940075799822807
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1312694400548935, train_loss: 0.04920487850904465
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13083304464817047, train_loss: 0.046229541301727295
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.629913866519928, train_loss: 0.6697438955307007
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12763148546218872, train_loss: 0.08488240838050842
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12688829004764557, train_loss: 0.06490641087293625
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12662702798843384, train_loss: 0.06074649840593338
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12639407813549042, train_loss: 0.06299005448818207
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7290540337562561, train_loss: 0.7690143585205078
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4342547059059143, train_loss: 0.41288647055625916
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3314814567565918, train_loss: 0.28717246651649475
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29162099957466125, train_loss: 0.2310936152935028
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2730153203010559, train_loss: 0.19490325450897217
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26436522603034973, train_loss: 0.1661558449268341
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.807513952255249, train_loss: 0.8215920329093933
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4933001697063446, train_loss: 0.4281626343727112
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3919752538204193, train_loss: 0.27705949544906616
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3680240213871002, train_loss: 0.2164784073829651
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36611810326576233, train_loss: 0.19196954369544983
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6294546723365784, train_loss: 0.6013084650039673
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38086506724357605, train_loss: 0.31935304403305054
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.331257700920105, train_loss: 0.22647356986999512
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32201600074768066, train_loss: 0.17653626203536987
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3223312199115753, train_loss: 0.16760237514972687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6242567896842957, train_loss: 0.6133903861045837
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3910055458545685, train_loss: 0.3336798846721649
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34264522790908813, train_loss: 0.24090644717216492
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33462637662887573, train_loss: 0.190606951713562
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3357405662536621, train_loss: 0.1822356879711151
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39732107520103455, train_loss: 0.4315547049045563
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1364082545042038, train_loss: 0.06534551084041595
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13363121449947357, train_loss: 0.05330034717917442
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13364948332309723, train_loss: 0.055046092718839645
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13354437053203583, train_loss: 0.049351416528224945
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.48492029309272766, train_loss: 0.5382437705993652
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12415032088756561, train_loss: 0.07802306115627289
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12044727802276611, train_loss: 0.05402756482362747
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12039344757795334, train_loss: 0.0493878535926342
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12042059004306793, train_loss: 0.04911131411790848
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6836190223693848, train_loss: 0.6754909753799438
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3975714445114136, train_loss: 0.36371463537216187
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3094386160373688, train_loss: 0.2653512954711914
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2813382148742676, train_loss: 0.21697774529457092
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27206525206565857, train_loss: 0.17861875891685486
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6829730272293091, train_loss: 0.6729457974433899
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43140512704849243, train_loss: 0.3518452048301697
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37778905034065247, train_loss: 0.2457517832517624
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36586377024650574, train_loss: 0.19901491701602936
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36516091227531433, train_loss: 0.16976964473724365
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6385964155197144, train_loss: 0.6505995988845825
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4005632996559143, train_loss: 0.33257681131362915
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3450024127960205, train_loss: 0.23274719715118408
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3317735195159912, train_loss: 0.18073543906211853
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33112192153930664, train_loss: 0.15968218445777893
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5053800940513611, train_loss: 0.4951101243495941
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36256158351898193, train_loss: 0.2988407015800476
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33697476983070374, train_loss: 0.23185111582279205
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3356419801712036, train_loss: 0.20813871920108795
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33591726422309875, train_loss: 0.20159491896629333
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.653973400592804, train_loss: 0.6585510969161987
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.160149484872818, train_loss: 0.06535258889198303
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15637551248073578, train_loss: 0.051352910697460175
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15649603307247162, train_loss: 0.05019687861204147
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15519820153713226, train_loss: 0.04953547567129135
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4485803544521332, train_loss: 0.5656399726867676
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11646346002817154, train_loss: 0.08399178087711334
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11124513298273087, train_loss: 0.06049087643623352
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11131057143211365, train_loss: 0.05856010317802429
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11113501340150833, train_loss: 0.055262453854084015
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0933723449707031, train_loss: 1.0685572624206543
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.636981189250946, train_loss: 0.5507932305335999
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.40217453241348267, train_loss: 0.33505770564079285
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3232646882534027, train_loss: 0.2512320876121521
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2921959161758423, train_loss: 0.19713141024112701
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27859219908714294, train_loss: 0.16703298687934875
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.27576160430908203, train_loss: 0.14932627975940704
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6862604022026062, train_loss: 0.6861907839775085
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42550796270370483, train_loss: 0.3535997271537781
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3693969249725342, train_loss: 0.25181668996810913
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35864558815956116, train_loss: 0.19350078701972961
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35873642563819885, train_loss: 0.1818503737449646
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8107322454452515, train_loss: 0.8606423139572144
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.467129111289978, train_loss: 0.4342053234577179
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36229169368743896, train_loss: 0.2740863561630249
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3357332646846771, train_loss: 0.1982227861881256
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3277968168258667, train_loss: 0.16432514786720276
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0954962968826294, train_loss: 1.1226136684417725
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6262614727020264, train_loss: 0.5690587162971497
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4154776930809021, train_loss: 0.32481497526168823
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.357861191034317, train_loss: 0.23737770318984985
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34365493059158325, train_loss: 0.18782149255275726
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.344011515378952, train_loss: 0.3468974828720093
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1517939269542694, train_loss: 0.07518646121025085
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14428657293319702, train_loss: 0.05207975208759308
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14286760985851288, train_loss: 0.04625846818089485
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14216971397399902, train_loss: 0.043517451733350754
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3368808329105377, train_loss: 0.41638484597206116
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1116841733455658, train_loss: 0.08038493990898132
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1098136231303215, train_loss: 0.0643550455570221
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10972672700881958, train_loss: 0.059364043176174164
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10966448485851288, train_loss: 0.0593118891119957
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7554509043693542, train_loss: 0.7568667531013489
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4419094920158386, train_loss: 0.4075564742088318
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3338615596294403, train_loss: 0.28952300548553467
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29334717988967896, train_loss: 0.2383178174495697
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27887067198753357, train_loss: 0.19447313249111176
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2750451862812042, train_loss: 0.16252729296684265
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9736958742141724, train_loss: 0.9916905164718628
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5617578029632568, train_loss: 0.5075088739395142
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39757809042930603, train_loss: 0.2927212715148926
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3605843782424927, train_loss: 0.20834945142269135
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3549414873123169, train_loss: 0.1685492992401123
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6677006483078003, train_loss: 0.661920428276062
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3970487117767334, train_loss: 0.3493056893348694
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3385481536388397, train_loss: 0.24572162330150604
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3278554081916809, train_loss: 0.19312749803066254
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3278997242450714, train_loss: 0.18245774507522583
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7705642580986023, train_loss: 0.8234425187110901
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46001988649368286, train_loss: 0.4150737524032593
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3594755232334137, train_loss: 0.27043354511260986
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3348824679851532, train_loss: 0.2085750699043274
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33235999941825867, train_loss: 0.1730000525712967
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4657352566719055, train_loss: 0.44377344846725464
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13261233270168304, train_loss: 0.07016361504793167
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12786279618740082, train_loss: 0.04784172400832176
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1277712732553482, train_loss: 0.04270791634917259
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12788763642311096, train_loss: 0.04405434429645538
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.32033997774124146, train_loss: 0.3696174621582031
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11444805562496185, train_loss: 0.08186377584934235
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1118888184428215, train_loss: 0.0623994879424572
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11181677877902985, train_loss: 0.060625120997428894
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11171116679906845, train_loss: 0.05900739133358002
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5747115612030029, train_loss: 0.6247625350952148
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3626212775707245, train_loss: 0.3552475571632385
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2984212338924408, train_loss: 0.2597774267196655
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27606043219566345, train_loss: 0.2265819013118744
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2677205204963684, train_loss: 0.18367314338684082
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2661241888999939, train_loss: 0.16038362681865692
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9600966572761536, train_loss: 0.9721521139144897
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5633904933929443, train_loss: 0.5071378946304321
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40485265851020813, train_loss: 0.3009221851825714
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3657083213329315, train_loss: 0.22827664017677307
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3577462136745453, train_loss: 0.18583683669567108
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7354604005813599, train_loss: 0.7469151020050049
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4578060805797577, train_loss: 0.38002797961235046
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3751015067100525, train_loss: 0.24904802441596985
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.354207307100296, train_loss: 0.19234716892242432
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3522694706916809, train_loss: 0.16298808157444
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9197968244552612, train_loss: 0.9430418014526367
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5414218902587891, train_loss: 0.4685114622116089
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3980952203273773, train_loss: 0.28127235174179077
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36011558771133423, train_loss: 0.21111555397510529
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3514854609966278, train_loss: 0.16811393201351166
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4584865868091583, train_loss: 0.4245816469192505
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16011913120746613, train_loss: 0.07386419177055359
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14900465309619904, train_loss: 0.047125037759542465
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14788495004177094, train_loss: 0.04028531163930893
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14719930291175842, train_loss: 0.04078742116689682
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8116227388381958, train_loss: 0.9097809791564941
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12149015814065933, train_loss: 0.07988275587558746
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11735974997282028, train_loss: 0.056077782064676285
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11757918447256088, train_loss: 0.05470719933509827
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11774361878633499, train_loss: 0.0517868809401989
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5247372984886169, train_loss: 0.5636832118034363
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.34832847118377686, train_loss: 0.3380017876625061
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3036961257457733, train_loss: 0.264163613319397
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29054999351501465, train_loss: 0.2110876739025116
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28744444251060486, train_loss: 0.18938271701335907
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.28703588247299194, train_loss: 0.18721792101860046
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2868000864982605, train_loss: 0.17925101518630981
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8463836908340454, train_loss: 0.8921321630477905
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.487621009349823, train_loss: 0.4557369351387024
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3709546625614166, train_loss: 0.28177547454833984
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.341270387172699, train_loss: 0.22360308468341827
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3351271152496338, train_loss: 0.17867620289325714
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7027269005775452, train_loss: 0.6774172782897949
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4163232147693634, train_loss: 0.3442761301994324
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35057732462882996, train_loss: 0.23798412084579468
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33656325936317444, train_loss: 0.18325579166412354
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3361528813838959, train_loss: 0.16539141535758972
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7485501170158386, train_loss: 0.751518964767456
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.45678457617759705, train_loss: 0.37625449895858765
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3655584454536438, train_loss: 0.24546220898628235
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34362953901290894, train_loss: 0.188789501786232
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34163591265678406, train_loss: 0.16650864481925964
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5737457871437073, train_loss: 0.5544251799583435
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1553131341934204, train_loss: 0.07226157933473587
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1453125774860382, train_loss: 0.04896022751927376
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1442224383354187, train_loss: 0.04628590866923332
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1438896805047989, train_loss: 0.043313778936862946
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.45141398906707764, train_loss: 0.5272217988967896
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13838618993759155, train_loss: 0.08786307275295258
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13006186485290527, train_loss: 0.05823006480932236
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12991152703762054, train_loss: 0.05281437933444977
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12977169454097748, train_loss: 0.05049106478691101
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7528403997421265, train_loss: 0.7385510206222534
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43465760350227356, train_loss: 0.3883316218852997
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.323693186044693, train_loss: 0.2659377455711365
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2852400541305542, train_loss: 0.2161468267440796
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2718909680843353, train_loss: 0.17748096585273743
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2662855386734009, train_loss: 0.14673101902008057
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6392186284065247, train_loss: 0.6430281400680542
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.413777232170105, train_loss: 0.3420952558517456
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.367902934551239, train_loss: 0.24191954731941223
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3624500036239624, train_loss: 0.1983722746372223
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36286547780036926, train_loss: 0.19269728660583496
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6670534014701843, train_loss: 0.710796058177948
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39901450276374817, train_loss: 0.3600309491157532
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3314964473247528, train_loss: 0.24994072318077087
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3174937665462494, train_loss: 0.1922268569469452
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.316914826631546, train_loss: 0.180080384016037
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6099666357040405, train_loss: 0.5905904769897461
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39474979043006897, train_loss: 0.33039915561676025
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3459579348564148, train_loss: 0.23788639903068542
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3360862135887146, train_loss: 0.19319921731948853
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3366474509239197, train_loss: 0.176954448223114
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5899615287780762, train_loss: 0.5337926149368286
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1386033445596695, train_loss: 0.07117771357297897
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13555434346199036, train_loss: 0.05076265335083008
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13486237823963165, train_loss: 0.04785361886024475
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13453464210033417, train_loss: 0.04706086963415146
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35474544763565063, train_loss: 0.4219849407672882
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13521212339401245, train_loss: 0.07940395921468735
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13120436668395996, train_loss: 0.055283404886722565
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13130269944667816, train_loss: 0.05342899635434151
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13102951645851135, train_loss: 0.053652115166187286
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6192832589149475, train_loss: 0.6220250725746155
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39366722106933594, train_loss: 0.3560326397418976
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32533273100852966, train_loss: 0.2653482258319855
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3005228042602539, train_loss: 0.21613802015781403
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29157742857933044, train_loss: 0.18226109445095062
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2891218364238739, train_loss: 0.15177419781684875
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6609683632850647, train_loss: 0.6761027574539185
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.416891485452652, train_loss: 0.3555627465248108
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3579097390174866, train_loss: 0.24850493669509888
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3454285264015198, train_loss: 0.18965770304203033
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3451453447341919, train_loss: 0.1819669008255005
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7677980065345764, train_loss: 0.745965838432312
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4470078647136688, train_loss: 0.38093167543411255
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3669538199901581, train_loss: 0.25039371848106384
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3445294201374054, train_loss: 0.19058829545974731
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3405162990093231, train_loss: 0.15960149466991425
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8663389682769775, train_loss: 0.8525335788726807
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.49218836426734924, train_loss: 0.4213586747646332
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3791649341583252, train_loss: 0.26797670125961304
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35190993547439575, train_loss: 0.20601502060890198
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35005173087120056, train_loss: 0.16831761598587036
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8992200493812561, train_loss: 1.065492868423462
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14232434332370758, train_loss: 0.07197022438049316
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1379365772008896, train_loss: 0.050462909042835236
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1375710368156433, train_loss: 0.05089704692363739
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13717995584011078, train_loss: 0.04913872480392456
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4746439754962921, train_loss: 0.5657685995101929
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1269962042570114, train_loss: 0.0784086287021637
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1227351501584053, train_loss: 0.05586616322398186
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12264901399612427, train_loss: 0.05153665691614151
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12257778644561768, train_loss: 0.04962780326604843
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7015934586524963, train_loss: 0.7222789525985718
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41391056776046753, train_loss: 0.3776547610759735
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.319312185049057, train_loss: 0.272164523601532
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2839809060096741, train_loss: 0.21959152817726135
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2683582305908203, train_loss: 0.178878515958786
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.260570764541626, train_loss: 0.1490531861782074
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2572357952594757, train_loss: 0.1318056881427765
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9493037462234497, train_loss: 1.0043244361877441
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5513646602630615, train_loss: 0.5077115893363953
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39163315296173096, train_loss: 0.2868410646915436
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3559511601924896, train_loss: 0.20914265513420105
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34798523783683777, train_loss: 0.1639096736907959
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.935558021068573, train_loss: 1.0266764163970947
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5368537902832031, train_loss: 0.5293233394622803
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3731703460216522, train_loss: 0.3027532994747162
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3305499255657196, train_loss: 0.2138635218143463
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3215957283973694, train_loss: 0.17089730501174927
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5243972539901733, train_loss: 0.5385664105415344
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36729922890663147, train_loss: 0.30948400497436523
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33633098006248474, train_loss: 0.23076581954956055
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33305978775024414, train_loss: 0.19364304840564728
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3332538306713104, train_loss: 0.1885109692811966
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6467891335487366, train_loss: 0.635400652885437
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17350293695926666, train_loss: 0.08088081330060959
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1584140807390213, train_loss: 0.05519477650523186
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15630440413951874, train_loss: 0.04109419882297516
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15619994699954987, train_loss: 0.04107050597667694
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6268734335899353, train_loss: 0.8359629511833191
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11816191673278809, train_loss: 0.08450377732515335
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11457499116659164, train_loss: 0.0645955353975296
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11438655108213425, train_loss: 0.06416915357112885
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11421774327754974, train_loss: 0.060534290969371796
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6766323447227478, train_loss: 0.7184869050979614
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40577077865600586, train_loss: 0.36595478653907776
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32436925172805786, train_loss: 0.2635689377784729
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2978638708591461, train_loss: 0.21316859126091003
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2881179451942444, train_loss: 0.17951413989067078
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0784791707992554, train_loss: 1.121108055114746
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.612898588180542, train_loss: 0.5706312656402588
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41519325971603394, train_loss: 0.31254059076309204
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3714045584201813, train_loss: 0.2227732241153717
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36513182520866394, train_loss: 0.17631053924560547
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7053409218788147, train_loss: 0.7430944442749023
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42558860778808594, train_loss: 0.3906732201576233
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3386381268501282, train_loss: 0.254642128944397
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31673792004585266, train_loss: 0.19966787099838257
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31421083211898804, train_loss: 0.17341002821922302
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6890923976898193, train_loss: 0.7065093517303467
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4235050678253174, train_loss: 0.3746646046638489
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3507416844367981, train_loss: 0.26019975543022156
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3334398865699768, train_loss: 0.19989560544490814
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33069270849227905, train_loss: 0.16573262214660645
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.43005985021591187, train_loss: 0.42315906286239624
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14530760049819946, train_loss: 0.07481446862220764
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1442263275384903, train_loss: 0.06471610069274902
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1431678682565689, train_loss: 0.061291977763175964
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14297252893447876, train_loss: 0.05622110515832901
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4229949116706848, train_loss: 0.4350994825363159
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13318878412246704, train_loss: 0.08238030970096588
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12686651945114136, train_loss: 0.057962387800216675
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12639161944389343, train_loss: 0.05394899100065231
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.126100555062294, train_loss: 0.05231437832117081
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8904386758804321, train_loss: 0.86931973695755
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5243256092071533, train_loss: 0.46631425619125366
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3712629973888397, train_loss: 0.31241685152053833
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31549400091171265, train_loss: 0.24176910519599915
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2918824851512909, train_loss: 0.20859922468662262
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.28209835290908813, train_loss: 0.18037670850753784
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.27846449613571167, train_loss: 0.15346971154212952
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6343019008636475, train_loss: 0.6150678396224976
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42548879981040955, train_loss: 0.3371722996234894
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38110509514808655, train_loss: 0.23921068012714386
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37606915831565857, train_loss: 0.20381328463554382
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37619203329086304, train_loss: 0.204392671585083
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7395986318588257, train_loss: 0.7505285739898682
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42408978939056396, train_loss: 0.3643280863761902
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3451230227947235, train_loss: 0.2454993724822998
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3207148611545563, train_loss: 0.19255331158638
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3089526891708374, train_loss: 0.15761712193489075
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6483709216117859, train_loss: 0.6250330209732056
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42268040776252747, train_loss: 0.3388140797615051
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3646791875362396, train_loss: 0.24862352013587952
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3519842028617859, train_loss: 0.1966848224401474
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3525094985961914, train_loss: 0.1770917773246765
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4914100170135498, train_loss: 0.4452882409095764
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1506115049123764, train_loss: 0.07789985835552216
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1439957320690155, train_loss: 0.05622650310397148
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1439262479543686, train_loss: 0.051945704966783524
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14370101690292358, train_loss: 0.04915118217468262
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5254603028297424, train_loss: 0.6891098022460938
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11597081273794174, train_loss: 0.08195404708385468
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11372854560613632, train_loss: 0.06469220668077469
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11329229921102524, train_loss: 0.06332984566688538
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11338001489639282, train_loss: 0.06320707499980927
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7551113367080688, train_loss: 0.7978098392486572
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4496091604232788, train_loss: 0.40952908992767334
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33847320079803467, train_loss: 0.28262633085250854
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2965471148490906, train_loss: 0.2145034223794937
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2774081230163574, train_loss: 0.1794886440038681
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2693803608417511, train_loss: 0.14494773745536804
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7808537483215332, train_loss: 0.7910236120223999
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4770016670227051, train_loss: 0.42156982421875
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3773363530635834, train_loss: 0.27661916613578796
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35378146171569824, train_loss: 0.21186204254627228
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35150179266929626, train_loss: 0.18863873183727264
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7659721374511719, train_loss: 0.7267078161239624
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45006224513053894, train_loss: 0.3680941164493561
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3722940683364868, train_loss: 0.2442183494567871
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.35229697823524475, train_loss: 0.19435328245162964
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3501584529876709, train_loss: 0.17356126010417938
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6056357622146606, train_loss: 0.5887628197669983
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38891756534576416, train_loss: 0.3146559000015259
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35047852993011475, train_loss: 0.23411303758621216
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3458336591720581, train_loss: 0.19327035546302795
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3462163209915161, train_loss: 0.1865508109331131
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.33908888697624207, train_loss: 0.3532811403274536
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15089289844036102, train_loss: 0.07333683967590332
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14406822621822357, train_loss: 0.056944362819194794
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1430322229862213, train_loss: 0.05335453897714615
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14272992312908173, train_loss: 0.05121338367462158
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.48283544182777405, train_loss: 0.6023052930831909
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12151344865560532, train_loss: 0.08497575670480728
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11766710132360458, train_loss: 0.06208404153585434
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11759258806705475, train_loss: 0.06183856725692749
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11762696504592896, train_loss: 0.06043410301208496
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6710155010223389, train_loss: 0.6646495461463928
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40614983439445496, train_loss: 0.37304118275642395
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3236916661262512, train_loss: 0.2678683400154114
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29515960812568665, train_loss: 0.21921119093894958
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2844812273979187, train_loss: 0.18043556809425354
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6819555163383484, train_loss: 0.6626372933387756
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43252232670783997, train_loss: 0.35054779052734375
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3732900023460388, train_loss: 0.24144142866134644
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3604740500450134, train_loss: 0.1961328387260437
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36064818501472473, train_loss: 0.17478275299072266
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6492906212806702, train_loss: 0.5801115036010742
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3845241665840149, train_loss: 0.3100385069847107
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33278724551200867, train_loss: 0.22551380097866058
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3175204396247864, train_loss: 0.1810838133096695
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31651991605758667, train_loss: 0.16763071715831757
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7186219692230225, train_loss: 0.7303314208984375
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4326888918876648, train_loss: 0.35922348499298096
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3617517650127411, train_loss: 0.24605093896389008
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3431154191493988, train_loss: 0.19154278934001923
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34048697352409363, train_loss: 0.16306722164154053
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8396222591400146, train_loss: 1.0667271614074707
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.12963859736919403, train_loss: 0.07221604138612747
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12587781250476837, train_loss: 0.06264632940292358
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12551568448543549, train_loss: 0.05854387208819389
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12519621849060059, train_loss: 0.05594515800476074
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3981071412563324, train_loss: 0.5351436138153076
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11773677915334702, train_loss: 0.08168569207191467
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11667148023843765, train_loss: 0.06627851724624634
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11677341908216476, train_loss: 0.06767210364341736
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11659065634012222, train_loss: 0.06173262745141983
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.682658314704895, train_loss: 0.6748925447463989
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4082069993019104, train_loss: 0.37720733880996704
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3147267997264862, train_loss: 0.2683449983596802
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27765095233917236, train_loss: 0.21996371448040009
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2603720426559448, train_loss: 0.17627212405204773
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2522645890712738, train_loss: 0.14963319897651672
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2489764243364334, train_loss: 0.11981841176748276
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5244300961494446, train_loss: 0.48186010122299194
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3838261365890503, train_loss: 0.2942161560058594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3661288917064667, train_loss: 0.22343206405639648
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3665296137332916, train_loss: 0.21387122571468353
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3667229413986206, train_loss: 0.2092742919921875
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6785902976989746, train_loss: 0.7013190388679504
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4063670039176941, train_loss: 0.35517364740371704
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.345022976398468, train_loss: 0.24384549260139465
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33543071150779724, train_loss: 0.19339114427566528
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3352886140346527, train_loss: 0.18504512310028076
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5229135751724243, train_loss: 0.5408420562744141
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3619852364063263, train_loss: 0.3120957314968109
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33757728338241577, train_loss: 0.2365717589855194
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33667394518852234, train_loss: 0.21357333660125732
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33660054206848145, train_loss: 0.2094496786594391
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39241793751716614, train_loss: 0.4278215169906616
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15843236446380615, train_loss: 0.07253797352313995
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15672150254249573, train_loss: 0.06194918602705002
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1569402515888214, train_loss: 0.059245847165584564
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15664350986480713, train_loss: 0.054607540369033813
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7760671377182007, train_loss: 0.8319476246833801
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13070732355117798, train_loss: 0.07247157394886017
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12694990634918213, train_loss: 0.0493616946041584
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12691770493984222, train_loss: 0.049494098871946335
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12696418166160583, train_loss: 0.0436670184135437
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8751756548881531, train_loss: 0.896648108959198
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.49889078736305237, train_loss: 0.4549062252044678
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3560498356819153, train_loss: 0.30108606815338135
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30727139115333557, train_loss: 0.23642215132713318
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28703656792640686, train_loss: 0.1913406103849411
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2783585786819458, train_loss: 0.15933045744895935
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7081608176231384, train_loss: 0.7116584181785583
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4206109046936035, train_loss: 0.35985106229782104
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35683634877204895, train_loss: 0.24367894232273102
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3442784547805786, train_loss: 0.18375176191329956
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3443616032600403, train_loss: 0.17999303340911865
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.58362877368927, train_loss: 0.5627133250236511
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3825252652168274, train_loss: 0.32506296038627625
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33322808146476746, train_loss: 0.24107182025909424
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31819218397140503, train_loss: 0.1959623247385025
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3165228068828583, train_loss: 0.16168341040611267
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5557333827018738, train_loss: 0.4940530061721802
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36722642183303833, train_loss: 0.29812341928482056
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3373737037181854, train_loss: 0.23287367820739746
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3344833552837372, train_loss: 0.196390300989151
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33469247817993164, train_loss: 0.1859193742275238
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3449877202510834, train_loss: 0.3863212466239929
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1315019577741623, train_loss: 0.072372667491436
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13127605617046356, train_loss: 0.060125891119241714
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13159778714179993, train_loss: 0.05909712612628937
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13194580376148224, train_loss: 0.05579905956983566
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41891536116600037, train_loss: 0.4731470048427582
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12936502695083618, train_loss: 0.08221669495105743
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12423919886350632, train_loss: 0.06057458743453026
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.123744897544384, train_loss: 0.05854451656341553
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12406442314386368, train_loss: 0.055641911923885345
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9694529175758362, train_loss: 0.9453195929527283
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.555667519569397, train_loss: 0.4782670736312866
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37922048568725586, train_loss: 0.31036123633384705
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3193189799785614, train_loss: 0.24116477370262146
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2948950231075287, train_loss: 0.19820009171962738
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2865038514137268, train_loss: 0.1668137013912201
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7749816179275513, train_loss: 0.785509467124939
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46189001202583313, train_loss: 0.3964979350566864
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37845274806022644, train_loss: 0.25629428029060364
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36231184005737305, train_loss: 0.20457929372787476
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36126917600631714, train_loss: 0.1728770136833191
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5523490309715271, train_loss: 0.5044411420822144
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39308038353919983, train_loss: 0.2948642373085022
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3579077124595642, train_loss: 0.21968317031860352
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3526836037635803, train_loss: 0.17898479104042053
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3528241813182831, train_loss: 0.1759747713804245
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0466266870498657, train_loss: 1.0851178169250488
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5968102216720581, train_loss: 0.5239765644073486
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4028078615665436, train_loss: 0.2908346652984619
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3535943925380707, train_loss: 0.2139650583267212
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3419705927371979, train_loss: 0.1683354377746582
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.30518582463264465, train_loss: 0.30442771315574646
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1281554251909256, train_loss: 0.07549764215946198
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12569017708301544, train_loss: 0.05855318903923035
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12576311826705933, train_loss: 0.058540284633636475
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1257157325744629, train_loss: 0.058427851647138596
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5279253125190735, train_loss: 0.5909531116485596
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13247033953666687, train_loss: 0.0831342488527298
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12612493336200714, train_loss: 0.05784530192613602
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12539878487586975, train_loss: 0.0534372515976429
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12534768879413605, train_loss: 0.051261380314826965
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6781055331230164, train_loss: 0.7048846483230591
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40583309531211853, train_loss: 0.3819136917591095
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3177855908870697, train_loss: 0.26816684007644653
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2859966456890106, train_loss: 0.2126605212688446
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27141860127449036, train_loss: 0.1803533434867859
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2677653133869171, train_loss: 0.16229526698589325
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5911277532577515, train_loss: 0.6007892489433289
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3919248878955841, train_loss: 0.3347562253475189
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34576037526130676, train_loss: 0.24446800351142883
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3361280560493469, train_loss: 0.200432687997818
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33629143238067627, train_loss: 0.18324509263038635
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.144774317741394, train_loss: 1.2018232345581055
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.625261127948761, train_loss: 0.5917213559150696
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.40221479535102844, train_loss: 0.31016969680786133
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34444698691368103, train_loss: 0.21182504296302795
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3316822350025177, train_loss: 0.16039228439331055
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3305816650390625, train_loss: 0.1432807892560959
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.001004695892334, train_loss: 0.9973235130310059
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5701196193695068, train_loss: 0.5037696361541748
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3965625464916229, train_loss: 0.2934737801551819
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35085418820381165, train_loss: 0.2152736485004425
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3400052487850189, train_loss: 0.17282786965370178
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5860591530799866, train_loss: 0.6065953373908997
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1482578068971634, train_loss: 0.07449312508106232
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14556467533111572, train_loss: 0.055772699415683746
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14504408836364746, train_loss: 0.05438542366027832
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14493517577648163, train_loss: 0.05265281721949577
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5892263650894165, train_loss: 0.689331591129303
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13126584887504578, train_loss: 0.07960253953933716
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12870585918426514, train_loss: 0.06404674053192139
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12835845351219177, train_loss: 0.05830182880163193
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1284889578819275, train_loss: 0.0585203543305397
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8991844058036804, train_loss: 0.9055012464523315
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5054765939712524, train_loss: 0.44021356105804443
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35890457034111023, train_loss: 0.28382304310798645
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30643996596336365, train_loss: 0.22219641506671906
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28286129236221313, train_loss: 0.18686646223068237
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27311134338378906, train_loss: 0.1497039496898651
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2698226273059845, train_loss: 0.12187598645687103
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5659776329994202, train_loss: 0.5434101819992065
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40889081358909607, train_loss: 0.3148791790008545
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3796064257621765, train_loss: 0.23318955302238464
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3782896101474762, train_loss: 0.2030969113111496
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3783261775970459, train_loss: 0.2009093314409256
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9288482666015625, train_loss: 0.992965042591095
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5353474617004395, train_loss: 0.5095505714416504
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38121330738067627, train_loss: 0.29566633701324463
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33872896432876587, train_loss: 0.21648022532463074
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3254847824573517, train_loss: 0.16876286268234253
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8052061796188354, train_loss: 0.8134554028511047
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.473915159702301, train_loss: 0.41427814960479736
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3723134994506836, train_loss: 0.26865828037261963
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34589675068855286, train_loss: 0.20393404364585876
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3437000811100006, train_loss: 0.18041330575942993
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5487402677536011, train_loss: 0.7238652110099792
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.12954220175743103, train_loss: 0.07018521428108215
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1267586499452591, train_loss: 0.05734821408987045
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12672385573387146, train_loss: 0.05423491448163986
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12651421129703522, train_loss: 0.050872210413217545
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34986430406570435, train_loss: 0.3672192692756653
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13603468239307404, train_loss: 0.08277955651283264
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1311214566230774, train_loss: 0.05704300105571747
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13092592358589172, train_loss: 0.05086927115917206
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13099144399166107, train_loss: 0.0498628094792366
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9077603816986084, train_loss: 0.8870910406112671
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5000808835029602, train_loss: 0.44617000222206116
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34942182898521423, train_loss: 0.29205769300460815
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2976035177707672, train_loss: 0.23368917405605316
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2767343521118164, train_loss: 0.195344015955925
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2694311738014221, train_loss: 0.16127720475196838
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5682997703552246, train_loss: 0.5759263038635254
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.385550856590271, train_loss: 0.3224055767059326
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34675437211990356, train_loss: 0.2350248545408249
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3413982093334198, train_loss: 0.19062182307243347
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34178417921066284, train_loss: 0.1833518147468567
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6074525117874146, train_loss: 0.6248704195022583
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3878585696220398, train_loss: 0.3340182304382324
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33047014474868774, train_loss: 0.23473499715328217
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3161095380783081, train_loss: 0.18207813799381256
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31594565510749817, train_loss: 0.16578362882137299
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.563158392906189, train_loss: 0.5484811067581177
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37457767128944397, train_loss: 0.31874728202819824
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34231552481651306, train_loss: 0.23690858483314514
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33910152316093445, train_loss: 0.19816848635673523
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3392637073993683, train_loss: 0.20038911700248718
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44388148188591003, train_loss: 0.401319295167923
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15977780520915985, train_loss: 0.07431590557098389
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15306302905082703, train_loss: 0.05912858247756958
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15290293097496033, train_loss: 0.05539395660161972
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15164947509765625, train_loss: 0.05483710765838623
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4142826795578003, train_loss: 0.46095776557922363
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1102454736828804, train_loss: 0.08007839322090149
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10828355699777603, train_loss: 0.06370480358600616
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.108586385846138, train_loss: 0.058172788470983505
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10847462713718414, train_loss: 0.05680033564567566
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:15<06:26, 15.48s/it]importance j:   8%|▊         | 2/26 [00:33<06:48, 17.01s/it]importance j:  12%|█▏        | 3/26 [00:45<05:39, 14.75s/it]importance j:  15%|█▌        | 4/26 [01:06<06:15, 17.08s/it]importance j:  19%|█▉        | 5/26 [01:23<05:59, 17.13s/it]importance j:  23%|██▎       | 6/26 [01:38<05:26, 16.31s/it]importance j:  27%|██▋       | 7/26 [01:56<05:20, 16.85s/it]importance j:  31%|███       | 8/26 [02:08<04:37, 15.39s/it]importance j:  35%|███▍      | 9/26 [02:28<04:43, 16.70s/it]importance j:  38%|███▊      | 10/26 [02:41<04:09, 15.56s/it]importance j:  42%|████▏     | 11/26 [02:57<03:59, 15.98s/it]importance j:  46%|████▌     | 12/26 [03:12<03:35, 15.39s/it]importance j:  50%|█████     | 13/26 [03:28<03:25, 15.82s/it]importance j:  54%|█████▍    | 14/26 [03:48<03:22, 16.92s/it]importance j:  58%|█████▊    | 15/26 [03:59<02:48, 15.30s/it]importance j:  62%|██████▏   | 16/26 [04:19<02:47, 16.74s/it]importance j:  65%|██████▌   | 17/26 [04:33<02:23, 15.90s/it]importance j:  69%|██████▉   | 18/26 [04:50<02:08, 16.01s/it]importance j:  73%|███████▎  | 19/26 [05:08<01:56, 16.64s/it]importance j:  77%|███████▋  | 20/26 [05:22<01:35, 15.96s/it]importance j:  81%|████████  | 21/26 [05:40<01:23, 16.63s/it]importance j:  85%|████████▍ | 22/26 [05:52<01:00, 15.13s/it]importance j:  88%|████████▊ | 23/26 [06:12<00:49, 16.63s/it]importance j:  92%|█████████▏| 24/26 [06:30<00:33, 16.95s/it]importance j:  96%|█████████▌| 25/26 [06:44<00:16, 16.13s/it]importance j: 100%|██████████| 26/26 [07:03<00:00, 16.90s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8698505759239197, train_loss: 0.8961061239242554
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5139696598052979, train_loss: 0.47981616854667664
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3656180500984192, train_loss: 0.31981661915779114
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30971622467041016, train_loss: 0.25408050417900085
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28237617015838623, train_loss: 0.22018641233444214
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2681572437286377, train_loss: 0.18518316745758057
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2616761326789856, train_loss: 0.16294829547405243
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.258527547121048, train_loss: 0.13491930067539215
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.69892418384552, train_loss: 0.7024160623550415
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4474480450153351, train_loss: 0.36096757650375366
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38099798560142517, train_loss: 0.2494606375694275
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36816468834877014, train_loss: 0.19916972517967224
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3682555854320526, train_loss: 0.17419761419296265
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8910789489746094, train_loss: 0.9174814224243164
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.49129223823547363, train_loss: 0.44868773221969604
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35764166712760925, train_loss: 0.26894688606262207
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3240189552307129, train_loss: 0.2031354159116745
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31602638959884644, train_loss: 0.15570424497127533
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.672598659992218, train_loss: 0.6909382343292236
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41439539194107056, train_loss: 0.3591521382331848
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35189542174339294, train_loss: 0.2635772228240967
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34049102663993835, train_loss: 0.20529723167419434
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3408649265766144, train_loss: 0.19690386950969696
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4042997658252716, train_loss: 0.505126953125
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15857863426208496, train_loss: 0.07526916265487671
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15282021462917328, train_loss: 0.05368330702185631
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.152426615357399, train_loss: 0.05256637930870056
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15215043723583221, train_loss: 0.05040883272886276
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6464461088180542, train_loss: 0.7780237197875977
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12315409630537033, train_loss: 0.08298254013061523
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12142953276634216, train_loss: 0.06592535972595215
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1216798797249794, train_loss: 0.06468802690505981
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12193863838911057, train_loss: 0.05774025619029999
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5477246046066284, train_loss: 0.5606826543807983
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.36962053179740906, train_loss: 0.3395765721797943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31183087825775146, train_loss: 0.2662140727043152
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28883469104766846, train_loss: 0.2190554141998291
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2784653902053833, train_loss: 0.18423007428646088
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27227842807769775, train_loss: 0.159133642911911
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.27092647552490234, train_loss: 0.13574595749378204
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7352929711341858, train_loss: 0.7729170322418213
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4324827194213867, train_loss: 0.38676512241363525
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35369372367858887, train_loss: 0.25665104389190674
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3391362726688385, train_loss: 0.20081692934036255
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33924028277397156, train_loss: 0.19240719079971313
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7529117465019226, train_loss: 0.8276414275169373
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4498760998249054, train_loss: 0.429416298866272
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34819114208221436, train_loss: 0.2788486182689667
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3182280957698822, train_loss: 0.21613070368766785
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3099665641784668, train_loss: 0.17036151885986328
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.45344144105911255, train_loss: 0.4353410601615906
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.35765475034713745, train_loss: 0.27721428871154785
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3451884984970093, train_loss: 0.2188524454832077
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3456054627895355, train_loss: 0.205169215798378
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3461037576198578, train_loss: 0.20145255327224731
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45371121168136597, train_loss: 0.4568217396736145
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1467471420764923, train_loss: 0.06945890188217163
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14277739822864532, train_loss: 0.05004812031984329
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14259777963161469, train_loss: 0.04954218491911888
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14280596375465393, train_loss: 0.047502633184194565
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.33619433641433716, train_loss: 0.4039520025253296
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12240074574947357, train_loss: 0.08562646806240082
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12098181992769241, train_loss: 0.06853044778108597
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12113258987665176, train_loss: 0.06356000900268555
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12117770314216614, train_loss: 0.06302480399608612
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6996692419052124, train_loss: 0.698277473449707
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40286388993263245, train_loss: 0.3700155019760132
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31622594594955444, train_loss: 0.26443246006965637
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28426483273506165, train_loss: 0.21597500145435333
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2700001299381256, train_loss: 0.181368887424469
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26435062289237976, train_loss: 0.1525053232908249
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5592780709266663, train_loss: 0.5659523606300354
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39123642444610596, train_loss: 0.3169172406196594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3556777834892273, train_loss: 0.2363806813955307
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3499229848384857, train_loss: 0.192033052444458
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34980398416519165, train_loss: 0.18646326661109924
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.600901186466217, train_loss: 0.6017966270446777
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3882073760032654, train_loss: 0.3238312304019928
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3383840024471283, train_loss: 0.23269206285476685
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3255879580974579, train_loss: 0.18639448285102844
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32514092326164246, train_loss: 0.16616290807724
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.583416223526001, train_loss: 0.5855387449264526
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38326334953308105, train_loss: 0.32630857825279236
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34100341796875, train_loss: 0.24085301160812378
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3308204412460327, train_loss: 0.1974371075630188
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3306021988391876, train_loss: 0.18347865343093872
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.43573641777038574, train_loss: 0.5018327236175537
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15006479620933533, train_loss: 0.07545693218708038
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1480576992034912, train_loss: 0.06874409317970276
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14681093394756317, train_loss: 0.06427492201328278
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14678047597408295, train_loss: 0.06396548449993134
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5235766768455505, train_loss: 0.6100032925605774
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12177671492099762, train_loss: 0.0834459662437439
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11678219586610794, train_loss: 0.059525489807128906
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11659684777259827, train_loss: 0.055037107318639755
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11664041876792908, train_loss: 0.05496513843536377
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6739636063575745, train_loss: 0.6874333620071411
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39276188611984253, train_loss: 0.37732741236686707
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30820560455322266, train_loss: 0.28101858496665955
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2776167690753937, train_loss: 0.230852872133255
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2670772969722748, train_loss: 0.19254395365715027
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8209259510040283, train_loss: 0.8562600612640381
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.49331843852996826, train_loss: 0.42885416746139526
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.385634183883667, train_loss: 0.2672743797302246
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36106064915657043, train_loss: 0.20258018374443054
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35983985662460327, train_loss: 0.1613423228263855
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6625430583953857, train_loss: 0.6866550445556641
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4074575901031494, train_loss: 0.353435218334198
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33877038955688477, train_loss: 0.24814221262931824
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32140231132507324, train_loss: 0.19102045893669128
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32078659534454346, train_loss: 0.16800808906555176
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5198190808296204, train_loss: 0.5174175500869751
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36354711651802063, train_loss: 0.3047942519187927
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33343634009361267, train_loss: 0.23669356107711792
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3305577337741852, train_loss: 0.1872648298740387
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33091244101524353, train_loss: 0.19057773053646088
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3034610152244568, train_loss: 0.3001471161842346
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1385953724384308, train_loss: 0.07969704270362854
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1349267214536667, train_loss: 0.06518421322107315
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13415716588497162, train_loss: 0.06085769459605217
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13325220346450806, train_loss: 0.055225104093551636
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5971248745918274, train_loss: 0.6453556418418884
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11781462281942368, train_loss: 0.08139234781265259
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1142021045088768, train_loss: 0.05688643828034401
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1144971251487732, train_loss: 0.053407102823257446
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11473426222801208, train_loss: 0.05157597362995148
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0907829999923706, train_loss: 1.1447739601135254
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6369679570198059, train_loss: 0.5965019464492798
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4055366516113281, train_loss: 0.34196192026138306
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33071473240852356, train_loss: 0.2556290626525879
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30208590626716614, train_loss: 0.20889362692832947
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2907494902610779, train_loss: 0.16896480321884155
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9057154059410095, train_loss: 0.9209067821502686
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5386784672737122, train_loss: 0.4750637710094452
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.399495393037796, train_loss: 0.28151649236679077
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36761659383773804, train_loss: 0.20881766080856323
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36496174335479736, train_loss: 0.17541423439979553
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7135303020477295, train_loss: 0.7544170618057251
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40822309255599976, train_loss: 0.36963045597076416
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33243075013160706, train_loss: 0.25569120049476624
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31342440843582153, train_loss: 0.20050004124641418
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31103581190109253, train_loss: 0.1681305468082428
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5178869962692261, train_loss: 0.550242006778717
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3545873165130615, train_loss: 0.3155078887939453
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.32704606652259827, train_loss: 0.2346695065498352
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3254703879356384, train_loss: 0.1972605586051941
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3259085714817047, train_loss: 0.1996195912361145
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.46530503034591675, train_loss: 0.5883011221885681
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15013450384140015, train_loss: 0.07880222797393799
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14126251637935638, train_loss: 0.055771030485630035
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14084526896476746, train_loss: 0.04581476002931595
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14071905612945557, train_loss: 0.04380519315600395
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7809239625930786, train_loss: 0.8450092077255249
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12308185547590256, train_loss: 0.07377983629703522
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12172510474920273, train_loss: 0.05924690142273903
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12170160561800003, train_loss: 0.0567145049571991
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12162838131189346, train_loss: 0.054257094860076904
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9189245700836182, train_loss: 0.9398137331008911
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5310439467430115, train_loss: 0.49566736817359924
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36227187514305115, train_loss: 0.3239661455154419
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3012596368789673, train_loss: 0.2493472546339035
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2746659517288208, train_loss: 0.2170199453830719
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2617330849170685, train_loss: 0.186484694480896
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2572658658027649, train_loss: 0.1538689285516739
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5223242044448853, train_loss: 0.5161100625991821
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37913769483566284, train_loss: 0.2932100296020508
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3530595600605011, train_loss: 0.22704565525054932
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35100898146629333, train_loss: 0.19387631118297577
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35128089785575867, train_loss: 0.19102850556373596
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5386959314346313, train_loss: 0.5283347368240356
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3526706099510193, train_loss: 0.2994232773780823
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31258082389831543, train_loss: 0.22307658195495605
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30328720808029175, train_loss: 0.1821436882019043
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3034845292568207, train_loss: 0.1702708601951599
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6438025832176208, train_loss: 0.6409128904342651
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3926163911819458, train_loss: 0.3282531499862671
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34175071120262146, train_loss: 0.23598016798496246
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33147478103637695, train_loss: 0.18734967708587646
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3314223885536194, train_loss: 0.17736351490020752
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6546462178230286, train_loss: 0.7253150939941406
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15000830590724945, train_loss: 0.07188687473535538
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14479845762252808, train_loss: 0.051101136952638626
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1445235013961792, train_loss: 0.04892536252737045
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1443009078502655, train_loss: 0.05018598213791847
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.39667558670043945, train_loss: 0.445368230342865
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.10776657611131668, train_loss: 0.08109179139137268
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10323628783226013, train_loss: 0.05865896865725517
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1032041534781456, train_loss: 0.05447528138756752
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10293278843164444, train_loss: 0.05345067381858826
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6243520975112915, train_loss: 0.6553397178649902
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37670379877090454, train_loss: 0.357707142829895
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29971930384635925, train_loss: 0.2683343291282654
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27043190598487854, train_loss: 0.21799291670322418
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2563283145427704, train_loss: 0.179016575217247
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2508593201637268, train_loss: 0.15223428606987
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7740824818611145, train_loss: 0.7845299243927002
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.46267810463905334, train_loss: 0.39833664894104004
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37490928173065186, train_loss: 0.26173657178878784
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35575002431869507, train_loss: 0.20563861727714539
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.353931725025177, train_loss: 0.1774892807006836
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8747105002403259, train_loss: 0.8805363774299622
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.48979949951171875, train_loss: 0.45430514216423035
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36143791675567627, train_loss: 0.2773072123527527
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32931846380233765, train_loss: 0.20713388919830322
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3225786089897156, train_loss: 0.16623201966285706
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8424615263938904, train_loss: 0.8498927354812622
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4906114637851715, train_loss: 0.43168944120407104
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37143653631210327, train_loss: 0.2728451192378998
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33989977836608887, train_loss: 0.21470680832862854
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33522695302963257, train_loss: 0.17265833914279938
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9336156845092773, train_loss: 1.1030992269515991
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14592993259429932, train_loss: 0.07016751915216446
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1405400186777115, train_loss: 0.04775061458349228
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1402125358581543, train_loss: 0.04611893743276596
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13970638811588287, train_loss: 0.04460147023200989
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5630820989608765, train_loss: 0.6465854644775391
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1124548688530922, train_loss: 0.07636748999357224
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11195295304059982, train_loss: 0.05585731565952301
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11213429272174835, train_loss: 0.05589955300092697
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11237156391143799, train_loss: 0.05379321798682213
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6231180429458618, train_loss: 0.6339961290359497
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.383358895778656, train_loss: 0.3678642511367798
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3071589469909668, train_loss: 0.27733126282691956
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28011736273765564, train_loss: 0.2271418273448944
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2719888985157013, train_loss: 0.1894087940454483
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5210732817649841, train_loss: 0.5095473527908325
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36817240715026855, train_loss: 0.29117441177368164
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34656813740730286, train_loss: 0.22227242588996887
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3455198109149933, train_loss: 0.20891578495502472
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34541958570480347, train_loss: 0.19912302494049072
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8182544708251953, train_loss: 0.8118510842323303
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.46353793144226074, train_loss: 0.40472161769866943
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3660903573036194, train_loss: 0.2617124617099762
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34221798181533813, train_loss: 0.19415107369422913
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3397514522075653, train_loss: 0.17456790804862976
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8997266888618469, train_loss: 0.8943228721618652
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5210508704185486, train_loss: 0.4636963903903961
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3782489001750946, train_loss: 0.29061728715896606
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3377676010131836, train_loss: 0.21725425124168396
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.326228529214859, train_loss: 0.17356881499290466
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45062026381492615, train_loss: 0.47816187143325806
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14023688435554504, train_loss: 0.07041975855827332
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13541589677333832, train_loss: 0.04691895470023155
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13551272451877594, train_loss: 0.04431542381644249
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13533911108970642, train_loss: 0.04292243346571922
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6819546818733215, train_loss: 0.7398651838302612
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11232936382293701, train_loss: 0.06813438981771469
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11153339594602585, train_loss: 0.06102781742811203
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11200665682554245, train_loss: 0.055597934871912
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11229562014341354, train_loss: 0.05562613531947136
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9537326693534851, train_loss: 0.9389585852622986
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5184007287025452, train_loss: 0.4780508875846863
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34718096256256104, train_loss: 0.30261683464050293
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.291475385427475, train_loss: 0.232947438955307
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2712962031364441, train_loss: 0.19242742657661438
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26472237706184387, train_loss: 0.16144132614135742
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7731347680091858, train_loss: 0.7610565423965454
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44954419136047363, train_loss: 0.3952040672302246
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3648340404033661, train_loss: 0.26888787746429443
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3463112413883209, train_loss: 0.2093927562236786
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3439484238624573, train_loss: 0.1808362454175949
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.92378830909729, train_loss: 0.9680037498474121
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5341618061065674, train_loss: 0.5018108487129211
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3796500265598297, train_loss: 0.2935013473033905
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3382769227027893, train_loss: 0.21847927570343018
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32842129468917847, train_loss: 0.17434903979301453
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7240952849388123, train_loss: 0.702382504940033
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4269616901874542, train_loss: 0.3493831157684326
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3630736470222473, train_loss: 0.24261359870433807
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3478045165538788, train_loss: 0.19356819987297058
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34680816531181335, train_loss: 0.16058070957660675
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6317740678787231, train_loss: 0.5834490060806274
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15459391474723816, train_loss: 0.07826454192399979
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15275074541568756, train_loss: 0.06972748041152954
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15164291858673096, train_loss: 0.06494370102882385
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15176650881767273, train_loss: 0.06269419193267822
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5381582379341125, train_loss: 0.597122073173523
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1281215250492096, train_loss: 0.08106578886508942
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1191878691315651, train_loss: 0.053327273577451706
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11901645362377167, train_loss: 0.051026735454797745
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11877265572547913, train_loss: 0.04750772565603256
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6500785946846008, train_loss: 0.6703395843505859
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3861471712589264, train_loss: 0.3504642844200134
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31013497710227966, train_loss: 0.2693237364292145
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.283789724111557, train_loss: 0.21756985783576965
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27469417452812195, train_loss: 0.17909452319145203
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2708994150161743, train_loss: 0.1491633951663971
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7482786774635315, train_loss: 0.7376205921173096
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4500531852245331, train_loss: 0.3800432085990906
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3734988868236542, train_loss: 0.25778594613075256
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35641708970069885, train_loss: 0.20075327157974243
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35615408420562744, train_loss: 0.18104735016822815
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8985037803649902, train_loss: 0.9640638828277588
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5299497842788696, train_loss: 0.48939085006713867
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38499656319618225, train_loss: 0.2851652503013611
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34544605016708374, train_loss: 0.21065431833267212
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33597156405448914, train_loss: 0.1608380377292633
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6383452415466309, train_loss: 0.6290766000747681
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4029576778411865, train_loss: 0.340692400932312
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.350762277841568, train_loss: 0.2489052712917328
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33635109663009644, train_loss: 0.20185674726963043
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33558064699172974, train_loss: 0.1767463982105255
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6290760040283203, train_loss: 0.583342432975769
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15479536354541779, train_loss: 0.0730370432138443
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1485118716955185, train_loss: 0.06332363933324814
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14708903431892395, train_loss: 0.059726782143116
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1457466185092926, train_loss: 0.057574499398469925
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4492899775505066, train_loss: 0.5311899781227112
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12242814898490906, train_loss: 0.08484327793121338
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11670316010713577, train_loss: 0.056686338037252426
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11634515970945358, train_loss: 0.05389080196619034
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11603802442550659, train_loss: 0.052198976278305054
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7660484313964844, train_loss: 0.7649962902069092
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4436640739440918, train_loss: 0.392636775970459
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33780959248542786, train_loss: 0.2817096710205078
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2984256148338318, train_loss: 0.22242161631584167
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2816856801509857, train_loss: 0.18894046545028687
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2752998471260071, train_loss: 0.15968477725982666
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5829375982284546, train_loss: 0.5738194584846497
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40576866269111633, train_loss: 0.33173036575317383
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3644216060638428, train_loss: 0.24629323184490204
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3570975959300995, train_loss: 0.1943369358778
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3573225438594818, train_loss: 0.1917157769203186
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5735144019126892, train_loss: 0.5002671480178833
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38286516070365906, train_loss: 0.30705419182777405
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33796876668930054, train_loss: 0.22186845541000366
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32752951979637146, train_loss: 0.18220457434654236
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32670509815216064, train_loss: 0.165040984749794
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6550765037536621, train_loss: 0.6789916157722473
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40004074573516846, train_loss: 0.3455554246902466
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3429173529148102, train_loss: 0.2420189082622528
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.32944566011428833, train_loss: 0.19206249713897705
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3286803364753723, train_loss: 0.1762169599533081
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44487306475639343, train_loss: 0.5144526958465576
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14649835228919983, train_loss: 0.07558470219373703
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1379878669977188, train_loss: 0.055928394198417664
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13692009449005127, train_loss: 0.05229518935084343
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13633742928504944, train_loss: 0.05283801257610321
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3511664569377899, train_loss: 0.3452686071395874
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11233233660459518, train_loss: 0.08086173236370087
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10933312028646469, train_loss: 0.057081982493400574
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10928858816623688, train_loss: 0.056805551052093506
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10936703532934189, train_loss: 0.05364414304494858
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6847821474075317, train_loss: 0.70388263463974
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40990307927131653, train_loss: 0.3838779330253601
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32238516211509705, train_loss: 0.273457407951355
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29021206498146057, train_loss: 0.2262020707130432
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.276885449886322, train_loss: 0.18987491726875305
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2745019197463989, train_loss: 0.16488388180732727
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.4835239350795746, train_loss: 0.45768919587135315
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3789040446281433, train_loss: 0.29341572523117065
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.362293004989624, train_loss: 0.2277584671974182
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3627311587333679, train_loss: 0.21646423637866974
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.363089919090271, train_loss: 0.2120036780834198
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.719821572303772, train_loss: 0.7123413681983948
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45670193433761597, train_loss: 0.3609217703342438
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3933213949203491, train_loss: 0.23837369680404663
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3810167908668518, train_loss: 0.1802566647529602
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3812417685985565, train_loss: 0.17101404070854187
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6143444776535034, train_loss: 0.6185657978057861
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38845473527908325, train_loss: 0.32420140504837036
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3422001302242279, train_loss: 0.23167110979557037
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3327449560165405, train_loss: 0.18667913973331451
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33272093534469604, train_loss: 0.16804851591587067
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.30111169815063477, train_loss: 0.35406631231307983
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13200852274894714, train_loss: 0.07603709399700165
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13214111328125, train_loss: 0.06568585336208344
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13190791010856628, train_loss: 0.06191788986325264
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13200600445270538, train_loss: 0.058682892471551895
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.5015367269515991, train_loss: 1.4599415063858032
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11825329065322876, train_loss: 0.07833119481801987
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11703690886497498, train_loss: 0.055601898580789566
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11715352535247803, train_loss: 0.05651484429836273
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11712181568145752, train_loss: 0.05210142582654953
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5620862245559692, train_loss: 0.6100339889526367
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35366544127464294, train_loss: 0.35246899724006653
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2934277057647705, train_loss: 0.2619013488292694
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27150654792785645, train_loss: 0.22599005699157715
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2645478844642639, train_loss: 0.1906941682100296
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6010484099388123, train_loss: 0.5873169302940369
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.396996408700943, train_loss: 0.32679176330566406
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35575348138809204, train_loss: 0.23945194482803345
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3507384657859802, train_loss: 0.2043839693069458
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3511553704738617, train_loss: 0.19138094782829285
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9364786148071289, train_loss: 1.0068154335021973
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5343807339668274, train_loss: 0.5169588327407837
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38288527727127075, train_loss: 0.29953038692474365
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34272828698158264, train_loss: 0.21352501213550568
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3327997624874115, train_loss: 0.17225120961666107
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5005062222480774, train_loss: 0.5176079273223877
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3684961795806885, train_loss: 0.3076438307762146
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34192347526550293, train_loss: 0.2376691997051239
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3387947380542755, train_loss: 0.2059895098209381
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3389441668987274, train_loss: 0.19958555698394775
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9099349975585938, train_loss: 0.9890373945236206
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1501709222793579, train_loss: 0.07720302045345306
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1455722153186798, train_loss: 0.05669786408543587
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14550915360450745, train_loss: 0.05604052171111107
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1453457921743393, train_loss: 0.05332288146018982
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.47127991914749146, train_loss: 0.5160630941390991
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12758216261863708, train_loss: 0.07752899080514908
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1266414374113083, train_loss: 0.06434488296508789
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12652966380119324, train_loss: 0.06369277089834213
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12683969736099243, train_loss: 0.05991828441619873
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.763777494430542, train_loss: 0.7450181841850281
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4489261507987976, train_loss: 0.3890993595123291
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3419267237186432, train_loss: 0.26899999380111694
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30209511518478394, train_loss: 0.211053729057312
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28489822149276733, train_loss: 0.1782224476337433
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2761743664741516, train_loss: 0.14473870396614075
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2748637795448303, train_loss: 0.13086888194084167
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.27417314052581787, train_loss: 0.12649905681610107
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7862866520881653, train_loss: 0.798062801361084
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47630175948143005, train_loss: 0.4099191427230835
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3857635259628296, train_loss: 0.2726721167564392
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36256834864616394, train_loss: 0.2105444073677063
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3603157103061676, train_loss: 0.17771099507808685
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8289661407470703, train_loss: 0.8637725114822388
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4631175994873047, train_loss: 0.4194064140319824
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35388824343681335, train_loss: 0.2642424702644348
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3251415193080902, train_loss: 0.20133771002292633
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3184654414653778, train_loss: 0.16436216235160828
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5613113641738892, train_loss: 0.5379985570907593
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3870406746864319, train_loss: 0.3124843239784241
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3546912968158722, train_loss: 0.23696233332157135
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35207265615463257, train_loss: 0.19510510563850403
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3526917099952698, train_loss: 0.19645334780216217
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5957309007644653, train_loss: 0.6763942241668701
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14358244836330414, train_loss: 0.07050062716007233
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13666097819805145, train_loss: 0.04762725904583931
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13636155426502228, train_loss: 0.0424158051609993
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13619384169578552, train_loss: 0.03979956731200218
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5442770719528198, train_loss: 0.5549130439758301
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12471044808626175, train_loss: 0.07784533500671387
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12232672423124313, train_loss: 0.061524562537670135
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12242916226387024, train_loss: 0.059104178100824356
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12246710807085037, train_loss: 0.05617697164416313
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7612753510475159, train_loss: 0.762190580368042
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.44499000906944275, train_loss: 0.4051843583583832
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3339338004589081, train_loss: 0.2846250534057617
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2948285639286041, train_loss: 0.2262243628501892
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27989983558654785, train_loss: 0.1896999478340149
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6126715540885925, train_loss: 0.596859872341156
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4027867615222931, train_loss: 0.3342129588127136
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36276671290397644, train_loss: 0.24600458145141602
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35787245631217957, train_loss: 0.19943468272686005
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3579353392124176, train_loss: 0.1948624551296234
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7901740074157715, train_loss: 0.7586933374404907
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45091676712036133, train_loss: 0.3802698254585266
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35779765248298645, train_loss: 0.25753962993621826
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3319520950317383, train_loss: 0.1920934021472931
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32700952887535095, train_loss: 0.15942472219467163
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6634106636047363, train_loss: 0.6869282126426697
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4106520712375641, train_loss: 0.3437401056289673
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.355473130941391, train_loss: 0.2400524616241455
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34717604517936707, train_loss: 0.18631282448768616
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34810036420822144, train_loss: 0.17268916964530945
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.9506330490112305, train_loss: 0.9914045929908752
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15348102152347565, train_loss: 0.06742006540298462
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1495545208454132, train_loss: 0.05191504955291748
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14902141690254211, train_loss: 0.04829777032136917
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14921580255031586, train_loss: 0.04904033988714218
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.270191490650177, train_loss: 0.38296473026275635
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12074705213308334, train_loss: 0.08450588583946228
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12028566747903824, train_loss: 0.07243773341178894
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1203538030385971, train_loss: 0.06761189550161362
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12073861807584763, train_loss: 0.06567512452602386
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6974215507507324, train_loss: 0.6810377836227417
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42889705300331116, train_loss: 0.3635648488998413
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3356924057006836, train_loss: 0.2603262662887573
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29892653226852417, train_loss: 0.2127043902873993
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2841222584247589, train_loss: 0.18101464211940765
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7191250920295715, train_loss: 0.7299255132675171
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43192893266677856, train_loss: 0.3664160370826721
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3634755313396454, train_loss: 0.25653699040412903
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3479263484477997, train_loss: 0.2016231119632721
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3466397225856781, train_loss: 0.17916443943977356
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9423772692680359, train_loss: 0.9263738989830017
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5190969109535217, train_loss: 0.4596753716468811
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37787970900535583, train_loss: 0.2733251452445984
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3389710485935211, train_loss: 0.20668350160121918
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3277606666088104, train_loss: 0.16380852460861206
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6627876162528992, train_loss: 0.6530202031135559
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4181138277053833, train_loss: 0.35013216733932495
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36171263456344604, train_loss: 0.24791903793811798
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3474047780036926, train_loss: 0.20057262480258942
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3468397557735443, train_loss: 0.179802805185318
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.0532505512237549, train_loss: 1.0580052137374878
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14736305177211761, train_loss: 0.06890539079904556
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14136186242103577, train_loss: 0.051227688789367676
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14101538062095642, train_loss: 0.04799176752567291
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14078876376152039, train_loss: 0.04478879272937775
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.671690046787262, train_loss: 0.7408465147018433
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13803717494010925, train_loss: 0.07557009160518646
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1359291672706604, train_loss: 0.05830051749944687
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13595086336135864, train_loss: 0.05189774930477142
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13610701262950897, train_loss: 0.05602853000164032
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.582057535648346, train_loss: 0.5772446393966675
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3650200366973877, train_loss: 0.33963602781295776
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.301164448261261, train_loss: 0.2653934955596924
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2778240144252777, train_loss: 0.22405695915222168
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.268334299325943, train_loss: 0.17775553464889526
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6283056139945984, train_loss: 0.6144601106643677
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.416515052318573, train_loss: 0.34256646037101746
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3653208017349243, train_loss: 0.25386086106300354
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35569891333580017, train_loss: 0.2084379941225052
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3556106388568878, train_loss: 0.20259514451026917
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6236559748649597, train_loss: 0.6222391724586487
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3882487118244171, train_loss: 0.3272170424461365
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3376052677631378, train_loss: 0.22653084993362427
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32779595255851746, train_loss: 0.18064364790916443
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3281196653842926, train_loss: 0.16912983357906342
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6393330097198486, train_loss: 0.6394343376159668
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3981783092021942, train_loss: 0.3402289152145386
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34867408871650696, train_loss: 0.24512116611003876
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33930686116218567, train_loss: 0.1960599720478058
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33927688002586365, train_loss: 0.18318642675876617
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6187537908554077, train_loss: 0.6819117069244385
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16685649752616882, train_loss: 0.07901269197463989
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1519012153148651, train_loss: 0.05488191545009613
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15058626234531403, train_loss: 0.05063289403915405
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1500934660434723, train_loss: 0.04711395502090454
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3560490608215332, train_loss: 0.4658479392528534
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12255904078483582, train_loss: 0.07842607796192169
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11922390758991241, train_loss: 0.058992139995098114
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11921197175979614, train_loss: 0.05831793695688248
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11902383714914322, train_loss: 0.05688841640949249
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9498569965362549, train_loss: 0.956132173538208
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5455259084701538, train_loss: 0.4886327087879181
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3671496510505676, train_loss: 0.31829679012298584
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30512455105781555, train_loss: 0.25300663709640503
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27916836738586426, train_loss: 0.20598845183849335
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2703512907028198, train_loss: 0.17722663283348083
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.659170389175415, train_loss: 0.6501625776290894
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41993072628974915, train_loss: 0.34244176745414734
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37084197998046875, train_loss: 0.24357539415359497
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3630162179470062, train_loss: 0.19584938883781433
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.364300400018692, train_loss: 0.18705874681472778
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7089163661003113, train_loss: 0.7261883020401001
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4328603744506836, train_loss: 0.37607404589653015
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3608355224132538, train_loss: 0.25581082701683044
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3407631516456604, train_loss: 0.19750486314296722
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3395862579345703, train_loss: 0.17283692955970764
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8767555952072144, train_loss: 0.9072228670120239
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5171458125114441, train_loss: 0.45350146293640137
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3858090937137604, train_loss: 0.2789113521575928
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35082393884658813, train_loss: 0.21605169773101807
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34246379137039185, train_loss: 0.16950413584709167
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44413313269615173, train_loss: 0.4787251949310303
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15310513973236084, train_loss: 0.08010628819465637
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1463279128074646, train_loss: 0.061991311609745026
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.144914910197258, train_loss: 0.059756383299827576
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1451040506362915, train_loss: 0.057528503239154816
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.38310399651527405, train_loss: 0.3873421549797058
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11572861671447754, train_loss: 0.08112180978059769
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11222987622022629, train_loss: 0.06277742236852646
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11219099164009094, train_loss: 0.0599517785012722
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11215589940547943, train_loss: 0.05833984911441803
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0014382600784302, train_loss: 1.0133917331695557
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.547954797744751, train_loss: 0.4992859661579132
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36175739765167236, train_loss: 0.3033473491668701
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30071091651916504, train_loss: 0.23053210973739624
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2754133343696594, train_loss: 0.1892217993736267
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2652273178100586, train_loss: 0.15512615442276
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2622887194156647, train_loss: 0.13439422845840454
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.600706160068512, train_loss: 0.6104987263679504
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40419304370880127, train_loss: 0.33294153213500977
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3579254150390625, train_loss: 0.23600922524929047
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3508833050727844, train_loss: 0.19402459263801575
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3506011664867401, train_loss: 0.18264473974704742
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7570255994796753, train_loss: 0.7689122557640076
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4469640254974365, train_loss: 0.3973016142845154
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3538896143436432, train_loss: 0.26502925157546997
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3278968036174774, train_loss: 0.20401166379451752
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3212989866733551, train_loss: 0.16786500811576843
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5981433391571045, train_loss: 0.5759418606758118
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36711493134498596, train_loss: 0.31167399883270264
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.32598572969436646, train_loss: 0.22383365035057068
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3192422091960907, train_loss: 0.18215449154376984
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.31906768679618835, train_loss: 0.18376794457435608
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.40665891766548157, train_loss: 0.40467435121536255
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14813350141048431, train_loss: 0.0759744942188263
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14574377238750458, train_loss: 0.06429039686918259
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1458546221256256, train_loss: 0.059858452528715134
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14530295133590698, train_loss: 0.055916596204042435
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.39347049593925476, train_loss: 0.4796639084815979
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12906281650066376, train_loss: 0.08073318749666214
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12224139273166656, train_loss: 0.05436531454324722
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12235666811466217, train_loss: 0.05282796919345856
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12273980677127838, train_loss: 0.05069493502378464
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8536457419395447, train_loss: 0.8659733533859253
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4825275242328644, train_loss: 0.44415566325187683
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34554728865623474, train_loss: 0.29505300521850586
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30048227310180664, train_loss: 0.23035314679145813
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2847220003604889, train_loss: 0.19309958815574646
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.28031057119369507, train_loss: 0.16464628279209137
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6161766648292542, train_loss: 0.6154839396476746
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40279677510261536, train_loss: 0.328720360994339
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3579135239124298, train_loss: 0.23669075965881348
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3526745140552521, train_loss: 0.18626758456230164
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.353535532951355, train_loss: 0.1762324869632721
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6836205720901489, train_loss: 0.715491533279419
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4308770000934601, train_loss: 0.37569525837898254
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3586227595806122, train_loss: 0.25455647706985474
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3428729474544525, train_loss: 0.19774562120437622
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3426605761051178, train_loss: 0.18990442156791687
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6963801980018616, train_loss: 0.715205192565918
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41919276118278503, train_loss: 0.36546027660369873
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34937575459480286, train_loss: 0.2554118037223816
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3377855122089386, train_loss: 0.19080838561058044
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3376508355140686, train_loss: 0.1871684044599533
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.39628663659095764, train_loss: 0.35532206296920776
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1583714485168457, train_loss: 0.0718386098742485
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15279288589954376, train_loss: 0.054206300526857376
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15219981968402863, train_loss: 0.054663654416799545
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15168796479701996, train_loss: 0.049394868314266205
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5873289704322815, train_loss: 0.6734185218811035
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12464112788438797, train_loss: 0.08682700991630554
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11618199199438095, train_loss: 0.058199070394039154
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11666049063205719, train_loss: 0.05079866945743561
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11662101745605469, train_loss: 0.05191856995224953
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0091900825500488, train_loss: 0.9774428606033325
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5785065293312073, train_loss: 0.5007973909378052
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.39152002334594727, train_loss: 0.3156425654888153
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3272385895252228, train_loss: 0.23872335255146027
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29742905497550964, train_loss: 0.19936363399028778
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.28348514437675476, train_loss: 0.17113015055656433
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.27710670232772827, train_loss: 0.14248549938201904
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.27439215779304504, train_loss: 0.11661233752965927
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8740752935409546, train_loss: 0.915252685546875
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5311281085014343, train_loss: 0.4751136898994446
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40273264050483704, train_loss: 0.2847941517829895
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37660691142082214, train_loss: 0.21139231324195862
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3757604658603668, train_loss: 0.1888696253299713
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.714061439037323, train_loss: 0.7052346467971802
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41710302233695984, train_loss: 0.36019793152809143
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33808988332748413, train_loss: 0.24793249368667603
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3144441843032837, train_loss: 0.18962779641151428
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30757248401641846, train_loss: 0.1546240597963333
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.663048505783081, train_loss: 0.6661752462387085
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41169053316116333, train_loss: 0.3537405729293823
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3533388674259186, train_loss: 0.25821393728256226
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34097135066986084, train_loss: 0.20832459628582
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34088587760925293, train_loss: 0.1916048377752304
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4084218144416809, train_loss: 0.41702044010162354
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14445646107196808, train_loss: 0.07863107323646545
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13684090971946716, train_loss: 0.05381319299340248
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1361185759305954, train_loss: 0.05239197611808777
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1356533318758011, train_loss: 0.05086875706911087
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2782193422317505, train_loss: 0.31827211380004883
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12236929684877396, train_loss: 0.082058846950531
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11944708228111267, train_loss: 0.06038142368197441
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1197698786854744, train_loss: 0.05766874551773071
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11999866366386414, train_loss: 0.055583640933036804
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9629808068275452, train_loss: 0.9485376477241516
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5435421466827393, train_loss: 0.48640677332878113
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36606666445732117, train_loss: 0.3047691583633423
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3070034384727478, train_loss: 0.2348022162914276
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2836659252643585, train_loss: 0.1942312866449356
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27563875913619995, train_loss: 0.1677258163690567
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.005846619606018, train_loss: 1.0201002359390259
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5711679458618164, train_loss: 0.5037503838539124
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41283485293388367, train_loss: 0.28862884640693665
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.38115692138671875, train_loss: 0.21066781878471375
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3775347173213959, train_loss: 0.1666390299797058
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6856183409690857, train_loss: 0.6387155055999756
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4146711528301239, train_loss: 0.3470975160598755
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3575526773929596, train_loss: 0.24800413846969604
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34163081645965576, train_loss: 0.19891713559627533
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33671239018440247, train_loss: 0.16168716549873352
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8912028074264526, train_loss: 0.90067058801651
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5100347995758057, train_loss: 0.4547128677368164
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3834174573421478, train_loss: 0.28243714570999146
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3495369255542755, train_loss: 0.2221192866563797
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34305107593536377, train_loss: 0.17960315942764282
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45237210392951965, train_loss: 0.4864894151687622
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.12572833895683289, train_loss: 0.07241109013557434
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12361818552017212, train_loss: 0.057247646152973175
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12366410344839096, train_loss: 0.055758263915777206
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12369631975889206, train_loss: 0.05403897166252136
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4158687889575958, train_loss: 0.4713703989982605
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13148464262485504, train_loss: 0.08117224276065826
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12560082972049713, train_loss: 0.0576566606760025
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12559722363948822, train_loss: 0.0534762367606163
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12564228475093842, train_loss: 0.05272471904754639
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.723024308681488, train_loss: 0.7300964593887329
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43085628747940063, train_loss: 0.38566863536834717
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33390316367149353, train_loss: 0.2810978889465332
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2948736250400543, train_loss: 0.22558653354644775
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.278236448764801, train_loss: 0.19235345721244812
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2716260850429535, train_loss: 0.1650838851928711
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.269253671169281, train_loss: 0.1496332734823227
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6141656637191772, train_loss: 0.6102476119995117
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41817498207092285, train_loss: 0.3350103497505188
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37391361594200134, train_loss: 0.2509858012199402
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3686867654323578, train_loss: 0.204462468624115
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36903196573257446, train_loss: 0.1997252255678177
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6619335412979126, train_loss: 0.6904311776161194
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41668981313705444, train_loss: 0.35756248235702515
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34522777795791626, train_loss: 0.24401944875717163
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3244238793849945, train_loss: 0.18955892324447632
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32060420513153076, train_loss: 0.1546744406223297
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9011908173561096, train_loss: 0.9037994742393494
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5282064080238342, train_loss: 0.4522566795349121
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39229026436805725, train_loss: 0.26854607462882996
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3592832088470459, train_loss: 0.2046639770269394
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3540807366371155, train_loss: 0.16806405782699585
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5695952773094177, train_loss: 0.5749297142028809
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1507543921470642, train_loss: 0.07114847749471664
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14603707194328308, train_loss: 0.056863248348236084
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14602354168891907, train_loss: 0.05395965650677681
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14556628465652466, train_loss: 0.05512699484825134
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.557402491569519, train_loss: 0.5842490196228027
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1268584430217743, train_loss: 0.08097200095653534
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12324167788028717, train_loss: 0.060368843376636505
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12332028150558472, train_loss: 0.05864814296364784
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12314023077487946, train_loss: 0.056030914187431335
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5790450572967529, train_loss: 0.5849113464355469
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37632957100868225, train_loss: 0.34380924701690674
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3151763379573822, train_loss: 0.2605058252811432
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2921694219112396, train_loss: 0.2211780697107315
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2810693085193634, train_loss: 0.18778769671916962
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2769177556037903, train_loss: 0.16224107146263123
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2765204608440399, train_loss: 0.1530320942401886
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8514704704284668, train_loss: 0.8735418319702148
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4940780997276306, train_loss: 0.43483731150627136
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38452547788619995, train_loss: 0.27120769023895264
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.360927551984787, train_loss: 0.20640894770622253
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3589574992656708, train_loss: 0.17571578919887543
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5210309624671936, train_loss: 0.5393580198287964
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35838785767555237, train_loss: 0.306443989276886
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3244647979736328, train_loss: 0.22709646821022034
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3184167146682739, train_loss: 0.18665267527103424
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.318348228931427, train_loss: 0.1738535612821579
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8692744970321655, train_loss: 0.9019269943237305
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5078116059303284, train_loss: 0.451488196849823
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3777562379837036, train_loss: 0.2787000834941864
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3449927270412445, train_loss: 0.21027211844921112
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33989202976226807, train_loss: 0.16979989409446716
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3876173794269562, train_loss: 0.36211204528808594
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14830899238586426, train_loss: 0.07764416933059692
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1421533077955246, train_loss: 0.051952335983514786
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14167428016662598, train_loss: 0.0457252636551857
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1416437178850174, train_loss: 0.04308571666479111
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.41311365365982056, train_loss: 0.4809577167034149
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11167323589324951, train_loss: 0.08554643392562866
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1059960126876831, train_loss: 0.0627579391002655
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10578994452953339, train_loss: 0.05933935195207596
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10621451586484909, train_loss: 0.05421389639377594
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.869156539440155, train_loss: 0.8447233438491821
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5038650035858154, train_loss: 0.45018327236175537
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36325427889823914, train_loss: 0.30210238695144653
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3107025623321533, train_loss: 0.23315444588661194
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28656792640686035, train_loss: 0.1969468593597412
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2773602306842804, train_loss: 0.16249525547027588
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6119698286056519, train_loss: 0.5859171152114868
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.407049298286438, train_loss: 0.33015429973602295
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3653658330440521, train_loss: 0.2475389540195465
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3572377562522888, train_loss: 0.20004990696907043
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35719946026802063, train_loss: 0.18810731172561646
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7160911560058594, train_loss: 0.7204650640487671
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4285985827445984, train_loss: 0.3729405999183655
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34589749574661255, train_loss: 0.25108328461647034
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.320245623588562, train_loss: 0.1937677264213562
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.317019522190094, train_loss: 0.15867269039154053
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5441341400146484, train_loss: 0.5494316816329956
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3796028792858124, train_loss: 0.31854066252708435
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34255075454711914, train_loss: 0.23533177375793457
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33749064803123474, train_loss: 0.19348612427711487
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.337484747171402, train_loss: 0.18719427287578583
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4067116975784302, train_loss: 0.379172682762146
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14736737310886383, train_loss: 0.08023546636104584
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14145594835281372, train_loss: 0.0538354367017746
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14053520560264587, train_loss: 0.04814890772104263
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1400642842054367, train_loss: 0.04498123750090599
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7420037388801575, train_loss: 0.824866771697998
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1317395120859146, train_loss: 0.07661639153957367
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12825138866901398, train_loss: 0.058485180139541626
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12807899713516235, train_loss: 0.05380074679851532
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12813740968704224, train_loss: 0.05211193114519119
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.472091406583786, train_loss: 0.49950656294822693
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.325857549905777, train_loss: 0.31036320328712463
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2838832437992096, train_loss: 0.2520655393600464
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26855573058128357, train_loss: 0.2100999653339386
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26279792189598083, train_loss: 0.1727418303489685
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6696230173110962, train_loss: 0.6654442548751831
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4229571223258972, train_loss: 0.3446801006793976
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3674425780773163, train_loss: 0.24450600147247314
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35646113753318787, train_loss: 0.1896219551563263
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35652944445610046, train_loss: 0.1737910956144333
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6542413830757141, train_loss: 0.6407010555267334
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4045453369617462, train_loss: 0.34367114305496216
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34160012006759644, train_loss: 0.24332007765769958
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32410159707069397, train_loss: 0.19003939628601074
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32068830728530884, train_loss: 0.16124777495861053
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6340973377227783, train_loss: 0.6280990839004517
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40332236886024475, train_loss: 0.3382693827152252
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34495192766189575, train_loss: 0.24277254939079285
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33190903067588806, train_loss: 0.18529406189918518
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33182135224342346, train_loss: 0.17353639006614685
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3510517477989197, train_loss: 0.2927338480949402
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15039990842342377, train_loss: 0.06979839503765106
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1440947949886322, train_loss: 0.052655480802059174
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14366410672664642, train_loss: 0.05016028508543968
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14382576942443848, train_loss: 0.049606937915086746
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5551992654800415, train_loss: 0.5968737602233887
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13419607281684875, train_loss: 0.0833621621131897
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1287081241607666, train_loss: 0.05998164042830467
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12848564982414246, train_loss: 0.0545918233692646
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12827245891094208, train_loss: 0.05414929240942001
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.obtaining subgroup results for loco, feature_num: 16.obtaining subgroup results for loco, feature_num: 17.obtaining subgroup results for loco, feature_num: 18.obtaining subgroup results for loco, feature_num: 19.obtaining subgroup results for loco, feature_num: 20.obtaining subgroup results for loco, feature_num: 21.obtaining subgroup results for loco, feature_num: 22.obtaining subgroup results for loco, feature_num: 23.obtaining subgroup results for loco, feature_num: 24.obtaining subgroup results for loco, feature_num: 25.obtaining subgroup results for loco, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.obtaining subgroup results for permucate, feature_num: 16.obtaining subgroup results for permucate, feature_num: 17.obtaining subgroup results for permucate, feature_num: 18.obtaining subgroup results for permucate, feature_num: 19.obtaining subgroup results for permucate, feature_num: 20.obtaining subgroup results for permucate, feature_num: 21.obtaining subgroup results for permucate, feature_num: 22.obtaining subgroup results for permucate, feature_num: 23.obtaining subgroup results for permucate, feature_num: 24.obtaining subgroup results for permucate, feature_num: 25.obtaining subgroup results for permucate, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.obtaining subgroup results for saliency, feature_num: 16.obtaining subgroup results for saliency, feature_num: 17.obtaining subgroup results for saliency, feature_num: 18.obtaining subgroup results for saliency, feature_num: 19.obtaining subgroup results for saliency, feature_num: 20.obtaining subgroup results for saliency, feature_num: 21.obtaining subgroup results for saliency, feature_num: 22.obtaining subgroup results for saliency, feature_num: 23.obtaining subgroup results for saliency, feature_num: 24.obtaining subgroup results for saliency, feature_num: 25.obtaining subgroup results for saliency, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.obtaining subgroup results for smooth_grad, feature_num: 16.obtaining subgroup results for smooth_grad, feature_num: 17.obtaining subgroup results for smooth_grad, feature_num: 18.obtaining subgroup results for smooth_grad, feature_num: 19.obtaining subgroup results for smooth_grad, feature_num: 20.obtaining subgroup results for smooth_grad, feature_num: 21.obtaining subgroup results for smooth_grad, feature_num: 22.obtaining subgroup results for smooth_grad, feature_num: 23.obtaining subgroup results for smooth_grad, feature_num: 24.obtaining subgroup results for smooth_grad, feature_num: 25.obtaining subgroup results for smooth_grad, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.obtaining subgroup results for gradient_shap, feature_num: 16.obtaining subgroup results for gradient_shap, feature_num: 17.obtaining subgroup results for gradient_shap, feature_num: 18.obtaining subgroup results for gradient_shap, feature_num: 19.obtaining subgroup results for gradient_shap, feature_num: 20.obtaining subgroup results for gradient_shap, feature_num: 21.obtaining subgroup results for gradient_shap, feature_num: 22.obtaining subgroup results for gradient_shap, feature_num: 23.obtaining subgroup results for gradient_shap, feature_num: 24.obtaining subgroup results for gradient_shap, feature_num: 25.obtaining subgroup results for gradient_shap, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.obtaining subgroup results for lime, feature_num: 16.obtaining subgroup results for lime, feature_num: 17.obtaining subgroup results for lime, feature_num: 18.obtaining subgroup results for lime, feature_num: 19.obtaining subgroup results for lime, feature_num: 20.obtaining subgroup results for lime, feature_num: 21.obtaining subgroup results for lime, feature_num: 22.obtaining subgroup results for lime, feature_num: 23.obtaining subgroup results for lime, feature_num: 24.obtaining subgroup results for lime, feature_num: 25.obtaining subgroup results for lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.obtaining subgroup results for baseline_lime, feature_num: 16.obtaining subgroup results for baseline_lime, feature_num: 17.obtaining subgroup results for baseline_lime, feature_num: 18.obtaining subgroup results for baseline_lime, feature_num: 19.obtaining subgroup results for baseline_lime, feature_num: 20.obtaining subgroup results for baseline_lime, feature_num: 21.obtaining subgroup results for baseline_lime, feature_num: 22.obtaining subgroup results for baseline_lime, feature_num: 23.obtaining subgroup results for baseline_lime, feature_num: 24.obtaining subgroup results for baseline_lime, feature_num: 25.obtaining subgroup results for baseline_lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 16.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 17.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 18.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 19.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 20.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 21.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 22.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 23.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 24.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 25.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 16.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 17.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 18.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 19.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 20.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 21.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 22.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 23.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 24.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 25.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.obtaining subgroup results for integrated_gradients, feature_num: 16.obtaining subgroup results for integrated_gradients, feature_num: 17.obtaining subgroup results for integrated_gradients, feature_num: 18.obtaining subgroup results for integrated_gradients, feature_num: 19.obtaining subgroup results for integrated_gradients, feature_num: 20.obtaining subgroup results for integrated_gradients, feature_num: 21.obtaining subgroup results for integrated_gradients, feature_num: 22.obtaining subgroup results for integrated_gradients, feature_num: 23.obtaining subgroup results for integrated_gradients, feature_num: 24.obtaining subgroup results for integrated_gradients, feature_num: 25.obtaining subgroup results for integrated_gradients, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.obtaining subgroup results for baseline_integrated_gradients, feature_num: 16.obtaining subgroup results for baseline_integrated_gradients, feature_num: 17.obtaining subgroup results for baseline_integrated_gradients, feature_num: 18.obtaining subgroup results for baseline_integrated_gradients, feature_num: 19.obtaining subgroup results for baseline_integrated_gradients, feature_num: 20.obtaining subgroup results for baseline_integrated_gradients, feature_num: 21.obtaining subgroup results for baseline_integrated_gradients, feature_num: 22.obtaining subgroup results for baseline_integrated_gradients, feature_num: 23.obtaining subgroup results for baseline_integrated_gradients, feature_num: 24.obtaining subgroup results for baseline_integrated_gradients, feature_num: 25.obtaining subgroup results for baseline_integrated_gradients, feature_num: 26.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6366693377494812, train_loss: 0.6370074152946472
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4025358259677887, train_loss: 0.3442363142967224
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35077977180480957, train_loss: 0.2541467249393463
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34433725476264954, train_loss: 0.2076379805803299
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3448505401611328, train_loss: 0.20267614722251892
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7086393237113953, train_loss: 0.691866397857666
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4630754888057709, train_loss: 0.35754454135894775
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40798357129096985, train_loss: 0.23766516149044037
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.4053232669830322, train_loss: 0.1934310495853424
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.4061982333660126, train_loss: 0.18642716109752655
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9474849104881287, train_loss: 0.9347043037414551
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5331431031227112, train_loss: 0.47997137904167175
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37223517894744873, train_loss: 0.30670008063316345
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32313594222068787, train_loss: 0.23706530034542084
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30440348386764526, train_loss: 0.19145402312278748
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.296448290348053, train_loss: 0.16610202193260193
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.29332399368286133, train_loss: 0.14127257466316223
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5907914638519287, train_loss: 0.5793458223342896
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4275050163269043, train_loss: 0.3058779537677765
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39492401480674744, train_loss: 0.2147040218114853
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3930279314517975, train_loss: 0.16832807660102844
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.39326247572898865, train_loss: 0.16464215517044067
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3889933228492737, train_loss: 0.4464142918586731
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1267351359128952, train_loss: 0.07565698027610779
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12215778976678848, train_loss: 0.056617699563503265
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12217986583709717, train_loss: 0.05229979008436203
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12221679836511612, train_loss: 0.04990869760513306
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4277544617652893, train_loss: 0.42034342885017395
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1370973140001297, train_loss: 0.07859119027853012
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13413622975349426, train_loss: 0.06405267119407654
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13345709443092346, train_loss: 0.058331988751888275
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13316015899181366, train_loss: 0.058513093739748
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   1%|          | 256/26001 [00:00<00:50, 509.96it/s]Shapley Value Sampling attribution:   2%|▏         | 512/26001 [00:01<00:49, 510.71it/s]Shapley Value Sampling attribution:   3%|▎         | 769/26001 [00:01<00:49, 511.37it/s]Shapley Value Sampling attribution:   4%|▍         | 1025/26001 [00:02<00:48, 511.25it/s]Shapley Value Sampling attribution:   5%|▍         | 1281/26001 [00:02<00:48, 510.88it/s]Shapley Value Sampling attribution:   6%|▌         | 1537/26001 [00:03<00:47, 511.03it/s]Shapley Value Sampling attribution:   7%|▋         | 1793/26001 [00:03<00:47, 510.52it/s]Shapley Value Sampling attribution:   8%|▊         | 2049/26001 [00:04<00:46, 510.51it/s]Shapley Value Sampling attribution:   9%|▉         | 2305/26001 [00:04<00:46, 506.71it/s]Shapley Value Sampling attribution:  10%|▉         | 2559/26001 [00:05<00:46, 504.49it/s]Shapley Value Sampling attribution:  11%|█         | 2812/26001 [00:05<00:46, 502.70it/s]Shapley Value Sampling attribution:  12%|█▏        | 3069/26001 [00:06<00:45, 505.65it/s]Shapley Value Sampling attribution:  13%|█▎        | 3340/26001 [00:06<00:43, 516.38it/s]Shapley Value Sampling attribution:  14%|█▍        | 3682/26001 [00:07<00:39, 566.75it/s]Shapley Value Sampling attribution:  16%|█▌        | 4117/26001 [00:07<00:33, 657.47it/s]Shapley Value Sampling attribution:  18%|█▊        | 4591/26001 [00:08<00:28, 744.40it/s]Shapley Value Sampling attribution:  20%|█▉        | 5073/26001 [00:08<00:25, 810.19it/s]Shapley Value Sampling attribution:  21%|██▏       | 5556/26001 [00:09<00:23, 856.42it/s]Shapley Value Sampling attribution:  23%|██▎       | 6039/26001 [00:09<00:22, 888.80it/s]Shapley Value Sampling attribution:  25%|██▌       | 6505/26001 [00:10<00:21, 901.21it/s]Shapley Value Sampling attribution:  27%|██▋       | 6987/26001 [00:10<00:20, 919.50it/s]Shapley Value Sampling attribution:  29%|██▊       | 7447/26001 [00:11<00:21, 845.18it/s]Shapley Value Sampling attribution:  30%|███       | 7876/26001 [00:11<00:22, 789.08it/s]Shapley Value Sampling attribution:  32%|███▏      | 8347/26001 [00:12<00:21, 830.47it/s]Shapley Value Sampling attribution:  34%|███▍      | 8830/26001 [00:12<00:19, 868.02it/s]Shapley Value Sampling attribution:  36%|███▌      | 9313/26001 [00:13<00:18, 895.65it/s]Shapley Value Sampling attribution:  38%|███▊      | 9795/26001 [00:13<00:17, 915.24it/s]Shapley Value Sampling attribution:  40%|███▉      | 10277/26001 [00:14<00:16, 929.50it/s]Shapley Value Sampling attribution:  41%|████▏     | 10759/26001 [00:14<00:16, 939.45it/s]Shapley Value Sampling attribution:  43%|████▎     | 11241/26001 [00:15<00:15, 946.59it/s]Shapley Value Sampling attribution:  45%|████▌     | 11723/26001 [00:15<00:15, 951.69it/s]Shapley Value Sampling attribution:  47%|████▋     | 12212/26001 [00:16<00:14, 959.21it/s]Shapley Value Sampling attribution:  49%|████▉     | 12698/26001 [00:16<00:13, 962.48it/s]Shapley Value Sampling attribution:  51%|█████     | 13191/26001 [00:17<00:13, 968.98it/s]Shapley Value Sampling attribution:  53%|█████▎    | 13676/26001 [00:17<00:12, 967.52it/s]Shapley Value Sampling attribution:  54%|█████▍    | 14169/26001 [00:18<00:12, 972.56it/s]Shapley Value Sampling attribution:  56%|█████▋    | 14656/26001 [00:18<00:11, 967.12it/s]Shapley Value Sampling attribution:  58%|█████▊    | 15140/26001 [00:19<00:11, 939.35it/s]Shapley Value Sampling attribution:  60%|██████    | 15611/26001 [00:19<00:11, 903.89it/s]Shapley Value Sampling attribution:  62%|██████▏   | 16065/26001 [00:20<00:11, 832.76it/s]Shapley Value Sampling attribution:  63%|██████▎   | 16488/26001 [00:21<00:13, 730.53it/s]Shapley Value Sampling attribution:  65%|██████▍   | 16867/26001 [00:22<00:15, 608.29it/s]Shapley Value Sampling attribution:  66%|██████▌   | 17194/26001 [00:22<00:15, 567.68it/s]Shapley Value Sampling attribution:  67%|██████▋   | 17494/26001 [00:23<00:15, 555.17it/s]Shapley Value Sampling attribution:  68%|██████▊   | 17782/26001 [00:24<00:15, 545.90it/s]Shapley Value Sampling attribution:  69%|██████▉   | 18062/26001 [00:24<00:14, 542.83it/s]Shapley Value Sampling attribution:  71%|███████   | 18348/26001 [00:25<00:13, 550.03it/s]Shapley Value Sampling attribution:  72%|███████▏  | 18644/26001 [00:25<00:13, 561.39it/s]Shapley Value Sampling attribution:  73%|███████▎  | 18928/26001 [00:26<00:12, 560.29it/s]Shapley Value Sampling attribution:  74%|███████▍  | 19211/26001 [00:26<00:12, 546.38it/s]Shapley Value Sampling attribution:  75%|███████▍  | 19486/26001 [00:27<00:12, 531.85it/s]Shapley Value Sampling attribution:  76%|███████▌  | 19754/26001 [00:27<00:12, 516.50it/s]Shapley Value Sampling attribution:  77%|███████▋  | 20014/26001 [00:28<00:11, 506.23it/s]Shapley Value Sampling attribution:  78%|███████▊  | 20268/26001 [00:28<00:11, 499.31it/s]Shapley Value Sampling attribution:  79%|███████▉  | 20518/26001 [00:29<00:11, 489.99it/s]Shapley Value Sampling attribution:  80%|███████▉  | 20764/26001 [00:29<00:10, 490.54it/s]Shapley Value Sampling attribution:  81%|████████  | 21010/26001 [00:30<00:10, 490.26it/s]Shapley Value Sampling attribution:  82%|████████▏ | 21374/26001 [00:30<00:08, 559.39it/s]Shapley Value Sampling attribution:  84%|████████▍ | 21828/26001 [00:31<00:06, 661.78it/s]Shapley Value Sampling attribution:  86%|████████▌ | 22313/26001 [00:31<00:04, 752.95it/s]Shapley Value Sampling attribution:  88%|████████▊ | 22806/26001 [00:32<00:03, 821.77it/s]Shapley Value Sampling attribution:  90%|████████▉ | 23298/26001 [00:32<00:03, 870.04it/s]Shapley Value Sampling attribution:  92%|█████████▏| 23791/26001 [00:33<00:02, 904.21it/s]Shapley Value Sampling attribution:  93%|█████████▎| 24282/26001 [00:33<00:01, 927.43it/s]Shapley Value Sampling attribution:  95%|█████████▌| 24774/26001 [00:34<00:01, 944.31it/s]Shapley Value Sampling attribution:  97%|█████████▋| 25266/26001 [00:34<00:00, 956.10it/s]Shapley Value Sampling attribution:  99%|█████████▉| 25757/26001 [00:35<00:00, 963.71it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:35<00:00, 728.79it/s]
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   2%|▏         | 492/26001 [00:00<00:25, 982.43it/s]Shapley Value Sampling attribution:   4%|▍         | 984/26001 [00:01<00:25, 982.65it/s]Shapley Value Sampling attribution:   6%|▌         | 1476/26001 [00:01<00:24, 981.80it/s]Shapley Value Sampling attribution:   8%|▊         | 1969/26001 [00:02<00:24, 982.71it/s]Shapley Value Sampling attribution:   9%|▉         | 2461/26001 [00:02<00:23, 982.84it/s]Shapley Value Sampling attribution:  11%|█▏        | 2953/26001 [00:03<00:23, 983.13it/s]Shapley Value Sampling attribution:  13%|█▎        | 3445/26001 [00:03<00:25, 879.12it/s]Shapley Value Sampling attribution:  15%|█▍        | 3894/26001 [00:04<00:26, 823.07it/s]Shapley Value Sampling attribution:  17%|█▋        | 4384/26001 [00:04<00:24, 867.14it/s]Shapley Value Sampling attribution:  19%|█▊        | 4874/26001 [00:05<00:23, 899.01it/s]Shapley Value Sampling attribution:  21%|██        | 5364/26001 [00:05<00:22, 922.37it/s]Shapley Value Sampling attribution:  23%|██▎       | 5852/26001 [00:06<00:21, 937.88it/s]Shapley Value Sampling attribution:  24%|██▍       | 6325/26001 [00:06<00:20, 940.23it/s]Shapley Value Sampling attribution:  26%|██▌       | 6813/26001 [00:07<00:20, 950.76it/s]Shapley Value Sampling attribution:  28%|██▊       | 7304/26001 [00:07<00:19, 959.73it/s]Shapley Value Sampling attribution:  30%|██▉       | 7795/26001 [00:08<00:18, 966.02it/s]Shapley Value Sampling attribution:  32%|███▏      | 8287/26001 [00:08<00:18, 970.97it/s]Shapley Value Sampling attribution:  34%|███▍      | 8779/26001 [00:09<00:17, 974.61it/s]Shapley Value Sampling attribution:  36%|███▌      | 9272/26001 [00:09<00:17, 977.60it/s]Shapley Value Sampling attribution:  38%|███▊      | 9762/26001 [00:10<00:17, 942.10it/s]Shapley Value Sampling attribution:  39%|███▉      | 10235/26001 [00:10<00:17, 916.56it/s]Shapley Value Sampling attribution:  41%|████      | 10695/26001 [00:11<00:17, 898.45it/s]Shapley Value Sampling attribution:  43%|████▎     | 11146/26001 [00:11<00:16, 886.05it/s]Shapley Value Sampling attribution:  45%|████▍     | 11590/26001 [00:12<00:16, 878.41it/s]Shapley Value Sampling attribution:  46%|████▋     | 12030/26001 [00:13<00:15, 873.36it/s]Shapley Value Sampling attribution:  48%|████▊     | 12467/26001 [00:13<00:16, 838.91it/s]Shapley Value Sampling attribution:  50%|████▉     | 12888/26001 [00:14<00:16, 796.64it/s]Shapley Value Sampling attribution:  51%|█████     | 13289/26001 [00:15<00:19, 663.84it/s]Shapley Value Sampling attribution:  52%|█████▏    | 13640/26001 [00:15<00:21, 573.59it/s]Shapley Value Sampling attribution:  54%|█████▎    | 13948/26001 [00:16<00:22, 525.73it/s]Shapley Value Sampling attribution:  55%|█████▍    | 14226/26001 [00:17<00:23, 495.38it/s]Shapley Value Sampling attribution:  56%|█████▌    | 14484/26001 [00:17<00:23, 483.65it/s]Shapley Value Sampling attribution:  57%|█████▋    | 14732/26001 [00:18<00:23, 485.22it/s]Shapley Value Sampling attribution:  58%|█████▊    | 15004/26001 [00:18<00:21, 500.14it/s]Shapley Value Sampling attribution:  59%|█████▉    | 15280/26001 [00:19<00:20, 513.95it/s]Shapley Value Sampling attribution:  60%|█████▉    | 15556/26001 [00:19<00:19, 524.11it/s]Shapley Value Sampling attribution:  61%|██████    | 15880/26001 [00:20<00:18, 559.04it/s]Shapley Value Sampling attribution:  63%|██████▎   | 16282/26001 [00:20<00:15, 629.54it/s]Shapley Value Sampling attribution:  64%|██████▍   | 16754/26001 [00:21<00:12, 721.29it/s]Shapley Value Sampling attribution:  66%|██████▋   | 17243/26001 [00:21<00:10, 796.40it/s]Shapley Value Sampling attribution:  68%|██████▊   | 17736/26001 [00:22<00:09, 852.00it/s]Shapley Value Sampling attribution:  70%|███████   | 18229/26001 [00:22<00:08, 891.46it/s]Shapley Value Sampling attribution:  72%|███████▏  | 18722/26001 [00:23<00:07, 919.06it/s]Shapley Value Sampling attribution:  74%|███████▍  | 19213/26001 [00:23<00:07, 937.42it/s]Shapley Value Sampling attribution:  76%|███████▌  | 19705/26001 [00:24<00:06, 951.30it/s]Shapley Value Sampling attribution:  78%|███████▊  | 20197/26001 [00:24<00:06, 960.87it/s]Shapley Value Sampling attribution:  80%|███████▉  | 20690/26001 [00:25<00:05, 967.97it/s]Shapley Value Sampling attribution:  81%|████████▏ | 21183/26001 [00:25<00:04, 973.02it/s]Shapley Value Sampling attribution:  83%|████████▎ | 21674/26001 [00:26<00:04, 975.52it/s]Shapley Value Sampling attribution:  85%|████████▌ | 22167/26001 [00:26<00:03, 978.19it/s]Shapley Value Sampling attribution:  87%|████████▋ | 22660/26001 [00:27<00:03, 979.99it/s]Shapley Value Sampling attribution:  89%|████████▉ | 23151/26001 [00:27<00:02, 977.23it/s]Shapley Value Sampling attribution:  91%|█████████ | 23642/26001 [00:28<00:02, 978.34it/s]Shapley Value Sampling attribution:  93%|█████████▎| 24135/26001 [00:28<00:01, 980.06it/s]Shapley Value Sampling attribution:  95%|█████████▍| 24628/26001 [00:29<00:01, 981.44it/s]Shapley Value Sampling attribution:  97%|█████████▋| 25119/26001 [00:30<00:00, 898.02it/s]Shapley Value Sampling attribution:  98%|█████████▊| 25575/26001 [00:30<00:00, 830.95it/s]Shapley Value Sampling attribution: 100%|██████████| 26001/26001 [00:31<00:00, 834.53it/s]
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:12<05:14, 12.59s/it]importance j:   8%|▊         | 2/26 [00:29<06:03, 15.13s/it]importance j:  12%|█▏        | 3/26 [00:41<05:13, 13.62s/it]importance j:  15%|█▌        | 4/26 [00:58<05:29, 14.97s/it]importance j:  19%|█▉        | 5/26 [01:10<04:49, 13.80s/it]importance j:  23%|██▎       | 6/26 [01:30<05:23, 16.17s/it]importance j:  27%|██▋       | 7/26 [01:50<05:27, 17.24s/it]importance j:  31%|███       | 8/26 [02:01<04:37, 15.44s/it]importance j:  35%|███▍      | 9/26 [02:21<04:43, 16.70s/it]importance j:  38%|███▊      | 10/26 [02:35<04:12, 15.79s/it]importance j:  42%|████▏     | 11/26 [02:53<04:07, 16.48s/it]importance j:  46%|████▌     | 12/26 [03:09<03:50, 16.50s/it]importance j:  50%|█████     | 13/26 [03:24<03:27, 15.98s/it]importance j:  54%|█████▍    | 14/26 [03:42<03:20, 16.67s/it]importance j:  58%|█████▊    | 15/26 [03:54<02:48, 15.28s/it]importance j:  62%|██████▏   | 16/26 [04:14<02:45, 16.54s/it]importance j:  65%|██████▌   | 17/26 [04:26<02:16, 15.12s/it]importance j:  69%|██████▉   | 18/26 [04:44<02:09, 16.24s/it]importance j:  73%|███████▎  | 19/26 [05:02<01:57, 16.79s/it]importance j:  77%|███████▋  | 20/26 [05:19<01:39, 16.66s/it]importance j:  81%|████████  | 21/26 [05:38<01:26, 17.31s/it]importance j:  85%|████████▍ | 22/26 [05:49<01:02, 15.63s/it]importance j:  88%|████████▊ | 23/26 [06:08<00:49, 16.59s/it]importance j:  92%|█████████▏| 24/26 [06:23<00:32, 16.03s/it]importance j:  96%|█████████▌| 25/26 [06:39<00:16, 16.16s/it]importance j: 100%|██████████| 26/26 [06:58<00:00, 16.79s/it]                                                             [po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5719186067581177, train_loss: 0.5927672982215881
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3669453561306, train_loss: 0.3521394729614258
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3027438819408417, train_loss: 0.2729358971118927
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27857014536857605, train_loss: 0.22012874484062195
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.270132452249527, train_loss: 0.1933448612689972
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7430001497268677, train_loss: 0.7643929719924927
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4536072909832001, train_loss: 0.39911189675331116
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3710741698741913, train_loss: 0.2670671343803406
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35071587562561035, train_loss: 0.21250498294830322
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34888073801994324, train_loss: 0.18738073110580444
[po_estimator_1_impute_pos] Epoch: 250, current validation loss: 0.348617821931839, train_loss: 0.18444377183914185
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6980034112930298, train_loss: 0.663258969783783
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4271373748779297, train_loss: 0.3491237461566925
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.358379989862442, train_loss: 0.2452060580253601
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3401431441307068, train_loss: 0.18884658813476562
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33756837248802185, train_loss: 0.1660817265510559
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.74223393201828, train_loss: 0.7473607659339905
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43825802206993103, train_loss: 0.3675200343132019
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3644236922264099, train_loss: 0.24998493492603302
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34962475299835205, train_loss: 0.18993699550628662
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3498125970363617, train_loss: 0.1782066375017166
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4234764277935028, train_loss: 0.5556859970092773
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14293229579925537, train_loss: 0.06436209380626678
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1371258944272995, train_loss: 0.04832121357321739
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13693301379680634, train_loss: 0.0485854297876358
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1364225298166275, train_loss: 0.04366772621870041
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34321704506874084, train_loss: 0.3847702741622925
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12315326184034348, train_loss: 0.0776776596903801
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12173078954219818, train_loss: 0.05687863379716873
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12137053161859512, train_loss: 0.05773506313562393
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12166858464479446, train_loss: 0.05586651712656021
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8460034728050232, train_loss: 0.8517720103263855
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4844205677509308, train_loss: 0.44133880734443665
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3528020679950714, train_loss: 0.2977375388145447
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3046056926250458, train_loss: 0.2320568859577179
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28266623616218567, train_loss: 0.1988045573234558
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27333152294158936, train_loss: 0.16390785574913025
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2700369656085968, train_loss: 0.14324621856212616
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8988401889801025, train_loss: 0.9234915971755981
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5262993574142456, train_loss: 0.46391382813453674
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39377838373184204, train_loss: 0.2762877345085144
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36486586928367615, train_loss: 0.20506206154823303
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3618873059749603, train_loss: 0.17198587954044342
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7169835567474365, train_loss: 0.7126802206039429
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42577511072158813, train_loss: 0.3611255884170532
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3490842580795288, train_loss: 0.239214688539505
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32736116647720337, train_loss: 0.1885036826133728
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3240727484226227, train_loss: 0.15628720819950104
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9647367596626282, train_loss: 0.9881551861763
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5595664381980896, train_loss: 0.49556630849838257
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40196308493614197, train_loss: 0.2944157123565674
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3625556528568268, train_loss: 0.22080016136169434
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35474348068237305, train_loss: 0.17824119329452515
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.48889175057411194, train_loss: 0.44768503308296204
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15099908411502838, train_loss: 0.0793810710310936
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14297308027744293, train_loss: 0.051760513335466385
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1430862843990326, train_loss: 0.04760291054844856
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1432306468486786, train_loss: 0.04740336537361145
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3734528124332428, train_loss: 0.43658390641212463
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1238207295536995, train_loss: 0.07814348489046097
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.122012197971344, train_loss: 0.06112822890281677
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12238676100969315, train_loss: 0.0582905039191246
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12231917679309845, train_loss: 0.05393065884709358
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5638624429702759, train_loss: 0.6318720579147339
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3655671179294586, train_loss: 0.35610902309417725
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3041175901889801, train_loss: 0.2669047713279724
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28302788734436035, train_loss: 0.2178610861301422
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27382737398147583, train_loss: 0.1910397708415985
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6293705105781555, train_loss: 0.6165538430213928
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42403465509414673, train_loss: 0.3421044945716858
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3770137429237366, train_loss: 0.24859613180160522
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3692437410354614, train_loss: 0.20028910040855408
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3694658875465393, train_loss: 0.1865207850933075
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9317935705184937, train_loss: 1.0189127922058105
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5251291394233704, train_loss: 0.5094362497329712
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3674358129501343, train_loss: 0.2981971502304077
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32373711466789246, train_loss: 0.21906957030296326
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31007885932922363, train_loss: 0.17556101083755493
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3062348961830139, train_loss: 0.14811798930168152
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8169528841972351, train_loss: 0.8357442021369934
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.48217272758483887, train_loss: 0.4038982689380646
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38127580285072327, train_loss: 0.2614606022834778
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35517066717147827, train_loss: 0.20522591471672058
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35035377740859985, train_loss: 0.1729949712753296
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6649442315101624, train_loss: 0.7758090496063232
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1448710858821869, train_loss: 0.0670623779296875
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1401102989912033, train_loss: 0.05034798011183739
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14002320170402527, train_loss: 0.05083629861474037
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1398831158876419, train_loss: 0.04881734773516655
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5018991231918335, train_loss: 0.49960798025131226
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12932924926280975, train_loss: 0.08870898932218552
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12172698974609375, train_loss: 0.05877353996038437
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12145885825157166, train_loss: 0.05266802757978439
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12133954465389252, train_loss: 0.052550479769706726
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7265105247497559, train_loss: 0.7440485954284668
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42742639780044556, train_loss: 0.3873767852783203
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3300737142562866, train_loss: 0.2773740887641907
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29539966583251953, train_loss: 0.22662511467933655
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2811334431171417, train_loss: 0.18842387199401855
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2757049798965454, train_loss: 0.160164475440979
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6964080333709717, train_loss: 0.6815569400787354
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4271022081375122, train_loss: 0.35069847106933594
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3776114583015442, train_loss: 0.2491285502910614
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37213221192359924, train_loss: 0.20766448974609375
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3723633289337158, train_loss: 0.19943124055862427
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6618907451629639, train_loss: 0.6213974952697754
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4052899479866028, train_loss: 0.33165469765663147
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.345042884349823, train_loss: 0.244862899184227
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3280228078365326, train_loss: 0.18841415643692017
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3248381018638611, train_loss: 0.16269463300704956
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7479603886604309, train_loss: 0.7289517521858215
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4431909918785095, train_loss: 0.3686143159866333
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3696380853652954, train_loss: 0.25510796904563904
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35273870825767517, train_loss: 0.19993247091770172
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3521014451980591, train_loss: 0.17804120481014252
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5415337681770325, train_loss: 0.5624131560325623
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14615806937217712, train_loss: 0.07240787148475647
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.144928976893425, train_loss: 0.060942843556404114
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14439834654331207, train_loss: 0.05901883915066719
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1442510038614273, train_loss: 0.058019593358039856
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4198440909385681, train_loss: 0.5148383975028992
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11563458293676376, train_loss: 0.0867244154214859
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1112690269947052, train_loss: 0.06055036187171936
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1114443764090538, train_loss: 0.05886375159025192
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11167997121810913, train_loss: 0.05609898641705513
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7767908573150635, train_loss: 0.7822744846343994
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45029184222221375, train_loss: 0.42583274841308594
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33300408720970154, train_loss: 0.297768235206604
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29320260882377625, train_loss: 0.24318420886993408
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27862319350242615, train_loss: 0.20312538743019104
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6396563053131104, train_loss: 0.6602864265441895
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4091116189956665, train_loss: 0.3633914589881897
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35387948155403137, train_loss: 0.25962790846824646
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.345781534910202, train_loss: 0.21206329762935638
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.345807820558548, train_loss: 0.20376108586788177
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5536430478096008, train_loss: 0.5521270632743835
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37179940938949585, train_loss: 0.32280871272087097
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3262495696544647, train_loss: 0.23423513770103455
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3153556287288666, train_loss: 0.19069728255271912
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3151310980319977, train_loss: 0.17583060264587402
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8347973823547363, train_loss: 0.8544416427612305
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.484466552734375, train_loss: 0.4307880103588104
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3739519417285919, train_loss: 0.27226880192756653
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.345668226480484, train_loss: 0.21332547068595886
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3436181843280792, train_loss: 0.18159550428390503
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3595031797885895, train_loss: 0.37799686193466187
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13760526478290558, train_loss: 0.07643293589353561
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.130239337682724, train_loss: 0.05191883072257042
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12921059131622314, train_loss: 0.05089418217539787
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12879326939582825, train_loss: 0.04827176034450531
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4383000135421753, train_loss: 0.5037468671798706
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11981106549501419, train_loss: 0.08011998236179352
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11804459244012833, train_loss: 0.06283118575811386
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11791033297777176, train_loss: 0.06206706538796425
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11791901290416718, train_loss: 0.05925211310386658
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.880031406879425, train_loss: 0.8888123631477356
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4934445023536682, train_loss: 0.444257915019989
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34866467118263245, train_loss: 0.2911359667778015
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2973918318748474, train_loss: 0.22726190090179443
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2736549377441406, train_loss: 0.1919022500514984
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.261870414018631, train_loss: 0.15791603922843933
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25672730803489685, train_loss: 0.1342129409313202
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2557294964790344, train_loss: 0.12649399042129517
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.25542935729026794, train_loss: 0.11632155627012253
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6043005585670471, train_loss: 0.5769978165626526
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40262842178344727, train_loss: 0.3209577798843384
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36515605449676514, train_loss: 0.23647624254226685
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35872602462768555, train_loss: 0.1857934296131134
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3586486876010895, train_loss: 0.18485167622566223
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6549479365348816, train_loss: 0.6903613209724426
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39971795678138733, train_loss: 0.3443782925605774
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3382006287574768, train_loss: 0.23759977519512177
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.324672669172287, train_loss: 0.19099581241607666
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32444506883621216, train_loss: 0.17481699585914612
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6177089810371399, train_loss: 0.6165825128555298
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4050862789154053, train_loss: 0.33398735523223877
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3511478900909424, train_loss: 0.248951256275177
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3400205969810486, train_loss: 0.19343847036361694
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33957043290138245, train_loss: 0.17819900810718536
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5116410255432129, train_loss: 0.4823738932609558
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16849826276302338, train_loss: 0.0814308226108551
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.16771405935287476, train_loss: 0.06816978007555008
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.16621027886867523, train_loss: 0.06505480408668518
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.16644679009914398, train_loss: 0.06387138366699219
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7064449191093445, train_loss: 0.7615134716033936
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1384122520685196, train_loss: 0.08314959704875946
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13339154422283173, train_loss: 0.059744127094745636
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13345623016357422, train_loss: 0.0573330819606781
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.133407860994339, train_loss: 0.05490517616271973
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5388796925544739, train_loss: 0.5539762377738953
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35488104820251465, train_loss: 0.32912391424179077
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29726454615592957, train_loss: 0.2527483403682709
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2748016119003296, train_loss: 0.21475638449192047
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26572543382644653, train_loss: 0.17611129581928253
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.728445291519165, train_loss: 0.7358375787734985
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44218313694000244, train_loss: 0.3734329342842102
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36770331859588623, train_loss: 0.2542332410812378
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35158416628837585, train_loss: 0.19663789868354797
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3518490493297577, train_loss: 0.17991365492343903
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6801572442054749, train_loss: 0.6945618391036987
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.41446787118911743, train_loss: 0.363418310880661
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3405754268169403, train_loss: 0.25014546513557434
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32095274329185486, train_loss: 0.1973554491996765
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31898725032806396, train_loss: 0.16869118809700012
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3187745213508606, train_loss: 0.16844457387924194
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.004154086112976, train_loss: 0.9953002333641052
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5834904313087463, train_loss: 0.5092689990997314
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40579953789711, train_loss: 0.3001753091812134
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3575214147567749, train_loss: 0.21996980905532837
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34668102860450745, train_loss: 0.17945659160614014
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.36683404445648193, train_loss: 0.36645498871803284
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14550377428531647, train_loss: 0.07223041355609894
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14409026503562927, train_loss: 0.06615325063467026
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14282958209514618, train_loss: 0.06139364838600159
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1433335840702057, train_loss: 0.05955493450164795
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3003373146057129, train_loss: 0.3305695652961731
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13626007735729218, train_loss: 0.07850940525531769
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13527162373065948, train_loss: 0.06549277156591415
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1351073980331421, train_loss: 0.06195223331451416
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13528399169445038, train_loss: 0.057503312826156616
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5772386789321899, train_loss: 0.6199701428413391
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37600040435791016, train_loss: 0.3499905467033386
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.31826794147491455, train_loss: 0.269589900970459
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2990928590297699, train_loss: 0.21798402070999146
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2930225729942322, train_loss: 0.18731437623500824
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5396523475646973, train_loss: 0.5436948537826538
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3829401731491089, train_loss: 0.32619792222976685
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34995922446250916, train_loss: 0.2456752359867096
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3474683165550232, train_loss: 0.20988905429840088
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3475920259952545, train_loss: 0.21069440245628357
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6823506951332092, train_loss: 0.6855384707450867
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3989419639110565, train_loss: 0.3468155264854431
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3349774181842804, train_loss: 0.23657914996147156
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3253725469112396, train_loss: 0.19509035348892212
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3256751298904419, train_loss: 0.18610510230064392
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5511646866798401, train_loss: 0.5413507223129272
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3687407970428467, train_loss: 0.31221580505371094
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.33617711067199707, train_loss: 0.23326417803764343
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.331688791513443, train_loss: 0.18847838044166565
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3321312963962555, train_loss: 0.18262311816215515
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.47758373618125916, train_loss: 0.46170875430107117
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1442863643169403, train_loss: 0.0730021670460701
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13953867554664612, train_loss: 0.059567857533693314
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13842301070690155, train_loss: 0.054071903228759766
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13833245635032654, train_loss: 0.053442638367414474
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5253352522850037, train_loss: 0.5237453579902649
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12902040779590607, train_loss: 0.08907195925712585
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12591686844825745, train_loss: 0.06109120696783066
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.125985249876976, train_loss: 0.05737321078777313
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12590205669403076, train_loss: 0.0582120418548584
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5848541855812073, train_loss: 0.5925629734992981
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35789090394973755, train_loss: 0.33364957571029663
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29013878107070923, train_loss: 0.2531648278236389
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2663875222206116, train_loss: 0.20816773176193237
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25863319635391235, train_loss: 0.17501601576805115
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7355726361274719, train_loss: 0.7689152956008911
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4509021043777466, train_loss: 0.3874289393424988
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3775573968887329, train_loss: 0.25733864307403564
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36275210976600647, train_loss: 0.20184792578220367
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3627546727657318, train_loss: 0.1866963505744934
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7485095858573914, train_loss: 0.7611328959465027
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4406558573246002, train_loss: 0.37716835737228394
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35904499888420105, train_loss: 0.24588650465011597
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3411458730697632, train_loss: 0.19500616192817688
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3402802646160126, train_loss: 0.1669391691684723
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6565099358558655, train_loss: 0.635015606880188
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4032329320907593, train_loss: 0.3453838527202606
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3423914909362793, train_loss: 0.24349898099899292
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3266548216342926, train_loss: 0.19475248456001282
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.32508963346481323, train_loss: 0.17456784844398499
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5558820366859436, train_loss: 0.5540832281112671
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13450714945793152, train_loss: 0.06243614852428436
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13282060623168945, train_loss: 0.05101750046014786
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13261257112026215, train_loss: 0.04995986074209213
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.132585346698761, train_loss: 0.04869186878204346
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5477317571640015, train_loss: 0.5656616687774658
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1277199238538742, train_loss: 0.08467992395162582
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12391679733991623, train_loss: 0.06056397035717964
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12367351353168488, train_loss: 0.05749589577317238
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12331388890743256, train_loss: 0.05468006432056427
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.47858890891075134, train_loss: 0.5122924447059631
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3292377293109894, train_loss: 0.3264930844306946
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.28431183099746704, train_loss: 0.26185107231140137
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.26846370100975037, train_loss: 0.21039481461048126
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2642599046230316, train_loss: 0.18107549846172333
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6811248064041138, train_loss: 0.6967331171035767
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42497706413269043, train_loss: 0.3644093871116638
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35960158705711365, train_loss: 0.2534283399581909
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34358492493629456, train_loss: 0.19641202688217163
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34327709674835205, train_loss: 0.16721537709236145
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7171589732170105, train_loss: 0.7443627119064331
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4283382296562195, train_loss: 0.3786458671092987
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35356226563453674, train_loss: 0.25890201330184937
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3339669406414032, train_loss: 0.19475454092025757
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3315778076648712, train_loss: 0.17613153159618378
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9370575547218323, train_loss: 0.9464867115020752
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5381475687026978, train_loss: 0.4732392728328705
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.394363671541214, train_loss: 0.28388404846191406
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35646384954452515, train_loss: 0.21613667905330658
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34929320216178894, train_loss: 0.174306720495224
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.0157850980758667, train_loss: 1.132521152496338
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16172166168689728, train_loss: 0.07363781332969666
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15598154067993164, train_loss: 0.05374636501073837
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1553935557603836, train_loss: 0.05219746753573418
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.155381977558136, train_loss: 0.04902349039912224
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.33928564190864563, train_loss: 0.36081400513648987
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1271807998418808, train_loss: 0.0840584933757782
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12207648903131485, train_loss: 0.06166813522577286
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12164785712957382, train_loss: 0.05840793997049332
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12161484360694885, train_loss: 0.057414837181568146
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6958661079406738, train_loss: 0.7207802534103394
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4245088994503021, train_loss: 0.3809438943862915
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32648324966430664, train_loss: 0.2786257266998291
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2895689606666565, train_loss: 0.2229612171649933
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27417296171188354, train_loss: 0.18554523587226868
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2664451003074646, train_loss: 0.15603330731391907
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2625958025455475, train_loss: 0.13282954692840576
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.646325409412384, train_loss: 0.6515830755233765
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40832358598709106, train_loss: 0.3499864935874939
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3491390645503998, train_loss: 0.24965070188045502
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33489924669265747, train_loss: 0.1935921609401703
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3340034782886505, train_loss: 0.17307373881340027
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.669171929359436, train_loss: 0.687636137008667
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4014780819416046, train_loss: 0.3539522588253021
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3396926820278168, train_loss: 0.2405332326889038
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32394495606422424, train_loss: 0.19216398894786835
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3227306008338928, train_loss: 0.15935511887073517
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6296985745429993, train_loss: 0.6285507678985596
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40006837248802185, train_loss: 0.34636905789375305
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34688910841941833, train_loss: 0.2547394931316376
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33190616965293884, train_loss: 0.19664233922958374
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3303607702255249, train_loss: 0.1695069968700409
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.49041274189949036, train_loss: 0.46018126606941223
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14047187566757202, train_loss: 0.07501494139432907
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1388661414384842, train_loss: 0.05710354447364807
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13913126289844513, train_loss: 0.058424219489097595
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13929617404937744, train_loss: 0.05718264356255531
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.34294286370277405, train_loss: 0.36586424708366394
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11561760306358337, train_loss: 0.07825186848640442
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11328151077032089, train_loss: 0.06350173056125641
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11337853968143463, train_loss: 0.059163860976696014
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11340733617544174, train_loss: 0.05696570873260498
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5710476636886597, train_loss: 0.5971137881278992
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.36523696780204773, train_loss: 0.34093981981277466
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2976120114326477, train_loss: 0.2598429024219513
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27223366498947144, train_loss: 0.20712149143218994
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26178181171417236, train_loss: 0.18020786345005035
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2589571177959442, train_loss: 0.15215173363685608
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2580220401287079, train_loss: 0.142965629696846
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7016016840934753, train_loss: 0.719404935836792
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4335482120513916, train_loss: 0.37488222122192383
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36004218459129333, train_loss: 0.2596772313117981
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3454184830188751, train_loss: 0.19960522651672363
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34576210379600525, train_loss: 0.18580952286720276
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.810137152671814, train_loss: 0.8178049325942993
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4853794276714325, train_loss: 0.423900842666626
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3738402724266052, train_loss: 0.2629953622817993
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34469202160835266, train_loss: 0.20150703191757202
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33840620517730713, train_loss: 0.16134928166866302
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7590788006782532, train_loss: 0.7770485281944275
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4524330794811249, train_loss: 0.3916422724723816
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3590892553329468, train_loss: 0.25955814123153687
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3359988331794739, train_loss: 0.19970747828483582
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.332207053899765, train_loss: 0.16347560286521912
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.1599150896072388, train_loss: 1.1691105365753174
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1579868346452713, train_loss: 0.0703464150428772
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15399830043315887, train_loss: 0.0548112578690052
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15356402099132538, train_loss: 0.05286445468664169
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15317802131175995, train_loss: 0.05156430974602699
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3572099506855011, train_loss: 0.39075714349746704
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11182554066181183, train_loss: 0.07760006189346313
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10748576372861862, train_loss: 0.06253021210432053
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10710737854242325, train_loss: 0.05900520458817482
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10691498965024948, train_loss: 0.0563705638051033
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8666462302207947, train_loss: 0.8824512958526611
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4930310845375061, train_loss: 0.46619194746017456
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3494369685649872, train_loss: 0.30388545989990234
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3012431561946869, train_loss: 0.23410889506340027
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28287622332572937, train_loss: 0.19594591856002808
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27648577094078064, train_loss: 0.1667216569185257
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6864227056503296, train_loss: 0.6744763255119324
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4253484606742859, train_loss: 0.3569720387458801
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37224647402763367, train_loss: 0.2485961765050888
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3621399998664856, train_loss: 0.19728690385818481
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36200985312461853, train_loss: 0.1859854757785797
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5777628421783447, train_loss: 0.49671733379364014
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37497785687446594, train_loss: 0.289523184299469
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34160885214805603, train_loss: 0.21867942810058594
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3389030992984772, train_loss: 0.17539188265800476
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3392135798931122, train_loss: 0.17615137994289398
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6363032460212708, train_loss: 0.6146717667579651
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42253226041793823, train_loss: 0.3357474207878113
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37120911478996277, train_loss: 0.24191291630268097
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3607145845890045, train_loss: 0.19613540172576904
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36054277420043945, train_loss: 0.1798585206270218
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5637190341949463, train_loss: 0.5938637256622314
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14189232885837555, train_loss: 0.06729774922132492
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14081472158432007, train_loss: 0.05848407745361328
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14098772406578064, train_loss: 0.05618614703416824
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1405661404132843, train_loss: 0.05453207343816757
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6487157940864563, train_loss: 0.7253963947296143
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12440752238035202, train_loss: 0.07692701369524002
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12217243760824203, train_loss: 0.057395223528146744
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1220807284116745, train_loss: 0.05729205161333084
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12207620590925217, train_loss: 0.054235152900218964
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0793520212173462, train_loss: 1.091663122177124
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6159897446632385, train_loss: 0.5718871355056763
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.39125409722328186, train_loss: 0.330926775932312
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3141273558139801, train_loss: 0.24795693159103394
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28437715768814087, train_loss: 0.20067669451236725
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27129611372947693, train_loss: 0.1729496866464615
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2657408118247986, train_loss: 0.14287066459655762
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9625347256660461, train_loss: 0.9684115052223206
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5460419654846191, train_loss: 0.48001283407211304
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39926987886428833, train_loss: 0.2906428873538971
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36761677265167236, train_loss: 0.21208740770816803
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3630848526954651, train_loss: 0.17249828577041626
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7462418675422668, train_loss: 0.7898280620574951
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43307676911354065, train_loss: 0.39378952980041504
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3415060043334961, train_loss: 0.2590118944644928
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3170154392719269, train_loss: 0.20013728737831116
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3131120204925537, train_loss: 0.1588602066040039
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9316228032112122, train_loss: 0.9554803371429443
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5207099318504333, train_loss: 0.4538964331150055
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3864724338054657, train_loss: 0.2836110591888428
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35325250029563904, train_loss: 0.21413317322731018
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3479926884174347, train_loss: 0.17351768910884857
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.2357179820537567, train_loss: 0.22263067960739136
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1451934576034546, train_loss: 0.06994172930717468
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14472603797912598, train_loss: 0.06482531130313873
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14411495625972748, train_loss: 0.06102666258811951
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1441889852285385, train_loss: 0.056170351803302765
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4651261568069458, train_loss: 0.5419126152992249
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14555871486663818, train_loss: 0.08740966022014618
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1365172415971756, train_loss: 0.058241136372089386
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13600313663482666, train_loss: 0.05678661912679672
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1360238939523697, train_loss: 0.05263853818178177
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5282948017120361, train_loss: 0.5563669800758362
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35271960496902466, train_loss: 0.333342045545578
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.29834359884262085, train_loss: 0.25719135999679565
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27822670340538025, train_loss: 0.21831168234348297
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27021363377571106, train_loss: 0.1815868616104126
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6056731939315796, train_loss: 0.5902861952781677
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40589016675949097, train_loss: 0.32144588232040405
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36403048038482666, train_loss: 0.22817692160606384
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35819852352142334, train_loss: 0.18308377265930176
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3589581847190857, train_loss: 0.17779463529586792
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8086082935333252, train_loss: 0.8064020872116089
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45533135533332825, train_loss: 0.4073212146759033
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35220617055892944, train_loss: 0.26156893372535706
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32126253843307495, train_loss: 0.20741668343544006
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31220221519470215, train_loss: 0.1657274216413498
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8258919715881348, train_loss: 0.8588749170303345
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47318997979164124, train_loss: 0.420063316822052
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3702046275138855, train_loss: 0.26668351888656616
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3488939106464386, train_loss: 0.20631355047225952
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3483451008796692, train_loss: 0.17219634354114532
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.48755091428756714, train_loss: 0.5110096335411072
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.17045021057128906, train_loss: 0.07884523272514343
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.16253137588500977, train_loss: 0.05527549237012863
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1623154580593109, train_loss: 0.052483804523944855
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1616906225681305, train_loss: 0.05444791167974472
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3270568549633026, train_loss: 0.37860143184661865
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11755606532096863, train_loss: 0.07921455800533295
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11661578714847565, train_loss: 0.06223402917385101
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1169305294752121, train_loss: 0.06006640940904617
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11706831306219101, train_loss: 0.05861790105700493
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6958982944488525, train_loss: 0.709293782711029
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4117129445075989, train_loss: 0.39248302578926086
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3205328583717346, train_loss: 0.28143972158432007
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28835412859916687, train_loss: 0.23848062753677368
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2753922641277313, train_loss: 0.19401708245277405
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.269022136926651, train_loss: 0.16515463590621948
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2664467692375183, train_loss: 0.13376596570014954
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8411228060722351, train_loss: 0.8552100658416748
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5085073113441467, train_loss: 0.4450708031654358
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3903807997703552, train_loss: 0.27605241537094116
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36130350828170776, train_loss: 0.21027013659477234
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3576296865940094, train_loss: 0.17391520738601685
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6442291140556335, train_loss: 0.6476529836654663
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40690985321998596, train_loss: 0.3403235375881195
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3453008830547333, train_loss: 0.23461642861366272
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32892945408821106, train_loss: 0.18278898298740387
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32721617817878723, train_loss: 0.15719065070152283
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7212504148483276, train_loss: 0.7411724328994751
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4320380687713623, train_loss: 0.3823391795158386
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35010552406311035, train_loss: 0.26503878831863403
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.32901036739349365, train_loss: 0.20080514252185822
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.32434800267219543, train_loss: 0.16843023896217346
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5833873748779297, train_loss: 0.6414265632629395
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14575566351413727, train_loss: 0.06852195411920547
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14240498840808868, train_loss: 0.0518345832824707
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14214575290679932, train_loss: 0.053107455372810364
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14200946688652039, train_loss: 0.051475442945957184
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4569345712661743, train_loss: 0.40585124492645264
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11229255050420761, train_loss: 0.08475464582443237
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10658822953701019, train_loss: 0.05203406885266304
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10717933624982834, train_loss: 0.049442119896411896
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10738877207040787, train_loss: 0.04604935273528099
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6240821480751038, train_loss: 0.632813572883606
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3783546984195709, train_loss: 0.3437598943710327
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30797508358955383, train_loss: 0.2628769278526306
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2830808460712433, train_loss: 0.21124431490898132
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2743901014328003, train_loss: 0.17805492877960205
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6829773187637329, train_loss: 0.6911896467208862
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43567395210266113, train_loss: 0.3572746515274048
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3751732110977173, train_loss: 0.24656730890274048
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3621343970298767, train_loss: 0.19931942224502563
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3612798750400543, train_loss: 0.1787610650062561
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5515074133872986, train_loss: 0.44795897603034973
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3508662283420563, train_loss: 0.2805338501930237
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3160267770290375, train_loss: 0.21648354828357697
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31043151021003723, train_loss: 0.18404287099838257
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31007733941078186, train_loss: 0.17957265675067902
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7094194293022156, train_loss: 0.6996347904205322
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.44787704944610596, train_loss: 0.36113184690475464
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37485888600349426, train_loss: 0.2509044110774994
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35585352778434753, train_loss: 0.19978949427604675
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3546086549758911, train_loss: 0.1768132895231247
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.483491450548172, train_loss: 0.4951391816139221
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13395702838897705, train_loss: 0.06617280840873718
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13303519785404205, train_loss: 0.062111929059028625
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13280749320983887, train_loss: 0.057908330112695694
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13242311775684357, train_loss: 0.05714181810617447
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35223740339279175, train_loss: 0.4075154662132263
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12874606251716614, train_loss: 0.07519124448299408
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12484492361545563, train_loss: 0.05196910351514816
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12466645985841751, train_loss: 0.047055624425411224
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12463175505399704, train_loss: 0.04927545040845871
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5498818755149841, train_loss: 0.6176011562347412
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3376587927341461, train_loss: 0.3423779308795929
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2798565626144409, train_loss: 0.26335328817367554
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.25783440470695496, train_loss: 0.2271084189414978
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.24816584587097168, train_loss: 0.19155851006507874
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.24205124378204346, train_loss: 0.1616734117269516
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.24033766984939575, train_loss: 0.14943866431713104
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8117159008979797, train_loss: 0.8004925847053528
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4752061069011688, train_loss: 0.40991485118865967
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3777149021625519, train_loss: 0.2689860463142395
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3531876802444458, train_loss: 0.20956319570541382
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3468686044216156, train_loss: 0.1714627593755722
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7454321384429932, train_loss: 0.7568148970603943
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.42709338665008545, train_loss: 0.37841862440109253
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35096779465675354, train_loss: 0.2585330009460449
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33221954107284546, train_loss: 0.19314633309841156
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3297949731349945, train_loss: 0.17681148648262024
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.329414427280426, train_loss: 0.1733589768409729
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7470722198486328, train_loss: 0.776305079460144
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.45938873291015625, train_loss: 0.38388532400131226
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37260666489601135, train_loss: 0.258867084980011
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3522058129310608, train_loss: 0.20619265735149384
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3520565927028656, train_loss: 0.18504825234413147
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4243534207344055, train_loss: 0.45404672622680664
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1485360860824585, train_loss: 0.07242446392774582
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14650858938694, train_loss: 0.05757937952876091
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14601394534111023, train_loss: 0.058172937482595444
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1460169553756714, train_loss: 0.05486908555030823
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5995067358016968, train_loss: 0.717284619808197
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12138615548610687, train_loss: 0.08502890914678574
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1161474958062172, train_loss: 0.060439713299274445
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11600185930728912, train_loss: 0.05660416930913925
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11586864292621613, train_loss: 0.05641784518957138
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7428718209266663, train_loss: 0.7780125737190247
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4242715537548065, train_loss: 0.3921985626220703
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32505589723587036, train_loss: 0.2719195783138275
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28854653239250183, train_loss: 0.22259868681430817
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2753473222255707, train_loss: 0.18105313181877136
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2693791091442108, train_loss: 0.1513037532567978
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26749563217163086, train_loss: 0.12706047296524048
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8144412636756897, train_loss: 0.8484275937080383
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4718569815158844, train_loss: 0.42680251598358154
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37526899576187134, train_loss: 0.27491873502731323
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3554927110671997, train_loss: 0.21052880585193634
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35492658615112305, train_loss: 0.18730536103248596
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6713538765907288, train_loss: 0.6556597948074341
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4017956256866455, train_loss: 0.34556081891059875
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3363811671733856, train_loss: 0.24103672802448273
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3187190592288971, train_loss: 0.18755263090133667
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31793534755706787, train_loss: 0.1664835810661316
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7694278359413147, train_loss: 0.7758231163024902
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4425331950187683, train_loss: 0.38707610964775085
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3652704358100891, train_loss: 0.2660823464393616
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35099706053733826, train_loss: 0.20909050107002258
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35112425684928894, train_loss: 0.1937478482723236
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6795912384986877, train_loss: 0.6952453851699829
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15323138236999512, train_loss: 0.07287520170211792
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14638204872608185, train_loss: 0.051533762365579605
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14541874825954437, train_loss: 0.049762971699237823
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14513978362083435, train_loss: 0.04785206541419029
[te_estimator_0_xnet] Epoch: 250, current validation loss: 0.14490148425102234, train_loss: 0.04415296018123627
[te_estimator_0_xnet] Epoch: 300, current validation loss: 0.14435242116451263, train_loss: 0.04385146498680115
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3290526568889618, train_loss: 0.3970171809196472
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1240890771150589, train_loss: 0.08711104094982147
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12122730910778046, train_loss: 0.06063418835401535
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12127392739057541, train_loss: 0.057480983436107635
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12116457521915436, train_loss: 0.055449530482292175
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8040374517440796, train_loss: 0.8227953910827637
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4621390402317047, train_loss: 0.42341119050979614
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3393693268299103, train_loss: 0.28486350178718567
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29726287722587585, train_loss: 0.23014004528522491
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2792508900165558, train_loss: 0.18736106157302856
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2716609835624695, train_loss: 0.1580088883638382
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0826021432876587, train_loss: 1.1209208965301514
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6250717043876648, train_loss: 0.5830038785934448
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41626596450805664, train_loss: 0.32312968373298645
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36350217461586, train_loss: 0.22820782661437988
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3534363806247711, train_loss: 0.18058933317661285
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9461097121238708, train_loss: 1.0033421516418457
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5406216382980347, train_loss: 0.5154359340667725
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37555259466171265, train_loss: 0.2953979969024658
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.332271009683609, train_loss: 0.21629568934440613
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3237842917442322, train_loss: 0.17501699924468994
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.32344523072242737, train_loss: 0.16797634959220886
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7027353048324585, train_loss: 0.7191534042358398
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43244242668151855, train_loss: 0.37801551818847656
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.362049400806427, train_loss: 0.2658560872077942
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3508065938949585, train_loss: 0.2127339243888855
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35096049308776855, train_loss: 0.1994590312242508
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.45551925897598267, train_loss: 0.40431496500968933
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15701240301132202, train_loss: 0.07498195022344589
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15018950402736664, train_loss: 0.05154532194137573
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1498890072107315, train_loss: 0.0465179905295372
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14943325519561768, train_loss: 0.04749954864382744
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3638489842414856, train_loss: 0.36465322971343994
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14906731247901917, train_loss: 0.08425072580575943
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.139435276389122, train_loss: 0.05662545561790466
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1381838023662567, train_loss: 0.05311889946460724
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13766035437583923, train_loss: 0.05079645663499832
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7728642821311951, train_loss: 0.7764871716499329
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45237115025520325, train_loss: 0.42294472455978394
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33913570642471313, train_loss: 0.30065757036209106
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2995412349700928, train_loss: 0.24145382642745972
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28310462832450867, train_loss: 0.20587587356567383
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27581241726875305, train_loss: 0.171015202999115
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6416841149330139, train_loss: 0.6333240270614624
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41741329431533813, train_loss: 0.34082111716270447
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36782917380332947, train_loss: 0.24392317235469818
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3609311878681183, train_loss: 0.1990639716386795
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36147844791412354, train_loss: 0.1920703649520874
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.2207626104354858, train_loss: 1.3030446767807007
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6860348582267761, train_loss: 0.7004426717758179
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.4364878833293915, train_loss: 0.3773297071456909
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3566925525665283, train_loss: 0.26115843653678894
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3332899212837219, train_loss: 0.19996397197246552
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.328581303358078, train_loss: 0.16591894626617432
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9683953523635864, train_loss: 0.9539090991020203
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5433560013771057, train_loss: 0.47275155782699585
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39366060495376587, train_loss: 0.2824532687664032
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3589080572128296, train_loss: 0.21291649341583252
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3543566167354584, train_loss: 0.17918342351913452
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4695705473423004, train_loss: 0.48753654956817627
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13413681089878082, train_loss: 0.06320873647928238
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.130880668759346, train_loss: 0.05219227448105812
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.131048321723938, train_loss: 0.05022687092423439
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13098356127738953, train_loss: 0.04901245981454849
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.355480432510376, train_loss: 0.39898645877838135
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14344263076782227, train_loss: 0.0762382224202156
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.14179246127605438, train_loss: 0.06261041015386581
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1416008323431015, train_loss: 0.059128109365701675
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.14154933393001556, train_loss: 0.05935180187225342
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8599352836608887, train_loss: 0.8707531094551086
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.48799654841423035, train_loss: 0.43260401487350464
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3520454466342926, train_loss: 0.28901660442352295
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30393433570861816, train_loss: 0.23077517747879028
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28368592262268066, train_loss: 0.18805521726608276
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27617326378822327, train_loss: 0.1518832892179489
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.57170170545578, train_loss: 0.5517067909240723
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3937285542488098, train_loss: 0.3230147957801819
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.356894850730896, train_loss: 0.23987141251564026
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35126641392707825, train_loss: 0.19687984883785248
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3514804542064667, train_loss: 0.1895516961812973
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.822763979434967, train_loss: 0.8651542663574219
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.48838454484939575, train_loss: 0.4395511746406555
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.38198649883270264, train_loss: 0.2741912603378296
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3558642566204071, train_loss: 0.20023944973945618
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3531922996044159, train_loss: 0.16807474195957184
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.935866117477417, train_loss: 0.9099509119987488
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5412182807922363, train_loss: 0.4602816700935364
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3955087661743164, train_loss: 0.28321224451065063
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3579355478286743, train_loss: 0.22001677751541138
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.349943071603775, train_loss: 0.1725863218307495
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2177320718765259, train_loss: 1.3700193166732788
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15086747705936432, train_loss: 0.07400821149349213
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14630049467086792, train_loss: 0.0511506050825119
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1457134187221527, train_loss: 0.04548940062522888
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14552314579486847, train_loss: 0.04598265886306763
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5362299084663391, train_loss: 0.5701315402984619
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1258174329996109, train_loss: 0.0889447033405304
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1198592260479927, train_loss: 0.0586526058614254
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11994986236095428, train_loss: 0.056256819516420364
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12016716599464417, train_loss: 0.05528790503740311
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5712435245513916, train_loss: 0.6119828820228577
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3640824258327484, train_loss: 0.3442676365375519
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3046075105667114, train_loss: 0.2674561142921448
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2833733856678009, train_loss: 0.21747878193855286
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2749349772930145, train_loss: 0.18986836075782776
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2727839946746826, train_loss: 0.1641293615102768
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7346287369728088, train_loss: 0.7644441723823547
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.45397934317588806, train_loss: 0.3834097385406494
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37549838423728943, train_loss: 0.2527596354484558
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36025798320770264, train_loss: 0.1918812394142151
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3595534563064575, train_loss: 0.17002969980239868
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6222251057624817, train_loss: 0.6158918738365173
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38411444425582886, train_loss: 0.32869699597358704
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32938674092292786, train_loss: 0.2328634262084961
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.31490421295166016, train_loss: 0.18349288403987885
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31294310092926025, train_loss: 0.15434518456459045
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7754533886909485, train_loss: 0.7818533182144165
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4532290995121002, train_loss: 0.392960786819458
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3611190617084503, train_loss: 0.25673580169677734
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33847787976264954, train_loss: 0.19638201594352722
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3362361490726471, train_loss: 0.16557222604751587
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3014371395111084, train_loss: 0.306124210357666
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1405939757823944, train_loss: 0.07049193978309631
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13961854577064514, train_loss: 0.06029155105352402
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13971464335918427, train_loss: 0.057337116450071335
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13994193077087402, train_loss: 0.053408294916152954
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3972991704940796, train_loss: 0.49250534176826477
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1278931200504303, train_loss: 0.07909541577100754
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12456411123275757, train_loss: 0.052136942744255066
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12482268363237381, train_loss: 0.0494452640414238
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12509417533874512, train_loss: 0.04924975708127022
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.835047721862793, train_loss: 0.8579161167144775
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4798007011413574, train_loss: 0.44930577278137207
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3436083495616913, train_loss: 0.2950510084629059
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29766348004341125, train_loss: 0.23793759942054749
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2794649004936218, train_loss: 0.19524429738521576
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2709299325942993, train_loss: 0.1633451133966446
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8313418626785278, train_loss: 0.825027585029602
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4919377267360687, train_loss: 0.422458291053772
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3920762836933136, train_loss: 0.27414941787719727
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37024185061454773, train_loss: 0.20823991298675537
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36785125732421875, train_loss: 0.1803194284439087
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8847806453704834, train_loss: 0.9328335523605347
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5165955424308777, train_loss: 0.4912406802177429
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3719736337661743, train_loss: 0.2924455404281616
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33383533358573914, train_loss: 0.2178705930709839
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32441091537475586, train_loss: 0.1748896688222885
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.731380045413971, train_loss: 0.7403323650360107
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4367213249206543, train_loss: 0.368452250957489
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3620913028717041, train_loss: 0.2508811950683594
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34378740191459656, train_loss: 0.1978262960910797
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34349721670150757, train_loss: 0.16846200823783875
[te_estimator_0_xnet] Epoch: 0, current validation loss: 1.2970308065414429, train_loss: 1.2681324481964111
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1347174495458603, train_loss: 0.06852999329566956
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13014541566371918, train_loss: 0.05262052267789841
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.129336878657341, train_loss: 0.048018455505371094
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12894520163536072, train_loss: 0.04816514253616333
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3854355812072754, train_loss: 0.39511024951934814
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12564128637313843, train_loss: 0.09138785302639008
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11990966647863388, train_loss: 0.06044671684503555
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11988212913274765, train_loss: 0.05813305824995041
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11977602541446686, train_loss: 0.0552324540913105
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8733742237091064, train_loss: 0.8447893857955933
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4804556965827942, train_loss: 0.4244387447834015
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34968093037605286, train_loss: 0.2878493070602417
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30397772789001465, train_loss: 0.228155255317688
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2866147756576538, train_loss: 0.18423444032669067
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2803020775318146, train_loss: 0.14463657140731812
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6696202158927917, train_loss: 0.6741815805435181
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41031625866889954, train_loss: 0.3551952838897705
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34939560294151306, train_loss: 0.24766415357589722
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33443161845207214, train_loss: 0.19655738770961761
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33319878578186035, train_loss: 0.17096807062625885
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6386767029762268, train_loss: 0.6400786638259888
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38426974415779114, train_loss: 0.32814258337020874
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33872008323669434, train_loss: 0.23484840989112854
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32945701479911804, train_loss: 0.18599379062652588
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3296654522418976, train_loss: 0.17719201743602753
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.156409740447998, train_loss: 1.1968708038330078
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6572909951210022, train_loss: 0.6109714508056641
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.41938477754592896, train_loss: 0.3367762565612793
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35156330466270447, train_loss: 0.23770132660865784
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3334546387195587, train_loss: 0.18356995284557343
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3958315849304199, train_loss: 0.3946002721786499
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14253699779510498, train_loss: 0.07489936053752899
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13997361063957214, train_loss: 0.06431379914283752
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1393861621618271, train_loss: 0.06301714479923248
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13927941024303436, train_loss: 0.06235840916633606
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7998937964439392, train_loss: 0.8945228457450867
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12406234443187714, train_loss: 0.07903344929218292
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12031837552785873, train_loss: 0.05091160163283348
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12077326327562332, train_loss: 0.04984830692410469
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12117799371480942, train_loss: 0.04708243906497955
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9605496525764465, train_loss: 0.9517179727554321
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5391268134117126, train_loss: 0.47678476572036743
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3657737970352173, train_loss: 0.2921658456325531
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30783241987228394, train_loss: 0.22868765890598297
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28537803888320923, train_loss: 0.18607938289642334
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2776431441307068, train_loss: 0.16352158784866333
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7386936545372009, train_loss: 0.7750041484832764
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.45160284638404846, train_loss: 0.40213555097579956
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.370965838432312, train_loss: 0.26901283860206604
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3569633662700653, train_loss: 0.2089768350124359
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3574735224246979, train_loss: 0.1956670731306076
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0879954099655151, train_loss: 1.1505465507507324
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.6043576598167419, train_loss: 0.5897549390792847
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.39887407422065735, train_loss: 0.31487926840782166
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3401651382446289, train_loss: 0.2269471287727356
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3222693204879761, train_loss: 0.17510032653808594
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3187924027442932, train_loss: 0.14658582210540771
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6859976053237915, train_loss: 0.6885352730751038
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4222520887851715, train_loss: 0.3550961911678314
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35754507780075073, train_loss: 0.24521973729133606
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34369727969169617, train_loss: 0.19811531901359558
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34392696619033813, train_loss: 0.18227244913578033
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42196017503738403, train_loss: 0.43676435947418213
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14087846875190735, train_loss: 0.07523693144321442
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13848596811294556, train_loss: 0.05911726877093315
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13823682069778442, train_loss: 0.05220455303788185
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13824054598808289, train_loss: 0.052318185567855835
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35482990741729736, train_loss: 0.3597513437271118
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.10792867839336395, train_loss: 0.08476649224758148
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10493849217891693, train_loss: 0.06374876946210861
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10542292147874832, train_loss: 0.060653284192085266
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10557950288057327, train_loss: 0.05668455734848976
importance j:   0%|          | 0/26 [00:00<?, ?it/s]importance j:   4%|▍         | 1/26 [00:13<05:49, 13.97s/it]importance j:   8%|▊         | 2/26 [00:32<06:45, 16.88s/it]importance j:  12%|█▏        | 3/26 [00:45<05:45, 15.00s/it]importance j:  15%|█▌        | 4/26 [01:05<06:08, 16.76s/it]importance j:  19%|█▉        | 5/26 [01:23<06:04, 17.34s/it]importance j:  23%|██▎       | 6/26 [01:36<05:15, 15.77s/it]importance j:  27%|██▋       | 7/26 [01:55<05:20, 16.87s/it]importance j:  31%|███       | 8/26 [02:09<04:47, 15.95s/it]importance j:  35%|███▍      | 9/26 [02:26<04:36, 16.29s/it]importance j:  38%|███▊      | 10/26 [02:46<04:41, 17.61s/it]importance j:  42%|████▏     | 11/26 [02:58<03:57, 15.85s/it]importance j:  46%|████▌     | 12/26 [03:17<03:53, 16.66s/it]importance j:  50%|█████     | 13/26 [03:32<03:32, 16.35s/it]importance j:  54%|█████▍    | 14/26 [03:49<03:18, 16.51s/it]importance j:  58%|█████▊    | 15/26 [04:09<03:12, 17.47s/it]importance j:  62%|██████▏   | 16/26 [04:21<02:39, 15.93s/it]importance j:  65%|██████▌   | 17/26 [04:40<02:31, 16.86s/it]importance j:  69%|██████▉   | 18/26 [04:58<02:16, 17.11s/it]importance j:  73%|███████▎  | 19/26 [05:11<01:51, 15.87s/it]importance j:  77%|███████▋  | 20/26 [05:30<01:40, 16.77s/it]importance j:  81%|████████  | 21/26 [05:46<01:22, 16.46s/it]importance j:  85%|████████▍ | 22/26 [06:03<01:06, 16.63s/it]importance j:  88%|████████▊ | 23/26 [06:24<00:54, 18.01s/it]importance j:  92%|█████████▏| 24/26 [06:38<00:33, 16.85s/it]importance j:  96%|█████████▌| 25/26 [06:58<00:17, 17.81s/it]importance j: 100%|██████████| 26/26 [07:19<00:00, 18.74s/it]
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8724862337112427, train_loss: 0.8693627715110779
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5059413909912109, train_loss: 0.44644883275032043
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.37298011779785156, train_loss: 0.3051435351371765
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32301947474479675, train_loss: 0.24230459332466125
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3018336892127991, train_loss: 0.20792311429977417
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2931880056858063, train_loss: 0.17484541237354279
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2893506586551666, train_loss: 0.14362701773643494
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7991041541099548, train_loss: 0.7745831608772278
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47424161434173584, train_loss: 0.40031641721725464
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3811163902282715, train_loss: 0.26317572593688965
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35980987548828125, train_loss: 0.19904351234436035
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3573196232318878, train_loss: 0.17066690325737
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5534927248954773, train_loss: 0.5391547679901123
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.37286972999572754, train_loss: 0.30788594484329224
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33039361238479614, train_loss: 0.22897526621818542
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32200443744659424, train_loss: 0.1913142204284668
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3220445215702057, train_loss: 0.1779145747423172
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.2028708457946777, train_loss: 1.210383415222168
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.696536123752594, train_loss: 0.620096743106842
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4466361701488495, train_loss: 0.3311103880405426
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37910333275794983, train_loss: 0.2383643388748169
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3636326789855957, train_loss: 0.18459340929985046
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4055596888065338, train_loss: 0.3950585424900055
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14873933792114258, train_loss: 0.07120902091264725
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13886699080467224, train_loss: 0.05044850707054138
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1380138248205185, train_loss: 0.04600986838340759
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13802915811538696, train_loss: 0.04853053390979767
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5548275709152222, train_loss: 0.5283489227294922
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12476843595504761, train_loss: 0.07820454239845276
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11941367387771606, train_loss: 0.057099588215351105
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11925690621137619, train_loss: 0.05459479242563248
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11936982721090317, train_loss: 0.05331675335764885
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8465896844863892, train_loss: 0.8785603046417236
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.46564197540283203, train_loss: 0.4342508018016815
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3375236988067627, train_loss: 0.2899690866470337
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2932058274745941, train_loss: 0.22490988671779633
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2742249667644501, train_loss: 0.1885298490524292
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2675047814846039, train_loss: 0.1604287028312683
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.26556044816970825, train_loss: 0.13671772181987762
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.0044355392456055, train_loss: 1.0232160091400146
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5706155300140381, train_loss: 0.5148147344589233
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3985280990600586, train_loss: 0.29519397020339966
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3534860908985138, train_loss: 0.21402104198932648
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34262815117836, train_loss: 0.16932159662246704
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9200542569160461, train_loss: 0.9762012362480164
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5050120949745178, train_loss: 0.4789573550224304
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36700984835624695, train_loss: 0.2804601490497589
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3349076211452484, train_loss: 0.20751294493675232
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3293515741825104, train_loss: 0.16662472486495972
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5141120553016663, train_loss: 0.494022011756897
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37487927079200745, train_loss: 0.2880093455314636
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3527173101902008, train_loss: 0.22052523493766785
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3523668050765991, train_loss: 0.19649553298950195
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3528238534927368, train_loss: 0.1891031414270401
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.44665664434432983, train_loss: 0.48220038414001465
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15904253721237183, train_loss: 0.07607940584421158
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15056335926055908, train_loss: 0.051968932151794434
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15055248141288757, train_loss: 0.053605712950229645
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.15070591866970062, train_loss: 0.04840197041630745
[te_estimator_1_xnet] Epoch: 0, current validation loss: 1.4177019596099854, train_loss: 1.4418998956680298
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13190853595733643, train_loss: 0.07682867348194122
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13012287020683289, train_loss: 0.06425182521343231
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12991231679916382, train_loss: 0.05705731362104416
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12982597947120667, train_loss: 0.05724024772644043
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7906985282897949, train_loss: 0.7736977338790894
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4640818238258362, train_loss: 0.42033880949020386
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3453567326068878, train_loss: 0.2974490523338318
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3006111681461334, train_loss: 0.240798220038414
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28197357058525085, train_loss: 0.20343415439128876
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27380138635635376, train_loss: 0.1771886944770813
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6562861800193787, train_loss: 0.6542132496833801
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4180029332637787, train_loss: 0.349943071603775
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36068761348724365, train_loss: 0.24933964014053345
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34972071647644043, train_loss: 0.19858331978321075
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34964337944984436, train_loss: 0.18136721849441528
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9229981899261475, train_loss: 0.9704415798187256
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5137088298797607, train_loss: 0.4842890202999115
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36760520935058594, train_loss: 0.284676194190979
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32774293422698975, train_loss: 0.20914596319198608
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3160538077354431, train_loss: 0.16304856538772583
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.3143032491207123, train_loss: 0.14461731910705566
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5087618231773376, train_loss: 0.509162962436676
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3531400263309479, train_loss: 0.3000813126564026
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.320383757352829, train_loss: 0.22671572864055634
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3162359595298767, train_loss: 0.1823274791240692
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.31626462936401367, train_loss: 0.18089359998703003
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7311075925827026, train_loss: 0.8454768657684326
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1559297889471054, train_loss: 0.07510644197463989
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14874513447284698, train_loss: 0.05050037428736687
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14770053327083588, train_loss: 0.05203603208065033
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14729773998260498, train_loss: 0.045797623693943024
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.39884713292121887, train_loss: 0.426853209733963
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11583453416824341, train_loss: 0.08876660466194153
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11080598086118698, train_loss: 0.0578516349196434
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1106472760438919, train_loss: 0.05499473214149475
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11030394583940506, train_loss: 0.05550611764192581
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.511455237865448, train_loss: 0.5181667804718018
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3459262251853943, train_loss: 0.32596370577812195
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30359727144241333, train_loss: 0.24977175891399384
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29378095269203186, train_loss: 0.21597380936145782
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29346370697021484, train_loss: 0.19660045206546783
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5185617208480835, train_loss: 0.5009162425994873
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.36748889088630676, train_loss: 0.295438677072525
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3550601005554199, train_loss: 0.22680874168872833
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35541585087776184, train_loss: 0.22148138284683228
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3559148907661438, train_loss: 0.21299949288368225
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7037538886070251, train_loss: 0.6590877771377563
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40413379669189453, train_loss: 0.3357958197593689
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3366241455078125, train_loss: 0.2349260151386261
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3219086527824402, train_loss: 0.1836479902267456
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.321909099817276, train_loss: 0.16105930507183075
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.48334452509880066, train_loss: 0.47589021921157837
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.34624534845352173, train_loss: 0.2889535427093506
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3293156921863556, train_loss: 0.21824705600738525
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.32991185784339905, train_loss: 0.20343628525733948
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3304843604564667, train_loss: 0.1972622275352478
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.8565998673439026, train_loss: 0.8857126832008362
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.12377099692821503, train_loss: 0.06531859934329987
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12123197317123413, train_loss: 0.048912934958934784
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12122857570648193, train_loss: 0.04483001306653023
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12104374915361404, train_loss: 0.0460653081536293
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3804943859577179, train_loss: 0.44585084915161133
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12790794670581818, train_loss: 0.08194957673549652
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12563306093215942, train_loss: 0.06549349427223206
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12539218366146088, train_loss: 0.06233924627304077
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12520292401313782, train_loss: 0.058098744601011276
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7533307075500488, train_loss: 0.7911091446876526
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43005114793777466, train_loss: 0.39983564615249634
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3251972496509552, train_loss: 0.2865654230117798
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28876668214797974, train_loss: 0.23471534252166748
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2765040993690491, train_loss: 0.1987169086933136
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9651136994361877, train_loss: 0.977825403213501
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5520803928375244, train_loss: 0.48326247930526733
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.40749070048332214, train_loss: 0.28365758061408997
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.374717116355896, train_loss: 0.21283087134361267
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3703882098197937, train_loss: 0.17490063607692719
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6243271231651306, train_loss: 0.6333690285682678
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40044116973876953, train_loss: 0.33228766918182373
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3387691080570221, train_loss: 0.23582419753074646
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3209553360939026, train_loss: 0.182991623878479
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3164282739162445, train_loss: 0.15160712599754333
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5540198683738708, train_loss: 0.5393874645233154
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.38559556007385254, train_loss: 0.31832265853881836
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34824687242507935, train_loss: 0.24308621883392334
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3443032205104828, train_loss: 0.20213434100151062
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3447530269622803, train_loss: 0.19854581356048584
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.37223631143569946, train_loss: 0.4353722929954529
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13366658985614777, train_loss: 0.06814692914485931
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12905895709991455, train_loss: 0.045812465250492096
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.12863022089004517, train_loss: 0.04436487704515457
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1284065693616867, train_loss: 0.04453881457448006
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6091517210006714, train_loss: 0.7017265558242798
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12151388823986053, train_loss: 0.08022241294384003
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11946532875299454, train_loss: 0.06636258959770203
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11904561519622803, train_loss: 0.06371962279081345
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11878128349781036, train_loss: 0.06294506788253784
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7232046127319336, train_loss: 0.7257415056228638
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.411626398563385, train_loss: 0.390140175819397
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3166365325450897, train_loss: 0.2774173617362976
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.27887097001075745, train_loss: 0.2242855280637741
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26408398151397705, train_loss: 0.18912184238433838
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2582935094833374, train_loss: 0.16218334436416626
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6995798349380493, train_loss: 0.684382975101471
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4305713474750519, train_loss: 0.3699323534965515
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3664785325527191, train_loss: 0.2637665271759033
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35096341371536255, train_loss: 0.20840878784656525
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35025107860565186, train_loss: 0.19698560237884521
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6819567084312439, train_loss: 0.6487101316452026
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4069545865058899, train_loss: 0.3509312868118286
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33562541007995605, train_loss: 0.24811743199825287
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3161151707172394, train_loss: 0.1999177485704422
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3149406313896179, train_loss: 0.16417920589447021
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7074310183525085, train_loss: 0.7275032997131348
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42835870385169983, train_loss: 0.37600356340408325
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3525773286819458, train_loss: 0.2561429738998413
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3333941102027893, train_loss: 0.1988012194633484
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33035197854042053, train_loss: 0.161279559135437
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4313156008720398, train_loss: 0.49549126625061035
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1436712145805359, train_loss: 0.08148013055324554
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13735312223434448, train_loss: 0.058640263974666595
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13670887053012848, train_loss: 0.05478762835264206
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1365962028503418, train_loss: 0.05226927250623703
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.40018025040626526, train_loss: 0.4534287750720978
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11895695328712463, train_loss: 0.08321767300367355
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11304272711277008, train_loss: 0.05620962381362915
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1129067912697792, train_loss: 0.05062105506658554
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11288256198167801, train_loss: 0.04931800067424774
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.672245979309082, train_loss: 0.6306048631668091
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3976559638977051, train_loss: 0.3500615656375885
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3158360719680786, train_loss: 0.26210400462150574
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28254586458206177, train_loss: 0.21374991536140442
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26847657561302185, train_loss: 0.1792682707309723
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26234138011932373, train_loss: 0.1545722484588623
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.565407395362854, train_loss: 0.551541805267334
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3974602222442627, train_loss: 0.3284454941749573
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3580605089664459, train_loss: 0.24745532870292664
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3508630394935608, train_loss: 0.2015579342842102
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35167598724365234, train_loss: 0.18545196950435638
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8189289569854736, train_loss: 0.8859987258911133
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4690805673599243, train_loss: 0.43476995825767517
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.35803481936454773, train_loss: 0.2707699239253998
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33038878440856934, train_loss: 0.2012891173362732
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3235570192337036, train_loss: 0.16430410742759705
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6627951264381409, train_loss: 0.6580592393875122
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41512373089790344, train_loss: 0.3436577320098877
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3611867129802704, train_loss: 0.24654124677181244
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35240647196769714, train_loss: 0.1924058198928833
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3524073362350464, train_loss: 0.18504056334495544
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5934140086174011, train_loss: 0.5730530023574829
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14463505148887634, train_loss: 0.07496824115514755
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13915646076202393, train_loss: 0.05136030167341232
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1390659213066101, train_loss: 0.0483584888279438
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13876567780971527, train_loss: 0.04471544176340103
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4228673577308655, train_loss: 0.3758702874183655
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13214486837387085, train_loss: 0.08068376034498215
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12367399781942368, train_loss: 0.05507383123040199
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12354061007499695, train_loss: 0.04362168535590172
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12359810620546341, train_loss: 0.04521017521619797
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6558113098144531, train_loss: 0.6708371043205261
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40772396326065063, train_loss: 0.37318506836891174
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.329479455947876, train_loss: 0.2724515497684479
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3023812174797058, train_loss: 0.22225168347358704
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2921973764896393, train_loss: 0.19352099299430847
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6980630159378052, train_loss: 0.684420108795166
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4402599632740021, train_loss: 0.3654751479625702
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3784353733062744, train_loss: 0.2520103454589844
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36723530292510986, train_loss: 0.19527634978294373
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36706259846687317, train_loss: 0.18239378929138184
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5924320816993713, train_loss: 0.5767505764961243
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3745960593223572, train_loss: 0.3151794373989105
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3315231204032898, train_loss: 0.23248979449272156
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3223420977592468, train_loss: 0.18202590942382812
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3226076662540436, train_loss: 0.16421012580394745
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7025227546691895, train_loss: 0.7185400128364563
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42668455839157104, train_loss: 0.3616655170917511
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36110901832580566, train_loss: 0.25450295209884644
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.346303790807724, train_loss: 0.20078855752944946
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3459998071193695, train_loss: 0.1729964017868042
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3048149645328522, train_loss: 0.28196606040000916
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13243356347084045, train_loss: 0.07400746643543243
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12883737683296204, train_loss: 0.05098593607544899
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1288975179195404, train_loss: 0.04929912090301514
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1289362609386444, train_loss: 0.0491785928606987
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3894314467906952, train_loss: 0.4758445620536804
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12756606936454773, train_loss: 0.08759274333715439
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12366566061973572, train_loss: 0.06251775473356247
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12352059036493301, train_loss: 0.056665606796741486
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12382233142852783, train_loss: 0.05370260030031204
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7176080346107483, train_loss: 0.7108907699584961
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40339747071266174, train_loss: 0.3866737186908722
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30517202615737915, train_loss: 0.28231239318847656
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.269916296005249, train_loss: 0.22892838716506958
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2553446590900421, train_loss: 0.19503706693649292
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.25073859095573425, train_loss: 0.1734171360731125
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.24872788786888123, train_loss: 0.15321779251098633
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6243640184402466, train_loss: 0.6285732984542847
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4084617495536804, train_loss: 0.3391459286212921
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3585868775844574, train_loss: 0.24857813119888306
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34945884346961975, train_loss: 0.1987498700618744
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34932249784469604, train_loss: 0.1899121105670929
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.644074559211731, train_loss: 0.6397496461868286
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40162503719329834, train_loss: 0.3399500250816345
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3502189815044403, train_loss: 0.24233238399028778
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34295424818992615, train_loss: 0.19354790449142456
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.34318551421165466, train_loss: 0.18883779644966125
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8834837079048157, train_loss: 0.8968536853790283
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5029215812683105, train_loss: 0.4389488101005554
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3885091543197632, train_loss: 0.28482991456985474
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3591432571411133, train_loss: 0.22496408224105835
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35362932085990906, train_loss: 0.18434655666351318
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4866015315055847, train_loss: 0.4716521203517914
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14940644800662994, train_loss: 0.07693050801753998
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14129818975925446, train_loss: 0.05200593173503876
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14091618359088898, train_loss: 0.050805188715457916
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14076104760169983, train_loss: 0.048454124480485916
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6437088847160339, train_loss: 0.596389889717102
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13668139278888702, train_loss: 0.09219709038734436
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12886862456798553, train_loss: 0.06124318391084671
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12824615836143494, train_loss: 0.0590352863073349
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12787677347660065, train_loss: 0.056469403207302094
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7774996757507324, train_loss: 0.7868294715881348
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45331212878227234, train_loss: 0.4077458083629608
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3347378969192505, train_loss: 0.28059837222099304
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28979456424713135, train_loss: 0.22426041960716248
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26947033405303955, train_loss: 0.17783178389072418
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2609245479106903, train_loss: 0.15355582535266876
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2585662305355072, train_loss: 0.1288468986749649
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7764360904693604, train_loss: 0.7674702405929565
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.47293928265571594, train_loss: 0.39527368545532227
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38384589552879333, train_loss: 0.2598351538181305
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3645268976688385, train_loss: 0.19864919781684875
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36386141180992126, train_loss: 0.17139506340026855
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7188233137130737, train_loss: 0.7147588729858398
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4323897659778595, train_loss: 0.36480605602264404
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3565724194049835, train_loss: 0.24323876202106476
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34089258313179016, train_loss: 0.19106405973434448
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.34067147970199585, train_loss: 0.17482145130634308
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 1.1096376180648804, train_loss: 1.1094350814819336
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.6267685294151306, train_loss: 0.5494655966758728
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4156336486339569, train_loss: 0.30101513862609863
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3602469861507416, train_loss: 0.2186310887336731
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.34661033749580383, train_loss: 0.1702824831008911
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3173311650753021, train_loss: 0.323946475982666
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1338193118572235, train_loss: 0.07236766815185547
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.12960492074489594, train_loss: 0.058029115200042725
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1293395608663559, train_loss: 0.054706305265426636
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.12909254431724548, train_loss: 0.05103081464767456
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.429372638463974, train_loss: 0.4841749966144562
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11748576164245605, train_loss: 0.07951939851045609
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11563844233751297, train_loss: 0.06273461878299713
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11558295786380768, train_loss: 0.06022745743393898
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11571719497442245, train_loss: 0.05928746610879898
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5393503308296204, train_loss: 0.5602096319198608
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35909757018089294, train_loss: 0.3343076705932617
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30381500720977783, train_loss: 0.2578069865703583
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28287041187286377, train_loss: 0.2169235199689865
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2744412124156952, train_loss: 0.17505154013633728
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2720738351345062, train_loss: 0.15059533715248108
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6643029451370239, train_loss: 0.6746395230293274
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4318848252296448, train_loss: 0.3596564531326294
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3736524283885956, train_loss: 0.24482551217079163
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3634827733039856, train_loss: 0.19694784283638
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3639693856239319, train_loss: 0.1893826723098755
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6706038117408752, train_loss: 0.6040549278259277
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4061935544013977, train_loss: 0.3229689598083496
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3512355387210846, train_loss: 0.2307191789150238
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34228843450546265, train_loss: 0.18096494674682617
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3422626256942749, train_loss: 0.17878973484039307
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.568260133266449, train_loss: 0.5502507090568542
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.37424352765083313, train_loss: 0.31118932366371155
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3397168815135956, train_loss: 0.23545967042446136
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33533939719200134, train_loss: 0.1930515170097351
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33560624718666077, train_loss: 0.18387986719608307
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3909183144569397, train_loss: 0.3714449107646942
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14145058393478394, train_loss: 0.07274740934371948
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13512055575847626, train_loss: 0.05487183481454849
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1350991427898407, train_loss: 0.054133858531713486
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1351986527442932, train_loss: 0.054192930459976196
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.3546314835548401, train_loss: 0.3800511360168457
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.14551658928394318, train_loss: 0.0799761563539505
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.14253811538219452, train_loss: 0.05890686810016632
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.14241068065166473, train_loss: 0.05879072844982147
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.14307904243469238, train_loss: 0.05661743879318237
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6641989350318909, train_loss: 0.6585335731506348
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.39382973313331604, train_loss: 0.37003180384635925
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3127953112125397, train_loss: 0.2754008173942566
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28452268242836, train_loss: 0.22599273920059204
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27254730463027954, train_loss: 0.18170598149299622
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2666516900062561, train_loss: 0.15395194292068481
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9293381571769714, train_loss: 0.9390342235565186
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5382920503616333, train_loss: 0.475883424282074
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39426368474960327, train_loss: 0.28264158964157104
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3600010275840759, train_loss: 0.21159246563911438
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3521738052368164, train_loss: 0.16929373145103455
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6816681623458862, train_loss: 0.676518976688385
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4259072244167328, train_loss: 0.35823166370391846
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3561285138130188, train_loss: 0.25225451588630676
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33657482266426086, train_loss: 0.19755715131759644
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3355313539505005, train_loss: 0.17329935729503632
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5924428701400757, train_loss: 0.583150327205658
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40850210189819336, train_loss: 0.32129624485969543
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3624780476093292, train_loss: 0.23184922337532043
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35559573769569397, train_loss: 0.18832328915596008
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3556254804134369, train_loss: 0.178401917219162
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6899921894073486, train_loss: 0.8026369214057922
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15544429421424866, train_loss: 0.07937687635421753
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1507280319929123, train_loss: 0.05778822302818298
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15115410089492798, train_loss: 0.053632862865924835
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1510043740272522, train_loss: 0.04976068437099457
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.7620574235916138, train_loss: 0.8324568271636963
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13749608397483826, train_loss: 0.08041073381900787
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13346652686595917, train_loss: 0.057850584387779236
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13359792530536652, train_loss: 0.05425915867090225
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13363920152187347, train_loss: 0.05381202697753906
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5556983947753906, train_loss: 0.5673511624336243
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.357652485370636, train_loss: 0.33512771129608154
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2969571053981781, train_loss: 0.25720036029815674
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2743782103061676, train_loss: 0.21372613310813904
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26506879925727844, train_loss: 0.1750626116991043
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2613442838191986, train_loss: 0.14703583717346191
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8347448110580444, train_loss: 0.8284885883331299
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4988841414451599, train_loss: 0.43065130710601807
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39193564653396606, train_loss: 0.2812446057796478
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3676103353500366, train_loss: 0.21816518902778625
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36513611674308777, train_loss: 0.1903616189956665
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7937224507331848, train_loss: 0.8269186019897461
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.45663541555404663, train_loss: 0.4270038604736328
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3528076708316803, train_loss: 0.27416127920150757
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3230588436126709, train_loss: 0.21247005462646484
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31414279341697693, train_loss: 0.17170745134353638
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8487240076065063, train_loss: 0.8516761660575867
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5147756934165955, train_loss: 0.4252680242061615
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.401786208152771, train_loss: 0.26844707131385803
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3727838397026062, train_loss: 0.20385898649692535
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36870643496513367, train_loss: 0.1704811453819275
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5066295862197876, train_loss: 0.506912350654602
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1568543016910553, train_loss: 0.07416985183954239
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15067856013774872, train_loss: 0.05333098769187927
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15057072043418884, train_loss: 0.05110795795917511
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.150004580616951, train_loss: 0.04986567795276642
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.35781043767929077, train_loss: 0.36515796184539795
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1140173152089119, train_loss: 0.07580218464136124
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.1131950169801712, train_loss: 0.06266187131404877
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1132262796163559, train_loss: 0.060493260622024536
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11316681653261185, train_loss: 0.06050954386591911
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6233932971954346, train_loss: 0.6423441767692566
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38185200095176697, train_loss: 0.3523678779602051
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30874505639076233, train_loss: 0.2646697163581848
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2849961519241333, train_loss: 0.2126900851726532
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.27812305092811584, train_loss: 0.18663620948791504
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9510840773582458, train_loss: 0.9890286922454834
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5444662570953369, train_loss: 0.49935317039489746
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39341282844543457, train_loss: 0.2950705587863922
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.36025750637054443, train_loss: 0.21315860748291016
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3543480932712555, train_loss: 0.17409035563468933
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9815350770950317, train_loss: 1.0627546310424805
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5383748412132263, train_loss: 0.5201538801193237
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36482512950897217, train_loss: 0.29459941387176514
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32170480489730835, train_loss: 0.21460580825805664
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3125358819961548, train_loss: 0.1717226803302765
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8067910075187683, train_loss: 0.8343571424484253
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4464528560638428, train_loss: 0.38370078802108765
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35419565439224243, train_loss: 0.24967345595359802
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3353896141052246, train_loss: 0.1875385344028473
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33448851108551025, train_loss: 0.16660818457603455
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.5069984793663025, train_loss: 0.6297939419746399
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15317346155643463, train_loss: 0.0819188728928566
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14945515990257263, train_loss: 0.06164674833416939
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14888957142829895, train_loss: 0.05808107554912567
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14898903667926788, train_loss: 0.06130320578813553
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.29026511311531067, train_loss: 0.3594318926334381
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11160821467638016, train_loss: 0.090084508061409
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10970313102006912, train_loss: 0.072392538189888
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11001115292310715, train_loss: 0.06588114798069
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11025416105985641, train_loss: 0.06437455117702484
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.0300530195236206, train_loss: 1.0245611667633057
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5763238072395325, train_loss: 0.5258908271789551
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3714354336261749, train_loss: 0.3196254372596741
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3021419644355774, train_loss: 0.24057653546333313
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.272749125957489, train_loss: 0.19291621446609497
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.25883305072784424, train_loss: 0.16047044098377228
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.25315061211586, train_loss: 0.13375625014305115
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.25232332944869995, train_loss: 0.12478110939264297
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6032869815826416, train_loss: 0.5935845375061035
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.40022778511047363, train_loss: 0.324102520942688
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35991013050079346, train_loss: 0.231802836060524
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35550493001937866, train_loss: 0.18900693953037262
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35567736625671387, train_loss: 0.18331646919250488
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.5829929709434509, train_loss: 0.5398797392845154
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3922085165977478, train_loss: 0.3028966784477234
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34642407298088074, train_loss: 0.2265920341014862
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3360046148300171, train_loss: 0.18046194314956665
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.33579444885253906, train_loss: 0.1726403534412384
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9287909269332886, train_loss: 0.9439271092414856
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5444281101226807, train_loss: 0.47784939408302307
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3955307602882385, train_loss: 0.2871452569961548
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3616270124912262, train_loss: 0.21038274466991425
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3585747480392456, train_loss: 0.1867167204618454
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.313546359539032, train_loss: 0.33359795808792114
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15130189061164856, train_loss: 0.07221709191799164
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14798156917095184, train_loss: 0.054753098636865616
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14686456322669983, train_loss: 0.0505499467253685
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14733797311782837, train_loss: 0.04945136234164238
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6088298559188843, train_loss: 0.6951082944869995
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13834096491336823, train_loss: 0.0741255134344101
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13549654185771942, train_loss: 0.05276041477918625
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13527911901474, train_loss: 0.0492839515209198
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13534791767597198, train_loss: 0.04915212467312813
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8997810482978821, train_loss: 0.9177857637405396
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4942153990268707, train_loss: 0.4437464773654938
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3511298596858978, train_loss: 0.2852990925312042
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3055838942527771, train_loss: 0.22612150013446808
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2860044240951538, train_loss: 0.1825331151485443
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27703389525413513, train_loss: 0.1556156575679779
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2743642032146454, train_loss: 0.12606850266456604
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.9126394391059875, train_loss: 0.9510674476623535
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5230833888053894, train_loss: 0.48170533776283264
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3799135982990265, train_loss: 0.28593242168426514
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34889352321624756, train_loss: 0.21297454833984375
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3465394973754883, train_loss: 0.16821852326393127
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6636312007904053, train_loss: 0.6565168499946594
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3955504894256592, train_loss: 0.3352257013320923
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3350359797477722, train_loss: 0.23234789073467255
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3204643428325653, train_loss: 0.18608635663986206
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31953731179237366, train_loss: 0.1569364070892334
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.44612735509872437, train_loss: 0.4263930916786194
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3412994146347046, train_loss: 0.273154079914093
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3296887278556824, train_loss: 0.20933076739311218
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.32991594076156616, train_loss: 0.20143049955368042
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3301595449447632, train_loss: 0.2004891335964203
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4623619318008423, train_loss: 0.47164851427078247
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16311141848564148, train_loss: 0.07389043271541595
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15968814492225647, train_loss: 0.05584845691919327
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.15929029881954193, train_loss: 0.0503702312707901
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1587972342967987, train_loss: 0.04818979650735855
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4989264905452728, train_loss: 0.5049905776977539
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1126914992928505, train_loss: 0.07682989537715912
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11135012656450272, train_loss: 0.06188330799341202
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11117769032716751, train_loss: 0.06138724088668823
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11112714558839798, train_loss: 0.05929584801197052
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7470547556877136, train_loss: 0.7278208136558533
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4300953447818756, train_loss: 0.3815958499908447
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32342204451560974, train_loss: 0.2660507559776306
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2826198935508728, train_loss: 0.2108755260705948
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.26632294058799744, train_loss: 0.1818741410970688
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2605401873588562, train_loss: 0.14985501766204834
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8907600045204163, train_loss: 0.910066545009613
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5250930190086365, train_loss: 0.4592985510826111
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.4005066156387329, train_loss: 0.26952114701271057
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37210628390312195, train_loss: 0.20286327600479126
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3688538074493408, train_loss: 0.16901302337646484
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6934468746185303, train_loss: 0.6455647945404053
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4048098623752594, train_loss: 0.34168270230293274
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.339569628238678, train_loss: 0.24460138380527496
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32041239738464355, train_loss: 0.1914510577917099
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.31820908188819885, train_loss: 0.17072004079818726
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7466645240783691, train_loss: 0.743598997592926
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4521973133087158, train_loss: 0.38867682218551636
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.372150182723999, train_loss: 0.2642505168914795
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3498499095439911, train_loss: 0.20696000754833221
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3460496962070465, train_loss: 0.1830289661884308
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4142303764820099, train_loss: 0.38110125064849854
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.16231150925159454, train_loss: 0.07507479190826416
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14994192123413086, train_loss: 0.05418144911527634
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14614713191986084, train_loss: 0.03894874453544617
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14631009101867676, train_loss: 0.038817886263132095
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.8322867155075073, train_loss: 0.8496376276016235
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13028275966644287, train_loss: 0.07500351965427399
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12582439184188843, train_loss: 0.053780946880578995
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12571361660957336, train_loss: 0.04760202020406723
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12574699521064758, train_loss: 0.04689459875226021
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.711151659488678, train_loss: 0.7050075531005859
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4147075414657593, train_loss: 0.38041558861732483
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.32369568943977356, train_loss: 0.2751319408416748
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2895696461200714, train_loss: 0.22137320041656494
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2757045030593872, train_loss: 0.18390807509422302
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26881176233291626, train_loss: 0.15682706236839294
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8372071981430054, train_loss: 0.8636187314987183
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.49357983469963074, train_loss: 0.4354236125946045
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.38378390669822693, train_loss: 0.2797306776046753
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3602518141269684, train_loss: 0.2171061486005783
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3591165244579315, train_loss: 0.19036835432052612
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7995867133140564, train_loss: 0.8480623960494995
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4625190496444702, train_loss: 0.409463107585907
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3609272837638855, train_loss: 0.2544526159763336
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33147311210632324, train_loss: 0.19608214497566223
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32298585772514343, train_loss: 0.1580619513988495
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6935257315635681, train_loss: 0.6686986684799194
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.42652562260627747, train_loss: 0.3586229681968689
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3601101338863373, train_loss: 0.25932738184928894
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34742996096611023, train_loss: 0.2017388790845871
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3472747802734375, train_loss: 0.1812134087085724
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.7148907780647278, train_loss: 0.7525193095207214
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15598298609256744, train_loss: 0.07972663640975952
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14929495751857758, train_loss: 0.0560835599899292
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14887842535972595, train_loss: 0.05728375166654587
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14879585802555084, train_loss: 0.05222189426422119
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6140754222869873, train_loss: 0.6526243686676025
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13845019042491913, train_loss: 0.07831105589866638
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13467073440551758, train_loss: 0.06044400483369827
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1343148797750473, train_loss: 0.05825072154402733
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13440343737602234, train_loss: 0.05512833595275879
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.43953728675842285, train_loss: 0.48148852586746216
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.30416908860206604, train_loss: 0.30254441499710083
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.2726629078388214, train_loss: 0.23940712213516235
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2635611593723297, train_loss: 0.2038474678993225
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.25991150736808777, train_loss: 0.16819575428962708
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8583899140357971, train_loss: 0.8965259790420532
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.5102575421333313, train_loss: 0.4414384663105011
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3934989869594574, train_loss: 0.276491641998291
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.369046688079834, train_loss: 0.20844385027885437
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36737364530563354, train_loss: 0.1795617789030075
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6220059990882874, train_loss: 0.6250279545783997
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.38574400544166565, train_loss: 0.316636860370636
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33355826139450073, train_loss: 0.22911396622657776
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32178255915641785, train_loss: 0.18107092380523682
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3217083513736725, train_loss: 0.16485854983329773
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.46098238229751587, train_loss: 0.4626728296279907
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.3466309607028961, train_loss: 0.2821941077709198
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3323688805103302, train_loss: 0.21445029973983765
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33266231417655945, train_loss: 0.2045445591211319
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3330635726451874, train_loss: 0.19411557912826538
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.4473912715911865, train_loss: 0.4154250919818878
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15617626905441284, train_loss: 0.07016876339912415
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14814341068267822, train_loss: 0.052214208990335464
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14750459790229797, train_loss: 0.050498202443122864
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14705976843833923, train_loss: 0.04646023362874985
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6671985387802124, train_loss: 0.774193286895752
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13875894248485565, train_loss: 0.08072718977928162
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.13577482104301453, train_loss: 0.06235353648662567
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.13498055934906006, train_loss: 0.06022455170750618
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.13453428447246552, train_loss: 0.05680738016963005
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9712862968444824, train_loss: 1.0057687759399414
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5517128705978394, train_loss: 0.5045689940452576
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3745162785053253, train_loss: 0.314116507768631
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3169877529144287, train_loss: 0.2339392751455307
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.29410672187805176, train_loss: 0.194052591919899
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2866712212562561, train_loss: 0.1605364978313446
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6325971484184265, train_loss: 0.6270710229873657
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4162900149822235, train_loss: 0.33700475096702576
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36978936195373535, train_loss: 0.23427468538284302
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3632648289203644, train_loss: 0.18972213566303253
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.36423230171203613, train_loss: 0.178190678358078
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.536484956741333, train_loss: 0.5361027717590332
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.35365012288093567, train_loss: 0.30404579639434814
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.313686341047287, train_loss: 0.22918495535850525
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3021717369556427, train_loss: 0.18343043327331543
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.30181288719177246, train_loss: 0.16354721784591675
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7340861558914185, train_loss: 0.731463611125946
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4372672736644745, train_loss: 0.36518657207489014
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35832902789115906, train_loss: 0.2495352327823639
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.339718222618103, train_loss: 0.19337788224220276
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.33890074491500854, train_loss: 0.1653660237789154
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.49148887395858765, train_loss: 0.5104066729545593
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14434856176376343, train_loss: 0.06894940137863159
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13923215866088867, train_loss: 0.04773368313908577
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13914188742637634, train_loss: 0.04519953578710556
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1386914998292923, train_loss: 0.04640946537256241
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.6448754668235779, train_loss: 0.7220813035964966
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.1183401346206665, train_loss: 0.07994438707828522
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11475609987974167, train_loss: 0.05541668087244034
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11443324387073517, train_loss: 0.05420934781432152
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.1146048977971077, train_loss: 0.05188586562871933
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6128415465354919, train_loss: 0.6015070676803589
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3788082003593445, train_loss: 0.34797579050064087
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.30638307332992554, train_loss: 0.26261672377586365
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2783448398113251, train_loss: 0.22065430879592896
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2671680450439453, train_loss: 0.18775434792041779
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.26100507378578186, train_loss: 0.15448537468910217
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6815240979194641, train_loss: 0.6845159530639648
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4307243525981903, train_loss: 0.3685370683670044
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3621057868003845, train_loss: 0.25776728987693787
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.34776872396469116, train_loss: 0.20058077573776245
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3479262590408325, train_loss: 0.1894409954547882
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 1.2277032136917114, train_loss: 1.3198206424713135
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.7041878700256348, train_loss: 0.6834179759025574
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.43323248624801636, train_loss: 0.3586183786392212
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3522443175315857, train_loss: 0.23361772298812866
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3305858075618744, train_loss: 0.1790466010570526
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6720696687698364, train_loss: 0.6545124053955078
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39818310737609863, train_loss: 0.3447781205177307
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.34904998540878296, train_loss: 0.25067850947380066
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3394657075405121, train_loss: 0.20300543308258057
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3398420512676239, train_loss: 0.18665741384029388
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3481093645095825, train_loss: 0.4149532914161682
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.15291263163089752, train_loss: 0.07964617758989334
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.15010033547878265, train_loss: 0.06251591444015503
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14951664209365845, train_loss: 0.062291231006383896
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14903956651687622, train_loss: 0.05777949094772339
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4129846394062042, train_loss: 0.5340542197227478
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11805813014507294, train_loss: 0.08315593004226685
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11439017951488495, train_loss: 0.06123795732855797
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11432985961437225, train_loss: 0.05883321538567543
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11427643150091171, train_loss: 0.05621558055281639
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.9353020787239075, train_loss: 0.9599122405052185
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.5250974297523499, train_loss: 0.48837435245513916
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36600393056869507, train_loss: 0.320117712020874
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3121735155582428, train_loss: 0.24970659613609314
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.28884899616241455, train_loss: 0.2107381522655487
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27798333764076233, train_loss: 0.17772197723388672
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2743380069732666, train_loss: 0.15539681911468506
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.2733526825904846, train_loss: 0.1482357233762741
[po_estimator_0_impute_pos] Epoch: 400, current validation loss: 0.27306169271469116, train_loss: 0.1431468427181244
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6612610220909119, train_loss: 0.648979902267456
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4158087372779846, train_loss: 0.345969021320343
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36446303129196167, train_loss: 0.25053513050079346
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3573337495326996, train_loss: 0.19607770442962646
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35746994614601135, train_loss: 0.19606760144233704
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8098642826080322, train_loss: 0.8416925668716431
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4634585976600647, train_loss: 0.39747825264930725
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3635173439979553, train_loss: 0.25208109617233276
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.33501332998275757, train_loss: 0.1905331015586853
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32904016971588135, train_loss: 0.1560976654291153
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6928636431694031, train_loss: 0.6697603464126587
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.43612590432167053, train_loss: 0.3597285747528076
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.36821290850639343, train_loss: 0.2599417269229889
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3526540994644165, train_loss: 0.20596164464950562
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35232287645339966, train_loss: 0.1877213418483734
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.3328719437122345, train_loss: 0.3233545124530792
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1447625756263733, train_loss: 0.06963969767093658
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1411936730146408, train_loss: 0.05200260505080223
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14071333408355713, train_loss: 0.04636932909488678
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14069578051567078, train_loss: 0.04438614100217819
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.5459768772125244, train_loss: 0.6452827453613281
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11641474813222885, train_loss: 0.08082849532365799
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11473922431468964, train_loss: 0.06973189860582352
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.1144578829407692, train_loss: 0.06107436120510101
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11458663642406464, train_loss: 0.06355267018079758
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8068172335624695, train_loss: 0.810476541519165
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.46382173895835876, train_loss: 0.4100986421108246
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.34415146708488464, train_loss: 0.2819215655326843
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30146703124046326, train_loss: 0.23531635105609894
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2826998233795166, train_loss: 0.1942749321460724
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2752028703689575, train_loss: 0.16612520813941956
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2720840275287628, train_loss: 0.14210215210914612
[po_estimator_0_impute_pos] Epoch: 350, current validation loss: 0.271505206823349, train_loss: 0.13362383842468262
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5562154054641724, train_loss: 0.545842170715332
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.39003443717956543, train_loss: 0.3200500011444092
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3566807508468628, train_loss: 0.23899692296981812
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.35269224643707275, train_loss: 0.20393750071525574
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3526585102081299, train_loss: 0.2024954855442047
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6412982940673828, train_loss: 0.6353086829185486
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.382762610912323, train_loss: 0.3226456642150879
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.33035099506378174, train_loss: 0.22589179873466492
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.32058125734329224, train_loss: 0.1782509982585907
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32060524821281433, train_loss: 0.16224299371242523
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8025373816490173, train_loss: 0.7986001968383789
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4819926619529724, train_loss: 0.415088951587677
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3821280002593994, train_loss: 0.27265727519989014
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3586640954017639, train_loss: 0.21016645431518555
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3564174473285675, train_loss: 0.1808028221130371
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.27068209648132324, train_loss: 0.26922959089279175
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.13965286314487457, train_loss: 0.0721530020236969
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1346396803855896, train_loss: 0.05138441175222397
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.1339922845363617, train_loss: 0.048194535076618195
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.13408653438091278, train_loss: 0.04790104925632477
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2530723512172699, train_loss: 0.3134015202522278
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11053125560283661, train_loss: 0.08056694269180298
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.10880903899669647, train_loss: 0.061585575342178345
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.10893073678016663, train_loss: 0.06314301490783691
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.10919199883937836, train_loss: 0.060292892158031464
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6229509711265564, train_loss: 0.6528704166412354
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.3816108703613281, train_loss: 0.35399025678634644
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3089669942855835, train_loss: 0.2627960443496704
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.28284505009651184, train_loss: 0.21871931850910187
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2733595073223114, train_loss: 0.18108108639717102
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.27020400762557983, train_loss: 0.15557798743247986
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6614713668823242, train_loss: 0.6381982564926147
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.426020085811615, train_loss: 0.33599740266799927
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3825148046016693, train_loss: 0.2452486902475357
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37683090567588806, train_loss: 0.2051793932914734
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.37709125876426697, train_loss: 0.19780489802360535
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6014496088027954, train_loss: 0.603233814239502
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.36612507700920105, train_loss: 0.3200710713863373
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3118937909603119, train_loss: 0.23017385601997375
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29833462834358215, train_loss: 0.17679166793823242
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2975785732269287, train_loss: 0.1647241711616516
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7145339846611023, train_loss: 0.736498236656189
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4222182631492615, train_loss: 0.3717305064201355
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.35042956471443176, train_loss: 0.25005730986595154
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33438462018966675, train_loss: 0.19619877636432648
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3335683345794678, train_loss: 0.169478178024292
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.540185272693634, train_loss: 0.5847266316413879
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1439342498779297, train_loss: 0.06682075560092926
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.13526053726673126, train_loss: 0.0482073649764061
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13458922505378723, train_loss: 0.04741309583187103
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1342209428548813, train_loss: 0.04724884778261185
[te_estimator_0_xnet] Epoch: 250, current validation loss: 0.13367584347724915, train_loss: 0.047380320727825165
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.2427903711795807, train_loss: 0.28221315145492554
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.11773190647363663, train_loss: 0.07813508808612823
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.11596538871526718, train_loss: 0.05486985296010971
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.11594539135694504, train_loss: 0.05361929163336754
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.11569438129663467, train_loss: 0.05071025341749191
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6886129975318909, train_loss: 0.7072889804840088
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.40775635838508606, train_loss: 0.3781909942626953
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3218456208705902, train_loss: 0.27056771516799927
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.29182520508766174, train_loss: 0.21833592653274536
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2785944640636444, train_loss: 0.17811785638332367
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2740679681301117, train_loss: 0.1499899923801422
[po_estimator_0_impute_pos] Epoch: 300, current validation loss: 0.2718951106071472, train_loss: 0.13184383511543274
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7817825675010681, train_loss: 0.7985560297966003
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4500333368778229, train_loss: 0.3843240737915039
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.372920960187912, train_loss: 0.25169482827186584
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3589900732040405, train_loss: 0.19793644547462463
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.35773396492004395, train_loss: 0.1912730485200882
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8061403632164001, train_loss: 0.8700057864189148
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.47479405999183655, train_loss: 0.43386223912239075
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.361550897359848, train_loss: 0.2674587368965149
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.3327377140522003, train_loss: 0.2018289566040039
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.32688194513320923, train_loss: 0.16547976434230804
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.8496845960617065, train_loss: 0.8541705012321472
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.500174343585968, train_loss: 0.42522889375686646
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.39085543155670166, train_loss: 0.2750430703163147
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3651231825351715, train_loss: 0.21402595937252045
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3629086911678314, train_loss: 0.18454018235206604
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.6779037117958069, train_loss: 0.6545536518096924
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1443711370229721, train_loss: 0.06788308173418045
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1381726861000061, train_loss: 0.046701155602931976
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.13747966289520264, train_loss: 0.04448504000902176
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.1371542513370514, train_loss: 0.04273945838212967
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.9085277318954468, train_loss: 0.9539785385131836
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.13485820591449738, train_loss: 0.07199805974960327
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12576277554035187, train_loss: 0.04867159575223923
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12569327652454376, train_loss: 0.04739665985107422
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12547996640205383, train_loss: 0.04407250136137009
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7380217909812927, train_loss: 0.7689751386642456
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4342680871486664, train_loss: 0.3944188356399536
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3346526026725769, train_loss: 0.2656228244304657
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.2991011440753937, train_loss: 0.21963071823120117
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2853773236274719, train_loss: 0.18558840453624725
[po_estimator_0_impute_pos] Epoch: 250, current validation loss: 0.2804155647754669, train_loss: 0.14770099520683289
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7578736543655396, train_loss: 0.7791734933853149
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4638012945652008, train_loss: 0.3979664444923401
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.37942516803741455, train_loss: 0.2633572816848755
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.3614402711391449, train_loss: 0.199668288230896
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3611319959163666, train_loss: 0.1802646964788437
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.8153055906295776, train_loss: 0.8195539116859436
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4468366801738739, train_loss: 0.3941892981529236
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3483256995677948, train_loss: 0.2465914934873581
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.324812650680542, train_loss: 0.1830500066280365
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3224179744720459, train_loss: 0.1567138135433197
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.6648841500282288, train_loss: 0.6923616528511047
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.41826874017715454, train_loss: 0.3694823384284973
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3519833981990814, train_loss: 0.2611285448074341
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.33727750182151794, train_loss: 0.20391511917114258
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3364650011062622, train_loss: 0.18888884782791138
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.42821693420410156, train_loss: 0.446161150932312
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.1486530303955078, train_loss: 0.07185892760753632
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.1431351900100708, train_loss: 0.05389086902141571
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14223888516426086, train_loss: 0.05274907499551773
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14182154834270477, train_loss: 0.05095318704843521
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.4344460666179657, train_loss: 0.44711053371429443
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.12921935319900513, train_loss: 0.08004242181777954
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.12422294914722443, train_loss: 0.0580805242061615
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.12409969419240952, train_loss: 0.05544421449303627
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.12404815107584, train_loss: 0.0503542535007
Calculating insertion/deletion and ablation results.
obtaining subgroup results for loco, feature_num: 1.obtaining subgroup results for loco, feature_num: 2.obtaining subgroup results for loco, feature_num: 3.obtaining subgroup results for loco, feature_num: 4.obtaining subgroup results for loco, feature_num: 5.obtaining subgroup results for loco, feature_num: 6.obtaining subgroup results for loco, feature_num: 7.obtaining subgroup results for loco, feature_num: 8.obtaining subgroup results for loco, feature_num: 9.obtaining subgroup results for loco, feature_num: 10.obtaining subgroup results for loco, feature_num: 11.obtaining subgroup results for loco, feature_num: 12.obtaining subgroup results for loco, feature_num: 13.obtaining subgroup results for loco, feature_num: 14.obtaining subgroup results for loco, feature_num: 15.obtaining subgroup results for loco, feature_num: 16.obtaining subgroup results for loco, feature_num: 17.obtaining subgroup results for loco, feature_num: 18.obtaining subgroup results for loco, feature_num: 19.obtaining subgroup results for loco, feature_num: 20.obtaining subgroup results for loco, feature_num: 21.obtaining subgroup results for loco, feature_num: 22.obtaining subgroup results for loco, feature_num: 23.obtaining subgroup results for loco, feature_num: 24.obtaining subgroup results for loco, feature_num: 25.obtaining subgroup results for loco, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for permucate, feature_num: 1.obtaining subgroup results for permucate, feature_num: 2.obtaining subgroup results for permucate, feature_num: 3.obtaining subgroup results for permucate, feature_num: 4.obtaining subgroup results for permucate, feature_num: 5.obtaining subgroup results for permucate, feature_num: 6.obtaining subgroup results for permucate, feature_num: 7.obtaining subgroup results for permucate, feature_num: 8.obtaining subgroup results for permucate, feature_num: 9.obtaining subgroup results for permucate, feature_num: 10.obtaining subgroup results for permucate, feature_num: 11.obtaining subgroup results for permucate, feature_num: 12.obtaining subgroup results for permucate, feature_num: 13.obtaining subgroup results for permucate, feature_num: 14.obtaining subgroup results for permucate, feature_num: 15.obtaining subgroup results for permucate, feature_num: 16.obtaining subgroup results for permucate, feature_num: 17.obtaining subgroup results for permucate, feature_num: 18.obtaining subgroup results for permucate, feature_num: 19.obtaining subgroup results for permucate, feature_num: 20.obtaining subgroup results for permucate, feature_num: 21.obtaining subgroup results for permucate, feature_num: 22.obtaining subgroup results for permucate, feature_num: 23.obtaining subgroup results for permucate, feature_num: 24.obtaining subgroup results for permucate, feature_num: 25.obtaining subgroup results for permucate, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for saliency, feature_num: 1.obtaining subgroup results for saliency, feature_num: 2.obtaining subgroup results for saliency, feature_num: 3.obtaining subgroup results for saliency, feature_num: 4.obtaining subgroup results for saliency, feature_num: 5.obtaining subgroup results for saliency, feature_num: 6.obtaining subgroup results for saliency, feature_num: 7.obtaining subgroup results for saliency, feature_num: 8.obtaining subgroup results for saliency, feature_num: 9.obtaining subgroup results for saliency, feature_num: 10.obtaining subgroup results for saliency, feature_num: 11.obtaining subgroup results for saliency, feature_num: 12.obtaining subgroup results for saliency, feature_num: 13.obtaining subgroup results for saliency, feature_num: 14.obtaining subgroup results for saliency, feature_num: 15.obtaining subgroup results for saliency, feature_num: 16.obtaining subgroup results for saliency, feature_num: 17.obtaining subgroup results for saliency, feature_num: 18.obtaining subgroup results for saliency, feature_num: 19.obtaining subgroup results for saliency, feature_num: 20.obtaining subgroup results for saliency, feature_num: 21.obtaining subgroup results for saliency, feature_num: 22.obtaining subgroup results for saliency, feature_num: 23.obtaining subgroup results for saliency, feature_num: 24.obtaining subgroup results for saliency, feature_num: 25.obtaining subgroup results for saliency, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for smooth_grad, feature_num: 1.obtaining subgroup results for smooth_grad, feature_num: 2.obtaining subgroup results for smooth_grad, feature_num: 3.obtaining subgroup results for smooth_grad, feature_num: 4.obtaining subgroup results for smooth_grad, feature_num: 5.obtaining subgroup results for smooth_grad, feature_num: 6.obtaining subgroup results for smooth_grad, feature_num: 7.obtaining subgroup results for smooth_grad, feature_num: 8.obtaining subgroup results for smooth_grad, feature_num: 9.obtaining subgroup results for smooth_grad, feature_num: 10.obtaining subgroup results for smooth_grad, feature_num: 11.obtaining subgroup results for smooth_grad, feature_num: 12.obtaining subgroup results for smooth_grad, feature_num: 13.obtaining subgroup results for smooth_grad, feature_num: 14.obtaining subgroup results for smooth_grad, feature_num: 15.obtaining subgroup results for smooth_grad, feature_num: 16.obtaining subgroup results for smooth_grad, feature_num: 17.obtaining subgroup results for smooth_grad, feature_num: 18.obtaining subgroup results for smooth_grad, feature_num: 19.obtaining subgroup results for smooth_grad, feature_num: 20.obtaining subgroup results for smooth_grad, feature_num: 21.obtaining subgroup results for smooth_grad, feature_num: 22.obtaining subgroup results for smooth_grad, feature_num: 23.obtaining subgroup results for smooth_grad, feature_num: 24.obtaining subgroup results for smooth_grad, feature_num: 25.obtaining subgroup results for smooth_grad, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for gradient_shap, feature_num: 1.obtaining subgroup results for gradient_shap, feature_num: 2.obtaining subgroup results for gradient_shap, feature_num: 3.obtaining subgroup results for gradient_shap, feature_num: 4.obtaining subgroup results for gradient_shap, feature_num: 5.obtaining subgroup results for gradient_shap, feature_num: 6.obtaining subgroup results for gradient_shap, feature_num: 7.obtaining subgroup results for gradient_shap, feature_num: 8.obtaining subgroup results for gradient_shap, feature_num: 9.obtaining subgroup results for gradient_shap, feature_num: 10.obtaining subgroup results for gradient_shap, feature_num: 11.obtaining subgroup results for gradient_shap, feature_num: 12.obtaining subgroup results for gradient_shap, feature_num: 13.obtaining subgroup results for gradient_shap, feature_num: 14.obtaining subgroup results for gradient_shap, feature_num: 15.obtaining subgroup results for gradient_shap, feature_num: 16.obtaining subgroup results for gradient_shap, feature_num: 17.obtaining subgroup results for gradient_shap, feature_num: 18.obtaining subgroup results for gradient_shap, feature_num: 19.obtaining subgroup results for gradient_shap, feature_num: 20.obtaining subgroup results for gradient_shap, feature_num: 21.obtaining subgroup results for gradient_shap, feature_num: 22.obtaining subgroup results for gradient_shap, feature_num: 23.obtaining subgroup results for gradient_shap, feature_num: 24.obtaining subgroup results for gradient_shap, feature_num: 25.obtaining subgroup results for gradient_shap, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for lime, feature_num: 1.obtaining subgroup results for lime, feature_num: 2.obtaining subgroup results for lime, feature_num: 3.obtaining subgroup results for lime, feature_num: 4.obtaining subgroup results for lime, feature_num: 5.obtaining subgroup results for lime, feature_num: 6.obtaining subgroup results for lime, feature_num: 7.obtaining subgroup results for lime, feature_num: 8.obtaining subgroup results for lime, feature_num: 9.obtaining subgroup results for lime, feature_num: 10.obtaining subgroup results for lime, feature_num: 11.obtaining subgroup results for lime, feature_num: 12.obtaining subgroup results for lime, feature_num: 13.obtaining subgroup results for lime, feature_num: 14.obtaining subgroup results for lime, feature_num: 15.obtaining subgroup results for lime, feature_num: 16.obtaining subgroup results for lime, feature_num: 17.obtaining subgroup results for lime, feature_num: 18.obtaining subgroup results for lime, feature_num: 19.obtaining subgroup results for lime, feature_num: 20.obtaining subgroup results for lime, feature_num: 21.obtaining subgroup results for lime, feature_num: 22.obtaining subgroup results for lime, feature_num: 23.obtaining subgroup results for lime, feature_num: 24.obtaining subgroup results for lime, feature_num: 25.obtaining subgroup results for lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_lime, feature_num: 1.obtaining subgroup results for baseline_lime, feature_num: 2.obtaining subgroup results for baseline_lime, feature_num: 3.obtaining subgroup results for baseline_lime, feature_num: 4.obtaining subgroup results for baseline_lime, feature_num: 5.obtaining subgroup results for baseline_lime, feature_num: 6.obtaining subgroup results for baseline_lime, feature_num: 7.obtaining subgroup results for baseline_lime, feature_num: 8.obtaining subgroup results for baseline_lime, feature_num: 9.obtaining subgroup results for baseline_lime, feature_num: 10.obtaining subgroup results for baseline_lime, feature_num: 11.obtaining subgroup results for baseline_lime, feature_num: 12.obtaining subgroup results for baseline_lime, feature_num: 13.obtaining subgroup results for baseline_lime, feature_num: 14.obtaining subgroup results for baseline_lime, feature_num: 15.obtaining subgroup results for baseline_lime, feature_num: 16.obtaining subgroup results for baseline_lime, feature_num: 17.obtaining subgroup results for baseline_lime, feature_num: 18.obtaining subgroup results for baseline_lime, feature_num: 19.obtaining subgroup results for baseline_lime, feature_num: 20.obtaining subgroup results for baseline_lime, feature_num: 21.obtaining subgroup results for baseline_lime, feature_num: 22.obtaining subgroup results for baseline_lime, feature_num: 23.obtaining subgroup results for baseline_lime, feature_num: 24.obtaining subgroup results for baseline_lime, feature_num: 25.obtaining subgroup results for baseline_lime, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 1.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 2.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 3.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 4.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 5.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 6.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 7.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 8.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 9.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 10.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 11.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 12.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 13.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 14.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 15.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 16.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 17.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 18.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 19.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 20.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 21.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 22.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 23.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 24.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 25.obtaining subgroup results for baseline_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 1.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 2.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 3.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 4.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 5.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 6.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 7.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 8.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 9.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 10.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 11.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 12.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 13.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 14.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 15.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 16.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 17.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 18.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 19.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 20.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 21.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 22.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 23.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 24.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 25.obtaining subgroup results for marginal_shapley_value_sampling, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for integrated_gradients, feature_num: 1.obtaining subgroup results for integrated_gradients, feature_num: 2.obtaining subgroup results for integrated_gradients, feature_num: 3.obtaining subgroup results for integrated_gradients, feature_num: 4.obtaining subgroup results for integrated_gradients, feature_num: 5.obtaining subgroup results for integrated_gradients, feature_num: 6.obtaining subgroup results for integrated_gradients, feature_num: 7.obtaining subgroup results for integrated_gradients, feature_num: 8.obtaining subgroup results for integrated_gradients, feature_num: 9.obtaining subgroup results for integrated_gradients, feature_num: 10.obtaining subgroup results for integrated_gradients, feature_num: 11.obtaining subgroup results for integrated_gradients, feature_num: 12.obtaining subgroup results for integrated_gradients, feature_num: 13.obtaining subgroup results for integrated_gradients, feature_num: 14.obtaining subgroup results for integrated_gradients, feature_num: 15.obtaining subgroup results for integrated_gradients, feature_num: 16.obtaining subgroup results for integrated_gradients, feature_num: 17.obtaining subgroup results for integrated_gradients, feature_num: 18.obtaining subgroup results for integrated_gradients, feature_num: 19.obtaining subgroup results for integrated_gradients, feature_num: 20.obtaining subgroup results for integrated_gradients, feature_num: 21.obtaining subgroup results for integrated_gradients, feature_num: 22.obtaining subgroup results for integrated_gradients, feature_num: 23.obtaining subgroup results for integrated_gradients, feature_num: 24.obtaining subgroup results for integrated_gradients, feature_num: 25.obtaining subgroup results for integrated_gradients, feature_num: 26.Calculating insertion/deletion and ablation results.
obtaining subgroup results for baseline_integrated_gradients, feature_num: 1.obtaining subgroup results for baseline_integrated_gradients, feature_num: 2.obtaining subgroup results for baseline_integrated_gradients, feature_num: 3.obtaining subgroup results for baseline_integrated_gradients, feature_num: 4.obtaining subgroup results for baseline_integrated_gradients, feature_num: 5.obtaining subgroup results for baseline_integrated_gradients, feature_num: 6.obtaining subgroup results for baseline_integrated_gradients, feature_num: 7.obtaining subgroup results for baseline_integrated_gradients, feature_num: 8.obtaining subgroup results for baseline_integrated_gradients, feature_num: 9.obtaining subgroup results for baseline_integrated_gradients, feature_num: 10.obtaining subgroup results for baseline_integrated_gradients, feature_num: 11.obtaining subgroup results for baseline_integrated_gradients, feature_num: 12.obtaining subgroup results for baseline_integrated_gradients, feature_num: 13.obtaining subgroup results for baseline_integrated_gradients, feature_num: 14.obtaining subgroup results for baseline_integrated_gradients, feature_num: 15.obtaining subgroup results for baseline_integrated_gradients, feature_num: 16.obtaining subgroup results for baseline_integrated_gradients, feature_num: 17.obtaining subgroup results for baseline_integrated_gradients, feature_num: 18.obtaining subgroup results for baseline_integrated_gradients, feature_num: 19.obtaining subgroup results for baseline_integrated_gradients, feature_num: 20.obtaining subgroup results for baseline_integrated_gradients, feature_num: 21.obtaining subgroup results for baseline_integrated_gradients, feature_num: 22.obtaining subgroup results for baseline_integrated_gradients, feature_num: 23.obtaining subgroup results for baseline_integrated_gradients, feature_num: 24.obtaining subgroup results for baseline_integrated_gradients, feature_num: 25.obtaining subgroup results for baseline_integrated_gradients, feature_num: 26.[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.6900694966316223, train_loss: 0.6930822730064392
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.43486282229423523, train_loss: 0.3514038920402527
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.36772868037223816, train_loss: 0.24547827243804932
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.34999069571495056, train_loss: 0.1971026211977005
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.3486502766609192, train_loss: 0.1671110987663269
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.5969135165214539, train_loss: 0.6204915046691895
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.35491204261779785, train_loss: 0.35057786107063293
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.2851282060146332, train_loss: 0.26419392228126526
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.26100000739097595, train_loss: 0.2123592048883438
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.2520205080509186, train_loss: 0.1752176582813263
[po_estimator_0_impute_pos] Epoch: 0, current validation loss: 0.7165940999984741, train_loss: 0.7234494090080261
[po_estimator_0_impute_pos] Epoch: 50, current validation loss: 0.4088928997516632, train_loss: 0.3474113941192627
[po_estimator_0_impute_pos] Epoch: 100, current validation loss: 0.3268124759197235, train_loss: 0.23974105715751648
[po_estimator_0_impute_pos] Epoch: 150, current validation loss: 0.30257999897003174, train_loss: 0.19227176904678345
[po_estimator_0_impute_pos] Epoch: 200, current validation loss: 0.2952042520046234, train_loss: 0.150943323969841
[po_estimator_1_impute_pos] Epoch: 0, current validation loss: 0.7621601819992065, train_loss: 0.8008379936218262
[po_estimator_1_impute_pos] Epoch: 50, current validation loss: 0.4681061804294586, train_loss: 0.40297436714172363
[po_estimator_1_impute_pos] Epoch: 100, current validation loss: 0.3876952528953552, train_loss: 0.2685011327266693
[po_estimator_1_impute_pos] Epoch: 150, current validation loss: 0.37232619524002075, train_loss: 0.20736241340637207
[po_estimator_1_impute_pos] Epoch: 200, current validation loss: 0.3722713887691498, train_loss: 0.18762916326522827
[te_estimator_0_xnet] Epoch: 0, current validation loss: 0.543300986289978, train_loss: 0.56984943151474
[te_estimator_0_xnet] Epoch: 50, current validation loss: 0.14955735206604004, train_loss: 0.07447506487369537
[te_estimator_0_xnet] Epoch: 100, current validation loss: 0.14289677143096924, train_loss: 0.05817181244492531
[te_estimator_0_xnet] Epoch: 150, current validation loss: 0.14255303144454956, train_loss: 0.05302811414003372
[te_estimator_0_xnet] Epoch: 200, current validation loss: 0.14209823310375214, train_loss: 0.050699569284915924
[te_estimator_1_xnet] Epoch: 0, current validation loss: 0.42682501673698425, train_loss: 0.47241950035095215
[te_estimator_1_xnet] Epoch: 50, current validation loss: 0.15183228254318237, train_loss: 0.0796872079372406
[te_estimator_1_xnet] Epoch: 100, current validation loss: 0.14750535786151886, train_loss: 0.05759574472904205
[te_estimator_1_xnet] Epoch: 150, current validation loss: 0.14718292653560638, train_loss: 0.054208073765039444
[te_estimator_1_xnet] Epoch: 200, current validation loss: 0.14727924764156342, train_loss: 0.05209678038954735
Explaining dataset with: XLearner
Shapley Value Sampling attribution:   0%|          | 0/26001 [00:00<?, ?it/s]Shapley Value Sampling attribution:   1%|▏         | 373/26001 [00:00<00:34, 745.26it/s]Shapley Value Sampling attribution:   3%|▎         | 749/26001 [00:01<00:33, 748.06it/s]Shapley Value Sampling attribution:   4%|▍         | 1124/26001 [00:01<00:33, 748.38it/s]Shapley Value Sampling attribution:   6%|▌         | 1501/26001 [00:02<00:32, 749.88it/s]Shapley Value Sampling attribution:   7%|▋         | 1877/26001 [00:02<00:32, 750.39it/s]Shapley Value Sampling attribution:   9%|▊         | 2255/26001 [00:03<00:31, 752.10it/s]Shapley Value Sampling attribution:  10%|█         | 2635/26001 [00:03<00:30, 754.28it/s]Shapley Value Sampling attribution:  12%|█▏        | 3013/26001 [00:04<00:30, 753.57it/s]Shapley Value Sampling attribution:  13%|█▎        | 3390/26001 [00:04<00:30, 751.52it/s]Shapley Value Sampling attribution:  14%|█▍        | 3766/26001 [00:05<00:29, 751.17it/s]Shapley Value Sampling attribution:  16%|█▌        | 4142/26001 [00:05<00:29, 742.70it/s]Shapley Value Sampling attribution:  17%|█▋        | 4522/26001 [00:06<00:28, 747.88it/s]Shapley Value Sampling attribution:  19%|█▉        | 4900/26001 [00:06<00:28, 749.71it/s]
