{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a564a210-0143-46d2-b58a-9d635659dfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/mingyulu/miniconda3/envs/torch_gpu/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('CATENets/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import catenets.models.torch.pseudo_outcome_nets as cate_models_masks\n",
    "\n",
    "\n",
    "def normalize_data(X_train):\n",
    "    \n",
    "    X_normalized_train = (X_train - np.min(X_train, axis=0)) / (np.max(X_train, axis=0) - np.min(X_train, axis=0))\n",
    "\n",
    "    return X_normalized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b303b39-fc42-4284-a5ca-355dcaa24bca",
   "metadata": {},
   "source": [
    "## Responder cohort analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8c731f6-d7c0-47d9-84a8-59370707eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31804/4139024282.py:4: DtypeWarning: Columns (9,16,45,57,58,59,60,61,62,63,64,71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_year = pd.read_csv(\"data/all_year.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "fluid_cohort = pd.read_pickle(\"data/trauma_responder.pkl\")\n",
    "\n",
    "\n",
    "all_year = pd.read_csv(\"data/all_year.csv\", index_col=0)\n",
    "\n",
    "fluid_cohort = pd.merge(fluid_cohort,all_year[['registryid','iss']],on='registryid', how='left')\n",
    "fluid_cohort[\"iss\"] = pd.to_numeric(fluid_cohort[\"iss\"], errors='coerce')\n",
    "\n",
    "#\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='proc')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='ethnicity')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='residencestate')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='toxicologyresults')))]\n",
    "\n",
    "\n",
    "x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "                                                            \"COV\",\n",
    "                                                            \"TT\",\n",
    "                                                            \"scenegcsmotor\",\n",
    "                                                            \"scenegcseye\",\n",
    "                                                            \"scenegcsverbal\",\n",
    "                                                            \"edgcsmotor\",\n",
    "                                                            \"edgcseye\",\n",
    "                                                            \"edgcsverbal\",\n",
    "                                                            \"outcome\",\n",
    "                                                            \"sex_F\",\n",
    "                                                            \"traumatype_P\",\n",
    "                                                            \"traumatype_other\"\n",
    "                                                            ])]\n",
    "\n",
    "# x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "#                                                             \"COV\",\n",
    "#                                                             \"TT\", \n",
    "#                                                             \"scenegcsmotor\",\n",
    "#                                                             \"scenegcseye\",\n",
    "#                                                             \"scenegcsverbal\",\n",
    "#                                                             \"edgcsmotor\",\n",
    "#                                                             \"edgcseye\",\n",
    "#                                                             \"edgcsverbal\",\n",
    "#                                                             \"outcome\"])]\n",
    "\n",
    "### normalize x_train \n",
    "#x = x_train.values \n",
    "\n",
    "n, feature_size = x.shape\n",
    "names = x.drop([\"treated\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"treated\")\n",
    "iss_index = x.columns.get_loc(\"iss\")\n",
    "sex_index = x.columns.get_loc(\"sex_M\")\n",
    "\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index and i != iss_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "## impute missing value\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             fluid_cohort[\"outcome\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=fluid_cohort[\"treated\"]\n",
    "                                    )\n",
    "\n",
    "w_train = X_train[:, treatment_index]\n",
    "w_test =  X_test[:, treatment_index]\n",
    "\n",
    "\n",
    "iss_train = X_train[:, iss_index]\n",
    "iss_test =  X_test[:, iss_index]\n",
    "\n",
    "X_train = X_train[:,var_index]\n",
    "X_test = X_test[:, var_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffa0d321-dfba-410d-82e4-2fa97fe0b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014403417111102866 0.01822509105776346\n",
      "0.019069704216733378 0.03517305039331138\n",
      "original 0.003058094507370424\n",
      "shap 0.7145713788906277\n",
      "shap - ate: 0.012433164428836112\n",
      "shap - iss  29.845238095238095 29.529411764705884\n",
      "shap- 0 0.547209181011998\n",
      "shap-0 - ate 0.0025370662854015042\n",
      "shap-0 - iss  30.134831460674157 29.0952380952381\n",
      "ig 0.5304294905233872\n",
      "ig - ate 0.0045667647204959425\n",
      "ig - iss  29.073170731707318 30.442857142857147\n",
      "clnical 0.5532950791166754\n",
      "clinical - ate 0.0027846100569576303\n",
      "clinical - iss  30.346666666666668 29.07792207792208\n",
      "full feature 0.6969222743870631\n",
      "full feature - ate 0.011469007882735005\n",
      "full - iss  28.721518987341774 30.76712328767123\n",
      "random feature 0.5772909059294036\n",
      "random feature - ate 0.00511608553782832\n",
      "random - iss  30.576576576576578 27.341463414634145\n"
     ]
    }
   ],
   "source": [
    "results_train = pickle.load(open(\"results/responder/result_train_responder_xlearner.pkl\", \"rb\"))\n",
    "results_test = pickle.load(open(\"results/responder/result_test_responder_xlearner.pkl\", \"rb\"))\n",
    "\n",
    "results_train = results_train.reshape(5, -1)\n",
    "results_test = results_test.reshape(5, -1)\n",
    "\n",
    "print(np.mean(results_train), np.std(results_train)/np.sqrt(results_train.shape[1]))\n",
    "print(np.mean(results_test), np.std(results_test)/np.sqrt(results_test.shape[1]))\n",
    "\n",
    "estimated_ate_train = np.mean(results_train, axis=0)\n",
    "estimated_ate_test = np.mean(results_test, axis=0)\n",
    "\n",
    "threshold = np.mean(estimated_ate_train)\n",
    "\n",
    "gender = x.columns.get_loc(\"sex_M\")\n",
    "cause_MV = x.columns.get_loc(\"causecode_MV\")\n",
    "cause_GUN = x.columns.get_loc(\"causecode_GUN\")\n",
    "scenegcs = x.columns.get_loc(\"scenegcs\")\n",
    "trauma = x.columns.get_loc(\"traumatype_B\")\n",
    "scenefirstbloodpressure = x.columns.get_loc(\"scenefirstbloodpressure\")\n",
    "\n",
    "\n",
    "lac  = x.columns.get_loc(\"LAC\")\n",
    "inr  = x.columns.get_loc(\"INR\")\n",
    "hgb  = x.columns.get_loc(\"HGB\")\n",
    "ph = x.columns.get_loc(\"PH\")\n",
    "fio2 = x.columns.get_loc(\"FIO2\")\n",
    "na = x.columns.get_loc(\"NA\")\n",
    "temp = x.columns.get_loc(\"temps2\")\n",
    "bd = x.columns.get_loc(\"BD\")\n",
    "pulse = x.columns.get_loc(\"edfirstpulse\")\n",
    "\n",
    "\n",
    "\n",
    "y_true_train = (estimated_ate_train > threshold)\n",
    "y_true_test = (estimated_ate_test > threshold)\n",
    "\n",
    "top_2_train = X_train[:, [trauma ,cause_MV, scenegcs, cause_GUN ]]\n",
    "top_2_test = X_test[:, [trauma ,cause_MV, scenegcs, cause_GUN]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"original\", np.sum(estimated_ate_test[w_test==1])/n)\n",
    "\n",
    "print(\"shap\",auroc)\n",
    "print(\"shap - ate:\", ate)\n",
    "print(\"shap - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [temp, ph, bd, hgb, pulse ]]\n",
    "top_2_test = X_test[:, [temp, ph, bd, hgb, pulse ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"shap- 0\",auroc)\n",
    "print(\"shap-0 - ate\", ate)\n",
    "print(\"shap-0 - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [ph, na, temp, gender, fio2 ]]\n",
    "top_2_test = X_test[:, [ph, na, temp, gender, fio2 ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "print(\"ig\",auroc)\n",
    "print(\"ig - ate\", ate)\n",
    "print(\"ig - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [lac, inr, hgb,scenefirstbloodpressure ]]\n",
    "top_2_test = X_test[:, [lac, inr,hgb, scenefirstbloodpressure ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "print(\"clnical\", auroc)\n",
    "print(\"clinical - ate\", ate)\n",
    "print(\"clinical - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(X_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"full feature\", auroc)\n",
    "print(\"full feature - ate\", ate)\n",
    "print(\"full - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "random_feature = np.random.randint(X_train.shape[1], size=(4))\n",
    "\n",
    "top_2_train = X_train[:, random_feature]\n",
    "top_2_test = X_test[:, random_feature]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"random feature\", auroc)\n",
    "print(\"random feature - ate\", ate)\n",
    "print(\"random - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d310673-83d3-4ec2-a5c7-682ee9462cc9",
   "metadata": {},
   "source": [
    "## Transfusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c9b4841-7234-4ce3-957f-82991b765a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31804/2458007031.py:12: DtypeWarning: Columns (9,16,45,57,58,59,60,61,62,63,64,71,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_year = pd.read_csv(\"data/all_year.csv\", index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 75.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "fluid_cohort = pd.read_pickle(\"data/low_bp_survival.pkl\")\n",
    "\n",
    "all_year = pd.read_csv(\"data/all_year.csv\", index_col=0)\n",
    "\n",
    "fluid_cohort = pd.merge(fluid_cohort,all_year[['registryid','iss']],on='registryid', how='left')\n",
    "fluid_cohort[\"iss\"] = pd.to_numeric(fluid_cohort[\"iss\"], errors='coerce')\n",
    "\n",
    "print(np.min(fluid_cohort[\"iss\"]), np.max(fluid_cohort[\"iss\"]))\n",
    "#\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='proc')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='ethnicity')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='residencestate')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='toxicologyresults')))]\n",
    "\n",
    "\n",
    "x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "                                                    \"COV\",\n",
    "                                                    \"TT\",\n",
    "                                                    \"scenegcsmotor\",\n",
    "                                                    \"scenegcseye\",\n",
    "                                                    \"scenegcsverbal\",\n",
    "                                                    \"edgcsmotor\",\n",
    "                                                    \"edgcseye\",\n",
    "                                                    \"edgcsverbal\",\n",
    "                                                    \"outcome\",\n",
    "                                                    \"sex_F\",\n",
    "                                                    \"traumatype_P\",\n",
    "                                                    \"traumatype_other\",\n",
    "                                                ])\n",
    "                    ]\n",
    "\n",
    "n, feature_size = x.shape\n",
    "names = x.drop([\"treated\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"treated\")\n",
    "iss_index = x.columns.get_loc(\"iss\")\n",
    "sex_index = x.columns.get_loc(\"sex_M\")\n",
    "\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index and i != iss_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "## impute missing value\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             fluid_cohort[\"outcome\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=fluid_cohort[\"treated\"]\n",
    "                                    )\n",
    "\n",
    "w_train = X_train[:, treatment_index]\n",
    "w_test =  X_test[:, treatment_index]\n",
    "\n",
    "iss_train = X_train[:, iss_index]\n",
    "iss_test =  X_test[:, iss_index]\n",
    "\n",
    "X_train = X_train[:,var_index]\n",
    "X_test = X_test[:, var_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35378c9-cefd-4d65-8b8e-83b465a69dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 201)\n",
      "-0.023062477658597282 0.00899912391591147\n",
      "-0.022944787911959547 0.017713969099360866\n",
      "(201,)\n",
      "original -0.00023330417962603807\n",
      "shap 0.6174985145573382\n",
      "shap - ate 0.001437606120786344\n",
      "shap - iss  25.78494623655914 32.96296296296296\n",
      "shap- 0 0.5372846108140226\n",
      "shap-0 - ate -0.0007112733564298764\n",
      "shap - 0 iss  27.15841584158416 32.150000000000006\n",
      "ig 0.5671420083184788\n",
      "ig - ate -0.0009134202669615827\n",
      "ig - iss  26.287128712871283 33.03000000000001\n",
      "clnical 0.5775401069518717\n",
      "clinical - ate 0.0008943701730632923\n",
      "clinical - iss  27.126315789473683 31.896226415094343\n",
      "full feature 0.6959298871063577\n",
      "full feature - ate 0.004188320494861717\n",
      "random feature 0.5111408199643493\n",
      "random feature - ate -0.002900782363318589\n",
      "random - iss  30.203389830508474 28.843373493975907\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "results_train = pickle.load(open(\"results/massive_trans/result_train_xlearner.pkl\", \"rb\"))\n",
    "results_test = pickle.load(open(\"results/massive_trans/result_test_xlearner.pkl\", \"rb\"))\n",
    "\n",
    "print(results_test.shape)\n",
    "results_train = results_train.reshape(5, -1)\n",
    "results_test = results_test.reshape(5, -1)\n",
    "\n",
    "print(np.mean(results_train), np.std(results_train)/np.sqrt(results_train.shape[1]))\n",
    "print(np.mean(results_test), np.std(results_test)/np.sqrt(results_test.shape[1]))\n",
    "\n",
    "estimated_ate_train = np.mean(results_train, axis=0)\n",
    "estimated_ate_test = np.mean(results_test, axis=0)\n",
    "\n",
    "print(estimated_ate_test.shape)\n",
    "threshold = np.mean(estimated_ate_train)\n",
    "\n",
    "trauma = x.columns.get_loc(\"traumatype_B\")\n",
    "gender = x.columns.get_loc(\"sex_M\")\n",
    "temp = x.columns.get_loc(\"temps2\")\n",
    "fio2 = x.columns.get_loc(\"FIO2\")\n",
    "ph = x.columns.get_loc(\"PH\")\n",
    "\n",
    "cause_cut = x.columns.get_loc(\"causecode_CUT\")\n",
    "cause_mv = x.columns.get_loc(\"causecode_MV\")\n",
    "edgcs = x.columns.get_loc(\"edgcs\")\n",
    "hgb  = x.columns.get_loc(\"HGB\")\n",
    "na = x.columns.get_loc(\"NA\")\n",
    "\n",
    "scenefirstbloodpressure = x.columns.get_loc(\"scenefirstbloodpressure\")\n",
    "\n",
    "\n",
    "lac  = x.columns.get_loc(\"LAC\")\n",
    "inr  = x.columns.get_loc(\"INR\")\n",
    "\n",
    "bd = x.columns.get_loc(\"BD\")\n",
    "pulse = x.columns.get_loc(\"edfirstpulse\")\n",
    "\n",
    "\n",
    "y_true_train = (estimated_ate_train > threshold)\n",
    "y_true_test = (estimated_ate_test > threshold)\n",
    "\n",
    "top_5_train = X_train[:, [gender,trauma ,cause_cut, edgcs, cause_mv ]]\n",
    "top_5_test = X_test[:, [gender, trauma ,cause_cut, edgcs, cause_mv]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_5_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_5_test)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"original\", np.sum(estimated_ate_test[w_test==1])/n)\n",
    "\n",
    "print(\"shap\",auroc)\n",
    "print(\"shap - ate\", ate)\n",
    "print(\"shap - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [temp, ph, bd, hgb, trauma ]]\n",
    "top_2_test = X_test[:, [temp, ph, bd, hgb, trauma ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "print(\"shap- 0\",auroc)\n",
    "print(\"shap-0 - ate\", ate)\n",
    "print(\"shap - 0 iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [ph, na, temp, gender, trauma ]]\n",
    "top_2_test = X_test[:, [ph, na, temp, gender, trauma ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "print(\"ig\",auroc)\n",
    "print(\"ig - ate\", ate)\n",
    "print(\"ig - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "top_2_train = X_train[:, [lac, inr, hgb, trauma,scenefirstbloodpressure ]]\n",
    "top_2_test = X_test[:, [lac, inr,hgb,trauma, scenefirstbloodpressure ]]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "print(\"clnical\", auroc)\n",
    "print(\"clinical - ate\", ate)\n",
    "print(\"clinical - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(X_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"full feature\", auroc)\n",
    "print(\"full feature - ate\", ate)\n",
    "\n",
    "random_feature = np.random.randint(X_train.shape[1], size=(4))\n",
    "\n",
    "top_2_train = X_train[:, random_feature]\n",
    "top_2_test = X_test[:, random_feature]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_model.fit(top_2_train, y_true_train)\n",
    "\n",
    "y_pred = xgb_model.predict(top_2_test)\n",
    "ate = np.sum(estimated_ate_test[y_pred == 1])/n\n",
    "\n",
    "auroc = metrics.roc_auc_score(y_true_test, y_pred)\n",
    "\n",
    "print(\"random feature\", auroc)\n",
    "print(\"random feature - ate\", ate)\n",
    "print(\"random - iss \", np.mean(iss_test[y_pred==1])*74+1, np.mean(iss_test[y_pred==0])*74+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5d06d9b-14e5-43ba-a3c4-634511aba502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2., 18.,  8.,  6.,  0.,  2.,  3.,  0.,  0.,  2.]),\n",
       " array([ 9. , 15.6, 22.2, 28.8, 35.4, 42. , 48.6, 55.2, 61.8, 68.4, 75. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.hist(iss_test[y_pred==1]*74+1)\n",
    "plt.hist(iss_test[y_pred==0]*74+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a7fc6-96c2-4bf9-8d86-e548f10f965b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
