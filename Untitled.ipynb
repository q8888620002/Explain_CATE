{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143147bb-5421-40a2-95af-f369a8afd8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "from shapreg import shapley, games, removal, shapley_sampling\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "from econml.metalearners import TLearner, SLearner, XLearner, DomainAdaptationLearner\n",
    "\n",
    "from captum.attr import (\n",
    "    DeepLift,\n",
    "    FeatureAblation,\n",
    "    FeaturePermutation,\n",
    "    IntegratedGradients,\n",
    "    KernelShap,\n",
    "    Lime,\n",
    "    ShapleyValueSampling,\n",
    "    GradientShap,\n",
    ")\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('CATENets/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import catenets.models.torch.pseudo_outcome_nets as cate_models_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890d45d6-f64e-4710-843c-9a1b54a7a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_values(feature_values):\n",
    "\n",
    "    \n",
    "    ind = np.argpartition(np.abs(feature_values).mean(0).round(2), -15)[-15:]\n",
    "    \n",
    "    feature_names = [\n",
    "        a + \": \" + str(b) for a,b in zip(names[ind], np.abs(feature_values[:, ind]).mean(0).round(2))\n",
    "    ]\n",
    "\n",
    "    shap.summary_plot(\n",
    "        feature_values[:, ind],\n",
    "        X_test[:, ind], \n",
    "        feature_names=feature_names,\n",
    "        title = \"IG\"\n",
    "     )\n",
    "    \n",
    "def plot_feature_values_ind(feature_values, indices):\n",
    "    \n",
    "    selected_sample = feature_values[indices]\n",
    "    filtered_test = X_test[indices]\n",
    "    \n",
    "    ind = np.argpartition(np.abs(selected_sample).mean(0).round(2), -15)[-15:]\n",
    "    \n",
    "    feature_names = [\n",
    "        a + \": \" + str(b) for a,b in zip(names[ind], np.abs(selected_sample[:, ind]).mean(0).round(2))\n",
    "    ]\n",
    "\n",
    "    shap.summary_plot(\n",
    "        selected_sample[:, ind],\n",
    "        filtered_test[:, ind], \n",
    "        feature_names=feature_names,\n",
    "        title = \"IG\"\n",
    "     )\n",
    "\n",
    "def normalize_data(X_train):\n",
    "    \n",
    "    X_normalized_train = (X_train - np.min(X_train, axis=0)) / (np.max(X_train, axis=0) - np.min(X_train, axis=0))\n",
    "\n",
    "    return X_normalized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be96665-be73-45b1-813e-b72b49e8d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'T_learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m est\u001b[38;5;241m.\u001b[39mfit(y_train, w_train, X\u001b[38;5;241m=\u001b[39mX_train)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Estimate treatment effects on test data\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m T_te \u001b[38;5;241m=\u001b[39m \u001b[43mT_learner\u001b[49m\u001b[38;5;241m.\u001b[39meffect(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T_learner' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "fluid_cohort = pd.read_pickle(\"data/trauma_responder.pkl\")\n",
    "\n",
    "#\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='proc')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='ethnicity')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='residencestate')))]\n",
    "fluid_cohort = fluid_cohort[fluid_cohort.columns.drop(list(fluid_cohort.filter(regex='toxicologyresults')))]\n",
    "\n",
    "\n",
    "x = fluid_cohort.loc[:, ~fluid_cohort.columns.isin([\"registryid\",\n",
    "                                                            \"COV\",\n",
    "                                                            \"TT\",\n",
    "                                                            \"scenegcsmotor\",\n",
    "                                                            \"scenegcseye\",\n",
    "                                                            \"scenegcsverbal\",\n",
    "                                                            \"edgcsmotor\",\n",
    "                                                            \"edgcseye\",\n",
    "                                                            \"edgcsverbal\",\n",
    "                                                            \"outcome\",\n",
    "                                                            \"sex_F\",\n",
    "                                                            \"traumatype_P\",\n",
    "                                                            \"traumatype_other\"\n",
    "                                                            ])]\n",
    "\n",
    "### normalize x_train \n",
    "#x = x_train.values \n",
    "\n",
    "n, feature_size = x.shape\n",
    "names = x.drop([\"treated\"], axis=1).columns\n",
    "treatment_index = x.columns.get_loc(\"treated\")\n",
    "sex_index = x.columns.get_loc(\"sex_M\")\n",
    "\n",
    "var_index = [i for i in range(feature_size) if i != treatment_index]\n",
    "\n",
    "x_norm = normalize_data(x)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(x_norm)\n",
    "x_train_scaled = imp.transform(x_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "                                             x_train_scaled,  \n",
    "                                             fluid_cohort[\"outcome\"], \n",
    "                                             test_size=0.2, \n",
    "                                             random_state=10,\n",
    "                                             stratify=fluid_cohort[\"outcome\"]\n",
    "                                    )\n",
    "\n",
    "w_train = X_train[:, treatment_index]\n",
    "w_test =  X_test[:, treatment_index]\n",
    "X_train = X_train[:,var_index]\n",
    "X_test = X_test[:, var_index]\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "learner_explanations = {}\n",
    "\n",
    "#### Getting top 10 features from multiple runs. \n",
    "\n",
    "trials = 50\n",
    "results_train = np.zeros((trials, len(X_train)))\n",
    "results_test = np.zeros((trials, len(X_test)))\n",
    "\n",
    "\n",
    "# for i in range(trials):\n",
    "\n",
    "\n",
    "models = GradientBoostingRegressor(n_estimators=100, max_depth=6, min_samples_leaf=int(n/100))\n",
    "est = TLearner(models=models)\n",
    "\n",
    "# Train T_learner\n",
    "est.fit(y_train, w_train, X=X_train)\n",
    "\n",
    "T_te = est.effect(X_test)\n",
    "\n",
    "    \n",
    "#     results_train[i] = model(X_train).detach().cpu().numpy().flatten()\n",
    "#     results_test[i] = model(X_test).detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac4ff7b-bbc3-428c-a279-717c3c89bb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't call 'const_marginal_ate_inference' because 'inference' is None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m intrp \u001b[38;5;241m=\u001b[39m SingleTreeCateInterpreter(include_model_uncertainty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We interpret the CATE model's behavior based on the features used for heterogeneity\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mintrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpret\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the tree\u001b[39;00m\n\u001b[1;32m      5\u001b[0m intrp\u001b[38;5;241m.\u001b[39mplot(feature_names\u001b[38;5;241m=\u001b[39mnames, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.8/site-packages/econml/cate_interpreter/_interpreters.py:201\u001b[0m, in \u001b[0;36mSingleTreeCateInterpreter.interpret\u001b[0;34m(self, cate_estimator, X)\u001b[0m\n\u001b[1;32m    198\u001b[0m Xsub \u001b[38;5;241m=\u001b[39m X[mask]\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_uncertainty \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         ((\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty_only_on_leaves) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_model_\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mchildren_left[node_id] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m))):\n\u001b[0;32m--> 201\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mcate_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconst_marginal_ate_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXsub\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     node_dict[node_id] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: res\u001b[38;5;241m.\u001b[39mmean_point,\n\u001b[1;32m    203\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m: res\u001b[38;5;241m.\u001b[39mstd_point,\n\u001b[1;32m    204\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mci\u001b[39m\u001b[38;5;124m'\u001b[39m: res\u001b[38;5;241m.\u001b[39mconf_int_mean(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncertainty_level)}\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_gpu/lib/python3.8/site-packages/econml/_cate_estimator.py:330\u001b[0m, in \u001b[0;36mBaseCateEstimator._defer_to_inference.<locals>.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is None\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't call 'const_marginal_ate_inference' because 'inference' is None"
     ]
    }
   ],
   "source": [
    "intrp = SingleTreeCateInterpreter(include_model_uncertainty=True, max_depth=2, min_samples_leaf=10)\n",
    "# We interpret the CATE model's behavior based on the features used for heterogeneity\n",
    "intrp.interpret(est, X_test)\n",
    "# Plot the tree\n",
    "intrp.plot(feature_names=names, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9268dd-a437-4032-b466-f115d6ea9b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
